{"url": "https://github.com/030jmk/CIObund", "owner": "030jmk", "repository_name": "CIObund", "date_all_variable_collection": "2023-09-10", "description": "AR Bund", "size": 72, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "030jmk", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# CIObund\n\n## Architekturrichtlinie f\u00fcr die IT des Bundes:\n\nhttps://www.cio.bund.de/Web/DE/Architekturen-und-Standards/Architekturrichtlinie-IT-Bund/architekturrichtlinie_it_bund_node.html\n\nhttps://www.cio.bund.de/SharedDocs/Publikationen/DE/Architekturen-und-Standards/architekturrichtlinie_it_bund_2020.pdf;jsessionid=DE636047F2E34F969406AC0A25B9401E.1_cid340?__blob=publicationFile"}
{"url": "https://github.com/030jmk/genAI-telephone", "owner": "030jmk", "repository_name": "genAI-telephone", "date_all_variable_collection": "2023-09-10", "description": "A retrofitted rotary dial phone with speech-to-text, a generative pre-trained transformer and text-to-speech", "size": 47, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "030jmk", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 20106}], "readme": "# genAI-telephone\nA retrofitted rotary dial phone with speech-to-text, a generative pre-trained transformer and text-to-speech.\n\n\n## Description\n\nThe telephone is a fun project that utilizes a retrofitted rotary telephone as a tangible, tactile interface for artificial intelligence. Built upon technologies such as OpenAI\u2019s Whisper API, which solves speech-to-text tasks, GPT-3.5, a fined-tuned version of the GPT3 (Generative Pre-Trained Transformer) model, Azure's Text to speech REST API, and a Raspberry Pi Zero W, 3b or 4.\n\n## Motivation\n\nThe motivation behind GenAI-Telephone stemmed from a desire to diverge from traditional, screen-based interfaces that are the most familiar of digital interfaces in our modern lives. By repurposing a nostalgic rotary telephone, my goal is to invoke the past to interact with the technology of the present, allowing users to experience the capabilities of AI magic in a differntly engaging and refreshing manner. It is supposed to be a conversations starter on the topics of user interfaces, user experiences, AI safety, chat bots and their personas, as well as circularity of prototypes and demonstrators. \n\n## Dependencies (hardware and services)\n\n- OpenAI's Whisper API (alternative: ![self hosted whisper](https://github.com/openai/whisper)) and GPT-3.5 (alternative: llama2) for speech recognition and text generation\n- Azure's Text-To-Speech API for clear and natural language output (alternative: ![coqui TTS](https://github.com/coqui-ai/TTS))\n- Raspberry Pi Zero W or 3b and later\n- a rotary telephone\n- a microphone from an old headset\n- 2in1 mic/audio USB adapter\n- TRRS Audio Male to 4-Pin screw terminal\n- soldering iron\n\n## Installation (Hardware)\n\n- disassemble the telephone, making sure that none of the plastics get damaged in the process.\n\n<img src=\"https://user-images.githubusercontent.com/12104518/258658876-311430c0-ae15-4ffb-b96b-73c940ffb540.jpg\" alt=\"disassembled telephone\" width=\"350\">\n\n- take out the inner parts of the telephone. For it, we will need a screwdriver and some wiggling around of the parts.\n\n<img src=\"https://user-images.githubusercontent.com/12104518/258658853-d754b0f4-fbd8-4de3-b709-d1b16471a687.jpg\" alt=\"plastic shell\" width=\"350\">\n\n- It can be advantageous to desolder some of the pins and electronics in order to gain room for the raspberry pi.\n  \n<img src=\"https://user-images.githubusercontent.com/12104518/258658940-dbcd8d0b-19a0-43ef-ba99-4e563478fc55.jpg\" alt=\"desoldered\" width=\"350\">\n\n- prepare some female-to-female GPIO cables\n\n<img src=\"https://user-images.githubusercontent.com/12104518/258658950-9252fbc0-d23b-49ba-9018-1e68db8ae401.jpg\" alt=\"pins\" width=\"350\">\n\n- and solder them to the rotary dial (yellow and green), button (green and brown), spring mechanism of the switch hook (which ever connections act as a button)\n\n<img src=\"https://user-images.githubusercontent.com/12104518/258659070-3c1d15f8-7c62-4d22-82dc-3abafd8450f2.jpg\" alt=\"colors\" width=\"350\">\n\n\n![blink](https://github.com/030jmk/genAI-telephone/assets/12104518/46dc766c-8c7d-4dc1-a9d2-a95cd705320e)\n\n- connect the cables of the handset to the TRRS Audio Male to 4-Pin screw terminal, plug the TRRS pin into the USB adapter and connect the adapter to the USB connection of the pi.\n- find the ground pins for the raspberry pi.\n- the rotary dial should be connected to GPIO pin 2\n- the black button should be connected to GPIO pin 3\n- the switch hook spring/button should be GPIO pin 26\n\n## Dependencies (OS, Python)\nOnce Raspian and the usual updates are installed using \n\n    sudo apt update && sudo apt -y upgrade\nthe following dependencies should be installed:\n\n    sudo apt install -y python3-pip python3-scipy python3-rpi.gpio sox gnuplot libsox-fmt-all ffmpeg libasound-dev libportaudio2 && pip install requests playsound numpy sounddevice Unidecode \n\ntest the mic set up once everything is connected:\n\n    arecord -f cd -c 1 -r 44100 | sox -t raw -r 44100 -e signed -b 16 -c 1 -V - -t raw - | gnuplot -persist -e \"set xlabel 'Time'; set ylabel 'Amplitude'; plot '-' with lines\"\n\n\nWhile waiting for an answer from the phone, elevator music may be used. \"Yesterday (Jazz Elevator)\" by Monument_Music is used for the current code:\n    \n    https://pixabay.com/de/music/bossa-nova-yesterday-jazz-elevator-147660/\n\n\n## Basic Storyline\n|    \t| Sound           \t| Story                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \t| Activity \t|\n|----\t|-----------------\t|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\t|----------\t|\n| 00  \t|                 \t|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \t| PICK UP  \t|\n| 01  \t| dual_tone       \t|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \t|          \t|\n| 02  \t|                 \t| \"Hello and thank you for giving this demo a try. My name is Whisper and i will guide you through this experience. In a moment will ask you to dial a number from the rotary in front of you. Each of the numbers correspond with a preconfigured persona and if you were to ask a different persona the same question, you should be able to hear different answers. I will give you a couple of seconds to make your selection after the audible beep sound. Please only dial one number.\"      \t|          \t|\n| 03  \t| beep            \t|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \t|          \t|\n| 04  \t|                 \t|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \t| USE DIAL \t|\n| 05  \t| beep            \t|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \t|          \t|\n| 06  \t|                 \t| \"It would seem that you have made your decision. You have dialed {}. With the following beep I will relay your message or question according to your selection. I will again give you a couple of seconds to speak your message into the handset. Once you are done speaking, i will wait two seconds and relay your message with the second beep. If for some reason you cant hear that second beep, press the black button to the right of the dial. Get ready for the beep in 3... 2... 1...\" \t|          \t|\n| 07  \t| beep            \t|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \t|          \t|\n| 08  \t|                 \t| \"I will relay our message. Let us wait a few seconds until we get a response. Please hold.\"                                                                                                                                                                                                                                                                                                                                                                                                      \t| SPEAK    \t|\n| 09  \t| elevator_music  \t|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \t|          \t|\n| 10 \t|                 \t| \"It would seem that we have received an answer. Here it is.\"                                                                                                                                                                                                                                                                                                                                                                                                                                     \t|          \t|\n| 11 \t| answer          \t|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \t|          \t|\n| 12 \t|                 \t| \"And that is it. Thank you for trying this short demonstration. If you like to give it another go, put down the handset back onto the switch hook and lift it up again after a few seconds. If you are done, place the handset onto the switch hook and leave the cabin once you are ready. Thank you and have a pleasant day.\"                                                                                                                                                                  \t|          \t|\n| 13 \t| congestion_tone \t|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \t|          \t|\n|    \t|                 \t|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \t| PUT DOWN \t|\n\n\n## In Action\nThe demo was presented at [Berlin Hack & Tell #89](https://berlinhackandtell.rocks/2023-07-25-no89-camping-hacks) 2023-07-25 and can now be tested and seen at the PwC Experience Center in Berlin.\n\n<img src=\"https://user-images.githubusercontent.com/12104518/258660552-dcf21ca2-a04a-49a1-97af-d41b795c0510.png\" alt=\"colors\" width=\"350\"> <img src=\"https://user-images.githubusercontent.com/12104518/258660575-2870c7c1-7ac7-4cc0-963b-05ddde5aabd0.jpg\" alt=\"colors\" width=\"350\">\n\n\n\n\n\n\n\n\n"}
{"url": "https://github.com/030jmk/gntm", "owner": "030jmk", "repository_name": "gntm", "date_all_variable_collection": "2023-09-10", "description": "scraped Instagram follower count for GNTM contestants", "size": 2374, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "030jmk", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 5078}]}
{"url": "https://github.com/030jmk/gntm2019", "owner": "030jmk", "repository_name": "gntm2019", "date_all_variable_collection": "2023-09-10", "description": "gntm 2019", "size": 638343, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "030jmk", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 920}]}
{"url": "https://github.com/030jmk/publicAmenitiesBerlin", "owner": "030jmk", "repository_name": "publicAmenitiesBerlin", "date_all_variable_collection": "2023-09-10", "description": "Telegram Bot to find the closest public amenity for urgent needs", "size": 196, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "030jmk", "contributions": 13}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 726646}, {"language": "Python", "num_chars": 10437}]}
{"url": "https://github.com/030jmk/python_telegram_bots", "owner": "030jmk", "repository_name": "python_telegram_bots", "date_all_variable_collection": "2023-09-10", "description": "cluster of personal telegram bot projects to fix everyday micro annoyances", "size": 8, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Apache License 2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "030jmk", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 5804}], "readme": "# python_telegram_bots\ncluster of personal telegram bot projects to fix everyday micro annoyances\n"}
{"url": "https://github.com/030jmk/ScrapingInstagram", "owner": "030jmk", "repository_name": "ScrapingInstagram", "date_all_variable_collection": "2023-09-10", "description": "Scrape Instagram posts using a specified hashtag and save them to a csv file for later analysis.", "size": 12173, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "030jmk", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 496642}, {"language": "Python", "num_chars": 6677}]}
{"url": "https://github.com/87surendra/clarkson", "owner": "87surendra", "repository_name": "clarkson", "date_all_variable_collection": "2023-09-10", "description": null, "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/87surendra/deep-learning-drone", "owner": "87surendra", "repository_name": "deep-learning-drone", "date_all_variable_collection": "2023-09-10", "description": null, "size": 1976, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "87surendra", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 3386970}, {"language": "Python", "num_chars": 10272}]}
{"url": "https://github.com/87surendra/Python_DS_Lect", "owner": "87surendra", "repository_name": "Python_DS_Lect", "date_all_variable_collection": "2023-09-10", "description": null, "size": 85663, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 35230484}]}
{"url": "https://github.com/87surendra/Random-Forest-Image-Classification-using-Python", "owner": "87surendra", "repository_name": "Random-Forest-Image-Classification-using-Python", "date_all_variable_collection": "2023-09-10", "description": "Random Forest Image Classification using Python", "size": 470, "stargazers_count": 19, "watchers_count": 19, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 17, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 17, "open_issues": 0, "watchers": 19, "default_branch": "master", "contributors": [{"contributor": "87surendra", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 620401}, {"language": "Python", "num_chars": 7020}], "readme": "# Random-Forest-Image-Classification-using-Python\nRandom Forest Image Classification using Python\n\nPlease follow below folder structure.\n\n\n\n<ul>\n  <li>image-classification (folder)</li>\n    <ul>\n      <li>dataset (folder)</li>\n      <ul>\n        <li>train (folder)</li>\n          <ul>\n            <li>Image Cat1 Folder</li>\n              <ul>\n                <li>train_img.jpg</li>\n                <li>train_img.jpg</li>\n                <li>train_img.jpg</li>\n                <li>.......</li>\n              </ul>\n            <li>Image Cat2 Folder</li>\n            <ul>\n                <li>train_img.jpg</li>\n                <li>train_img.jpg</li>\n                <li>train_img.jpg</li>\n                <li>.......</li>\n              </ul>\n          </ul>  \n        <li>test (folder)</li>\n          <ul>\n             <li>test_img.jpg</li>\n             <li>test_img.jpg</li>\n             <li>test_img.jpg</li>\n             <li>.......</li>\n           </ul>\n      </ul> \n     <li>output (folder)</li> \n      <ul>\n          <li>data.h5</li>\n          <li>labels.h5</li>\n       </ul> \n    <li>random_fo_image.py</li>\n    </ul> \n</ul>\n\n\n"}
{"url": "https://github.com/a-moi/disaster-tweets", "owner": "a-moi", "repository_name": "disaster-tweets", "date_all_variable_collection": "2023-09-10", "description": "Notebooks with codes used for the Kaggle competition \"Real or Not? NLP with Disaster Tweets\"", "size": 47, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "a-moi", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 265954}], "readme": "# disaster-tweets\nThis repository contains notebooks with codes used for the Kaggle competition \"Real or Not? NLP with Disaster Tweets\"\n\n*The competition description*\n\nTwitter has become an important communication channel in times of emergency.\nThe ubiquitousness of smartphones enables people to announce an emergency they\u2019re observing in real-time. Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).\nThe **goal** of the present competition is to predict which Tweets are about real disasters and which one\u2019s aren\u2019t. \n\nThe team: Mazunina Zoya, Minnigulova Alina, Poyaganova Maria \n\nPreprocessing: SpaCy. \nWord representation techniques used: tf-idf, word2vec.\nModels used: Logistic Regression, Sequential, CNN.\nTransformer models used: RoBERTa, Albert.\nThe best score achieved: **0.82** on **RoBERTa Large** \n\nThe repository contains 2 notebooks:\n1) basic.ipynb - the implementation of simple word representations, LogReg and NN models.  \n2) transfer.ipynb - the implementation of trasfer-learning techniques. \nThe notebooks include comments in Russian. \n\nThe data can be found on the page of the competition (https://www.kaggle.com/c/nlp-getting-started/data) \n\n"}
{"url": "https://github.com/a-moi/political-argument-mining", "owner": "a-moi", "repository_name": "political-argument-mining", "date_all_variable_collection": "2023-09-10", "description": "Mining arguments in political discourse with BERT and RoBERTa. We also present a new corpus of UNSC speeches annotated wrt their argumentative structure", "size": 8190, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "a-moi", "contributions": 48}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["argument-mining", "claim-detection", "natural-language-processing"], "languages": [{"language": "Jupyter Notebook", "num_chars": 435594}, {"language": "Python", "num_chars": 6167}], "readme": "# Mining Arguments in Political Domain with Transformer Language Models \n\n## Project description \n\nThis repository was developed as part of the Master's individual research project carried out at the University of Potsdam, Germany. Please find our detailed report [here](https://github.com/a-moi/political-argument-mining/blob/main/report.pdf). \n\n**Abstract**\n\n\nThis project is focused on argumentation\nmining framed through the tasks of argument\ndetection (predict whether the utterance\nis an argument or not) and argument\ncomponent identification (predict whether\nthe argumentative utterance is a claim or\na premise). We implement BERT and\nRoBERTa models and approach both tasks\non the sentence-level. The second task,\ncomponent identification, is also modelled\non the argumentative discourse unit level.\nTo train and test our models, we use a\nlarge-scale corpus of the US presidential\ndebates data (Haddadan et al., 2019). Additionally,\nwe study models\u2019 generalizability\nto the data within the same domain.\nFor that, we collect and manually annotate\na novel dataset of diplomatic speeches\npresented in the United Nations Security\nCouncil.\n\n\n## Corpora \n\nFor our experiments, we use two corpora. \n\n1. [USElecDeb](https://github.com/a-moi/political-argument-mining/tree/main/ElecDeb60To16) contains speeches of presidential debates in the US from the years 1960 to 2016. The corpus is annotated according to argumentative structure of speeches and contains such labels as claims and premises. The dataset was introduced in this [paper](https://aclanthology.org/P19-1463/). For the sentence-level experiments, we used only `sentence_db_candidate.csv` file as it provides all the necessary texts along with labels and the original train, test and validation splits. \n\n2. [UC-UNSC](https://github.com/a-moi/political-argument-mining/tree/main/UC-UNSC) As part of the project, we develop a novel corpus of argument annotations. We retrive diplomatic speeches given during gatherings of the UNSC. We select 144 speeches from 2014 to 2018, dedicated to the conflict in Ukraine. We name it UC(Ukraine Conflict)-UNSC. The speeches were annotated analogically to USElecDeb and the labels include claims, premises or none of these. \n\nWe provide 144 pairs of raw data: original .txt files and .xmi files with their respective annotations, retrived from Inception. Additionally, we provide two ready-to-use datasets. The file `sentence_full.csv` contains the following columns: sentences, final labels (claims or premises or none) and detailed labels, i.e., per each sentence, we list all its components along with their length. This length measure was used to give the final label to a sentence, since some sentences contained both a claim and a premise, and we made the decision in favor of the longer component. The file `component_full.csv` includes two columns: the component (original span, not always a sentence) and its label. \n\nTwo python [functions](https://github.com/a-moi/political-argument-mining/blob/main/annotation2df.py) were developed to map .xmi files from Inception and the original .txt files. The outputs are ready-to-use .csv files. \n\n## Reproduction and running on your data \n\nWe use `bert-for-sequence-classification` Python [framework](https://pypi.org/project/bert-for-sequence-classification/) to fine-tune BERT and RoBERTa models. We attach three Python notebooks, each representing a different problem setting: 1) classification of arg vs non-arg the sentence-level; 2) classification of claims and premises on the sentence-level; 3) classification of claims and premises on the ADU-level. \n\nTo reproduce the models, we recommend using Google Colab which enables free GPU unit. \n- Load a notebook into your Colab env, then load and prepare the data.\n- To change RoBERTa to BERT, simply amend the config by selecting a model you want to use. We experimented with `chkla/roberta-argument`, `roberta-base` and `bert-base-uncased`, depending on the task. We also attach `hyperparams.csv` with all the parameters and settings we used at each experiment, to facilitate reproduction. \n"}
{"url": "https://github.com/a-moi/tbbt-character-detection", "owner": "a-moi", "repository_name": "tbbt-character-detection", "date_all_variable_collection": "2023-09-10", "description": null, "size": 622, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "a-moi", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 892921}], "readme": "# tbbt-character-detection"}
{"url": "https://github.com/Abdelwahab86/Ahmed", "owner": "Abdelwahab86", "repository_name": "Ahmed", "date_all_variable_collection": "2023-09-10", "description": null, "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/Abdelwahab86/DEM-Analysis", "owner": "Abdelwahab86", "repository_name": "DEM-Analysis", "date_all_variable_collection": "2023-09-10", "description": "A robot powered training repository :robot:", "size": 3538, "stargazers_count": 0, "watchers_count": 0, "language": "Ruby", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "Abdelwahab86-patch-2", "contributors": [{"contributor": "githubteacher", "contributions": 15}, {"contributor": "hectorsector", "contributions": 8}, {"contributor": "Abdelwahab86", "contributions": 4}, {"contributor": "brianamarie", "contributions": 2}, {"contributor": "JasonEtco", "contributions": 2}, {"contributor": "dependabot[bot]", "contributions": 2}, {"contributor": "snyk-bot", "contributions": 2}, {"contributor": "carolynshin", "contributions": 1}, {"contributor": "crichID", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Ruby", "num_chars": 7522}, {"language": "HTML", "num_chars": 3039}, {"language": "Shell", "num_chars": 2193}], "readme": "# Your GitHub Learning Lab Repository for Introducing GitHub\n\nWelcome to **your** repository for your GitHub Learning Lab course. This repository will be used during the different activities that I will be guiding you through. See a word you don't understand? We've included an emoji \ud83d\udcd6 next to some key terms. Click on it to see its definition.\n\nOh! I haven't introduced myself...\n\nI'm the GitHub Learning Lab bot and I'm here to help guide you in your journey to learn and master the various topics covered in this course. I will be using Issue and Pull Request comments to communicate with you. In fact, I already added an issue for you to check out.\n\n![issue tab](https://lab.github.com/public/images/issue_tab.png)\n\nI'll meet you over there, can't wait to get started!\n\nThis course is using the :sparkles: open source project [reveal.js](https://github.com/hakimel/reveal.js/). In some cases we\u2019ve made changes to the history so it would behave during class, so head to the original project repo to learn more about the cool people behind this project.\n"}
{"url": "https://github.com/Abdelwahab86/Water-polygons-photogrammetry", "owner": "Abdelwahab86", "repository_name": "Water-polygons-photogrammetry", "date_all_variable_collection": "2023-09-10", "description": "My master thesis at Potsdam University", "size": 1383, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "Abdelwahab86", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 1890254}], "readme": "# Water-polygons-photogrammetry\n## Supervised By : Prof. Guido Grosse and Dr. Ingmar Nitze\n## Author        : Ahmed Abdelwahab\nMy master thesis at Potsdam University\n"}
{"url": "https://github.com/abrarhasinkml/Bangla2EnglishNumberConversion", "owner": "abrarhasinkml", "repository_name": "Bangla2EnglishNumberConversion", "date_all_variable_collection": "2023-09-10", "description": "A simple function that converts Bengali numbers to their English coefficients", "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "abrarhasinkml", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["bangla", "bangla-number", "bengali", "bengali-number", "english", "number-converter", "python", "python3"], "languages": [{"language": "Python", "num_chars": 1207}], "readme": "A simple python function that takes in a list of Bengali integer numbers and returns a list containing the English counterparts of the input list.\nSingle integers can also be passed into the function, but will need to be joined using the join() function."}
{"url": "https://github.com/abrarhasinkml/coinMarketCapAPI", "owner": "abrarhasinkml", "repository_name": "coinMarketCapAPI", "date_all_variable_collection": "2023-09-10", "description": "A crypto currency tracker app to monitor the currencies of interest. This is a v1 version.", "size": 4, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "abrarhasinkml", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 1288}], "readme": "# coinMarketCapAPI\n\nA crypto currency tracker app to monitor the currencies of interest. This is a v1 version.\nCurrently the quotes latest API is used to get the information required from Coin Market Cap.\n"}
{"url": "https://github.com/abrarhasinkml/Command-Based-Text-Editor", "owner": "abrarhasinkml", "repository_name": "Command-Based-Text-Editor", "date_all_variable_collection": "2023-09-10", "description": "A command based text editor done in C++ as a project for Object Oriented Programming Course", "size": 279, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "abrarhasinkml", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 7864}], "readme": "# Command-Based-Text-Editor\n\nThis command based text editor was done as a project for the Object Oriented Programming Course. The commands are descripted below.\n\n\nCOMMAND MODE\n\nesc= switches to Insert Mode\ns= saves file to data.txt\nc= counts the number of characters input\nn= cursor jumps to new line\nu= cursor moves up\nd= cursor moves down\nl= cursor moves left\nr= cursor moves right\no= obtains text from data.txt file\nb= cursor moves to the bottom line of Insert Mode\nm= text moves to the bottom of Insert Mode\ng= cursor moves back up top to Insert Mode\nx= asks the user for a line number and jumps to it\ny= asks the user for a column number and jumps to it\nw= clears the screen\nq= exits the application\n\nINSERT MODE\n\nesc= switches to Command Mode\n/ = option to append new text with previously entered text.\nbackspace = cursor moves left under desired character to enable replace function\ntab= press twice to delete one by one character to the left\n"}
{"url": "https://github.com/abrarhasinkml/COVID-19BD", "owner": "abrarhasinkml", "repository_name": "COVID-19BD", "date_all_variable_collection": "2023-09-10", "description": "A simple visualization script using Plotly to convert the numerical data from IEDCR's website into interactive plots. The data has been scraped from IEDCR's COVID dashboard and some additional data has been added. If you are running the plotting script from a jupyter notebook, the .show() function will suffice. For offline view in IDE's like Spyder, the plot() function has also been written which generates a temporary html file consisting of the plot. ", "size": 16032, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "abrarhasinkml", "contributions": 46}, {"contributor": "tusher16", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 312261}, {"language": "CSS", "num_chars": 299968}, {"language": "PHP", "num_chars": 57275}, {"language": "TSQL", "num_chars": 25766}, {"language": "Python", "num_chars": 23373}, {"language": "HTML", "num_chars": 1414}, {"language": "Hack", "num_chars": 781}], "readme": "# COVID-19BD\nA simple visualization script using Plotly to convert the numerical data from IEDCR's website into interactive plots. The data has been scraped from IEDCR's COVID dashboard and some additional data has been added. If you are running the plotting script from a jupyter notebook, the .show() function will suffice. For offline view in IDE's like Spyder, the plot() function has also been written which generates a temporary html file consisting of the plot. \n"}
{"url": "https://github.com/abrarhasinkml/cse480moviesonthegobd", "owner": "abrarhasinkml", "repository_name": "cse480moviesonthegobd", "date_all_variable_collection": "2023-09-10", "description": "My final project for CSE-480 (Web Technology). Movies on the go Bangladesh is basically an informative site which has all the information regarding movie schedules in the most popular halls in Dhaka. ", "size": 2633, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "abrarhasinkml", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 62022}, {"language": "CSS", "num_chars": 43474}, {"language": "HTML", "num_chars": 29311}]}
{"url": "https://github.com/abrarhasinkml/Image-recognition-using-softmax", "owner": "abrarhasinkml", "repository_name": "Image-recognition-using-softmax", "date_all_variable_collection": "2023-09-10", "description": "A simple softmax script that learns from the CIFAR-10 dataset. Accuracy is about 24%.", "size": 10, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "abrarhasinkml", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 8810}], "readme": "# Image-recognition-using-softmax\nA simple softmax script that learns from the CIFAR-10 dataset. Accuracy is about 24%.\nFollowed wolflib's article to write the script\nCIFAR-10 Dataset used https://www.cs.toronto.edu/~kriz/cifar.html\n"}
{"url": "https://github.com/abrarhasinkml/kotha-BSLR", "owner": "abrarhasinkml", "repository_name": "kotha-BSLR", "date_all_variable_collection": "2023-09-10", "description": null, "size": 1102968, "stargazers_count": 0, "watchers_count": 0, "language": "PureBasic", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "abrarhasinkml", "contributions": 33}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PureBasic", "num_chars": 23618}, {"language": "Python", "num_chars": 4792}], "readme": "kotha- A Bengali Sign Language Recognition System\na Bangla Sign Language Recognizer to ease up the communication gap between the Deaf & Mute and the general people. The python script consists\nthe first model used to train our system. \n"}
{"url": "https://github.com/abrarhasinkml/MovieApp", "owner": "abrarhasinkml", "repository_name": "MovieApp", "date_all_variable_collection": "2023-09-10", "description": "A Movie searching application created using React-Native", "size": 174, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "abrarhasinkml", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 8891}], "readme": "# MovieApp\nA movie searching application created using React-Native.\nIt is expected that you have the following versions are installed: Node: v14.16.1+, npm: 6.14.12 & react-native: 0.64.0\n\nClone the repository and run: `npm install` \nto install the necessary libraries from the package.json file. For development purposes, expo has been used. To run the application the following command has to be executed: `npm start`\n\nThe movie app greets users with a search screen where users can search for any movie in the OMDb database. The application returns a list of movies matching the search query. Upon clicking on the title of the movie, users are redirected to a new page where they can view further details of the movie (ie. title, cast, director, genre, poster etc.)\n\n\nThe OMDb API has been used for this project: http://www.omdbapi.com/"}
{"url": "https://github.com/abrarhasinkml/RandomMusicPlayer", "owner": "abrarhasinkml", "repository_name": "RandomMusicPlayer", "date_all_variable_collection": "2023-09-10", "description": "Testing out Selenium webdriver by making a script that randomly plays Salman Khan songs", "size": 4272, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "abrarhasinkml", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 1498}], "readme": "# RandomMusicPlayer\nTesting out Selenium webdriver by making a script that randomly plays Salman Khan songs\n\nYou will require a Python environment to run the code. Names of a few songs are already extracted and stored in the csv file, so the namesExtractor script is not required to be executed. \nThe chromedriver executable is added in the repository. Update it if you have a newer version of chrome and make the necessary changes in your code.\nA pretty simple script that doesn't do much but play his songs randomly.\n"}
{"url": "https://github.com/abrarhasinkml/restaurantmanagementsystem", "owner": "abrarhasinkml", "repository_name": "restaurantmanagementsystem", "date_all_variable_collection": "2023-09-10", "description": "A Restaurant management system i did for my Java project during my 6th semester. The system can generate excel files for reports and can store in a database.", "size": 13522, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "abrarhasinkml", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 72938}], "readme": "# restaurantmanagementsystem\nA Restaurant management system i did for my Java project during my 6th semester. The system can generate excel files for reports and can store in a database.\n"}
{"url": "https://github.com/abrarhasinkml/Textmage", "owner": "abrarhasinkml", "repository_name": "Textmage", "date_all_variable_collection": "2023-09-10", "description": "Textmage is a neural caption generator that can generate captions in Bengali for images that belong to the Bangladeshi domain. This project was done for my CSE499 project. The model has been referred from sachinkmrs Neural Image Captioning model.", "size": 4, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "abrarhasinkml", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 12491}]}
{"url": "https://github.com/Adrian-Abendroth/Adrian-Abendroth", "owner": "Adrian-Abendroth", "repository_name": "Adrian-Abendroth", "date_all_variable_collection": "2023-09-10", "description": "Config files for my GitHub profile.", "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "Adrian-Abendroth", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["config", "github-config"], "languages": [], "readme": "- \ud83d\udc4b Hi, I\u2019m @Adrian-Abendroth\n- \ud83d\udc40 I\u2019m interested in DevOps, IT-Architecture and Process Management.\n- \ud83c\udf31 I\u2019m currently learning Docker in order to make enhancements in ERP systems with Low-Code Application Platforms.\n- \ud83d\udc9e\ufe0f I\u2019m looking to collaborate on Open-Source Low-Code Application Platforms as well as Open Source ERP systems.\n- \ud83d\udceb How to reach me: kontakt@adrian-abendroth.com\n\n<!---\nAdrian-Abendroth/Adrian-Abendroth is a \u2728 special \u2728 repository because its `README.md` (this file) appears on your GitHub profile.\nYou can click the Preview link to take a look at your changes.\n--->\n"}
{"url": "https://github.com/Adrian-Abendroth/iterm2", "owner": "Adrian-Abendroth", "repository_name": "iterm2", "date_all_variable_collection": "2023-09-10", "description": "Profile settings for MacOS terminal iterm2 ", "size": 5, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "Adrian-Abendroth", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# iterm2\nProfile settings for MacOS terminal iterm2 \n\n\n"}
{"url": "https://github.com/Adrian-Abendroth/OCaml-DFA-Equivalence", "owner": "Adrian-Abendroth", "repository_name": "OCaml-DFA-Equivalence", "date_all_variable_collection": "2023-09-10", "description": "This is an OCaml program to check whether two DFA's are equivalent and minimize them. It uses the Table-Filling Algorithm.", "size": 865, "stargazers_count": 0, "watchers_count": 0, "language": "OCaml", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "DrDragonKiller", "contributions": 54}, {"contributor": "Adrian-Abendroth", "contributions": 50}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "OCaml", "num_chars": 29535}], "readme": "# OCaml-DFA-Equivalence\n\nThis is an OCaml program to check whether two DFA's are equivalent and minimize them. It uses the Table-Filling Algorithm.\n\nTo see how the program works, see: <br />\nhttps://github.com/Adrian-Abendroth/OCaml-DFA-Equivalence/blob/master/documentation/1.method.md\n\n### Set-Up\nTo start the program, you need to instal OCaml.\nPlease follow this guide here: <br />\nhttps://ocaml.org/docs/install.html\n\n### Compiling and Running\nAfter you installed OCaml on your machine, you need to compile the program in your terminal with:\n```\nocamlc -o NameOfCompilatedFile program.ml\n```\n<br />\n\nNow you can execute the compiled file in your terminal with:\n```\n./NameOfCompilatedFile\n```\n"}
{"url": "https://github.com/Adrian-Abendroth/SharedBox-Ultimate", "owner": "Adrian-Abendroth", "repository_name": "SharedBox-Ultimate", "date_all_variable_collection": "2023-09-10", "description": "SharedBox-Ultimate Projekt fuer die Uni", "size": 31, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Adrian-Abendroth", "contributions": 17}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 9203}], "readme": "# SharedBox-Ultimate\n\n## Beschreibung\nUniversit\u00e4tsprojekt f\u00fcr das Fach Software Engineering der Universit\u00e4t Potsdam.\nWeitere Informationen unter: https://www.uni-potsdam.de/en/cs-se/teaching.html\n\n## Setups\nhttps://github.com/Adrian-Abendroth/SharedBox-Ultimate/wiki/Setup-Dev-Env\n"}
{"url": "https://github.com/Adrian-Abendroth/single-machine-scheduling-eed", "owner": "Adrian-Abendroth", "repository_name": "single-machine-scheduling-eed", "date_all_variable_collection": "2023-09-10", "description": "Single Machine Scheduling Early Due Date (EED) in Javascript programmed", "size": 13, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "Adrian-Abendroth", "contributions": 4}, {"contributor": "valentindoering", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 5602}], "readme": "# Description\nScheduling algorithm programmend in Javascript for single machine scheduling (only one worker) optimized for \n1. least delay\n2. earliest finish of all jobs \n\n# Usage\nIn the [/scr folder](https://github.com/Adrian-Abendroth/single-machine-scheduling-eed/blob/main/src/scheduleSingleMachineEDD.js), you will find the main file executing the algorithm.\n<br/>\nIn the [/data folder](https://github.com/Adrian-Abendroth/single-machine-scheduling-eed/blob/main/data/exampleJobs.json), you can find a data example, which you can adapt and change. It uses a JSON file.\n"}
{"url": "https://github.com/Adrian-Abendroth/zsh", "owner": "Adrian-Abendroth", "repository_name": "zsh", "date_all_variable_collection": "2023-09-10", "description": "Personal file for shell zsh", "size": 3, "stargazers_count": 0, "watchers_count": 0, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "Adrian-Abendroth", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 3914}], "readme": "# zsh\nPersonal file for shell zsh\n"}
{"url": "https://github.com/Adrian-Ziupka/ba-thesis", "owner": "Adrian-Ziupka", "repository_name": "ba-thesis", "date_all_variable_collection": "2023-09-10", "description": "My bachelor thesis about evaluating pavement distress of point clouds.", "size": 77840, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "scheibel", "contributions": 23}, {"contributor": "karyon", "contributions": 9}, {"contributor": "Adrian-Ziupka", "contributions": 4}, {"contributor": "soerendischer", "contributions": 3}, {"contributor": "cgcostume", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 779596}, {"language": "PostScript", "num_chars": 68010}, {"language": "GLSL", "num_chars": 1199}, {"language": "Shell", "num_chars": 201}]}
{"url": "https://github.com/Adrian-Ziupka/noodle-bot", "owner": "Adrian-Ziupka", "repository_name": "noodle-bot", "date_all_variable_collection": "2023-09-10", "description": "A telegram bot providing information about today's dishes at the canteen of the University of Potsdam.", "size": 7, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Adrian-Ziupka", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 3510}], "readme": "# noodle-bot\nA telegram bot providing information about today's dishes at the canteen of the University of Potsdam.\n\ntelegram username: @noodle_up_bot\n\n## commands\n\n- /noodles : Get an overview of all today's dishes (not only noodles ;))\n"}
{"url": "https://github.com/aeye-lab/ecml-ADHD", "owner": "aeye-lab", "repository_name": "ecml-ADHD", "date_all_variable_collection": "2023-09-10", "description": null, "size": 702534, "stargazers_count": 6, "watchers_count": 6, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 6, "default_branch": "main", "contributors": [{"contributor": "Shuwen27", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 65841}, {"language": "Shell", "num_chars": 3454}], "readme": "# Detection of ADHD based on Eye Movements during Natural Viewing\n[![paper](https://img.shields.io/static/v1?label=paper&message=download%20link&color=brightgreen)](https://arxiv.org/abs/2207.01377)\n\nIn this paper, we explore whether Attention-deficit/hyperactivity disorder (ADHD) can be detected based on recorded eye movements together with information about the video stimulus in a free-viewing task\n\n## Setup\n\nClone repository:\n\n```\ngit clone git@github.com:aeye-lab/ecml-ADHD\n```\n\nor\n\n```\ngit clone https://github.com/aeye-lab/ecml-ADHD\n```\n\nand change to the cloned repo via `cd ecml-ADHD`.\n\n\nInstall dependencies:\n\n```\npip install -r requirements.txt\n```\n\n## Run Experiments\n\n### Prepare saliency maps\nPlease download videos from http://fcon_1000.projects.nitrc.org/indi/cmi_healthy_brain_network/EEG-Eyetracking%20Protocol.html, and break it down into frames (e.g. use ffmpeg packages) and put them under the folder /Data/videos/frames_{video_name}/\n\nWe use a state-of-the-art saliency model, DeepGazeII to compute salinecy maps for our video stimuli. Download the files you need to run the DeepGazeII model https://drive.google.com/file/d/1kYUwoatqQUS5EabeeSDc6gRmCysnVZ6N/view, and stored under the folder /DNN_model/DataGeneration/\n\nTo generate the saliency maps for all videos, run\n```\nbash gen_saliency_map_data.sh\n```\n\n### Prepare model input files\n\nTo generate model input files, run\n\n```\nbash gen_model_input_data.sh\n```\n\n### Run models\n\n```\nbash run_models.sh\n```\n\n\n## Cite our work\nIf you use our code for your research, please consider citing our paper:\n\n```bibtex\n@inproceedings{deng2023detection,\n  title={Detection of ADHD based on eye movements during natural viewing},\n  author={Deng, Shuwen and Prasse, Paul and Reich, David R and Dziemian, Sabine and Stegenwallner-Sch{\\\"u}tz, Maja and Krakowczyk, Daniel and Makowski, Silvia and Langer, Nicolas and Scheffer, Tobias and J{\\\"a}ger, Lena A},\n  booktitle={Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2022, Grenoble, France, September 19--23, 2022, Proceedings, Part VI},\n  pages={403--418},\n  year={2023},\n  organization={Springer}\n}\n```\n"}
{"url": "https://github.com/aeye-lab/etra-2023-bridging-the-gap", "owner": "aeye-lab", "repository_name": "etra-2023-bridging-the-gap", "date_all_variable_collection": "2023-09-10", "description": null, "size": 945, "stargazers_count": 2, "watchers_count": 2, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "main", "contributors": [{"contributor": "dkrako", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 1593819}, {"language": "Python", "num_chars": 330629}], "readme": "# Bridging the Gap: Gaze Events as Interpretable Concepts to Explain Deep Neural Sequence Models\n\n\nBefore running any experiments, please adjust the file source/config/basepaths.py to your own paths.\n\nTo run the experiments please first write the datasets into npy files and detect all events with the following command:\n\n```\npython -m datasets.write_gazebase\npython -m datasets.write_judo\npython -m datasets.write_potec\n```\n\n\nTo train the models on the datasets run the following commands:\n\n```\npython -m train --model=eky2 --data=gazebase\npython -m train --model=eky2 --data=judo\npython -m train --model=eky2 --data=potec\n```\n\n\nTo evaluate concept influences for fixations and saccades run:\n\n```\npython -m evaluate.segmentations --model=eky2 --data=gazebase --metric=etra23 --segmentation=etra23\npython -m evaluate.segmentations --model=eky2 --data=judo1000 --metric=etra23 --segmentation=etra23\npython -m evaluate.segmentations --model=eky2 --data=potec --metric=etra23 --segmentation=etra23\n```\n\n\nTo evaluate concept influneces for saccade sub-events run:\n\n```\npython -m evaluate.segmentations --model=eky2 --data=gazebase --metric=etra23 --segmentation=engbert.saccade_dissection_vpeak80\npython -m evaluate.segmentations --model=eky2 --data=judo1000 --metric=etra23 --segmentation=engbert.saccade_dissection_vpeak80\npython -m evaluate.segmentations --model=eky2 --data=potec --metric=etra23 --segmentation=engbert.saccade_dissection_vpeak80\n```\n\n\nTo evaluate concept influneces for saccade sub-events run:\n\n```\npython -m evaluate.segmentations --model=eky2 --data=gazebase --metric=etra23 --segmentation=engbert.saccade_binning_duration_n100\npython -m evaluate.segmentations --model=eky2 --data=judo1000 --metric=etra23 --segmentation=engbert.saccade_binning_amplitude_n100\npython -m evaluate.segmentations --model=eky2 --data=gazebase --metric=etra23 --segmentation=ivt.fixation_binning_dispersion_n100\npython -m evaluate.segmentations --model=eky2 --data=judo1000 --metric=etra23 --segmentation=ivt.fixation_binning_v_std_n100\n```\n"}
{"url": "https://github.com/aeye-lab/etra-fairness", "owner": "aeye-lab", "repository_name": "etra-fairness", "date_all_variable_collection": "2023-09-10", "description": null, "size": 39577, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "SiQube", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 14029819}, {"language": "Python", "num_chars": 139245}, {"language": "Shell", "num_chars": 13177}], "readme": "# Fairness in Oculomotoric Biometric Identification\n[![paper](https://img.shields.io/static/v1?label=paper&message=download%20link&color=brightgreen)](https://dl.acm.org/doi/10.1145/3517031.3529633)\n\nThis repo provides the code for reproducing the experiments in [Fairness in Oculomotoric Biometric Identification](https://doi.org/10.1145/3517031.3529633).\n\nIn the paper, we investigate the fairness of a biometric system based on eye-tracking data with respect to gender, ethnicity, and age.\n![DeepEyedentification embedding evolution animation](https://user-images.githubusercontent.com/43832476/170812609-cb6d8b5a-cfc1-4e03-928a-b39596871229.gif)\nThe figure above shows the embedding evolution of the DeepEyedentificationLive subnets across ethnicities.\n\n\n## Reproduce the experiments\n\n### Download the data\nYou can download the publicly available data here: [GazeBase, a large-scale, multi-stimulus, longitudinal eye movement dataset](https://figshare.com/articles/dataset/GazeBase_Data_Repository/12912257). The corresponding paper can be found [here](https://www.nature.com/articles/s41597-021-00959-y).\n\n### Clone this repository \nYou can clone this repository by either using \n```bash\ngit clone git@github.com:aeye-lab/etra-fairness\n```\nor \n```bash\ngit clone https://github.com/aeye-lab/etra-fairness\n```\ndepending on your preferences and settings.\nAfterward, change into the directory by using `cd etra-fairness`.\n\n### Install packages\nInstall all required python packages via:\n```bash\npip install -r requirements.txt\n```\n### Extract data\nAfter moving the zipped gazebase data download in the first step into the repository, extract all files by executing:\n```bash\npython3 extract_gazebase_data.py\n```\n\nThen you can directly start using the [DeepEyedentification](https://ecmlpkdd2019.org/downloads/paper/231.pdf) network by adjusting and executing the following scripts for the experiment you want to investigate. A description of the CLI arguments is available via `python3 deepEye_fairness_gazebase.py --help`.\n\nA list of all bash scripts used is below. Note: Running the experiments, especially on CPU, will take some time.\n### Pipeline [DeepEyedentification](https://ieeexplore.ieee.org/abstract/document/9555831)\n* run experiments:\n    * run_random_sampling_all_settings.sh\n    * run_experiment_age.sh\n    * run_experiments_VD1_VD2.sh\n    * run_experiments_RAN.sh\n    * run_experiments_HSS.sh\n    * run_experiments_FXS.sh\n    * run_experiments_BLG.sh\n    * run_experiments_TEX.sh\n* create score dicts:\n    * run_create_score_dicts.sh\n\nUnfortunately the [Lohr _et al._](https://ieeexplore.ieee.org/document/9304859) takes a bit more work. After downloading the data you have to adjust the following two scripts:\n* extract the eye movement events (fixation, saccades, PSO)\n    * adjust the path in the scripts from  [A novel evaluation of two related and two independent algorithms for eye movement classification during reading](https://digital.library.txstate.edu/handle/10877/6874). The paper can be found [here](https://link.springer.com/epdf/10.3758/s13428-018-1050-7).\n* adjust the statistical feature extraction: [Study of an Extensive Set of Eye Movement Features: Extraction Methods and Statistical Analysis](https://digital.library.txstate.edu/handle/10877/6904). The paper can be found [here](https://pubmed.ncbi.nlm.nih.gov/33828682/). Note, you don't only have to adjust the script to match your data path (the data created by MNH) but also such that the algorithm only takes one eye movement event as input instead of the complete sequence.\n\nAfterwards copy the data to `lohr_feature_data/`. You can execute all experiments with the bash scripts below. CLI options are available via  `python3 lohr_fairness_gazebase.py --help`.\n### Pipeline [Lohr _et al._](https://ieeexplore.ieee.org/document/9304859)\n* run experiments:\n    * run_experiments_lohr.sh\n    * run_experiments_lohr_adam_w.sh\n* create score dicts:\n    * run_create_score_dicts_lohr.sh\n\n### Calculate fairness metrics and visualize results\nYou can calculate the fairness metrics and visualize the results from your experiments with the notebooks: \n* Fairness:\n    * plot_results_deepEye.ipynb\n    * plot_results_lohr.ipynb\n* Visualize embeddings:\n    * plot_t-sne_visualization_deepEye.ipynb\n    * plot_t-sne_visualization_lohr.ipynb\n* Eye movement similarities for different demographics:\n    * inspect_differences.ipynb\n\n## Contribution\nIf you find any issues, please open an issue in the issue tracker.\n\nIf you want, you can also test your own oculomotoric biometric models substituting it within the piplines described above. \n\n\n## Cite our work\nIf you use our code for your research, please consider citing our paper:\n\n```bibtex\n@inproceedings{10.1145/3517031.3529633,\nauthor = {Prasse, Paul and Reich, David Robert and Makowski, Silvia and J\\\"{a}ger, Lena A. and Scheffer, Tobias},\ntitle = {Fairness in Oculomotoric Biometric Identification},\nyear = {2022},\nisbn = {9781450392525},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\ndoi = {10.1145/3517031.3529633},\nbooktitle = {2022 Symposium on Eye Tracking Research and Applications},\narticleno = {22},\nnumpages = {8},\nkeywords = {fairness, neural networks, biometrics},\nlocation = {Seattle, WA, USA},\nseries = {ETRA '22}\n}\n```\n"}
{"url": "https://github.com/aeye-lab/etra-reading-comprehension", "owner": "aeye-lab", "repository_name": "etra-reading-comprehension", "date_all_variable_collection": "2023-09-10", "description": null, "size": 135, "stargazers_count": 4, "watchers_count": 4, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 4, "default_branch": "main", "contributors": [{"contributor": "SiQube", "contributions": 57}, {"contributor": "pre-commit-ci[bot]", "contributions": 29}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 98374}, {"language": "Jupyter Notebook", "num_chars": 11244}], "readme": "Inferring Native and Non-Native Human Reading Comprehension and Subjective Text Difficulty from Scanpaths in Reading\n====================================================================================================================\n[![paper](https://img.shields.io/static/v1?label=paper&message=download%20link&color=brightgreen)](https://dl.acm.org/doi/abs/10.1145/3517031.3529639)\n\nThis repo provides the code for reproducing the experiments in [Inferring Native and Non-Native Human Reading Comprehension and Subjective Text Difficulty from Scanpaths in Reading](https://dl.acm.org/doi/abs/10.1145/3517031.3529639).\n\n![BEyeLSTM](https://user-images.githubusercontent.com/43832476/171489683-332d88ba-45f7-4f68-86dd-8288f52bd34c.png)\nThe figure above shows our architecture `BEyeLSTM`.\nWe investigate and show that we can generalize to unseen test persons for all tasks investigated.\n\n## Reproduce the experiments\n\n### Clone this repository\nYou can clone this repository by either using\n```bash\ngit clone git@github.com:aeye-lab/etra-reading-comprehension\n```\nor\n```bash\ngit clone https://github.com/aeye-lab/etra-reading-comprehension\n```\ndepending on your preferences and settings.\nAfterward, change into the directory by using `cd etra-reading-comprehension`.\n\n### Download the data\nYou can download the publicly available data here\n```bash\ngit clone git@github.com:ahnchive/SB-SAT\n```\nor\n```bash\ngit clone https://github.com/ahnchive/SB-SAT\n```\n\n### Install packages\nInstall all required python packages via:\n```bash\npip install -r requirements.txt\n```\n### Extract data\nYou can create the data splits using:\n```bash\npython3 utils/generate_text_sequence_splits.py\n```\n\nThen you can directly start using both BEyeLSTM and the baseline of [Ahn et al.](https://dl.acm.org/doi/10.1145/3379156.3391335) using `python3 nn/train_model.py` or `python3 ahn_baseline/evaluate_ahn_baseline.py` respectively. By changing the boolean arguments in `nn/train_model.py` you can recreate our ablation study or use different subnets only.\n\nNote: Running the experiments, especially on CPU, will take some time.\n\n## Contribute\nIf you find any issues, please open an issue in the issue tracker.\n\n## Cite our work\nIf you use our code for your research, please consider citing our paper:\n\n```bibtex\n@inproceedings{10.1145/3517031.3529639,\nauthor = {Reich, David Robert and Prasse, Paul and Tschirner, Chiara and Haller, Patrick and Goldhammer, Frank and J\\\"{a}ger, Lena A.},\ntitle = {Inferring Native and Non-Native Human Reading Comprehension and Subjective Text Difficulty from Scanpaths in Reading},\nyear = {2022},\nisbn = {9781450392525},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\ndoi = {10.1145/3517031.3529639},\nbooktitle = {2022 Symposium on Eye Tracking Research and Applications},\narticleno = {23},\nnumpages = {8},\nkeywords = {deep learning, reading comprehension, eye tracking-while-reading},\nlocation = {Seattle, WA, USA},\nseries = {ETRA '22}\n}\n```\n"}
{"url": "https://github.com/aeye-lab/Eyettention", "owner": "aeye-lab", "repository_name": "Eyettention", "date_all_variable_collection": "2023-09-10", "description": null, "size": 3787, "stargazers_count": 7, "watchers_count": 7, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 7, "default_branch": "main", "contributors": [{"contributor": "Shuwen27", "contributions": 8}, {"contributor": "LenaJaeger", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 128477}, {"language": "Jupyter Notebook", "num_chars": 101458}], "readme": "# Eyettention: An Attention-based Dual-Sequence Model for Predicting Human Scanpaths during Reading\n[![paper](https://img.shields.io/static/v1?label=paper&message=download%20link&color=brightgreen)](https://arxiv.org/abs/2304.10784)\n\nIn this paper, we develop Eyettention, the first dual-sequence model that simultaneously processes the sequence of words and the chronological sequence of fixations. The alignment of the two sequences is achieved by a cross-sequence attention mechanism. We show that Eyettention outperforms state-of-the-art models in predicting scanpaths. We provide an extensive within- and across-data set evaluation on different languages. An ablation study and qualitative analysis support an in-depth understanding of the model's behavior.\n\n## Setup\n\nClone repository:\n\n```\ngit clone git@github.com:aeye-lab/Eyettention\n```\n\nor\n\n```\ngit clone https://github.com/aeye-lab/Eyettention\n```\nand change to the cloned repo via `cd Eyettention`.\n\nInstall dependencies:\n\n```\npip install -r requirements.txt\n```\n\n## Dataset\nFor CELER dataset, you need to follow the instructions \nhttps://github.com/berzak/celer\nIn order to run the experiments, place the downloaded CELER dataset in the /Data/ folder.\n\n## Run Experiments\n#For Chinese BSC dataset:\n```\npython main_BSC.py --test_mode='text'\npython main_BSC.py --test_mode='subject'\npython main_BSC_NRS_setting.py\npython main_BSC_reader_identifier.py\n```\n\n#For English CELER dataset:\n```\npython main_celer.py --test_mode='text'\npython main_celer.py --test_mode='subject'\npython main_celer_NRS_setting.py\npython main_celer_reader_identifier.py\n```\n\n## Cite our work\nIf you use our code for your research, please consider citing our paper:\n\n```bibtex\n@article{deng2023eyettention,\n  title={Eyettention: {A}n Attention-based Dual-Sequence Model for Predicting Human Scanpaths during Reading},\n  author={Deng, Shuwen and Reich, David R and Prasse, Paul and Haller, Patrick and Scheffer, Tobias and J{\\\"a}ger, Lena A},\n  journal={Proceedings of the {ACM} on Human-Computer Interaction},\n  volume={7},\n  number={ETRA},\n  pages={1--24},\n  year={2023},\n  publisher={ACM New York, NY, USA}\n}\n```\n"}
{"url": "https://github.com/aeye-lab/neurips-gmml-2022-xai-eye-tracking-evaluation", "owner": "aeye-lab", "repository_name": "neurips-gmml-2022-xai-eye-tracking-evaluation", "date_all_variable_collection": "2023-09-10", "description": null, "size": 32640, "stargazers_count": 2, "watchers_count": 2, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "main", "contributors": [{"contributor": "dkrako", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 258716}, {"language": "Shell", "num_chars": 1257}], "readme": "# Eye Tracking Explainability Evaluation Pipeline\n\n### Install requirements\n\n```\npip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\npip install -e external/quantus\npip install -r requirements.txt\n```\n"}
{"url": "https://github.com/aeye-lab/pymovements", "owner": "aeye-lab", "repository_name": "pymovements", "date_all_variable_collection": "2023-09-10", "description": "A python package for processing eye movement data", "size": 820, "stargazers_count": 28, "watchers_count": 28, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": true, "has_discussions": false, "forks_count": 4, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 114, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 4, "open_issues": 114, "watchers": 28, "default_branch": "main", "contributors": [{"contributor": "dkrako", "contributions": 266}, {"contributor": "SiQube", "contributions": 32}, {"contributor": "pre-commit-ci[bot]", "contributions": 21}, {"contributor": "jakobchwastek", "contributions": 13}, {"contributor": "theDebbister", "contributions": 7}, {"contributor": "prassepaul", "contributions": 3}, {"contributor": "siqube-adobe", "contributions": 3}, {"contributor": "ketrab2003", "contributions": 1}, {"contributor": "hallerp", "contributions": 1}, {"contributor": "Shuwen27", "contributions": 1}, {"contributor": "assuntasuess", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": true, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["event-detection", "eye-tracking", "eyetracking", "python", "scientific-computing", "scientific-software", "scientific-visualization"], "languages": [{"language": "Python", "num_chars": 779729}], "readme": "<p style=\"text-align:center;\">\n<img width=\"110%\" height=\"110%\" alt=\"pymovements\"\n src=\"https://raw.githubusercontent.com/aeye-lab/pymovements/main/docs/source/_static/logo.svg\"\n onerror=\"this.onerror=null;this.src='./docs/source/_static/logo.svg';\"/>\n</p>\n\n---\n\n[![PyPI Latest Release](https://img.shields.io/pypi/v/pymovements.svg)](https://pypi.python.org/pypi/pymovements/)\n[![Conda Latest Release](https://img.shields.io/conda/vn/conda-forge/pymovements)](https://anaconda.org/conda-forge/pymovements)\n[![PyPI status](https://img.shields.io/pypi/status/pymovements.svg)](https://pypi.python.org/pypi/pymovements/)\n[![Python version](https://img.shields.io/pypi/pyversions/pymovements.svg)](https://pypi.python.org/pypi/pymovements/)\n![Operating System](https://img.shields.io/badge/os-linux%20%7C%20macOS%20%7C%20windows-blue)\n[![License](https://img.shields.io/pypi/l/pymovements.svg)](https://github.com/aeye-lab/pymovements/blob/master/LICENSE.txt)\n[![Test Status](https://img.shields.io/github/actions/workflow/status/aeye-lab/pymovements/tests.yml?label=tests)](https://github.com/aeye-lab/pymovements/actions/workflows/tests.yml)\n[![Documentation Status](https://readthedocs.org/projects/pymovements/badge/?version=latest)](https://pymovements.readthedocs.io/en/latest/?badge=latest)\n[![codecov](https://codecov.io/github/aeye-lab/pymovements/branch/main/graph/badge.svg?token=QY3NDHAT2C)](https://app.codecov.io/gh/aeye-lab/pymovements)\n[![PyPI downloads/month](https://img.shields.io/pypi/dm/pymovements.svg)](https://pypistats.org/packages/pymovements)\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/aeye-lab/pymovements/HEAD?labpath=docs%2Fsource%2Ftutorials)\n\n\npymovements is an open-source python package for processing eye movement data. It provides a simple\ninterface to download publicly available datasets, preprocess gaze data, detect oculomotoric events\nand render plots to visually analyze your results.\n\n- **Website:** https://github.com/aeye-lab/pymovements\n- **Documentation:** https://pymovements.readthedocs.io\n- **Source code:** https://github.com/aeye-lab/pymovements\n- **Mailing list:** pymovements-list@uni-potsdam.de\n- **Contributing:** https://github.com/aeye-lab/pymovements/blob/main/CONTRIBUTING.md\n- **Bug reports:** https://github.com/aeye-lab/pymovements/issues\n- **PyPI package:** https://pypi.org/project/pymovements\n- **Conda package:** https://anaconda.org/conda-forge/pymovements\n\n\n## Getting Started\n\nCheck out our guide on how to install *pymovements* and get started here:\n[Installation](https://pymovements.readthedocs.io/en/stable/getting-started.html)\n\nWe provide a range of tutorial aimed at beginners:\n[Tutorials](https://pymovements.readthedocs.io/en/stable/tutorials/index.html)\n\nThe complete reference of the package can be found here:\n[API Reference](https://pymovements.readthedocs.io/en/stable/reference/index.html)\n\n\n## Contributing\n\nWe welcome any sort of contribution to pymovements!\n\nFor a detailed guide, please refer to our [CONTRIBUTING.md](CONTRIBUTING.md) first.\n\nIf you have any questions, please [open an issue](\nhttps://github.com/aeye-lab/pymovements/issues/new/choose) or write us at\n[pymovements-list@uni-potsdam.de](mailto:pymovements-list@uni-potsdam.de)\n\n\n## Citing\n\nIf you are using pymovements in your research, we would be happy if you cite our work by using the following BibTex entry:\n\n```bibtex\n@inproceedings{pymovements,\n    author = {Krakowczyk, Daniel G. and Reich, David R. and Chwastek, Jakob and Jakobi, Deborah N.\n   and Prasse, Paul and S\u00fcss, Assunta and Turuta, Oleksii and Kasprowski, Pawe\u0142\n   and J\u00e4ger, Lena A.},\n    title = {pymovements: A Python Package for Processing Eye Movement Data},\n    year = {2023},\n    isbn = {979-8-4007-0150-4/23/05},\n    publisher = {Association for Computing Machinery},\n    address = {New York, NY, USA},\n    url = {https://doi.org/10.1145/3588015.3590134},\n    doi = {10.1145/3588015.3590134},\n    booktitle = {2023 Symposium on Eye Tracking Research and Applications},\n    location = {Tubingen, Germany},\n    series = {ETRA '23},\n}\n```\n\nThere is also a preprint available on [arxiv](https://arxiv.org/abs/2304.09859).\n"}
{"url": "https://github.com/aeye-lab/pymovements-toy-dataset", "owner": "aeye-lab", "repository_name": "pymovements-toy-dataset", "date_all_variable_collection": "2023-09-10", "description": "Example toy dataset resource for the pymovements package", "size": 3129, "stargazers_count": 1, "watchers_count": 1, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "dkrako", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# pymovements Toy Dataset\n\nThis repository serves as an example toy dataset resource for the\n[pymovements](https://github.com/aeye-lab/pymovements) package.\n\nIt features gaze data from a single subject reading 4 texts with 5 screens each.\n\nFilenames have the format `trial_{text_id}_{page_id}.csv`.\n\nThe experiment configuration is specified as:\n```\nExperiment(\n\tscreen_width_px=1280,\n\tscreen_height_px=1024,\n\tscreen_width_cm=38,\n\tscreen_height_cm=30.2,\n\tdistance_cm=68,\n\torigin='lower left',\n\tsampling_rate=1000,\n)\n```"}
{"url": "https://github.com/aeye-lab/pymovements-toy-dataset-eyelink", "owner": "aeye-lab", "repository_name": "pymovements-toy-dataset-eyelink", "date_all_variable_collection": "2023-09-10", "description": null, "size": 1625, "stargazers_count": 1, "watchers_count": 1, "language": "AGS Script", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "dkrako", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "AGS Script", "num_chars": 10997464}]}
{"url": "https://github.com/aeye-lab/python-wmc-battery", "owner": "aeye-lab", "repository_name": "python-wmc-battery", "date_all_variable_collection": "2023-09-10", "description": "  Python reimplementation of the WMC battery described in Lewandowsky, Oberauer, Yang, & Ecker (2010), Behavior Research Methods.", "size": 5162, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "dkrako", "contributions": 88}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 1210931}], "readme": "# WMC-Battery\n\nPython re-implementation of the WMC battery described in Lewandowsky, S., Oberauer, K., Yang, L. X., & Ecker, U. K. (2010). A working memory test battery for MATLAB. Behavior research methods, 42(2), 571\u2013585. https://doi.org/10.3758/BRM.42.2.571\n\nThis implementation is a minute reproduction of the original MATLAB implementation and uses the same file output format.\nThis way the accompanying R-script of the original implementation can still be used for data processing.\n\n\n## Differences to original MATLAB implementation\n\n- implementation limited to the following tasks: Memory Update, Operation Span, Sentence Span, and Spatial Short-Term Memory  (left out Choice Reaction Test, Task Switching, and Word Recognition as not referenced in paper)\n- random seed can be either set explicitly or will be automatically determined by the session name / subject id\n- Spatial Short-Term Memory trials are dynamically generated for each new experiment run\n- corrections in chinese language files (instruction pages, experiment messages and sentences for Sentence Span task)\n\n\n## Installation\n\n### Ubuntu 20.04\nYou may need to put `.local/bin` in your `PATH` by adding this to your `.bashrc` in your home folder:\n```\n# set PATH so it includes user's private bin if it exists\nif [ -d \"$HOME/.local/bin\" ] ; then\n    PATH=\"$HOME/.local/bin:$PATH\"\nfi\n```\n\nAfter that, create a new terminal and close the old one to reload the configuration.\n\n```\nsudo apt-get install psychopy python3-pip python3-wxgtk-webview4.0 libxcb-xinerama0\n\npip3 install --upgrade pip\npip3 install -r requirements.txt\npip3 install -U -f https://extras.wxpython.org/wxPython4/extras/linux/gtk3/ubuntu-20.04 wxPython==4.1.1\n```\n\nFor Chinese font support:\n\n```\nsudo apt-get install fonts-noto-cjk\n```\n\n\n### Mac OS\n\n```\npip install psychopy==2020.2.10 pygame wxPython numpy pandas scipy dotmap pyyaml\n```\n\nFor Chinese, please download and install the required font package 'Noto Serif CJK SC': https://www.google.com/get/noto/\n\nThe support for font install : https://www.google.com/get/noto/help/install/\n\n\n\n### Windows\n\n```\npip install psychopy==2020.2.10 pygame wxPython numpy pandas scipy dotmap pyyaml\n```\n\nFor Chinese, please download and install the required font package 'Noto Serif CJK SC': https://www.google.com/get/noto/\n\nThe support for font install : https://www.google.com/get/noto/help/install/\n\n\n## Run WMC Battery\n\n### Ubuntu 20.04\n\n\n```\npython3 wmc_ubuntu.py\n```\n\n\n### MacOS\n\n\n```\npython3 wmc_mac.py\n```\n\n\n### Windows\n\n\n```\npython3 wmc_windows.py\n```\n\n\n## Usage\n\nYou can quit the experiment by pressing `F12`.\n\n\nIt is advised to mark the arrow-keys on your physical keyboard for the *Operation Span* and *Sentence Span* tasks. You can configure the keys in the `yaml`-config files in the `config` folder (`key_map` field).\n\n\n## Test language files\n\nYou can test your language files by running the following command:\n\n```\npython3 test_language.py\n```\n\nYou will move through all experiment messages, instruction pages, a summary for sentence span sentences and all sentence span sentences with the respective label. For the sentence summary, moving on is possible only after one second has passed to prevent accidental skipping.\n"}
{"url": "https://github.com/aeye-lab/SFB-1287-Summer-School", "owner": "aeye-lab", "repository_name": "SFB-1287-Summer-School", "date_all_variable_collection": "2023-09-10", "description": null, "size": 11715, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "Shuwen27", "contributions": 16}, {"contributor": "theDebbister", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 24708820}], "readme": "#  SFB-1287-Summer-School\n\nFor all the hands-on sessions we will use a jupyter notebook. You can use Google colab to run them. The links below point to a public version of the notebooks on colab. If something does not work you can also download the notebooks from this repository and upload it to colab manually.\n\n## E1: Function / Linear model\nhttps://colab.research.google.com/drive/1g3CLkAvfWXpLfIDKnNCmAJjFPsaxH6cG?usp=sharing\n\n## E2: Visualize attention\nhttps://colab.research.google.com/drive/1oF7Sql5jrR2QgqNcBBDPO8ilwsV-JAVU?usp=sharing\n\n## E3: Generate scanpaths using Eyettention \nhttps://colab.research.google.com/drive/1e3rMu951es8SuhP-5qrDy1MpmqCM3nMg?usp=sharing\n"}
{"url": "https://github.com/aeye-lab/sp-eyegan", "owner": "aeye-lab", "repository_name": "sp-eyegan", "date_all_variable_collection": "2023-09-10", "description": null, "size": 56877, "stargazers_count": 7, "watchers_count": 7, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 7, "default_branch": "main", "contributors": [{"contributor": "prassepaul", "contributions": 4}, {"contributor": "SiQube", "contributions": 3}, {"contributor": "dkrako", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 887637}, {"language": "Python", "num_chars": 251375}, {"language": "Shell", "num_chars": 3600}], "readme": "SP-EyeGAN: Generating Synthetic Eye Movement Data\n=================================================\n\nThis repository provides the code for reproducing the experiments in SP-EyeGAN: Generating Synthetic Eye Movement Data. Additionally, you can also use the pre-trained models and create the synthetic data you need for your experiments.\n\n![Method overview](images/sp-eyegan.png)\n\n## Reproduce the experiments\n\nClone the github repository to obtain the ADHD dataset:\n* Using git(hub)s CLI and ssh:\n    * `git clone git@github.com:aeye-lab/sp-eyegan`\n* without ssh:\n    * `git clone https://github.com/aeye-lab/sp-eyegan`\n* if you do not use the terminal / git bash / ide you can download the zip file at the top right of the [repository](https://github.com/aeye-lab/sp-eyegan). Extract the zip file after downloading it.\n\n### Rerun all experiments\n\nWe provide a ssh script which lets you rerun all experiments. We assume that you will have activate a virtual or conda environment, or work with a global pip installation.\n```bash\nrerun_experiments.sh\n```\n\nIf you do not to replicate all experiments, you can either choose to comment out certain parts of the `rerun_experiments.sh` or other bash scripts or follow the steps provided below. Depending on your hardware rerunning all experiments might take several days.\n\n\n\n### Download data\n\nWe use the [`pymovements`](https://github.com/aeye-lab/pymovements) package to download the data. For this either execute `scripts/get_data.sh` or it is also part of the `rerun_experiments.sh` script. Note, you have to download both `Gaze on Faces` and `SB-SAT` manually. We will try to fix this as soon as possible.\n\n\nAlternatively, you can also download the original data from the sources listed below.\n\nDownload the GazeBase data:\n* Download and extract the GazeBase data into a `data/GazeBase` to train FixGAN and SacGAN [figshare-link](https://figshare.com/articles/dataset/GazeBase_Data_Repository/12912257).\n\nDownload the SB-SAT data:\n* Download the SB-SAT data into a `data/SB-SAT` [osf-link](https://osf.io/cdx69/).\n\nClone the github repository to obtain the ADHD dataset into `data/ecml-ADHD`:\n* Using git(hub)s CLI and ssh:\n    * `git clone git@github.com:aeye-lab/ecml-ADHD data/ecml-ADHD`\n* without ssh.:\n    * `git clone https://github.com/aeye-lab/ecml-ADHD data/ecml-ADHD`\n* if you do not use the terminal / git bash / ide you can download the zip file at the top right of the [repository](https://github.com/aeye-lab/ecml-ADHD). After downloading the zip file, extract it to your local clone of this repositry.\n\nDownload the Gaze on Faces dataset:\n* Download the [Gaze on Faces data](https://uncloud.univ-nantes.fr/index.php/s/8KW6dEdyBJqxpmo) into the `data/Gaze_on_Faces` folder where you cloned this repositry. Then extract the zip file `gaze_csv.zip`.\n\n### Configure the paths\nModify `config.py` to contain the path to the GazeBase, SB-SAT, HBN, and Gaze on Faces directories, where you want to store the models and classification results.\n\n### Pipeline to train FixGAN and SacGAN and to create synthtic data\n\nTo train generative models to create fixations and saccades follow the next steps.\n\n#### 1. Create data to train FixGAN and SacGAN\nCreate the data containing fixations and saccades extracted from GazeBase (for the task of reading a text) by running:\n* `python -m sp_eyegan.create_event_data_from_gazebase.py --stimulus text`\nFixations and saccades for the other stimuli could be extracted by change the `stimulus` (allowed stimili are {text, ran, hss, fxs, video, all}).\n\n#### 2. Train FixGAN/SacGAN\nTrain GANs to create fixations and saccades on previously created set of fixations and saccades:\n* Train FixGAN: `python -m sp_eyegan.train_event_model --event_type fixation --stimulus text`\n* Train SacGAN: `python -m sp_eyegan.train_event_model --event_type saccade --stimulus text`\n\nNote, in the script the models will be trained one after the other. You can also parallel the runs by either adding a `&` at the end of the line in the `scripts/train_sp_eyegan.sh`. Or starting two processes with the two lines above. Models trained for the other stimuli could be extracted by change the `stimulus` (allowed stimili are {text, ran, hss, fxs, video, all}).\n\n#### 3. Create synthetic data:\nCreate synthetic data using the previously trained GANs:\n\n```bash\npython -m create_synthetic_data --stimulus text --scanpath_model random --window_size 5000\n```\n\nCreating synthetic data for the other stimuli could be extracted by change the `stimulus` (allowed stimili are {text, ran, hss, fxs, video, all}). You can also change the `scanpath_model` to `stat_model `.\n\n### Apply model on downstream tasks:\n\n#### 1. Pretrain the model with contrastive loss:\nIn the following we will show how to pretrain two different models on several different sampling rates using [contrastive loss](sp_eyegan/pretrain_constastive_learning.py). The [rerun_experiments.sh](rerun_experiments.sh) will train for two models at 1000Hz. If you want to use your own architecture, you can add the architecture to [contrastive learning environment](sp_eyegan/model/contrastive_learner.py) and call it via `--encoder_name YOUR ARCHITECTURE NAME`. Note that `window_size` should be equal for both the synthetic data created and the pretraining script.\n* for training on 1,000 Hz (note, these examples assume you have access to at least 4 gpus -- if not adjust by not using -GPU NUMBER):\n\t* pretrain model with contrastive loss with random augmentation on synthetic data and EKYT architecture:\n    ```bash\n    python -m sp_eyegan.pretrain_constastive_learning --stimulus text -augmentation_mode random  -sd 0.1     -sd_factor 1.25 -encoder_name ekyt -GPU 0 --window_size 5000\n    ```\n\t* pretrain model with contrastive loss with random augmentation on synthetic data and CLRGaze architecture:\n    ```bash\n    python -m sp_eyegan.pretrain_constastive_learning --stimulus text -augmentation_mode random  -sd 0.1     -sd_factor 1.25 -encoder_name clrgaze -GPU 0 --window_size 5000\n    ```\n* for training on 120 Hz\n    * pretrain model with contrastive loss with random augmentation on synthetic data and CLRGaze architecture:\n    ```bash\n    python -m sp_eyegan.pretrain_constastive_learning --augmentation_mode random --sd 0.05 --encoder_name clrgaze --GPU 2 --data_suffix baseline_120 --target_sampling_rate 120 --window_size 5000\n    ```\n    * pretrain model with contrastive loss with random augmentation on synthetic data and EKYT architecture:\n    ```bash\n    python -m sp_eyegan.pretrain_constastive_learning --stimulus text--augmentation_mode random --sd 0.05 --encoder_name ekyt --GPU 3 --data_suffix baseline_120 --target_sampling_rate 120 --window_size 5000\n    ```\n\n* for training on 60 Hz\n    * pretrain model with contrastive loss with random augmentation on synthetic data and CLRGaze architecture:\n    ```bash\n    python -m sp_eyegan.pretrain_constastive_learning --stimulus text --augmentation_mode random --sd 0.05 --encoder_name clrgaze --GPU 0 --data_suffix baseline_60 --target_sampling_rate 60 --window_size 5000\n    ```\n    * pretrain model with contrastive loss with random augmentation on synthetic data and EKYT architecture:\n    ```bash\n    python -m sp_eyegan.pretrain_constastive_learning --stimulus text --augmentation_mode random --sd 0.05 --encoder_name ekyt --GPU 0 --data_suffix baseline_60 --target_sampling_rate 60 --window_size 5000\n    ```\n\n#### 2. Evaluate model on downstream tasks:\nEvaluate models on SB-SAT downstream tasks via:\n* with fine-tuning and using a random forest:\n    * `python -m sp_eyegan.evaluate_downstream_task_reading_comprehension --encoder_name clrgaze`\n    * `python -m sp_eyegan.evaluate_downstream_task_reading_comprehension --encoder_name ekyt`\n\n* without pre-training (training from scratch):\n    * `python -m sp_eyegan.evaluate_downstream_task_reading_comprehension --encoder_name clrgaze --fine_tune 0`\n    * `python -m sp_eyegan.evaluate_downstream_task_reading_comprehension --encoder_name ekyt --fine_tune 0`\n\n\nEvaluate on biometric verification tasks via (using two gpus):\n* with fine-tuning and using a random forest:\n    * `python -m sp_eyegan.evaluate_downstream_task_biometric --dataset judo --gpu 0 --encoder_name clrgaze`\n    * `python -m sp_eyegan.evaluate_downstream_task_biometric --dataset judo --gpu 1 --encoder_name ekyt`\n    * `python -m sp_eyegan.evaluate_downstream_task_biometric --dataset gazebase --gpu 0 --encoder_name clrgaze`\n    * `python -m sp_eyegan.evaluate_downstream_task_biometric --dataset gazebase --gpu 1 --encoder_name ekyt`\n* without pre-training (training from scratch):\n    * `python -m sp_eyegan.evaluate_downstream_task_biometric --dataset judo --gpu 0 --encoder_name clrgaze --fine_tune 0`\n    * `python -m sp_eyegan.evaluate_downstream_task_biometric --dataset judo --gpu 0 --encoder_name ekyt --fine_tune 0`\n    * `python -m sp_eyegan.evaluate_downstream_task_biometric --dataset gazebase --gpu 0 --encoder_name clrgaze --fine_tune 0`\n    * `python -m sp_eyegan.evaluate_downstream_task_biometric --dataset gazebase --gpu 0 --encoder_name ekyt --fine_tune 0`\n\nEvaluate contrastively pre-trained models on gender classification task via:\n* `python -m sp_eyegan.evaluate_downstream_task_gender_classification --gpu 0 --encoder_name clrgaze`\n* `python -m sp_eyegan.evaluate_downstream_task_gender_classification --gpu 0 --encoder_name ekyt`\n\nEvaluate contrastively pre-trained models on ADHD detection task via:\n* `python -m sp_eyegan.evaluate_downstream_task_adhd_classification --gpu 0 --encoder_name clrgaze`\n* `python -m sp_eyegan.evaluate_downstream_task_adhd_classification --gpu 0 --encoder_name ekyt`\n\n\n\n## Test model\nTo see an example of how to create synthetic data look into [this notebook](notebooks/generate_syn_data_for_reading.ipynb).\n\n### Citation\nIf you are using SP-EyeGAN in your research, we would be happy if you cite our work by using the following BibTex entry:\n```bibtex\n@inproceedings{Prasse_SP-EyeGAN2023,\n  author    = {Paul Prasse and David R. Reich and Silvia Makowski and Shuwen Deng and Daniel Krakowczyk and Tobias Scheffer and Lena A. J{\\\"a}ger},\n  title     = {{SP-EyeGAN}: {G}enerating Synthetic Eye Movement Data with {G}enerative {A}dversarial {N}etworks},\n  booktitle = {Proceedings of the ACM Symposium on Eye-Tracking Research and Applications},\n  series    = {ETRA 2023},\n  year      = {2023},\n  publisher = {ACM},\n  doi       = {10.1145/3588015.3588410],\n}\n```\n"}
{"url": "https://github.com/Alaa-Noor/365DataScience_Course", "owner": "Alaa-Noor", "repository_name": "365DataScience_Course", "date_all_variable_collection": "2023-09-10", "description": null, "size": 849, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Alaa-Noor", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# 365DataScience_Course"}
{"url": "https://github.com/Alaa-Noor/Loan-Defaulters-Prediction-using-Lending-Club-Data", "owner": "Alaa-Noor", "repository_name": "Loan-Defaulters-Prediction-using-Lending-Club-Data", "date_all_variable_collection": "2023-09-10", "description": null, "size": 322, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Alaa-Noor", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 733837}], "readme": "# Loan Defaulters Prediction using Lending Club Data\n \n"}
{"url": "https://github.com/030jmk/CIObund", "owner": "030jmk", "repository_name": "CIObund", "date_all_variable_collection": "2023-09-11", "description": "AR Bund", "size": 72, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "030jmk", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# CIObund\n\n## Architekturrichtlinie f\u00fcr die IT des Bundes:\n\nhttps://www.cio.bund.de/Web/DE/Architekturen-und-Standards/Architekturrichtlinie-IT-Bund/architekturrichtlinie_it_bund_node.html\n\nhttps://www.cio.bund.de/SharedDocs/Publikationen/DE/Architekturen-und-Standards/architekturrichtlinie_it_bund_2020.pdf;jsessionid=DE636047F2E34F969406AC0A25B9401E.1_cid340?__blob=publicationFile"}
{"url": "https://github.com/030jmk/genAI-telephone", "owner": "030jmk", "repository_name": "genAI-telephone", "date_all_variable_collection": "2023-09-11", "description": "A retrofitted rotary dial phone with speech-to-text, a generative pre-trained transformer and text-to-speech", "size": 47, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "030jmk", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 20106}], "readme": "# genAI-telephone\nA retrofitted rotary dial phone with speech-to-text, a generative pre-trained transformer and text-to-speech.\n\n\n## Description\n\nThe telephone is a fun project that utilizes a retrofitted rotary telephone as a tangible, tactile interface for artificial intelligence. Built upon technologies such as OpenAI\u2019s Whisper API, which solves speech-to-text tasks, GPT-3.5, a fined-tuned version of the GPT3 (Generative Pre-Trained Transformer) model, Azure's Text to speech REST API, and a Raspberry Pi Zero W, 3b or 4.\n\n## Motivation\n\nThe motivation behind GenAI-Telephone stemmed from a desire to diverge from traditional, screen-based interfaces that are the most familiar of digital interfaces in our modern lives. By repurposing a nostalgic rotary telephone, my goal is to invoke the past to interact with the technology of the present, allowing users to experience the capabilities of AI magic in a differntly engaging and refreshing manner. It is supposed to be a conversations starter on the topics of user interfaces, user experiences, AI safety, chat bots and their personas, as well as circularity of prototypes and demonstrators. \n\n## Dependencies (hardware and services)\n\n- OpenAI's Whisper API (alternative: ![self hosted whisper](https://github.com/openai/whisper)) and GPT-3.5 (alternative: llama2) for speech recognition and text generation\n- Azure's Text-To-Speech API for clear and natural language output (alternative: ![coqui TTS](https://github.com/coqui-ai/TTS))\n- Raspberry Pi Zero W or 3b and later\n- a rotary telephone\n- a microphone from an old headset\n- 2in1 mic/audio USB adapter\n- TRRS Audio Male to 4-Pin screw terminal\n- soldering iron\n\n## Installation (Hardware)\n\n- disassemble the telephone, making sure that none of the plastics get damaged in the process.\n\n<img src=\"https://user-images.githubusercontent.com/12104518/258658876-311430c0-ae15-4ffb-b96b-73c940ffb540.jpg\" alt=\"disassembled telephone\" width=\"350\">\n\n- take out the inner parts of the telephone. For it, we will need a screwdriver and some wiggling around of the parts.\n\n<img src=\"https://user-images.githubusercontent.com/12104518/258658853-d754b0f4-fbd8-4de3-b709-d1b16471a687.jpg\" alt=\"plastic shell\" width=\"350\">\n\n- It can be advantageous to desolder some of the pins and electronics in order to gain room for the raspberry pi.\n  \n<img src=\"https://user-images.githubusercontent.com/12104518/258658940-dbcd8d0b-19a0-43ef-ba99-4e563478fc55.jpg\" alt=\"desoldered\" width=\"350\">\n\n- prepare some female-to-female GPIO cables\n\n<img src=\"https://user-images.githubusercontent.com/12104518/258658950-9252fbc0-d23b-49ba-9018-1e68db8ae401.jpg\" alt=\"pins\" width=\"350\">\n\n- and solder them to the rotary dial (yellow and green), button (green and brown), spring mechanism of the switch hook (which ever connections act as a button)\n\n<img src=\"https://user-images.githubusercontent.com/12104518/258659070-3c1d15f8-7c62-4d22-82dc-3abafd8450f2.jpg\" alt=\"colors\" width=\"350\">\n\n\n![blink](https://github.com/030jmk/genAI-telephone/assets/12104518/46dc766c-8c7d-4dc1-a9d2-a95cd705320e)\n\n- connect the cables of the handset to the TRRS Audio Male to 4-Pin screw terminal, plug the TRRS pin into the USB adapter and connect the adapter to the USB connection of the pi.\n- find the ground pins for the raspberry pi.\n- the rotary dial should be connected to GPIO pin 2\n- the black button should be connected to GPIO pin 3\n- the switch hook spring/button should be GPIO pin 26\n\n## Dependencies (OS, Python)\nOnce Raspian and the usual updates are installed using \n\n    sudo apt update && sudo apt -y upgrade\nthe following dependencies should be installed:\n\n    sudo apt install -y python3-pip python3-scipy python3-rpi.gpio sox gnuplot libsox-fmt-all ffmpeg libasound-dev libportaudio2 && pip install requests playsound numpy sounddevice Unidecode \n\ntest the mic set up once everything is connected:\n\n    arecord -f cd -c 1 -r 44100 | sox -t raw -r 44100 -e signed -b 16 -c 1 -V - -t raw - | gnuplot -persist -e \"set xlabel 'Time'; set ylabel 'Amplitude'; plot '-' with lines\"\n\n\nWhile waiting for an answer from the phone, elevator music may be used. \"Yesterday (Jazz Elevator)\" by Monument_Music is used for the current code:\n    \n    https://pixabay.com/de/music/bossa-nova-yesterday-jazz-elevator-147660/\n\n\n## Basic Storyline\n|    \t| Sound           \t| Story                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \t| Activity \t|\n|----\t|-----------------\t|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\t|----------\t|\n| 00  \t|                 \t|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \t| PICK UP  \t|\n| 01  \t| dual_tone       \t|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \t|          \t|\n| 02  \t|                 \t| \"Hello and thank you for giving this demo a try. My name is Whisper and i will guide you through this experience. In a moment will ask you to dial a number from the rotary in front of you. Each of the numbers correspond with a preconfigured persona and if you were to ask a different persona the same question, you should be able to hear different answers. I will give you a couple of seconds to make your selection after the audible beep sound. Please only dial one number.\"      \t|          \t|\n| 03  \t| beep            \t|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \t|          \t|\n| 04  \t|                 \t|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \t| USE DIAL \t|\n| 05  \t| beep            \t|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \t|          \t|\n| 06  \t|                 \t| \"It would seem that you have made your decision. You have dialed {}. With the following beep I will relay your message or question according to your selection. I will again give you a couple of seconds to speak your message into the handset. Once you are done speaking, i will wait two seconds and relay your message with the second beep. If for some reason you cant hear that second beep, press the black button to the right of the dial. Get ready for the beep in 3... 2... 1...\" \t|          \t|\n| 07  \t| beep            \t|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \t|          \t|\n| 08  \t|                 \t| \"I will relay our message. Let us wait a few seconds until we get a response. Please hold.\"                                                                                                                                                                                                                                                                                                                                                                                                      \t| SPEAK    \t|\n| 09  \t| elevator_music  \t|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \t|          \t|\n| 10 \t|                 \t| \"It would seem that we have received an answer. Here it is.\"                                                                                                                                                                                                                                                                                                                                                                                                                                     \t|          \t|\n| 11 \t| answer          \t|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \t|          \t|\n| 12 \t|                 \t| \"And that is it. Thank you for trying this short demonstration. If you like to give it another go, put down the handset back onto the switch hook and lift it up again after a few seconds. If you are done, place the handset onto the switch hook and leave the cabin once you are ready. Thank you and have a pleasant day.\"                                                                                                                                                                  \t|          \t|\n| 13 \t| congestion_tone \t|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \t|          \t|\n|    \t|                 \t|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \t| PUT DOWN \t|\n\n\n## In Action\nThe demo was presented at [Berlin Hack & Tell #89](https://berlinhackandtell.rocks/2023-07-25-no89-camping-hacks) 2023-07-25 and can now be tested and seen at the PwC Experience Center in Berlin.\n\n<img src=\"https://user-images.githubusercontent.com/12104518/258660552-dcf21ca2-a04a-49a1-97af-d41b795c0510.png\" alt=\"colors\" width=\"350\"> <img src=\"https://user-images.githubusercontent.com/12104518/258660575-2870c7c1-7ac7-4cc0-963b-05ddde5aabd0.jpg\" alt=\"colors\" width=\"350\">\n\n\n\n\n\n\n\n\n"}
{"url": "https://github.com/030jmk/gntm", "owner": "030jmk", "repository_name": "gntm", "date_all_variable_collection": "2023-09-11", "description": "scraped Instagram follower count for GNTM contestants", "size": 2374, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "030jmk", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 5078}]}
{"url": "https://github.com/030jmk/gntm2019", "owner": "030jmk", "repository_name": "gntm2019", "date_all_variable_collection": "2023-09-11", "description": "gntm 2019", "size": 638343, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "030jmk", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 920}]}
{"url": "https://github.com/030jmk/publicAmenitiesBerlin", "owner": "030jmk", "repository_name": "publicAmenitiesBerlin", "date_all_variable_collection": "2023-09-11", "description": "Telegram Bot to find the closest public amenity for urgent needs", "size": 196, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "030jmk", "contributions": 13}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 726646}, {"language": "Python", "num_chars": 10437}]}
{"url": "https://github.com/030jmk/python_telegram_bots", "owner": "030jmk", "repository_name": "python_telegram_bots", "date_all_variable_collection": "2023-09-11", "description": "cluster of personal telegram bot projects to fix everyday micro annoyances", "size": 8, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Apache License 2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "030jmk", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 5804}], "readme": "# python_telegram_bots\ncluster of personal telegram bot projects to fix everyday micro annoyances\n"}
{"url": "https://github.com/030jmk/ScrapingInstagram", "owner": "030jmk", "repository_name": "ScrapingInstagram", "date_all_variable_collection": "2023-09-11", "description": "Scrape Instagram posts using a specified hashtag and save them to a csv file for later analysis.", "size": 12173, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "030jmk", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 496642}, {"language": "Python", "num_chars": 6677}]}
{"url": "https://github.com/87surendra/clarkson", "owner": "87surendra", "repository_name": "clarkson", "date_all_variable_collection": "2023-09-11", "description": null, "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/87surendra/deep-learning-drone", "owner": "87surendra", "repository_name": "deep-learning-drone", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1976, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "87surendra", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 3386970}, {"language": "Python", "num_chars": 10272}]}
{"url": "https://github.com/87surendra/Python_DS_Lect", "owner": "87surendra", "repository_name": "Python_DS_Lect", "date_all_variable_collection": "2023-09-11", "description": null, "size": 85663, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 35230484}]}
{"url": "https://github.com/87surendra/Random-Forest-Image-Classification-using-Python", "owner": "87surendra", "repository_name": "Random-Forest-Image-Classification-using-Python", "date_all_variable_collection": "2023-09-11", "description": "Random Forest Image Classification using Python", "size": 470, "stargazers_count": 19, "watchers_count": 19, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 17, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 17, "open_issues": 0, "watchers": 19, "default_branch": "master", "contributors": [{"contributor": "87surendra", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 620401}, {"language": "Python", "num_chars": 7020}], "readme": "# Random-Forest-Image-Classification-using-Python\nRandom Forest Image Classification using Python\n\nPlease follow below folder structure.\n\n\n\n<ul>\n  <li>image-classification (folder)</li>\n    <ul>\n      <li>dataset (folder)</li>\n      <ul>\n        <li>train (folder)</li>\n          <ul>\n            <li>Image Cat1 Folder</li>\n              <ul>\n                <li>train_img.jpg</li>\n                <li>train_img.jpg</li>\n                <li>train_img.jpg</li>\n                <li>.......</li>\n              </ul>\n            <li>Image Cat2 Folder</li>\n            <ul>\n                <li>train_img.jpg</li>\n                <li>train_img.jpg</li>\n                <li>train_img.jpg</li>\n                <li>.......</li>\n              </ul>\n          </ul>  \n        <li>test (folder)</li>\n          <ul>\n             <li>test_img.jpg</li>\n             <li>test_img.jpg</li>\n             <li>test_img.jpg</li>\n             <li>.......</li>\n           </ul>\n      </ul> \n     <li>output (folder)</li> \n      <ul>\n          <li>data.h5</li>\n          <li>labels.h5</li>\n       </ul> \n    <li>random_fo_image.py</li>\n    </ul> \n</ul>\n\n\n"}
{"url": "https://github.com/a-moi/disaster-tweets", "owner": "a-moi", "repository_name": "disaster-tweets", "date_all_variable_collection": "2023-09-11", "description": "Notebooks with codes used for the Kaggle competition \"Real or Not? NLP with Disaster Tweets\"", "size": 47, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "a-moi", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 265954}], "readme": "# disaster-tweets\nThis repository contains notebooks with codes used for the Kaggle competition \"Real or Not? NLP with Disaster Tweets\"\n\n*The competition description*\n\nTwitter has become an important communication channel in times of emergency.\nThe ubiquitousness of smartphones enables people to announce an emergency they\u2019re observing in real-time. Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).\nThe **goal** of the present competition is to predict which Tweets are about real disasters and which one\u2019s aren\u2019t. \n\nThe team: Mazunina Zoya, Minnigulova Alina, Poyaganova Maria \n\nPreprocessing: SpaCy. \nWord representation techniques used: tf-idf, word2vec.\nModels used: Logistic Regression, Sequential, CNN.\nTransformer models used: RoBERTa, Albert.\nThe best score achieved: **0.82** on **RoBERTa Large** \n\nThe repository contains 2 notebooks:\n1) basic.ipynb - the implementation of simple word representations, LogReg and NN models.  \n2) transfer.ipynb - the implementation of trasfer-learning techniques. \nThe notebooks include comments in Russian. \n\nThe data can be found on the page of the competition (https://www.kaggle.com/c/nlp-getting-started/data) \n\n"}
{"url": "https://github.com/a-moi/political-argument-mining", "owner": "a-moi", "repository_name": "political-argument-mining", "date_all_variable_collection": "2023-09-11", "description": "Mining arguments in political discourse with BERT and RoBERTa. We also present a new corpus of UNSC speeches annotated wrt their argumentative structure", "size": 8190, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "a-moi", "contributions": 48}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["argument-mining", "claim-detection", "natural-language-processing"], "languages": [{"language": "Jupyter Notebook", "num_chars": 435594}, {"language": "Python", "num_chars": 6167}], "readme": "# Mining Arguments in Political Domain with Transformer Language Models \n\n## Project description \n\nThis repository was developed as part of the Master's individual research project carried out at the University of Potsdam, Germany. Please find our detailed report [here](https://github.com/a-moi/political-argument-mining/blob/main/report.pdf). \n\n**Abstract**\n\n\nThis project is focused on argumentation\nmining framed through the tasks of argument\ndetection (predict whether the utterance\nis an argument or not) and argument\ncomponent identification (predict whether\nthe argumentative utterance is a claim or\na premise). We implement BERT and\nRoBERTa models and approach both tasks\non the sentence-level. The second task,\ncomponent identification, is also modelled\non the argumentative discourse unit level.\nTo train and test our models, we use a\nlarge-scale corpus of the US presidential\ndebates data (Haddadan et al., 2019). Additionally,\nwe study models\u2019 generalizability\nto the data within the same domain.\nFor that, we collect and manually annotate\na novel dataset of diplomatic speeches\npresented in the United Nations Security\nCouncil.\n\n\n## Corpora \n\nFor our experiments, we use two corpora. \n\n1. [USElecDeb](https://github.com/a-moi/political-argument-mining/tree/main/ElecDeb60To16) contains speeches of presidential debates in the US from the years 1960 to 2016. The corpus is annotated according to argumentative structure of speeches and contains such labels as claims and premises. The dataset was introduced in this [paper](https://aclanthology.org/P19-1463/). For the sentence-level experiments, we used only `sentence_db_candidate.csv` file as it provides all the necessary texts along with labels and the original train, test and validation splits. \n\n2. [UC-UNSC](https://github.com/a-moi/political-argument-mining/tree/main/UC-UNSC) As part of the project, we develop a novel corpus of argument annotations. We retrive diplomatic speeches given during gatherings of the UNSC. We select 144 speeches from 2014 to 2018, dedicated to the conflict in Ukraine. We name it UC(Ukraine Conflict)-UNSC. The speeches were annotated analogically to USElecDeb and the labels include claims, premises or none of these. \n\nWe provide 144 pairs of raw data: original .txt files and .xmi files with their respective annotations, retrived from Inception. Additionally, we provide two ready-to-use datasets. The file `sentence_full.csv` contains the following columns: sentences, final labels (claims or premises or none) and detailed labels, i.e., per each sentence, we list all its components along with their length. This length measure was used to give the final label to a sentence, since some sentences contained both a claim and a premise, and we made the decision in favor of the longer component. The file `component_full.csv` includes two columns: the component (original span, not always a sentence) and its label. \n\nTwo python [functions](https://github.com/a-moi/political-argument-mining/blob/main/annotation2df.py) were developed to map .xmi files from Inception and the original .txt files. The outputs are ready-to-use .csv files. \n\n## Reproduction and running on your data \n\nWe use `bert-for-sequence-classification` Python [framework](https://pypi.org/project/bert-for-sequence-classification/) to fine-tune BERT and RoBERTa models. We attach three Python notebooks, each representing a different problem setting: 1) classification of arg vs non-arg the sentence-level; 2) classification of claims and premises on the sentence-level; 3) classification of claims and premises on the ADU-level. \n\nTo reproduce the models, we recommend using Google Colab which enables free GPU unit. \n- Load a notebook into your Colab env, then load and prepare the data.\n- To change RoBERTa to BERT, simply amend the config by selecting a model you want to use. We experimented with `chkla/roberta-argument`, `roberta-base` and `bert-base-uncased`, depending on the task. We also attach `hyperparams.csv` with all the parameters and settings we used at each experiment, to facilitate reproduction. \n"}
{"url": "https://github.com/a-moi/tbbt-character-detection", "owner": "a-moi", "repository_name": "tbbt-character-detection", "date_all_variable_collection": "2023-09-11", "description": null, "size": 622, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "a-moi", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 892921}], "readme": "# tbbt-character-detection"}
{"url": "https://github.com/Abdelwahab86/Ahmed", "owner": "Abdelwahab86", "repository_name": "Ahmed", "date_all_variable_collection": "2023-09-11", "description": null, "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/Abdelwahab86/DEM-Analysis", "owner": "Abdelwahab86", "repository_name": "DEM-Analysis", "date_all_variable_collection": "2023-09-11", "description": "A robot powered training repository :robot:", "size": 3538, "stargazers_count": 0, "watchers_count": 0, "language": "Ruby", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "Abdelwahab86-patch-2", "contributors": [{"contributor": "githubteacher", "contributions": 15}, {"contributor": "hectorsector", "contributions": 8}, {"contributor": "Abdelwahab86", "contributions": 4}, {"contributor": "brianamarie", "contributions": 2}, {"contributor": "JasonEtco", "contributions": 2}, {"contributor": "dependabot[bot]", "contributions": 2}, {"contributor": "snyk-bot", "contributions": 2}, {"contributor": "carolynshin", "contributions": 1}, {"contributor": "crichID", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Ruby", "num_chars": 7522}, {"language": "HTML", "num_chars": 3039}, {"language": "Shell", "num_chars": 2193}], "readme": "# Your GitHub Learning Lab Repository for Introducing GitHub\n\nWelcome to **your** repository for your GitHub Learning Lab course. This repository will be used during the different activities that I will be guiding you through. See a word you don't understand? We've included an emoji \ud83d\udcd6 next to some key terms. Click on it to see its definition.\n\nOh! I haven't introduced myself...\n\nI'm the GitHub Learning Lab bot and I'm here to help guide you in your journey to learn and master the various topics covered in this course. I will be using Issue and Pull Request comments to communicate with you. In fact, I already added an issue for you to check out.\n\n![issue tab](https://lab.github.com/public/images/issue_tab.png)\n\nI'll meet you over there, can't wait to get started!\n\nThis course is using the :sparkles: open source project [reveal.js](https://github.com/hakimel/reveal.js/). In some cases we\u2019ve made changes to the history so it would behave during class, so head to the original project repo to learn more about the cool people behind this project.\n"}
{"url": "https://github.com/Abdelwahab86/Water-polygons-photogrammetry", "owner": "Abdelwahab86", "repository_name": "Water-polygons-photogrammetry", "date_all_variable_collection": "2023-09-11", "description": "My master thesis at Potsdam University", "size": 1383, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "Abdelwahab86", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 1890254}], "readme": "# Water-polygons-photogrammetry\n## Supervised By : Prof. Guido Grosse and Dr. Ingmar Nitze\n## Author        : Ahmed Abdelwahab\nMy master thesis at Potsdam University\n"}
{"url": "https://github.com/abrarhasinkml/Bangla2EnglishNumberConversion", "owner": "abrarhasinkml", "repository_name": "Bangla2EnglishNumberConversion", "date_all_variable_collection": "2023-09-11", "description": "A simple function that converts Bengali numbers to their English coefficients", "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "abrarhasinkml", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["bangla", "bangla-number", "bengali", "bengali-number", "english", "number-converter", "python", "python3"], "languages": [{"language": "Python", "num_chars": 1207}], "readme": "A simple python function that takes in a list of Bengali integer numbers and returns a list containing the English counterparts of the input list.\nSingle integers can also be passed into the function, but will need to be joined using the join() function."}
{"url": "https://github.com/abrarhasinkml/coinMarketCapAPI", "owner": "abrarhasinkml", "repository_name": "coinMarketCapAPI", "date_all_variable_collection": "2023-09-11", "description": "A crypto currency tracker app to monitor the currencies of interest. This is a v1 version.", "size": 4, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "abrarhasinkml", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 1288}], "readme": "# coinMarketCapAPI\n\nA crypto currency tracker app to monitor the currencies of interest. This is a v1 version.\nCurrently the quotes latest API is used to get the information required from Coin Market Cap.\n"}
{"url": "https://github.com/abrarhasinkml/Command-Based-Text-Editor", "owner": "abrarhasinkml", "repository_name": "Command-Based-Text-Editor", "date_all_variable_collection": "2023-09-11", "description": "A command based text editor done in C++ as a project for Object Oriented Programming Course", "size": 279, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "abrarhasinkml", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 7864}], "readme": "# Command-Based-Text-Editor\n\nThis command based text editor was done as a project for the Object Oriented Programming Course. The commands are descripted below.\n\n\nCOMMAND MODE\n\nesc= switches to Insert Mode\ns= saves file to data.txt\nc= counts the number of characters input\nn= cursor jumps to new line\nu= cursor moves up\nd= cursor moves down\nl= cursor moves left\nr= cursor moves right\no= obtains text from data.txt file\nb= cursor moves to the bottom line of Insert Mode\nm= text moves to the bottom of Insert Mode\ng= cursor moves back up top to Insert Mode\nx= asks the user for a line number and jumps to it\ny= asks the user for a column number and jumps to it\nw= clears the screen\nq= exits the application\n\nINSERT MODE\n\nesc= switches to Command Mode\n/ = option to append new text with previously entered text.\nbackspace = cursor moves left under desired character to enable replace function\ntab= press twice to delete one by one character to the left\n"}
{"url": "https://github.com/abrarhasinkml/COVID-19BD", "owner": "abrarhasinkml", "repository_name": "COVID-19BD", "date_all_variable_collection": "2023-09-11", "description": "A simple visualization script using Plotly to convert the numerical data from IEDCR's website into interactive plots. The data has been scraped from IEDCR's COVID dashboard and some additional data has been added. If you are running the plotting script from a jupyter notebook, the .show() function will suffice. For offline view in IDE's like Spyder, the plot() function has also been written which generates a temporary html file consisting of the plot. ", "size": 16032, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "abrarhasinkml", "contributions": 46}, {"contributor": "tusher16", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 312261}, {"language": "CSS", "num_chars": 299968}, {"language": "PHP", "num_chars": 57275}, {"language": "TSQL", "num_chars": 25766}, {"language": "Python", "num_chars": 23373}, {"language": "HTML", "num_chars": 1414}, {"language": "Hack", "num_chars": 781}], "readme": "# COVID-19BD\nA simple visualization script using Plotly to convert the numerical data from IEDCR's website into interactive plots. The data has been scraped from IEDCR's COVID dashboard and some additional data has been added. If you are running the plotting script from a jupyter notebook, the .show() function will suffice. For offline view in IDE's like Spyder, the plot() function has also been written which generates a temporary html file consisting of the plot. \n"}
{"url": "https://github.com/abrarhasinkml/cse480moviesonthegobd", "owner": "abrarhasinkml", "repository_name": "cse480moviesonthegobd", "date_all_variable_collection": "2023-09-11", "description": "My final project for CSE-480 (Web Technology). Movies on the go Bangladesh is basically an informative site which has all the information regarding movie schedules in the most popular halls in Dhaka. ", "size": 2633, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "abrarhasinkml", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 62022}, {"language": "CSS", "num_chars": 43474}, {"language": "HTML", "num_chars": 29311}]}
{"url": "https://github.com/abrarhasinkml/Image-recognition-using-softmax", "owner": "abrarhasinkml", "repository_name": "Image-recognition-using-softmax", "date_all_variable_collection": "2023-09-11", "description": "A simple softmax script that learns from the CIFAR-10 dataset. Accuracy is about 24%.", "size": 10, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "abrarhasinkml", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 8810}], "readme": "# Image-recognition-using-softmax\nA simple softmax script that learns from the CIFAR-10 dataset. Accuracy is about 24%.\nFollowed wolflib's article to write the script\nCIFAR-10 Dataset used https://www.cs.toronto.edu/~kriz/cifar.html\n"}
{"url": "https://github.com/abrarhasinkml/kotha-BSLR", "owner": "abrarhasinkml", "repository_name": "kotha-BSLR", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1102968, "stargazers_count": 0, "watchers_count": 0, "language": "PureBasic", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "abrarhasinkml", "contributions": 33}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PureBasic", "num_chars": 23618}, {"language": "Python", "num_chars": 4792}], "readme": "kotha- A Bengali Sign Language Recognition System\na Bangla Sign Language Recognizer to ease up the communication gap between the Deaf & Mute and the general people. The python script consists\nthe first model used to train our system. \n"}
{"url": "https://github.com/abrarhasinkml/MovieApp", "owner": "abrarhasinkml", "repository_name": "MovieApp", "date_all_variable_collection": "2023-09-11", "description": "A Movie searching application created using React-Native", "size": 174, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "abrarhasinkml", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 8891}], "readme": "# MovieApp\nA movie searching application created using React-Native.\nIt is expected that you have the following versions are installed: Node: v14.16.1+, npm: 6.14.12 & react-native: 0.64.0\n\nClone the repository and run: `npm install` \nto install the necessary libraries from the package.json file. For development purposes, expo has been used. To run the application the following command has to be executed: `npm start`\n\nThe movie app greets users with a search screen where users can search for any movie in the OMDb database. The application returns a list of movies matching the search query. Upon clicking on the title of the movie, users are redirected to a new page where they can view further details of the movie (ie. title, cast, director, genre, poster etc.)\n\n\nThe OMDb API has been used for this project: http://www.omdbapi.com/"}
{"url": "https://github.com/abrarhasinkml/RandomMusicPlayer", "owner": "abrarhasinkml", "repository_name": "RandomMusicPlayer", "date_all_variable_collection": "2023-09-11", "description": "Testing out Selenium webdriver by making a script that randomly plays Salman Khan songs", "size": 4272, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "abrarhasinkml", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 1498}], "readme": "# RandomMusicPlayer\nTesting out Selenium webdriver by making a script that randomly plays Salman Khan songs\n\nYou will require a Python environment to run the code. Names of a few songs are already extracted and stored in the csv file, so the namesExtractor script is not required to be executed. \nThe chromedriver executable is added in the repository. Update it if you have a newer version of chrome and make the necessary changes in your code.\nA pretty simple script that doesn't do much but play his songs randomly.\n"}
{"url": "https://github.com/abrarhasinkml/restaurantmanagementsystem", "owner": "abrarhasinkml", "repository_name": "restaurantmanagementsystem", "date_all_variable_collection": "2023-09-11", "description": "A Restaurant management system i did for my Java project during my 6th semester. The system can generate excel files for reports and can store in a database.", "size": 13522, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "abrarhasinkml", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 72938}], "readme": "# restaurantmanagementsystem\nA Restaurant management system i did for my Java project during my 6th semester. The system can generate excel files for reports and can store in a database.\n"}
{"url": "https://github.com/abrarhasinkml/Textmage", "owner": "abrarhasinkml", "repository_name": "Textmage", "date_all_variable_collection": "2023-09-11", "description": "Textmage is a neural caption generator that can generate captions in Bengali for images that belong to the Bangladeshi domain. This project was done for my CSE499 project. The model has been referred from sachinkmrs Neural Image Captioning model.", "size": 4, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "abrarhasinkml", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 12491}]}
{"url": "https://github.com/Adrian-Abendroth/Adrian-Abendroth", "owner": "Adrian-Abendroth", "repository_name": "Adrian-Abendroth", "date_all_variable_collection": "2023-09-11", "description": "Config files for my GitHub profile.", "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "Adrian-Abendroth", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["config", "github-config"], "languages": [], "readme": "- \ud83d\udc4b Hi, I\u2019m @Adrian-Abendroth\n- \ud83d\udc40 I\u2019m interested in DevOps, IT-Architecture and Process Management.\n- \ud83c\udf31 I\u2019m currently learning Docker in order to make enhancements in ERP systems with Low-Code Application Platforms.\n- \ud83d\udc9e\ufe0f I\u2019m looking to collaborate on Open-Source Low-Code Application Platforms as well as Open Source ERP systems.\n- \ud83d\udceb How to reach me: kontakt@adrian-abendroth.com\n\n<!---\nAdrian-Abendroth/Adrian-Abendroth is a \u2728 special \u2728 repository because its `README.md` (this file) appears on your GitHub profile.\nYou can click the Preview link to take a look at your changes.\n--->\n"}
{"url": "https://github.com/Adrian-Abendroth/iterm2", "owner": "Adrian-Abendroth", "repository_name": "iterm2", "date_all_variable_collection": "2023-09-11", "description": "Profile settings for MacOS terminal iterm2 ", "size": 5, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "Adrian-Abendroth", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# iterm2\nProfile settings for MacOS terminal iterm2 \n\n\n"}
{"url": "https://github.com/Adrian-Abendroth/OCaml-DFA-Equivalence", "owner": "Adrian-Abendroth", "repository_name": "OCaml-DFA-Equivalence", "date_all_variable_collection": "2023-09-11", "description": "This is an OCaml program to check whether two DFA's are equivalent and minimize them. It uses the Table-Filling Algorithm.", "size": 865, "stargazers_count": 0, "watchers_count": 0, "language": "OCaml", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "DrDragonKiller", "contributions": 54}, {"contributor": "Adrian-Abendroth", "contributions": 50}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "OCaml", "num_chars": 29535}], "readme": "# OCaml-DFA-Equivalence\n\nThis is an OCaml program to check whether two DFA's are equivalent and minimize them. It uses the Table-Filling Algorithm.\n\nTo see how the program works, see: <br />\nhttps://github.com/Adrian-Abendroth/OCaml-DFA-Equivalence/blob/master/documentation/1.method.md\n\n### Set-Up\nTo start the program, you need to instal OCaml.\nPlease follow this guide here: <br />\nhttps://ocaml.org/docs/install.html\n\n### Compiling and Running\nAfter you installed OCaml on your machine, you need to compile the program in your terminal with:\n```\nocamlc -o NameOfCompilatedFile program.ml\n```\n<br />\n\nNow you can execute the compiled file in your terminal with:\n```\n./NameOfCompilatedFile\n```\n"}
{"url": "https://github.com/Adrian-Abendroth/SharedBox-Ultimate", "owner": "Adrian-Abendroth", "repository_name": "SharedBox-Ultimate", "date_all_variable_collection": "2023-09-11", "description": "SharedBox-Ultimate Projekt fuer die Uni", "size": 31, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Adrian-Abendroth", "contributions": 17}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 9203}], "readme": "# SharedBox-Ultimate\n\n## Beschreibung\nUniversit\u00e4tsprojekt f\u00fcr das Fach Software Engineering der Universit\u00e4t Potsdam.\nWeitere Informationen unter: https://www.uni-potsdam.de/en/cs-se/teaching.html\n\n## Setups\nhttps://github.com/Adrian-Abendroth/SharedBox-Ultimate/wiki/Setup-Dev-Env\n"}
{"url": "https://github.com/Adrian-Abendroth/single-machine-scheduling-eed", "owner": "Adrian-Abendroth", "repository_name": "single-machine-scheduling-eed", "date_all_variable_collection": "2023-09-11", "description": "Single Machine Scheduling Early Due Date (EED) in Javascript programmed", "size": 13, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "Adrian-Abendroth", "contributions": 4}, {"contributor": "valentindoering", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 5602}], "readme": "# Description\nScheduling algorithm programmend in Javascript for single machine scheduling (only one worker) optimized for \n1. least delay\n2. earliest finish of all jobs \n\n# Usage\nIn the [/scr folder](https://github.com/Adrian-Abendroth/single-machine-scheduling-eed/blob/main/src/scheduleSingleMachineEDD.js), you will find the main file executing the algorithm.\n<br/>\nIn the [/data folder](https://github.com/Adrian-Abendroth/single-machine-scheduling-eed/blob/main/data/exampleJobs.json), you can find a data example, which you can adapt and change. It uses a JSON file.\n"}
{"url": "https://github.com/Adrian-Abendroth/zsh", "owner": "Adrian-Abendroth", "repository_name": "zsh", "date_all_variable_collection": "2023-09-11", "description": "Personal file for shell zsh", "size": 3, "stargazers_count": 0, "watchers_count": 0, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "Adrian-Abendroth", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 3914}], "readme": "# zsh\nPersonal file for shell zsh\n"}
{"url": "https://github.com/Adrian-Ziupka/ba-thesis", "owner": "Adrian-Ziupka", "repository_name": "ba-thesis", "date_all_variable_collection": "2023-09-11", "description": "My bachelor thesis about evaluating pavement distress of point clouds.", "size": 77840, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "scheibel", "contributions": 23}, {"contributor": "karyon", "contributions": 9}, {"contributor": "Adrian-Ziupka", "contributions": 4}, {"contributor": "soerendischer", "contributions": 3}, {"contributor": "cgcostume", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 779596}, {"language": "PostScript", "num_chars": 68010}, {"language": "GLSL", "num_chars": 1199}, {"language": "Shell", "num_chars": 201}]}
{"url": "https://github.com/Adrian-Ziupka/noodle-bot", "owner": "Adrian-Ziupka", "repository_name": "noodle-bot", "date_all_variable_collection": "2023-09-11", "description": "A telegram bot providing information about today's dishes at the canteen of the University of Potsdam.", "size": 7, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Adrian-Ziupka", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 3510}], "readme": "# noodle-bot\nA telegram bot providing information about today's dishes at the canteen of the University of Potsdam.\n\ntelegram username: @noodle_up_bot\n\n## commands\n\n- /noodles : Get an overview of all today's dishes (not only noodles ;))\n"}
{"url": "https://github.com/aeye-lab/ecml-ADHD", "owner": "aeye-lab", "repository_name": "ecml-ADHD", "date_all_variable_collection": "2023-09-11", "description": null, "size": 702534, "stargazers_count": 6, "watchers_count": 6, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 6, "default_branch": "main", "contributors": [{"contributor": "Shuwen27", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 65841}, {"language": "Shell", "num_chars": 3454}], "readme": "# Detection of ADHD based on Eye Movements during Natural Viewing\n[![paper](https://img.shields.io/static/v1?label=paper&message=download%20link&color=brightgreen)](https://arxiv.org/abs/2207.01377)\n\nIn this paper, we explore whether Attention-deficit/hyperactivity disorder (ADHD) can be detected based on recorded eye movements together with information about the video stimulus in a free-viewing task\n\n## Setup\n\nClone repository:\n\n```\ngit clone git@github.com:aeye-lab/ecml-ADHD\n```\n\nor\n\n```\ngit clone https://github.com/aeye-lab/ecml-ADHD\n```\n\nand change to the cloned repo via `cd ecml-ADHD`.\n\n\nInstall dependencies:\n\n```\npip install -r requirements.txt\n```\n\n## Run Experiments\n\n### Prepare saliency maps\nPlease download videos from http://fcon_1000.projects.nitrc.org/indi/cmi_healthy_brain_network/EEG-Eyetracking%20Protocol.html, and break it down into frames (e.g. use ffmpeg packages) and put them under the folder /Data/videos/frames_{video_name}/\n\nWe use a state-of-the-art saliency model, DeepGazeII to compute salinecy maps for our video stimuli. Download the files you need to run the DeepGazeII model https://drive.google.com/file/d/1kYUwoatqQUS5EabeeSDc6gRmCysnVZ6N/view, and stored under the folder /DNN_model/DataGeneration/\n\nTo generate the saliency maps for all videos, run\n```\nbash gen_saliency_map_data.sh\n```\n\n### Prepare model input files\n\nTo generate model input files, run\n\n```\nbash gen_model_input_data.sh\n```\n\n### Run models\n\n```\nbash run_models.sh\n```\n\n\n## Cite our work\nIf you use our code for your research, please consider citing our paper:\n\n```bibtex\n@inproceedings{deng2023detection,\n  title={Detection of ADHD based on eye movements during natural viewing},\n  author={Deng, Shuwen and Prasse, Paul and Reich, David R and Dziemian, Sabine and Stegenwallner-Sch{\\\"u}tz, Maja and Krakowczyk, Daniel and Makowski, Silvia and Langer, Nicolas and Scheffer, Tobias and J{\\\"a}ger, Lena A},\n  booktitle={Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2022, Grenoble, France, September 19--23, 2022, Proceedings, Part VI},\n  pages={403--418},\n  year={2023},\n  organization={Springer}\n}\n```\n"}
{"url": "https://github.com/aeye-lab/etra-2023-bridging-the-gap", "owner": "aeye-lab", "repository_name": "etra-2023-bridging-the-gap", "date_all_variable_collection": "2023-09-11", "description": null, "size": 945, "stargazers_count": 2, "watchers_count": 2, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "main", "contributors": [{"contributor": "dkrako", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 1593819}, {"language": "Python", "num_chars": 330629}], "readme": "# Bridging the Gap: Gaze Events as Interpretable Concepts to Explain Deep Neural Sequence Models\n\n\nBefore running any experiments, please adjust the file source/config/basepaths.py to your own paths.\n\nTo run the experiments please first write the datasets into npy files and detect all events with the following command:\n\n```\npython -m datasets.write_gazebase\npython -m datasets.write_judo\npython -m datasets.write_potec\n```\n\n\nTo train the models on the datasets run the following commands:\n\n```\npython -m train --model=eky2 --data=gazebase\npython -m train --model=eky2 --data=judo\npython -m train --model=eky2 --data=potec\n```\n\n\nTo evaluate concept influences for fixations and saccades run:\n\n```\npython -m evaluate.segmentations --model=eky2 --data=gazebase --metric=etra23 --segmentation=etra23\npython -m evaluate.segmentations --model=eky2 --data=judo1000 --metric=etra23 --segmentation=etra23\npython -m evaluate.segmentations --model=eky2 --data=potec --metric=etra23 --segmentation=etra23\n```\n\n\nTo evaluate concept influneces for saccade sub-events run:\n\n```\npython -m evaluate.segmentations --model=eky2 --data=gazebase --metric=etra23 --segmentation=engbert.saccade_dissection_vpeak80\npython -m evaluate.segmentations --model=eky2 --data=judo1000 --metric=etra23 --segmentation=engbert.saccade_dissection_vpeak80\npython -m evaluate.segmentations --model=eky2 --data=potec --metric=etra23 --segmentation=engbert.saccade_dissection_vpeak80\n```\n\n\nTo evaluate concept influneces for saccade sub-events run:\n\n```\npython -m evaluate.segmentations --model=eky2 --data=gazebase --metric=etra23 --segmentation=engbert.saccade_binning_duration_n100\npython -m evaluate.segmentations --model=eky2 --data=judo1000 --metric=etra23 --segmentation=engbert.saccade_binning_amplitude_n100\npython -m evaluate.segmentations --model=eky2 --data=gazebase --metric=etra23 --segmentation=ivt.fixation_binning_dispersion_n100\npython -m evaluate.segmentations --model=eky2 --data=judo1000 --metric=etra23 --segmentation=ivt.fixation_binning_v_std_n100\n```\n"}
{"url": "https://github.com/aeye-lab/etra-fairness", "owner": "aeye-lab", "repository_name": "etra-fairness", "date_all_variable_collection": "2023-09-11", "description": null, "size": 39577, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "SiQube", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 14029819}, {"language": "Python", "num_chars": 139245}, {"language": "Shell", "num_chars": 13177}], "readme": "# Fairness in Oculomotoric Biometric Identification\n[![paper](https://img.shields.io/static/v1?label=paper&message=download%20link&color=brightgreen)](https://dl.acm.org/doi/10.1145/3517031.3529633)\n\nThis repo provides the code for reproducing the experiments in [Fairness in Oculomotoric Biometric Identification](https://doi.org/10.1145/3517031.3529633).\n\nIn the paper, we investigate the fairness of a biometric system based on eye-tracking data with respect to gender, ethnicity, and age.\n![DeepEyedentification embedding evolution animation](https://user-images.githubusercontent.com/43832476/170812609-cb6d8b5a-cfc1-4e03-928a-b39596871229.gif)\nThe figure above shows the embedding evolution of the DeepEyedentificationLive subnets across ethnicities.\n\n\n## Reproduce the experiments\n\n### Download the data\nYou can download the publicly available data here: [GazeBase, a large-scale, multi-stimulus, longitudinal eye movement dataset](https://figshare.com/articles/dataset/GazeBase_Data_Repository/12912257). The corresponding paper can be found [here](https://www.nature.com/articles/s41597-021-00959-y).\n\n### Clone this repository \nYou can clone this repository by either using \n```bash\ngit clone git@github.com:aeye-lab/etra-fairness\n```\nor \n```bash\ngit clone https://github.com/aeye-lab/etra-fairness\n```\ndepending on your preferences and settings.\nAfterward, change into the directory by using `cd etra-fairness`.\n\n### Install packages\nInstall all required python packages via:\n```bash\npip install -r requirements.txt\n```\n### Extract data\nAfter moving the zipped gazebase data download in the first step into the repository, extract all files by executing:\n```bash\npython3 extract_gazebase_data.py\n```\n\nThen you can directly start using the [DeepEyedentification](https://ecmlpkdd2019.org/downloads/paper/231.pdf) network by adjusting and executing the following scripts for the experiment you want to investigate. A description of the CLI arguments is available via `python3 deepEye_fairness_gazebase.py --help`.\n\nA list of all bash scripts used is below. Note: Running the experiments, especially on CPU, will take some time.\n### Pipeline [DeepEyedentification](https://ieeexplore.ieee.org/abstract/document/9555831)\n* run experiments:\n    * run_random_sampling_all_settings.sh\n    * run_experiment_age.sh\n    * run_experiments_VD1_VD2.sh\n    * run_experiments_RAN.sh\n    * run_experiments_HSS.sh\n    * run_experiments_FXS.sh\n    * run_experiments_BLG.sh\n    * run_experiments_TEX.sh\n* create score dicts:\n    * run_create_score_dicts.sh\n\nUnfortunately the [Lohr _et al._](https://ieeexplore.ieee.org/document/9304859) takes a bit more work. After downloading the data you have to adjust the following two scripts:\n* extract the eye movement events (fixation, saccades, PSO)\n    * adjust the path in the scripts from  [A novel evaluation of two related and two independent algorithms for eye movement classification during reading](https://digital.library.txstate.edu/handle/10877/6874). The paper can be found [here](https://link.springer.com/epdf/10.3758/s13428-018-1050-7).\n* adjust the statistical feature extraction: [Study of an Extensive Set of Eye Movement Features: Extraction Methods and Statistical Analysis](https://digital.library.txstate.edu/handle/10877/6904). The paper can be found [here](https://pubmed.ncbi.nlm.nih.gov/33828682/). Note, you don't only have to adjust the script to match your data path (the data created by MNH) but also such that the algorithm only takes one eye movement event as input instead of the complete sequence.\n\nAfterwards copy the data to `lohr_feature_data/`. You can execute all experiments with the bash scripts below. CLI options are available via  `python3 lohr_fairness_gazebase.py --help`.\n### Pipeline [Lohr _et al._](https://ieeexplore.ieee.org/document/9304859)\n* run experiments:\n    * run_experiments_lohr.sh\n    * run_experiments_lohr_adam_w.sh\n* create score dicts:\n    * run_create_score_dicts_lohr.sh\n\n### Calculate fairness metrics and visualize results\nYou can calculate the fairness metrics and visualize the results from your experiments with the notebooks: \n* Fairness:\n    * plot_results_deepEye.ipynb\n    * plot_results_lohr.ipynb\n* Visualize embeddings:\n    * plot_t-sne_visualization_deepEye.ipynb\n    * plot_t-sne_visualization_lohr.ipynb\n* Eye movement similarities for different demographics:\n    * inspect_differences.ipynb\n\n## Contribution\nIf you find any issues, please open an issue in the issue tracker.\n\nIf you want, you can also test your own oculomotoric biometric models substituting it within the piplines described above. \n\n\n## Cite our work\nIf you use our code for your research, please consider citing our paper:\n\n```bibtex\n@inproceedings{10.1145/3517031.3529633,\nauthor = {Prasse, Paul and Reich, David Robert and Makowski, Silvia and J\\\"{a}ger, Lena A. and Scheffer, Tobias},\ntitle = {Fairness in Oculomotoric Biometric Identification},\nyear = {2022},\nisbn = {9781450392525},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\ndoi = {10.1145/3517031.3529633},\nbooktitle = {2022 Symposium on Eye Tracking Research and Applications},\narticleno = {22},\nnumpages = {8},\nkeywords = {fairness, neural networks, biometrics},\nlocation = {Seattle, WA, USA},\nseries = {ETRA '22}\n}\n```\n"}
{"url": "https://github.com/aeye-lab/etra-reading-comprehension", "owner": "aeye-lab", "repository_name": "etra-reading-comprehension", "date_all_variable_collection": "2023-09-11", "description": null, "size": 135, "stargazers_count": 4, "watchers_count": 4, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 4, "default_branch": "main", "contributors": [{"contributor": "SiQube", "contributions": 57}, {"contributor": "pre-commit-ci[bot]", "contributions": 29}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 98374}, {"language": "Jupyter Notebook", "num_chars": 11244}], "readme": "Inferring Native and Non-Native Human Reading Comprehension and Subjective Text Difficulty from Scanpaths in Reading\n====================================================================================================================\n[![paper](https://img.shields.io/static/v1?label=paper&message=download%20link&color=brightgreen)](https://dl.acm.org/doi/abs/10.1145/3517031.3529639)\n\nThis repo provides the code for reproducing the experiments in [Inferring Native and Non-Native Human Reading Comprehension and Subjective Text Difficulty from Scanpaths in Reading](https://dl.acm.org/doi/abs/10.1145/3517031.3529639).\n\n![BEyeLSTM](https://user-images.githubusercontent.com/43832476/171489683-332d88ba-45f7-4f68-86dd-8288f52bd34c.png)\nThe figure above shows our architecture `BEyeLSTM`.\nWe investigate and show that we can generalize to unseen test persons for all tasks investigated.\n\n## Reproduce the experiments\n\n### Clone this repository\nYou can clone this repository by either using\n```bash\ngit clone git@github.com:aeye-lab/etra-reading-comprehension\n```\nor\n```bash\ngit clone https://github.com/aeye-lab/etra-reading-comprehension\n```\ndepending on your preferences and settings.\nAfterward, change into the directory by using `cd etra-reading-comprehension`.\n\n### Download the data\nYou can download the publicly available data here\n```bash\ngit clone git@github.com:ahnchive/SB-SAT\n```\nor\n```bash\ngit clone https://github.com/ahnchive/SB-SAT\n```\n\n### Install packages\nInstall all required python packages via:\n```bash\npip install -r requirements.txt\n```\n### Extract data\nYou can create the data splits using:\n```bash\npython3 utils/generate_text_sequence_splits.py\n```\n\nThen you can directly start using both BEyeLSTM and the baseline of [Ahn et al.](https://dl.acm.org/doi/10.1145/3379156.3391335) using `python3 nn/train_model.py` or `python3 ahn_baseline/evaluate_ahn_baseline.py` respectively. By changing the boolean arguments in `nn/train_model.py` you can recreate our ablation study or use different subnets only.\n\nNote: Running the experiments, especially on CPU, will take some time.\n\n## Contribute\nIf you find any issues, please open an issue in the issue tracker.\n\n## Cite our work\nIf you use our code for your research, please consider citing our paper:\n\n```bibtex\n@inproceedings{10.1145/3517031.3529639,\nauthor = {Reich, David Robert and Prasse, Paul and Tschirner, Chiara and Haller, Patrick and Goldhammer, Frank and J\\\"{a}ger, Lena A.},\ntitle = {Inferring Native and Non-Native Human Reading Comprehension and Subjective Text Difficulty from Scanpaths in Reading},\nyear = {2022},\nisbn = {9781450392525},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\ndoi = {10.1145/3517031.3529639},\nbooktitle = {2022 Symposium on Eye Tracking Research and Applications},\narticleno = {23},\nnumpages = {8},\nkeywords = {deep learning, reading comprehension, eye tracking-while-reading},\nlocation = {Seattle, WA, USA},\nseries = {ETRA '22}\n}\n```\n"}
{"url": "https://github.com/aeye-lab/Eyettention", "owner": "aeye-lab", "repository_name": "Eyettention", "date_all_variable_collection": "2023-09-11", "description": null, "size": 3787, "stargazers_count": 7, "watchers_count": 7, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 7, "default_branch": "main", "contributors": [{"contributor": "Shuwen27", "contributions": 8}, {"contributor": "LenaJaeger", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 128477}, {"language": "Jupyter Notebook", "num_chars": 101458}], "readme": "# Eyettention: An Attention-based Dual-Sequence Model for Predicting Human Scanpaths during Reading\n[![paper](https://img.shields.io/static/v1?label=paper&message=download%20link&color=brightgreen)](https://arxiv.org/abs/2304.10784)\n\nIn this paper, we develop Eyettention, the first dual-sequence model that simultaneously processes the sequence of words and the chronological sequence of fixations. The alignment of the two sequences is achieved by a cross-sequence attention mechanism. We show that Eyettention outperforms state-of-the-art models in predicting scanpaths. We provide an extensive within- and across-data set evaluation on different languages. An ablation study and qualitative analysis support an in-depth understanding of the model's behavior.\n\n## Setup\n\nClone repository:\n\n```\ngit clone git@github.com:aeye-lab/Eyettention\n```\n\nor\n\n```\ngit clone https://github.com/aeye-lab/Eyettention\n```\nand change to the cloned repo via `cd Eyettention`.\n\nInstall dependencies:\n\n```\npip install -r requirements.txt\n```\n\n## Dataset\nFor CELER dataset, you need to follow the instructions \nhttps://github.com/berzak/celer\nIn order to run the experiments, place the downloaded CELER dataset in the /Data/ folder.\n\n## Run Experiments\n#For Chinese BSC dataset:\n```\npython main_BSC.py --test_mode='text'\npython main_BSC.py --test_mode='subject'\npython main_BSC_NRS_setting.py\npython main_BSC_reader_identifier.py\n```\n\n#For English CELER dataset:\n```\npython main_celer.py --test_mode='text'\npython main_celer.py --test_mode='subject'\npython main_celer_NRS_setting.py\npython main_celer_reader_identifier.py\n```\n\n## Cite our work\nIf you use our code for your research, please consider citing our paper:\n\n```bibtex\n@article{deng2023eyettention,\n  title={Eyettention: {A}n Attention-based Dual-Sequence Model for Predicting Human Scanpaths during Reading},\n  author={Deng, Shuwen and Reich, David R and Prasse, Paul and Haller, Patrick and Scheffer, Tobias and J{\\\"a}ger, Lena A},\n  journal={Proceedings of the {ACM} on Human-Computer Interaction},\n  volume={7},\n  number={ETRA},\n  pages={1--24},\n  year={2023},\n  publisher={ACM New York, NY, USA}\n}\n```\n"}
{"url": "https://github.com/aeye-lab/neurips-gmml-2022-xai-eye-tracking-evaluation", "owner": "aeye-lab", "repository_name": "neurips-gmml-2022-xai-eye-tracking-evaluation", "date_all_variable_collection": "2023-09-11", "description": null, "size": 32640, "stargazers_count": 2, "watchers_count": 2, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "main", "contributors": [{"contributor": "dkrako", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 258716}, {"language": "Shell", "num_chars": 1257}], "readme": "# Eye Tracking Explainability Evaluation Pipeline\n\n### Install requirements\n\n```\npip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\npip install -e external/quantus\npip install -r requirements.txt\n```\n"}
{"url": "https://github.com/aeye-lab/pymovements", "owner": "aeye-lab", "repository_name": "pymovements", "date_all_variable_collection": "2023-09-11", "description": "A python package for processing eye movement data", "size": 820, "stargazers_count": 28, "watchers_count": 28, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": true, "has_discussions": false, "forks_count": 4, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 114, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 4, "open_issues": 114, "watchers": 28, "default_branch": "main", "contributors": [{"contributor": "dkrako", "contributions": 266}, {"contributor": "SiQube", "contributions": 32}, {"contributor": "pre-commit-ci[bot]", "contributions": 21}, {"contributor": "jakobchwastek", "contributions": 13}, {"contributor": "theDebbister", "contributions": 7}, {"contributor": "prassepaul", "contributions": 3}, {"contributor": "siqube-adobe", "contributions": 3}, {"contributor": "ketrab2003", "contributions": 1}, {"contributor": "hallerp", "contributions": 1}, {"contributor": "Shuwen27", "contributions": 1}, {"contributor": "assuntasuess", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": true, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["event-detection", "eye-tracking", "eyetracking", "python", "scientific-computing", "scientific-software", "scientific-visualization"], "languages": [{"language": "Python", "num_chars": 779729}], "readme": "<p style=\"text-align:center;\">\n<img width=\"110%\" height=\"110%\" alt=\"pymovements\"\n src=\"https://raw.githubusercontent.com/aeye-lab/pymovements/main/docs/source/_static/logo.svg\"\n onerror=\"this.onerror=null;this.src='./docs/source/_static/logo.svg';\"/>\n</p>\n\n---\n\n[![PyPI Latest Release](https://img.shields.io/pypi/v/pymovements.svg)](https://pypi.python.org/pypi/pymovements/)\n[![Conda Latest Release](https://img.shields.io/conda/vn/conda-forge/pymovements)](https://anaconda.org/conda-forge/pymovements)\n[![PyPI status](https://img.shields.io/pypi/status/pymovements.svg)](https://pypi.python.org/pypi/pymovements/)\n[![Python version](https://img.shields.io/pypi/pyversions/pymovements.svg)](https://pypi.python.org/pypi/pymovements/)\n![Operating System](https://img.shields.io/badge/os-linux%20%7C%20macOS%20%7C%20windows-blue)\n[![License](https://img.shields.io/pypi/l/pymovements.svg)](https://github.com/aeye-lab/pymovements/blob/master/LICENSE.txt)\n[![Test Status](https://img.shields.io/github/actions/workflow/status/aeye-lab/pymovements/tests.yml?label=tests)](https://github.com/aeye-lab/pymovements/actions/workflows/tests.yml)\n[![Documentation Status](https://readthedocs.org/projects/pymovements/badge/?version=latest)](https://pymovements.readthedocs.io/en/latest/?badge=latest)\n[![codecov](https://codecov.io/github/aeye-lab/pymovements/branch/main/graph/badge.svg?token=QY3NDHAT2C)](https://app.codecov.io/gh/aeye-lab/pymovements)\n[![PyPI downloads/month](https://img.shields.io/pypi/dm/pymovements.svg)](https://pypistats.org/packages/pymovements)\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/aeye-lab/pymovements/HEAD?labpath=docs%2Fsource%2Ftutorials)\n\n\npymovements is an open-source python package for processing eye movement data. It provides a simple\ninterface to download publicly available datasets, preprocess gaze data, detect oculomotoric events\nand render plots to visually analyze your results.\n\n- **Website:** https://github.com/aeye-lab/pymovements\n- **Documentation:** https://pymovements.readthedocs.io\n- **Source code:** https://github.com/aeye-lab/pymovements\n- **Mailing list:** pymovements-list@uni-potsdam.de\n- **Contributing:** https://github.com/aeye-lab/pymovements/blob/main/CONTRIBUTING.md\n- **Bug reports:** https://github.com/aeye-lab/pymovements/issues\n- **PyPI package:** https://pypi.org/project/pymovements\n- **Conda package:** https://anaconda.org/conda-forge/pymovements\n\n\n## Getting Started\n\nCheck out our guide on how to install *pymovements* and get started here:\n[Installation](https://pymovements.readthedocs.io/en/stable/getting-started.html)\n\nWe provide a range of tutorial aimed at beginners:\n[Tutorials](https://pymovements.readthedocs.io/en/stable/tutorials/index.html)\n\nThe complete reference of the package can be found here:\n[API Reference](https://pymovements.readthedocs.io/en/stable/reference/index.html)\n\n\n## Contributing\n\nWe welcome any sort of contribution to pymovements!\n\nFor a detailed guide, please refer to our [CONTRIBUTING.md](CONTRIBUTING.md) first.\n\nIf you have any questions, please [open an issue](\nhttps://github.com/aeye-lab/pymovements/issues/new/choose) or write us at\n[pymovements-list@uni-potsdam.de](mailto:pymovements-list@uni-potsdam.de)\n\n\n## Citing\n\nIf you are using pymovements in your research, we would be happy if you cite our work by using the following BibTex entry:\n\n```bibtex\n@inproceedings{pymovements,\n    author = {Krakowczyk, Daniel G. and Reich, David R. and Chwastek, Jakob and Jakobi, Deborah N.\n   and Prasse, Paul and S\u00fcss, Assunta and Turuta, Oleksii and Kasprowski, Pawe\u0142\n   and J\u00e4ger, Lena A.},\n    title = {pymovements: A Python Package for Processing Eye Movement Data},\n    year = {2023},\n    isbn = {979-8-4007-0150-4/23/05},\n    publisher = {Association for Computing Machinery},\n    address = {New York, NY, USA},\n    url = {https://doi.org/10.1145/3588015.3590134},\n    doi = {10.1145/3588015.3590134},\n    booktitle = {2023 Symposium on Eye Tracking Research and Applications},\n    location = {Tubingen, Germany},\n    series = {ETRA '23},\n}\n```\n\nThere is also a preprint available on [arxiv](https://arxiv.org/abs/2304.09859).\n"}
{"url": "https://github.com/aeye-lab/pymovements-toy-dataset", "owner": "aeye-lab", "repository_name": "pymovements-toy-dataset", "date_all_variable_collection": "2023-09-11", "description": "Example toy dataset resource for the pymovements package", "size": 3129, "stargazers_count": 1, "watchers_count": 1, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "dkrako", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# pymovements Toy Dataset\n\nThis repository serves as an example toy dataset resource for the\n[pymovements](https://github.com/aeye-lab/pymovements) package.\n\nIt features gaze data from a single subject reading 4 texts with 5 screens each.\n\nFilenames have the format `trial_{text_id}_{page_id}.csv`.\n\nThe experiment configuration is specified as:\n```\nExperiment(\n\tscreen_width_px=1280,\n\tscreen_height_px=1024,\n\tscreen_width_cm=38,\n\tscreen_height_cm=30.2,\n\tdistance_cm=68,\n\torigin='lower left',\n\tsampling_rate=1000,\n)\n```"}
{"url": "https://github.com/aeye-lab/pymovements-toy-dataset-eyelink", "owner": "aeye-lab", "repository_name": "pymovements-toy-dataset-eyelink", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1625, "stargazers_count": 1, "watchers_count": 1, "language": "AGS Script", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "dkrako", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "AGS Script", "num_chars": 10997464}]}
{"url": "https://github.com/aeye-lab/python-wmc-battery", "owner": "aeye-lab", "repository_name": "python-wmc-battery", "date_all_variable_collection": "2023-09-11", "description": "  Python reimplementation of the WMC battery described in Lewandowsky, Oberauer, Yang, & Ecker (2010), Behavior Research Methods.", "size": 5162, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "dkrako", "contributions": 88}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 1210931}], "readme": "# WMC-Battery\n\nPython re-implementation of the WMC battery described in Lewandowsky, S., Oberauer, K., Yang, L. X., & Ecker, U. K. (2010). A working memory test battery for MATLAB. Behavior research methods, 42(2), 571\u2013585. https://doi.org/10.3758/BRM.42.2.571\n\nThis implementation is a minute reproduction of the original MATLAB implementation and uses the same file output format.\nThis way the accompanying R-script of the original implementation can still be used for data processing.\n\n\n## Differences to original MATLAB implementation\n\n- implementation limited to the following tasks: Memory Update, Operation Span, Sentence Span, and Spatial Short-Term Memory  (left out Choice Reaction Test, Task Switching, and Word Recognition as not referenced in paper)\n- random seed can be either set explicitly or will be automatically determined by the session name / subject id\n- Spatial Short-Term Memory trials are dynamically generated for each new experiment run\n- corrections in chinese language files (instruction pages, experiment messages and sentences for Sentence Span task)\n\n\n## Installation\n\n### Ubuntu 20.04\nYou may need to put `.local/bin` in your `PATH` by adding this to your `.bashrc` in your home folder:\n```\n# set PATH so it includes user's private bin if it exists\nif [ -d \"$HOME/.local/bin\" ] ; then\n    PATH=\"$HOME/.local/bin:$PATH\"\nfi\n```\n\nAfter that, create a new terminal and close the old one to reload the configuration.\n\n```\nsudo apt-get install psychopy python3-pip python3-wxgtk-webview4.0 libxcb-xinerama0\n\npip3 install --upgrade pip\npip3 install -r requirements.txt\npip3 install -U -f https://extras.wxpython.org/wxPython4/extras/linux/gtk3/ubuntu-20.04 wxPython==4.1.1\n```\n\nFor Chinese font support:\n\n```\nsudo apt-get install fonts-noto-cjk\n```\n\n\n### Mac OS\n\n```\npip install psychopy==2020.2.10 pygame wxPython numpy pandas scipy dotmap pyyaml\n```\n\nFor Chinese, please download and install the required font package 'Noto Serif CJK SC': https://www.google.com/get/noto/\n\nThe support for font install : https://www.google.com/get/noto/help/install/\n\n\n\n### Windows\n\n```\npip install psychopy==2020.2.10 pygame wxPython numpy pandas scipy dotmap pyyaml\n```\n\nFor Chinese, please download and install the required font package 'Noto Serif CJK SC': https://www.google.com/get/noto/\n\nThe support for font install : https://www.google.com/get/noto/help/install/\n\n\n## Run WMC Battery\n\n### Ubuntu 20.04\n\n\n```\npython3 wmc_ubuntu.py\n```\n\n\n### MacOS\n\n\n```\npython3 wmc_mac.py\n```\n\n\n### Windows\n\n\n```\npython3 wmc_windows.py\n```\n\n\n## Usage\n\nYou can quit the experiment by pressing `F12`.\n\n\nIt is advised to mark the arrow-keys on your physical keyboard for the *Operation Span* and *Sentence Span* tasks. You can configure the keys in the `yaml`-config files in the `config` folder (`key_map` field).\n\n\n## Test language files\n\nYou can test your language files by running the following command:\n\n```\npython3 test_language.py\n```\n\nYou will move through all experiment messages, instruction pages, a summary for sentence span sentences and all sentence span sentences with the respective label. For the sentence summary, moving on is possible only after one second has passed to prevent accidental skipping.\n"}
{"url": "https://github.com/aeye-lab/SFB-1287-Summer-School", "owner": "aeye-lab", "repository_name": "SFB-1287-Summer-School", "date_all_variable_collection": "2023-09-11", "description": null, "size": 11715, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "Shuwen27", "contributions": 16}, {"contributor": "theDebbister", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 24708820}], "readme": "#  SFB-1287-Summer-School\n\nFor all the hands-on sessions we will use a jupyter notebook. You can use Google colab to run them. The links below point to a public version of the notebooks on colab. If something does not work you can also download the notebooks from this repository and upload it to colab manually.\n\n## E1: Function / Linear model\nhttps://colab.research.google.com/drive/1g3CLkAvfWXpLfIDKnNCmAJjFPsaxH6cG?usp=sharing\n\n## E2: Visualize attention\nhttps://colab.research.google.com/drive/1oF7Sql5jrR2QgqNcBBDPO8ilwsV-JAVU?usp=sharing\n\n## E3: Generate scanpaths using Eyettention \nhttps://colab.research.google.com/drive/1e3rMu951es8SuhP-5qrDy1MpmqCM3nMg?usp=sharing\n"}
{"url": "https://github.com/aeye-lab/sp-eyegan", "owner": "aeye-lab", "repository_name": "sp-eyegan", "date_all_variable_collection": "2023-09-11", "description": null, "size": 56877, "stargazers_count": 7, "watchers_count": 7, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 7, "default_branch": "main", "contributors": [{"contributor": "prassepaul", "contributions": 4}, {"contributor": "SiQube", "contributions": 3}, {"contributor": "dkrako", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 887637}, {"language": "Python", "num_chars": 251375}, {"language": "Shell", "num_chars": 3600}], "readme": "SP-EyeGAN: Generating Synthetic Eye Movement Data\n=================================================\n\nThis repository provides the code for reproducing the experiments in SP-EyeGAN: Generating Synthetic Eye Movement Data. Additionally, you can also use the pre-trained models and create the synthetic data you need for your experiments.\n\n![Method overview](images/sp-eyegan.png)\n\n## Reproduce the experiments\n\nClone the github repository to obtain the ADHD dataset:\n* Using git(hub)s CLI and ssh:\n    * `git clone git@github.com:aeye-lab/sp-eyegan`\n* without ssh:\n    * `git clone https://github.com/aeye-lab/sp-eyegan`\n* if you do not use the terminal / git bash / ide you can download the zip file at the top right of the [repository](https://github.com/aeye-lab/sp-eyegan). Extract the zip file after downloading it.\n\n### Rerun all experiments\n\nWe provide a ssh script which lets you rerun all experiments. We assume that you will have activate a virtual or conda environment, or work with a global pip installation.\n```bash\nrerun_experiments.sh\n```\n\nIf you do not to replicate all experiments, you can either choose to comment out certain parts of the `rerun_experiments.sh` or other bash scripts or follow the steps provided below. Depending on your hardware rerunning all experiments might take several days.\n\n\n\n### Download data\n\nWe use the [`pymovements`](https://github.com/aeye-lab/pymovements) package to download the data. For this either execute `scripts/get_data.sh` or it is also part of the `rerun_experiments.sh` script. Note, you have to download both `Gaze on Faces` and `SB-SAT` manually. We will try to fix this as soon as possible.\n\n\nAlternatively, you can also download the original data from the sources listed below.\n\nDownload the GazeBase data:\n* Download and extract the GazeBase data into a `data/GazeBase` to train FixGAN and SacGAN [figshare-link](https://figshare.com/articles/dataset/GazeBase_Data_Repository/12912257).\n\nDownload the SB-SAT data:\n* Download the SB-SAT data into a `data/SB-SAT` [osf-link](https://osf.io/cdx69/).\n\nClone the github repository to obtain the ADHD dataset into `data/ecml-ADHD`:\n* Using git(hub)s CLI and ssh:\n    * `git clone git@github.com:aeye-lab/ecml-ADHD data/ecml-ADHD`\n* without ssh.:\n    * `git clone https://github.com/aeye-lab/ecml-ADHD data/ecml-ADHD`\n* if you do not use the terminal / git bash / ide you can download the zip file at the top right of the [repository](https://github.com/aeye-lab/ecml-ADHD). After downloading the zip file, extract it to your local clone of this repositry.\n\nDownload the Gaze on Faces dataset:\n* Download the [Gaze on Faces data](https://uncloud.univ-nantes.fr/index.php/s/8KW6dEdyBJqxpmo) into the `data/Gaze_on_Faces` folder where you cloned this repositry. Then extract the zip file `gaze_csv.zip`.\n\n### Configure the paths\nModify `config.py` to contain the path to the GazeBase, SB-SAT, HBN, and Gaze on Faces directories, where you want to store the models and classification results.\n\n### Pipeline to train FixGAN and SacGAN and to create synthtic data\n\nTo train generative models to create fixations and saccades follow the next steps.\n\n#### 1. Create data to train FixGAN and SacGAN\nCreate the data containing fixations and saccades extracted from GazeBase (for the task of reading a text) by running:\n* `python -m sp_eyegan.create_event_data_from_gazebase.py --stimulus text`\nFixations and saccades for the other stimuli could be extracted by change the `stimulus` (allowed stimili are {text, ran, hss, fxs, video, all}).\n\n#### 2. Train FixGAN/SacGAN\nTrain GANs to create fixations and saccades on previously created set of fixations and saccades:\n* Train FixGAN: `python -m sp_eyegan.train_event_model --event_type fixation --stimulus text`\n* Train SacGAN: `python -m sp_eyegan.train_event_model --event_type saccade --stimulus text`\n\nNote, in the script the models will be trained one after the other. You can also parallel the runs by either adding a `&` at the end of the line in the `scripts/train_sp_eyegan.sh`. Or starting two processes with the two lines above. Models trained for the other stimuli could be extracted by change the `stimulus` (allowed stimili are {text, ran, hss, fxs, video, all}).\n\n#### 3. Create synthetic data:\nCreate synthetic data using the previously trained GANs:\n\n```bash\npython -m create_synthetic_data --stimulus text --scanpath_model random --window_size 5000\n```\n\nCreating synthetic data for the other stimuli could be extracted by change the `stimulus` (allowed stimili are {text, ran, hss, fxs, video, all}). You can also change the `scanpath_model` to `stat_model `.\n\n### Apply model on downstream tasks:\n\n#### 1. Pretrain the model with contrastive loss:\nIn the following we will show how to pretrain two different models on several different sampling rates using [contrastive loss](sp_eyegan/pretrain_constastive_learning.py). The [rerun_experiments.sh](rerun_experiments.sh) will train for two models at 1000Hz. If you want to use your own architecture, you can add the architecture to [contrastive learning environment](sp_eyegan/model/contrastive_learner.py) and call it via `--encoder_name YOUR ARCHITECTURE NAME`. Note that `window_size` should be equal for both the synthetic data created and the pretraining script.\n* for training on 1,000 Hz (note, these examples assume you have access to at least 4 gpus -- if not adjust by not using -GPU NUMBER):\n\t* pretrain model with contrastive loss with random augmentation on synthetic data and EKYT architecture:\n    ```bash\n    python -m sp_eyegan.pretrain_constastive_learning --stimulus text -augmentation_mode random  -sd 0.1     -sd_factor 1.25 -encoder_name ekyt -GPU 0 --window_size 5000\n    ```\n\t* pretrain model with contrastive loss with random augmentation on synthetic data and CLRGaze architecture:\n    ```bash\n    python -m sp_eyegan.pretrain_constastive_learning --stimulus text -augmentation_mode random  -sd 0.1     -sd_factor 1.25 -encoder_name clrgaze -GPU 0 --window_size 5000\n    ```\n* for training on 120 Hz\n    * pretrain model with contrastive loss with random augmentation on synthetic data and CLRGaze architecture:\n    ```bash\n    python -m sp_eyegan.pretrain_constastive_learning --augmentation_mode random --sd 0.05 --encoder_name clrgaze --GPU 2 --data_suffix baseline_120 --target_sampling_rate 120 --window_size 5000\n    ```\n    * pretrain model with contrastive loss with random augmentation on synthetic data and EKYT architecture:\n    ```bash\n    python -m sp_eyegan.pretrain_constastive_learning --stimulus text--augmentation_mode random --sd 0.05 --encoder_name ekyt --GPU 3 --data_suffix baseline_120 --target_sampling_rate 120 --window_size 5000\n    ```\n\n* for training on 60 Hz\n    * pretrain model with contrastive loss with random augmentation on synthetic data and CLRGaze architecture:\n    ```bash\n    python -m sp_eyegan.pretrain_constastive_learning --stimulus text --augmentation_mode random --sd 0.05 --encoder_name clrgaze --GPU 0 --data_suffix baseline_60 --target_sampling_rate 60 --window_size 5000\n    ```\n    * pretrain model with contrastive loss with random augmentation on synthetic data and EKYT architecture:\n    ```bash\n    python -m sp_eyegan.pretrain_constastive_learning --stimulus text --augmentation_mode random --sd 0.05 --encoder_name ekyt --GPU 0 --data_suffix baseline_60 --target_sampling_rate 60 --window_size 5000\n    ```\n\n#### 2. Evaluate model on downstream tasks:\nEvaluate models on SB-SAT downstream tasks via:\n* with fine-tuning and using a random forest:\n    * `python -m sp_eyegan.evaluate_downstream_task_reading_comprehension --encoder_name clrgaze`\n    * `python -m sp_eyegan.evaluate_downstream_task_reading_comprehension --encoder_name ekyt`\n\n* without pre-training (training from scratch):\n    * `python -m sp_eyegan.evaluate_downstream_task_reading_comprehension --encoder_name clrgaze --fine_tune 0`\n    * `python -m sp_eyegan.evaluate_downstream_task_reading_comprehension --encoder_name ekyt --fine_tune 0`\n\n\nEvaluate on biometric verification tasks via (using two gpus):\n* with fine-tuning and using a random forest:\n    * `python -m sp_eyegan.evaluate_downstream_task_biometric --dataset judo --gpu 0 --encoder_name clrgaze`\n    * `python -m sp_eyegan.evaluate_downstream_task_biometric --dataset judo --gpu 1 --encoder_name ekyt`\n    * `python -m sp_eyegan.evaluate_downstream_task_biometric --dataset gazebase --gpu 0 --encoder_name clrgaze`\n    * `python -m sp_eyegan.evaluate_downstream_task_biometric --dataset gazebase --gpu 1 --encoder_name ekyt`\n* without pre-training (training from scratch):\n    * `python -m sp_eyegan.evaluate_downstream_task_biometric --dataset judo --gpu 0 --encoder_name clrgaze --fine_tune 0`\n    * `python -m sp_eyegan.evaluate_downstream_task_biometric --dataset judo --gpu 0 --encoder_name ekyt --fine_tune 0`\n    * `python -m sp_eyegan.evaluate_downstream_task_biometric --dataset gazebase --gpu 0 --encoder_name clrgaze --fine_tune 0`\n    * `python -m sp_eyegan.evaluate_downstream_task_biometric --dataset gazebase --gpu 0 --encoder_name ekyt --fine_tune 0`\n\nEvaluate contrastively pre-trained models on gender classification task via:\n* `python -m sp_eyegan.evaluate_downstream_task_gender_classification --gpu 0 --encoder_name clrgaze`\n* `python -m sp_eyegan.evaluate_downstream_task_gender_classification --gpu 0 --encoder_name ekyt`\n\nEvaluate contrastively pre-trained models on ADHD detection task via:\n* `python -m sp_eyegan.evaluate_downstream_task_adhd_classification --gpu 0 --encoder_name clrgaze`\n* `python -m sp_eyegan.evaluate_downstream_task_adhd_classification --gpu 0 --encoder_name ekyt`\n\n\n\n## Test model\nTo see an example of how to create synthetic data look into [this notebook](notebooks/generate_syn_data_for_reading.ipynb).\n\n### Citation\nIf you are using SP-EyeGAN in your research, we would be happy if you cite our work by using the following BibTex entry:\n```bibtex\n@inproceedings{Prasse_SP-EyeGAN2023,\n  author    = {Paul Prasse and David R. Reich and Silvia Makowski and Shuwen Deng and Daniel Krakowczyk and Tobias Scheffer and Lena A. J{\\\"a}ger},\n  title     = {{SP-EyeGAN}: {G}enerating Synthetic Eye Movement Data with {G}enerative {A}dversarial {N}etworks},\n  booktitle = {Proceedings of the ACM Symposium on Eye-Tracking Research and Applications},\n  series    = {ETRA 2023},\n  year      = {2023},\n  publisher = {ACM},\n  doi       = {10.1145/3588015.3588410],\n}\n```\n"}
{"url": "https://github.com/Alaa-Noor/365DataScience_Course", "owner": "Alaa-Noor", "repository_name": "365DataScience_Course", "date_all_variable_collection": "2023-09-11", "description": null, "size": 849, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Alaa-Noor", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# 365DataScience_Course"}
{"url": "https://github.com/Alaa-Noor/Loan-Defaulters-Prediction-using-Lending-Club-Data", "owner": "Alaa-Noor", "repository_name": "Loan-Defaulters-Prediction-using-Lending-Club-Data", "date_all_variable_collection": "2023-09-11", "description": null, "size": 322, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Alaa-Noor", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 733837}], "readme": "# Loan Defaulters Prediction using Lending Club Data\n \n"}
{"url": "https://github.com/alecamcr/Immigration-RSE", "owner": "alecamcr", "repository_name": "Immigration-RSE", "date_all_variable_collection": "2023-09-11", "description": "This project aims at summarizing important factors of immigration in Germany, such as: number of immigrants, origin countries, sex, age, and concentration and movement between Bundesl\u00e4nder. This project was done for the course of research  software engineering at the University of Potsdam", "size": 1507, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": true, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 764374}, {"language": "Python", "num_chars": 27251}], "readme": "# Project overview\n\n## Goal\n\nThis project aims at summarizing important factors of [immigration](https://en.wikipedia.org/wiki/Immigration)  in Germany, such as: number of immigrants, origin countries, sex, age, and concentration and movement between Bundesl\u00e4nder. This summary become relevant for further analysis about public policies and future research about:\n\n- Public policies addressing specific immigrant groups\n- linguistic integration in general and in each of the federal countries\n- General linguistic public policies and preservation of heritage languages\n- Needed future implementations in order to facilitate integration\n\n## Project research questions\n\n1. Total number of immigrants reported per year, differentiating countries\n2. Distribution of sex and age of children reported per year\n3. Distribution of sex and age in scholarization ages reported per year\n4. Distribution of sex and age of older persons ages reported per year\n5. Movement of immigrants, differentiating sex, between Bundesl\u00e4nder \n\n## Data sets\n\nFor this project three data sets with data about migration in Germany until 2021 were used. The data sets can be recovered in the page of the database of the Federal Statistical Office of Germany [destatis](https://www-genesis.destatis.de/genesis/online/data?operation=sprachwechsel&language=en) under **1 territory, population, labour market, elections**; **12 population**; **127 migration** and **[12711 migration statistics](https://www-genesis.destatis.de/genesis/online?operation=statistic&levelindex=0&levelid=1684962399278&code=12711#abreadcrumb)**:\n\n1. For external migration: [12711-0008 Migration between Germany and foreign countries: Germany, years, nationality, countries of origin / destination](https://www-genesis.destatis.de/genesis//online?operation=table&code=12711-0008&bypass=true&levelindex=1&levelid=1685788618051#abreadcrumb) \n2. For internal migration: [12711-0022 Migration between the L\u00e4nder: Land of origin, Land of destination, years, nationality, sex](https://www-genesis.destatis.de/genesis//online?operation=table&code=12711-0022&bypass=true&levelindex=1&levelid=1685788618051#abreadcrumb)\n3. For data about sex and age: [12711-0006 Migration between Germany and foreign countries: Germany, years, nationality, sex, age years](https://www-genesis.destatis.de/genesis//online?operation=table&code=12711-0006&bypass=true&levelindex=1&levelid=1685788618051#abreadcrumb)\n\nThe data sets were preprocessed to suit the workflow. No changes to the data were made niether data were dropped. Only the name of the columns were adjusted.\n\n# Installation instructions\n\nThis project is written using python 3 and it is important to have the following packages installed in order to succesfully run it: ***pandas*** and ***seaborn***.\n\n\n1. Pandas \n\n\tIf you have anaconda, install with:\n\t\n\t\t$ conda install pandas\n\t\n\tOtherwise refer to the [installation guide](https://pandas.pydata.org/docs/getting_started/install.html) of the [pandas documentation](https://pandas.pydata.org/docs/index.html)\n\t\n2. Seaborn\n\n\tYou can install seaborn using:\n\n\t\t$ pip install seaborn\n\t\t\n\tOtherwise refer to the [installation guide](https://seaborn.pydata.org/installing.html) of the [Seaborn main page](https://seaborn.pydata.org/index.html).\n\n# Usage guide\n\n## Migration summary\n\nThis project is composed from 3 main programs wich might be used independently or altogether for a quick summary. If used in the summary mode, simply run `migration_summary.py`. You can run it without arguments and it'll plot a summary containing information about:\n\n- migration in the past 6 years from 2021 \n- 5 origin countries in the world with the most migrants coming to Germany\n- 5 federal countries receiving most migration\n- Sex of migrants with 10, 20, 30, 40 and 50 years\n\nIt takes corresponding datasets and save output plots with default file names in the results folder.\n\n\t$ python bin/migration_summary.py\n\t\nHowever the name of the output files can be changed with positional arguments. There are four output files but if only some names are given, it'll order the names 1) sex and age, 2) external migration line, 3) external migration bar and 4) internal migration:\n\n\t$ python bin/migration_summary.py results/first_name.png ...\n\nIf specific information wants to be plotted, such as specific age span, sex, number of year, number of countries or specific country, it can be done with the following flags:\n\n- `-y, --years` number of years to be plotted (max 21). *eg. 8*\n- `-nc, --numcountries` number of countries to be plotted (ordered by the n countries with most migrants) *e.g. 3*\n- `-c, --country` country to be plotted *eg. France*. Countries must be written in English with a capital letter at the start.\n- `-fc, --federalcountry` federal country to be plotted. *e.g. Baden-Wurttemberg* with capital initial letters and german names without special characters. If names are complex, link them with a minus sign (-).\n- `-age, --age_span ` list containing age span to be plotted *e.g 30 31 32 33 34 35*\n- `-s, --sex` sex to be plotted. Only *male* or *female* possible. If none is given both are plotted by default.\n\nFor instance, the following program plots the 8 past years from 7 most migrant countries world (and Bundesl\u00e4nder) and female kids with 5, 6, 7, 8, 9 and 10 years\n\n\t$ python bin/migration_summary.py -y 8 -nc 7 -age 5 6 7 8 9 10 -s female\n\t\nIf I want to see Colombia and general information in the past 3 years:\n\n\t$ python bin/migration_summary,py -y 3 -c Colombia\n\t\n\n> **Note:** The flags will only change information for some of the plots but not for all of them, as not every data set has complete information. External migration does not contain information about sex and age and sex and age does not consider country.\n\nThe summary program is built upon three other programs which plot specific information about external migration, internal migration and sex and age. These programs can also be used from the independently from the terminal so that the arguments are only applied to their specific output plots. It'll allow to have more control over the plots.\n\n## External migration\n\nThis program plots a line and a bar plot with countries and years and runs under:\n\n\t$ python bin/external_migration.py\n\t\nThe names of plots can be changed positionally (but are given by default):\n\n\t$ python bin/external_migration.py results/first_name.png ... \n\t\noptional arguments:\n\n- `-y, --years` number of years to be plotted (max 21)\n- `-nc, --numcountries` number of countries to be plotted (ordered by the n countries with most migrants)\n- `-c, --country` country to be plotted\n- `-k, --federalcountry` federal country to be plotted\n\nIt plots a bar and a line plot with information about countries from migrants. Specifically in this program it is possible to only plot one of the possible plots if argument `-k --kind` is given:\n\nif only bar plot:\n\n\t$ python bin/external_migration.py -k bar\n\t\nor specifying output name:\n\n\t$ python bin/external_migration.py results/only_bar.png -k bar\n\t\nif only line:\n\n\t$ python bin/external_migration.py results/only_line.png -k bar\n\t\nAll other arguments are used as in summary.\n\n## Internal migration\n\nThis program plots scatter plot with federal countries, years and sex and runs under:\n\n\t$ python bin/internal_migration.py\n\t\nThe names of the plot can be changed positionally (but is given by default):\n\n\t$ python bin/internal_migration.py results/new_name.png\n\t\noptional arguments:\n\n- `-y, --years` number of years to be plotted (max 21)\n- `-nc, --numcountries` number of countries to be plotted (ordered by the n countries with most migrants)\n- `-fc, --federalcountry` country to be plotted\n- `-s, --sex` sex to be plotted\n\nImportantly in internal migration, if only one federal country is to be plotted. It can be done with the flag `-fc`. The following program plots the males going to Brandenburg in the past 5 years (default).\n\n\t$python bin/internal_migration.py -fc Brandenburg -s male\n\t\nAll other arguments are used as in summary.\n\n## Sex and age\n\nThis program plots a bar plot dicriminating sex and age and runs under:\n\n\t$ python bin/sex_age.py\n\t\nThe names of plots can be changed positionally (but is given by default):\n\n\t$ python bin/sex_age.py results/new_name.png\n\noptional arguments:\n\n- `-y, --years` number of years to be plotted (max 21)\n- `-age, --age_span` list containing age span to be plotted\n- `-s, --sex` sex to be plotted\n\nImportantly in sex and age is the possibility of giving an age span to be plotted. Which can be used to observe migration of different age groups. By default is 10,20,30,40 and 50 but the following program plots migrants between 70 and 80 years.\n\n\t$python bin/sex_age.py -age 70 71 72 73 74 75 76 77 78 79 80\n\t\nAll other arguments are used as in summary.\n\n# License\n\n> GPL-3.0-or-later\n\n\tCopyright (C) 2023 Alejandra Camelo Cruz\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or \n    any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see <https://www.gnu.org/licenses/>.\n   \nFull license text can be recovered [here](COPYING.txt)\n\n# Citation\n\tcff-version: 1.0.\n\ttitle: Important factors of migration to Germany\n\tmessage: >-\n\t  If you use this software, please cite it using the\n\t  metadata from this file.\n\ttype: software\n\tauthors:\n\t  - given-names: Alejandra\n\t    family-names: Camelo Cruz\n\t    email: camelocruz@uni-potsdam.de\n\t    affiliation: University of Potsdam, Institute for Informatics and Computational Science\n\trepository-code: 'https://gitup.uni-potsdam.de/camelocruz/immigration_rse'\n\tabstract: >\n\t  This software aims at summarizing important factors of\n\t  immigration  in Germany, such as: number of immigrants,\n\t  origin countries, sex, age, and concentration and movement\n\t  between Bundesl\u00e4nder.\n\tlicense: GPL-3.0-or-later\n\tversion: 1.0.\n\tdate-released: '2023-06-04'\n\t\nThe information for citation can be used from the [.cff file](CITATION.cff) in the root folder\n\n# Contact information\n\n>Alejandra Camelo Cruz\n>\n>Institute for Informatics and Computational Science, University of Potsdam\n>\n>camelocruz@uni-potsdam.de"}
{"url": "https://github.com/alecamcr/polysyllabic-shortening-BA", "owner": "alecamcr", "repository_name": "polysyllabic-shortening-BA", "date_all_variable_collection": "2023-09-11", "description": "This repository contains the codes and files I used for getting the data of my Bachelor Thesis in linguistics at the University of Potsdam", "size": 19278, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "alecamcr", "contributions": 55}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 111678}, {"language": "Python", "num_chars": 19891}], "readme": "# polysyllabic-shortening-BA\nThis repository contains the codes and files I used for getting the data of my Bachelor Thesis in linguistics at the University of Potsdam\n"}
{"url": "https://github.com/alexanderc360/AOC2017", "owner": "alexanderc360", "repository_name": "AOC2017", "date_all_variable_collection": "2023-09-11", "description": "some c++ practice", "size": 1240, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "alexanderc360", "contributions": 13}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 33733}, {"language": "C", "num_chars": 25701}, {"language": "CMake", "num_chars": 12335}], "readme": "# AOC2017\n some c++ practice\n"}
{"url": "https://github.com/alexanderc360/AOC2020", "owner": "alexanderc360", "repository_name": "AOC2020", "date_all_variable_collection": "2023-09-11", "description": "My solutions for Advent of Code 2020", "size": 96, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alexanderc360", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 53406}]}
{"url": "https://github.com/alexanderc360/AOC2021", "owner": "alexanderc360", "repository_name": "AOC2021", "date_all_variable_collection": "2023-09-11", "description": null, "size": 55, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alexanderc360", "contributions": 33}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 29290}], "readme": "# These are my solutions to Advent of Code 2021\n# All my solutions are written in python\n"}
{"url": "https://github.com/alexanderc360/AOC2022", "owner": "alexanderc360", "repository_name": "AOC2022", "date_all_variable_collection": "2023-09-11", "description": "Solutions for Advent of Code 2022", "size": 90, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "alexanderc360", "contributions": 49}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 35470}], "readme": "# AOC2022\nSolutions for Advent of Code 2022\n"}
{"url": "https://github.com/alexanderc360/CS344_Project", "owner": "alexanderc360", "repository_name": "CS344_Project", "date_all_variable_collection": "2023-09-11", "description": null, "size": 3, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "bosladnj", "contributions": 2}, {"contributor": "alexanderc360", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 2594}, {"language": "CMake", "num_chars": 127}]}
{"url": "https://github.com/alexanderc360/website", "owner": "alexanderc360", "repository_name": "website", "date_all_variable_collection": "2023-09-11", "description": "my personal website", "size": 174, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "alexanderc360", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 8897}, {"language": "CSS", "num_chars": 1331}, {"language": "Shell", "num_chars": 55}], "readme": "# website\nmy personal website\n"}
{"url": "https://github.com/alexkli/adventofcode2018", "owner": "alexkli", "repository_name": "adventofcode2018", "date_all_variable_collection": "2023-09-11", "description": "My solutions for Advent of Code 2018", "size": 7, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "alexkli", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 3285}], "readme": "My solutions for Advent of Code 2018\n====================================\n\n[Advent of code 2018](https://adventofcode.com/2018)\n\nSolved in Node.js on the iPad using Rescript & Working Copy apps.\n\nDisclaimer: Code is not very elegant, but works \ud83d\ude09."}
{"url": "https://github.com/alexkli/alfredworkflows", "owner": "alexkli", "repository_name": "alfredworkflows", "date_all_variable_collection": "2023-09-11", "description": "My workflows for alfred", "size": 259, "stargazers_count": 2, "watchers_count": 2, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "alexkli", "contributions": 7}, {"contributor": "justinedelson", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 1926}, {"language": "Ruby", "num_chars": 1454}], "readme": "My [Alfred](http://alfredapp.com) workflows.\n\nWorkflow Downloads:\n* [Open in github](https://dl.dropboxusercontent.com/u/31186/Alfred/Open%20in%20Github.alfredworkflow)\n  Open github web URL for a git checkout path. Also use the\n  [raw ruby script](https://github.com/alexkli/alfredworkflows/blob/master/open-in-github/githuburl) like\n  this: `` open `githuburl path/to/file` ``\n* [Clear](https://dl.dropboxusercontent.com/u/31186/Alfred/Clear.alfredworkflow)\n  Adds task at the top of current list of your [Clear](http://www.realmacsoftware.com/clear/) todo list\n* [Google Calculator](https://dl.dropboxusercontent.com/u/31186/Alfred/Google%20Calculator.alfredworkflow)\n  (enhanced from [this one by SonicXP](http://www.alfredworkflow.com/#Google%20Calculator))\n\nThemes:\n\n* [Terminal Large](http://www.alfredforum.com/topic/1301-terminal-large-theme/)\n  (based on [this one](http://www.alfredforum.com/topic/156-terminal-theme/))\n"}
{"url": "https://github.com/alexkli/github-api-scripts", "owner": "alexkli", "repository_name": "github-api-scripts", "date_all_variable_collection": "2023-09-11", "description": "Shell scripts to work with the Github REST API", "size": 4, "stargazers_count": 6, "watchers_count": 6, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 1, "watchers": 6, "default_branch": "master", "contributors": [{"contributor": "alexkli", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 3037}], "readme": "Github API Scripts\n==================\n\nThis is a collection of shell scripts using curl to manage things with the [Github REST API](https://developer.github.com/v3/). Works with Github enterprise installations.\n\n* [Installation](#installation)\n* [General usage](#general-usage)\n* [Labels](#labels)\n\nInstallation\n------------\n\nRequirements:\n\n* bash version 4+\n* [curl](https://curl.haxx.se)\n* [jq](https://stedolan.github.io/jq/)\n\nClone the repository, download a source zip or copy the shell scripts as needed, and add the folder to your `$PATH`.\n\nGeneral usage\n-------------\n\nAll scripts require to pass username, personal access token and the API endpoint URL.\n\nExample for public [github.com](https://github.com):\n\n```\n<github-script.sh> alexkli:1234567890abcdefgh https://api.github.com/api ...\n```\n\nExample for a Github Enterprise installation\n\n```\n<github-script.sh> alexkli:1234567890abcdefgh https://git.corp.mycompany.com ...\n```\n\n### Token Authentication\n\nYou need to create a [personal token](https://github.com/settings/tokens) (public github link). In your Github Enterprise you can find it under _User drop down top right_ > _Settings_ > _Developer Settings_ > _Personal access tokens_.\n\nThe scopes to select depend on the particular feature, see below. `repo` is a typical one.\n\nThe scripts take the authentication as first argument in the format `user:token`, where `user` is your github user id and `token` is the personal access token.\n\n### API endpoint\n\nFor public github.com use:\n\n```\nhttps://api.github.com\n```\n\nFor a Github Enterprise instance it depends, check the documentation or ask your admins. Make sure it's v3 of the rest API. It might look like this:\n\n```\nhttps://git.mycompany.com/api/v3\n```\n\n### Repository\n\nMost scripts require to specify a repository in the form of\n\n```\norg/repo\n```\n\nFor example, for <https://github.com/alexkli/github-api-scripts> it would be `alexkli/github-api-scripts`.\n\nOrg can be your personal space on github, or a github organization.\n\nLabels\n------\n\nManage issue labels. Required token scope: `repo`.\n\n### Download labels\n\nOutputs all labels from a repository as one JSON.\n\n```\ngithub-get-labels.sh <user:token> <api-url> <org/repo> > labels.json\n```\n\n### Push labels\n\nCreates or updates multiple labels in a repository from a local JSON file (same format as in [Download Labels](#download-labels)). This will not delete any labels.\n\n```\ngithub-push-labels.sh <user:token> <api-url> labels.json <org/repo>\n```\n\n### Delete all labels\n\nDeletes all labels in a repository. Useful to remove the default labels if you want to start from scratch. This will show the labels and ask for confirmation before it actually deletes them.\n\n```\ngithub-delete-all-labels.sh <user:token> <api-url> <org/repo>\n```\n\n### Delete label(s)\n\nDeletes one or multiple labels in a repository. You have to specify the name of the labels on the command line. Note this will NOT ask for confirmation.\n\nMake sure to use the URL escaped name that you find in the `url` in the label JSON returned from Github, for example, a label with a space such as `help wanted` needs to be referenced as `help%20wanted`.\n\n```\ngithub-delete-labels.sh <user:token> <api-url> <org/repo> <label>...\n```\n\nRepos\n------\n\n### List all repos of an organization\n\nTo get the full repo json for each repo in an organization:\n\n```\ngithub-get-org-repos.sh <user>:<token> <github-api-url> <org> [type]\n```\n\nTo get just the repo names, use with `jq`:\n\n```\ngithub-get-org-repos.sh <user>:<token> <github-api-url> <org> [type] | jq -r .[].name\n```"}
{"url": "https://github.com/alexkli/helix-mytestproject", "owner": "alexkli", "repository_name": "helix-mytestproject", "date_all_variable_collection": "2023-09-11", "description": null, "size": 9, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alexkli", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1076}, {"language": "CSS", "num_chars": 711}]}
{"url": "https://github.com/alexkli/helix-tutorial", "owner": "alexkli", "repository_name": "helix-tutorial", "date_all_variable_collection": "2023-09-11", "description": null, "size": 23, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Apache License 2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "alexkli", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 36050}, {"language": "CSS", "num_chars": 12045}, {"language": "HTML", "num_chars": 8624}], "readme": "# Your Project's Title...\nYour project's description...\n\n## Environments\n- Preview: https://main--{repo}--{owner}.hlx.page/\n- Live: https://main--{repo}--{owner}.hlx.live/\n\n## Installation\n\n```sh\nnpm i\n```\n\n## Tests\n\n```sh\nnpm tst\n```\n\n## Local development\n\n1. Create a new repository based on the `helix-project-boilerplate` template and add a mountpoint in the `fstab.yaml`\n1. Add the [helix-bot](https://github.com/apps/helix-bot) to the repository\n1. Install the [Helix CLI](https://github.com/adobe/helix-cli): `npm install -g @adobe/helix-cli`\n1. Start Helix Pages Proxy: `hlx up` (opens your browser at `http://localhost:3000`)\n1. Open the `{repo}` directory in your favorite IDE and start coding :)\n"}
{"url": "https://github.com/alexkli/homebrew-tap", "owner": "alexkli", "repository_name": "homebrew-tap", "date_all_variable_collection": "2023-09-11", "description": "Custom Homebrew Formulae", "size": 4, "stargazers_count": 0, "watchers_count": 0, "language": "Ruby", "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alexkli", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Ruby", "num_chars": 968}], "readme": "# Custom Homebrew Formulae\n\nThis is a tap for [homebrew](http://brew.sh) containing some custom formulae I wrote and wanted to share.\n\nTo add this to your taps (available homebrew repos):\n```\nbrew tap alexkli/tap\n```\n\nThen install via:\n```\nbrew install <formula>\n```\n\nor using the tap-specific name if there are conflicts:\n```\nbrew install alexkli/tap/<formula>\n```\n"}
{"url": "https://github.com/alexkli/jhb", "owner": "alexkli", "repository_name": "jhb", "date_all_variable_collection": "2023-09-11", "description": "Java HTTP Benchmark Tool", "size": 14, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Apache License 2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alexkli", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 28062}, {"language": "Shell", "num_chars": 52}], "readme": "jhb - Java Http Benchmarking tool\n=================================\n\n"}
{"url": "https://github.com/alexkli/lfs-test", "owner": "alexkli", "repository_name": "lfs-test", "date_all_variable_collection": "2023-09-11", "description": null, "size": 7767, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alexkli", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# lfs-test\n\n![](eagle.jpg)\n\n![](test-transparent.png)"}
{"url": "https://github.com/alexkli/oak-chest", "owner": "alexkli", "repository_name": "oak-chest", "date_all_variable_collection": "2023-09-11", "description": "Oak Chest - Packages for Apache Jackrabbit Oak", "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alexkli", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# oak-chest\nOak Chest - Packages for Apache Jackrabbit Oak\n"}
{"url": "https://github.com/alexkli/openwhisk-kubernetes-installer", "owner": "alexkli", "repository_name": "openwhisk-kubernetes-installer", "date_all_variable_collection": "2023-09-11", "description": "Docker image to install and run Apache OpenWhisk locally on Docker for Mac", "size": 13, "stargazers_count": 2, "watchers_count": 2, "language": "Shell", "has_issues": true, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "alexkli", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 2549}, {"language": "Makefile", "num_chars": 456}, {"language": "Dockerfile", "num_chars": 199}], "readme": "[![](https://images.microbadger.com/badges/version/alexkli/openwhisk-kubernetes-installer.svg)](https://microbadger.com/images/alexkli/openwhisk-kubernetes-installer) [![](https://images.microbadger.com/badges/image/alexkli/openwhisk-kubernetes-installer.svg)](https://microbadger.com/images/alexkli/openwhisk-kubernetes-installer \"Get your own image badge on microbadger.com\")\n\n[![](http://dockeri.co/image/alexkli/openwhisk-kubernetes-installer)](https://hub.docker.com/r/alexkli/openwhisk-kubernetes-installer)\n\nopenwhisk-kubernetes-installer\n==============================\n\nThis is a simple way to install and run [Apache OpenWhisk](https://openwhisk.apache.org) locally. It requires Docker for Mac with Kubernetes enabled, and uses the [OpenWhisk Deployment on Kubernetes](https://github.com/apache/incubator-openwhisk-deploy-kube). Most of the installer logic is in the [alexkli/openwhisk-kubernetes-installer](https://hub.docker.com/r/alexkli/openwhisk-kubernetes-installer) docker image used by the install script.\n\n## Requirements\n\n* Docker for Mac\n* with Kubernetes enabled\n* with 4 GB of RAM (advanced Docker settings)\n* with `docker-for-desktop` context (should be the default)\n* with a docker network `host` that allows access to the host from the containers via localhost (should be available by default)\n\n## Install\n\nSingle command:\n\n```\ndocker run --net=host -v ~/.kube:/root/.kube alexkli/openwhisk-kubernetes-installer\n```\n\nAlternatively use this script from this git repository (which might do some more checks in the future):\n\n```\n./install-openwhisk.sh\n```\n\n\u23f0 This might take a few minutes.\n\nThe output should end with instructions how to install [wsk](https://github.com/apache/incubator-openwhisk-cli) and with the `~/.wskprops` to use:\n\n```\nAPIHOST=http://localhost:31001\nAUTH=23bc46b1-71f6-4ed5-8c54-816aa4f8c502:123zO3xZCLrMN6v2BKK1dXYFpXlPkccOFqm12CdAsMgRU4VrNZ9lyGVCGuMDGIwP\nNAMESPACE=guest\n```\n\nOpenwhisk experts: Please note that the API host is `HTTP` and not `HTTPS`, which avoids the annoying self-signed certificate issue that would have required use of `wsk -i` everywhere. Not using SSL is fine since this is only meant for local development installations.\n\nVerify that it works:\n\n```\nwsk namespace get\n```\n\nShould output:\n\n```\nEntities in namespace: guest\npackages\nactions\ntriggers\nrules\n```\n\n## Stop/remove\n\nQuitting Docker for Mac or stopping it's Kubernetes will shut things down. When starting it again, openwhisk should come back up.\n\nTo remove the installation, run this while Docker for Mac & Kubernetes is running:\n\n```\n./uninstall-openwhisk.sh\n```\n\n## Admin commands\n\n### wskadmin\n\nTo run [wskadmin](https://github.com/apache/incubator-openwhisk/tree/master/tools/admin), use the included `wskadmin` script:\n\n* create a user/namespace\n\n    ```\n    ./wskadmin user create userA\n    ```\n\n* list all users/namespaces\n\n    ```\n    ./wskadmin db get subjects | grep key\n    ```\n\n### helm\n\n`helm` is also available as script. This can be used to inspect or manage the running environment, for example:\n\n```\n./helm get openwhisk\n```\n\n## Develop\n\nThe `alexkli/openwhisk-kubernetes-installer` docker image is in the [docker/](docker/) folder. Build it using `make`.\n"}
{"url": "https://github.com/alexkli/osgi-troubleshoot", "owner": "alexkli", "repository_name": "osgi-troubleshoot", "date_all_variable_collection": "2023-09-11", "description": "Apache Felix Webconsole Plugin for troubleshooting OSGi bundles and services", "size": 31, "stargazers_count": 1, "watchers_count": 1, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Apache License 2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "alexkli", "contributions": 16}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 51491}, {"language": "JavaScript", "num_chars": 4409}, {"language": "CSS", "num_chars": 2532}], "readme": "# osgi-troubleshoot\nApache Felix Webconsole Plugin for troubleshooting OSGi bundles and services\n\nMore info in [FELIX-5410](https://issues.apache.org/jira/browse/FELIX-5410).\n\n## Build and installation\n\n    mvn\n    mvn sling:install -Dsling.url=http://localhost:4502/system/console\n    \nAdapt host and port in `sling.url` accordingly to your server.\n\nThen go to Felix Webconsole > OSGi > Troubleshoot:\n\n<http://localhost:4502/system/console/troubleshoot>\n\n"}
{"url": "https://github.com/alexkli/versionatorr", "owner": "alexkli", "repository_name": "versionatorr", "date_all_variable_collection": "2023-09-11", "description": "Web app to compare maven and osgi version numbers using Google Appengine", "size": 25, "stargazers_count": 2, "watchers_count": 2, "language": "CSS", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Apache License 2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "alexkli", "contributions": 18}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "CSS", "num_chars": 16245}, {"language": "Java", "num_chars": 8598}], "readme": "versionatorr\n============\n\nWeb app to compare maven and osgi version numbers using Google Appengine.\n\nIn action: [versionatorr.appspot.com](http://versionatorr.appspot.com)\n\nDevelop\n-------\n\nThe actual web app code is in [versionatorr-war/src/main/webapp](versionatorr-war/src/main/webapp/).\n\n### Run a local test server\n\n    cd versionatorr-war\n    mvn appengine:devserver\n    \nThen go to <http://localhost:8080>\n    \nKill server with `CTRL+C`. Must be restarted every time a file has changed.\n\n### Deploy to Google App engine\n\n    cd versionatorr-war\n    mvn appengine:update\n    \nIf that fails with \"Either the access code is invalid or the OAuth token is revoked.Details: invalid_grant\", run\n\n    rm ~/.appcfg_oauth2_tokens_java"}
{"url": "https://github.com/alexkorga/house-pricing-prediction", "owner": "alexkorga", "repository_name": "house-pricing-prediction", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1732, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "alexkorga", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 2784496}], "readme": "# house-pricing-prediction\n\nThe goal of this notebook was to use learned techniques on a scenario to deepen/showcase acquired knowledge/skills.\nThe target is to predict the sales price of each housing object.\n\nThe dataset used in this notebook is the \"Ames Housing\" dataset, provided in the \"House Prices - Advanced Regression Techniques\" kaggle competition.\nhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview\n"}
{"url": "https://github.com/alexkorga/SimpleChatbot", "owner": "alexkorga", "repository_name": "SimpleChatbot", "date_all_variable_collection": "2023-09-11", "description": "A Chatbot based on a bag-of-words system", "size": 47, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 3, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 3, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alexkorga", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 4710}], "readme": "# SimpleChatbot\n \n"}
{"url": "https://github.com/Alfeezy/AI", "owner": "Alfeezy", "repository_name": "AI", "date_all_variable_collection": "2023-09-11", "description": "Artificial Intelligence assignments", "size": 979, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 93841}, {"language": "Shell", "num_chars": 300}]}
{"url": "https://github.com/Alfeezy/ALGO", "owner": "Alfeezy", "repository_name": "ALGO", "date_all_variable_collection": "2023-09-11", "description": "All of my algorithms assignments (don't steal pls)", "size": 998, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 16307}]}
{"url": "https://github.com/Alfeezy/BCO", "owner": "Alfeezy", "repository_name": "BCO", "date_all_variable_collection": "2023-09-11", "description": "Bus Colony Optimization", "size": 25, "stargazers_count": 1, "watchers_count": 1, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 10644}, {"language": "Ruby", "num_chars": 7783}]}
{"url": "https://github.com/Alfeezy/graphicdesignportfolio", "owner": "Alfeezy", "repository_name": "graphicdesignportfolio", "date_all_variable_collection": "2023-09-11", "description": "portfolio for various art and graphics design works", "size": 15516, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Alfeezy", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Graphic Design Portfolio\nThis is a portfolio of various work by Bastien Gliech.\n\n### For the SUNY Potsdam Wilderness Education Minor\n![](./WildernessEducation/FallCourses2020.png)\n![](./WildernessEducation/SpringCourses2021.png)\n![](./WildernessEducation/BeALeader.png)\n\n### For the SUNY Potsdam Lougheed Learning Commons:\n![](./LougheedLearningCommons/CircDesk.png)\n![](./LougheedLearningCommons/AskUs2472.png)\n\n| ![](./LougheedLearningCommons/MakerspaceBannerPurple.png) | ![](./LougheedLearningCommons/YarnClosetBanner.png) |\n| ----------------------- | --------- |\n\n![](./LougheedLearningCommons/StudyAbroadFair-01.png)\n![](./LougheedLearningCommons/MacUpdate.png)\n\n<<<<<<< HEAD\n![](./LougheedLearningCommons/TobaccosFree.png)\n![](./LougheedLearningCommons/LostandFound.png)\n=======\n| ![](Hands.jpg) |\n| -------------- |\n\n| ![](./waves/IMG_2049.PNG) | ![](./waves/IMG_2050.PNG) | ![](./waves/IMG_2051.PNG) |\n| - | - | - |\n>>>>>>> 4fc0bfd2f3f32ad36380b2075fe3ea92da16ce63\n"}
{"url": "https://github.com/Alfeezy/learn-to-fly", "owner": "Alfeezy", "repository_name": "learn-to-fly", "date_all_variable_collection": "2023-09-11", "description": "Python implementation of QLearning on top of custom gym environment; senior capstone project ", "size": 3327, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Alfeezy", "contributions": 4}, {"contributor": "LemonIceStuff", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 16156}, {"language": "Shell", "num_chars": 3302}], "readme": "# learn-to-fly\nPython implementation of QLearning on top of a custom gym environment.\nAuthors: Miranda Yates, Bastien Gliech\n\n#### Description:\nThis project uses the [openai/gym](https://github.com/openai/gym) toolkit to build and test a flexible QLearning algorithm optimized for flight control in Python. The enviornment used is custom built to simulate an extremely simple flight environment. As the project continues, we hope to eventually create an increasingly complex flight environment. The final goal is to create an action space that resembles that of an actual RC plane, so that we may use the algorithm in a real world scenario. \n\n#### To Run:\n1. ensure that the following python libraries are installed:\n\n   [openai/gym](https://github.com/openai/gym)  \n   [numpy](https://github.com/numpy/numpy)  \n   [matplotlib](https://github.com/matplotlib/matplotlib)  \n   [pandas](https://github.com/pandas-dev/pandas)\n\n2. In the repository folder, run the following:\n```\npython3 learn.py\n```\n"}
{"url": "https://github.com/Alfeezy/PDWorkshop", "owner": "Alfeezy", "repository_name": "PDWorkshop", "date_all_variable_collection": "2023-09-11", "description": "Example PD code and notes for a PureData Workshop", "size": 769, "stargazers_count": 0, "watchers_count": 0, "language": "Max", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Alfeezy", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Max", "num_chars": 138774}], "readme": "## PureData Workshop \n### Author: Bastien Gliech\n\n#### Description\nThis is a repository of a lot of my basic PD notes. PureData was originally written by Miller Puckeete, and I do not own the application in any way. These notes are meant as a basis for new user of the program to understand how to explore what's possible.\n\n#### To Install PureData\n1. Download the appropriate install file from [their website](https://puredata.info/)\n2. Install it, of course!\n"}
{"url": "https://github.com/Alfeezy/Rand", "owner": "Alfeezy", "repository_name": "Rand", "date_all_variable_collection": "2023-09-11", "description": null, "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/Alfeezy/VisualPSO", "owner": "Alfeezy", "repository_name": "VisualPSO", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": "Processing", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Processing", "num_chars": 2499}]}
{"url": "https://github.com/alisher-turubayev/alisher-turubayev", "owner": "alisher-turubayev", "repository_name": "alisher-turubayev", "date_all_variable_collection": "2023-09-11", "description": "Config files for my GitHub profile.", "size": 7, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "alisher-turubayev", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["config", "github-config"], "languages": [], "readme": "# Hey there!\n\nMy name is Alisher Turubayev, and I am a recent Computer Science graduate from Trent University, Canada. I am currently pursuing a Master's degree in Digital Health at Hasso-Plattner Institute (HPI) in Potsdam, Germany.\n\nMy interests include:\n- \ud83d\udcf1 Mobile App development\n- \ud83c\udfa8 User Experience and User Interface design (both for native and web-based applications)\n- \ud83c\udfae Game design and development\n\nI graduated with:\n- B.Sc. (General) in Computer Science - Trent University - Peterborough, ON, Canada (2017 - 2021).\n\nI am currently learning:\n- M.Sc. in Digital Health - Hasso-Plattner Institute (HPI) - Potsdam, Germany (2021 - 23).\n\nI am currently working on:\n- Windows Presentation Foundation (WPF) launcher for Doki Doki Literature Club and DDLC Plus games, with the GUI like the DDLC Plus Desktop environment. \n_DDLC / DDLC Plus are property of [Team Salvato](http://teamsalvato.com/)/[SerenityForge](https://serenityforge.com/)._\n- Themy - an app to help people create positive change in their lifestyle without forceful tactics or shaming.\n\nTake a look around, and contact me via LinkedIn ([alisherturubayev](https://www.linkedin.com/in/alisherturubayev/))!\n"}
{"url": "https://github.com/alisher-turubayev/dl-normalizing-flows", "owner": "alisher-turubayev", "repository_name": "dl-normalizing-flows", "date_all_variable_collection": "2023-09-11", "description": "Utilizing Normalizing Flows for Anime Face Generation - Journey Log", "size": 13190, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": false, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alisher-turubayev", "contributions": 27}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 7674836}, {"language": "Python", "num_chars": 65286}, {"language": "Shell", "num_chars": 447}], "readme": "# Utilizing Normalizing Flows for Anime Face Generation - Code\n### Deep Learning Summer 2022 - Final Project\n### Alisher Turubayev, Hasso-Platter Institute - M.Sc. in Digital Health student\n\nThis is the GitHub repository for the code part of the Deep Learning final project on normalizing flows and their performance in generating novel anime faces. \n\n**Used dataset:**\n\n[Kaggle - Anime Faces Dataset](https://www.kaggle.com/datasets/splcher/animefacedataset)\n\n**Used algorithms:**\n\nDensity estimation using RealNVP by Dihn, L., Sohl-Dickstein, J. and Bengio, S. (2017) [arXiv: 1605.08803](https://arxiv.org/pdf/1605.08803.pdf)\n\nUnsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks by Radford, A., Metz, L. and Chintala, S. (2016) [arXiv: 1511.06434](https://arxiv.org/pdf/1511.06434.pdf)\n\n**Code references and used repositories:**\n\n~~[Glow implementation on Pytorch by Joost van Amersfoort (@y0ast) & Caleb Carr (@calebmcarr)](https://github.com/y0ast/Glow-PyTorch)~~\n\n*Removed due to consistent issues / concerns about implementation. However, the code was used during training of a Glow algorithm, and the results from that experiment were included in the final report - see [glow_progression.jpg](samples/glow_progression.jpg).*\n\n[Implementation of selected normalizing flows on PyTorch by Ilya Kostrikov (@ikostrikov)](https://github.com/ikostrikov/pytorch-flows)\n\n[realNVP by Fangzhou Mu (@fmu2)](https://github.com/fmu2/realNVP)\n\n[DCGAN by Nathan Inkawhich @inkawhich](https://github.com/pytorch/tutorials/blob/master/beginner_source/dcgan_faces_tutorial.py)\n\n## Results\n\nResults are reported in the [final report](report/final_report.pdf) and the [code demo](etc/colab_demo.ipynb). Samples from the training are available in the `samples` folder. \n\n## Reproducing Project Results\n\nTo reproduce project results, consult [code demo](etc/colab_demo.ipynb) file. \n\n### For RealNVP:\n\n*PATH* refers to the dataset path - see an additional [DATA_README](datasets/DATA_README.md) for information on how to correctly import a dataset and about data prunning used. *OUTPUT_PATH* refers to the path of program outputs - by default, states are saved for all trained models as either `realnvp_state{_optim}.pt` or `{generator,discriminator}_state{_optim}.pt`.  \n\nFor random-seed, 64 x 64 x 3 -> 4 x 4 x 48 training with 4 residual blocks/32 features per block:\n```\npython3 main.py --algo realnvp --epochs 25 --res-blocks 4 --base-dim 32 --datapath PATH --output-dir OUTPUT_PATH --nofixed\npython3 main.py --algo realnvp --epochs 25 --res-blocks 4 --base-dim 32 --datapath PATH --output-dir OUTPUT_PATH --nofresh --saved-path OUTPUT_PATH/states --nofixed\npython3 main.py --algo realnvp --epochs 25 --res-blocks 4 --base-dim 32 --datapath PATH --output-dir OUTPUT_PATH --nofresh --saved-path OUTPUT_PATH/states --nofixed\n```\n*Note:* due to the limitations of Google Colab free tier, the author has trained the models in several passes, which are reflected in the commands above.\n\nFor fixed seed, 64 x 64 x 3 -> 4 x 4 x 48 training with 4 residual blocks/32 features per block:\n```\npython3 main.py --algo realnvp --epochs 25 --res-blocks 4 --base-dim 32 --datapath PATH --output-dir OUTPUT_PATH --fixed-seed 409\npython3 main.py --algo realnvp --epochs 25 --res-blocks 4 --base-dim 32 --datapath PATH --output-dir OUTPUT_PATH --nofresh --saved-path OUTPUT_PATH/states --fixed-seed 409\npython3 main.py --algo realnvp --epochs 25 --res-blocks 4 --base-dim 32 --datapath PATH --output-dir OUTPUT_PATH --nofresh --saved-path OUTPUT_PATH/states --fixed-seed 409\n```\n\nFor training 32 x 32 x 3 -> 16 x 16 x 6, 8 residual blocks/64 features per block, download files from commit [bab504a](https://github.com/alisher-turubayev/dl-normalizing-flows/commit/bab504a2671de6ae5e3032e4d0fbb661d1ae563c), and use the following command:\n```\npython3 main.py --algo realnvp --epochs 50 --image-size 32 --datapath PATH --output-dir OUTPUT_PATH --nofixed\npython3 main.py --algo realnvp --epochs 50 --image-size 32 --datapath PATH --output-dir OUTPUT_PATH --nofresh --saved-path OUTPUT_PATH/states --nofixed\npython3 main.py --algo realnvp --epochs 50 --image-size 32 --datapath PATH --output-dir OUTPUT_PATH --nofresh --saved-path OUTPUT_PATH/states --nofixed\npython3 main.py --algo realnvp --epochs 20 --image-size 32 --datapath PATH --output-dir OUTPUT_PATH --nofresh --saved-path OUTPUT_PATH/states --nofixed\n```\n\n### For DCGAN:\n\n```\n!python3 dl-normalizing-flows/main.py --algo gan --epochs 500 --datapath PATH --output-dir OUTPUT_PATH --nofixed\n```\n\n## General Usage Information\n\nFor general usage, see `-h` or `--help`. Additional information is available in additional [DATA_README](datasets/DATA_README.md) file."}
{"url": "https://github.com/alisher-turubayev/trent-university-code", "owner": "alisher-turubayev", "repository_name": "trent-university-code", "date_all_variable_collection": "2023-09-11", "description": "University Code from all classes | Trent University | 2017-2021", "size": 51818, "stargazers_count": 0, "watchers_count": 0, "language": "C#", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "alisher-turubayev", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C#", "num_chars": 193370}, {"language": "Java", "num_chars": 164068}, {"language": "HTML", "num_chars": 157409}, {"language": "C", "num_chars": 80093}, {"language": "PHP", "num_chars": 71682}, {"language": "Assembly", "num_chars": 50595}, {"language": "CSS", "num_chars": 47488}, {"language": "Visual Basic .NET", "num_chars": 40560}, {"language": "JavaScript", "num_chars": 11060}, {"language": "Hack", "num_chars": 2303}, {"language": "Python", "num_chars": 2040}, {"language": "C++", "num_chars": 1285}, {"language": "Makefile", "num_chars": 458}], "readme": "# University Code - B.Sc. (General) in Computer Science | Trent University | 2017-2021\n\n## Disclaimer\nTHE OWNER DOES NOT ENDORSE ACADEMIC DISHONESTY, AS DEFINED IN THE UNDERGRADUATE ACADEMIC INTEGRITY POLICY OF TRENT UNIVERSITY (AVAILABLE ON TRENT WEBSITE: https://www.trentu.ca/vpacademic/academic-integrity).\nANY USAGE OF THE CODE PROVIDED IN THIS REPOSITORY FOR ACADEMIC DISHONESTY, INCLUDING PLAGIARISM OR CHEATING, IS STRONGLY DISCOURAGED\n\n## Purporse:\nThis code is provided to potential employers so that they can judge my depth and quality of knowledge. Code is provided here as it was submitted to the various courses I took \nwhile at Trent University, and represents how I wrote and organized my code at various points of my programming journey.\n"}
{"url": "https://github.com/alisher-turubayev/uni-potsdam-code", "owner": "alisher-turubayev", "repository_name": "uni-potsdam-code", "date_all_variable_collection": "2023-09-11", "description": "University Code from all classes | Universit\u00e4t Potsdam - Hasso-Plattner Institut | 2021-2023", "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "alisher-turubayev", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# University Code - M.Sc. in Digital Health | Universit\u00e4t Potsdam - Hasso-Plattner Institut | 2021-2023\n\n## Disclaimer\nTHE OWNER DOES NOT ENDORSE PLAGIARISM, AS DEFINED IN THE UNIVERSITY OF POTSDAM POLICY DOCUMENT (AVAILABLE ON UNIVERSITY OF POTSDAM WEBSITE: https://www.uni-potsdam.de/fileadmin/projects/iaa/docs/Plagiarism_guideline_english.pdf).\nANY USAGE OF THE CODE PROVIDED IN THIS REPOSITORY FOR ACADEMIC DISHONESTY, INCLUDING PLAGIARISM OR CHEATING, IS STRONGLY DISCOURAGED\n\n## Purporse:\nThis code is provided to potential employers so that they can judge my depth and quality of knowledge. Code is provided here as it was submitted to the various courses I took \nwhile at Hasso-Plattner Institute (HPI), and represents how I wrote and organized my code at various points of my programming journey.\n"}
{"url": "https://github.com/alsino/AirBNB", "owner": "alsino", "repository_name": "AirBNB", "date_all_variable_collection": "2023-09-11", "description": "Project from the course \u00bbData Journalism\u00ab which took place at the University of Applied Sciences Potsdam in the department Design during the winter semester 2014/15.", "size": 3957, "stargazers_count": 4, "watchers_count": 4, "language": "CSS", "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 4, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "CSS", "num_chars": 35264}, {"language": "JavaScript", "num_chars": 12776}], "readme": "# IS SHARING CARING?\n## AirBnB und die Wohnraum\u00adknappheit in Berlin\n\n### Hintergrund\nIm Zuge der zunehmenden Verknappung von bezahlbarem Wohnraum in deutschen Gro\u00dfst\u00e4dten geraten auch zunehmend \u00bbSharing Economy\u00ab-Portale wie AirBnB unter Beschuss. Die Kritik: Sie gie\u00dfen in Anbetracht der bereits existierenden Wohnungsnot \u00d6l ins Feuer, indem Privatanbieter auf ihnen Unterk\u00fcnfte zu einem \u00fcberh\u00f6hten Marktpreis anbieten und somit zus\u00e4tzliche Wohnungen dem Mietmarkt entziehen. Vor allem in New York ist die Kritik an AirBnB zuletzt sehr laut geworden. Aber auch in deutschen Gro\u00dfst\u00e4dten werden diese Vorw\u00fcrfe vermehrt angebracht. Neue rechtliche Rahmenbedingungen sollen diesen Missbrauch nun stoppen. So ist es beispielsweise seit Mai 2014 in Berlin verboten, private Wohnungen durch gewerbliche Vermietung ihrem urspr\u00fcnglichen Zweck zu entfremden (\u00bbZweckentfremdungsverbot\u00ab).\n\n### Motivation und Intention\nIm Dezember 2014 wurde eine von AirBnB in Auftrag gegebene Studie ver\u00f6ffentlicht, in welcher der vermeintlich negative Einfluss der Wohnungsplattform AirBnB auf den Berliner Wohnungsmarkt als verschwindend gering eingesch\u00e4tzt wurde (GEWOS, 2014). So sollen zwischen September 2013 und August 2014 nur 1.075 Wohnungen, die auf AirBnB angeboten wurden, l\u00e4ngerfristig als Ferienwohnungen (mehr als 120 Tage im Jahr) vermietet worden sein. Die entspricht einem Anteil von 0,06% aller Berliner Wohnungen. Auch die Anzahl von Anbietern, die mehr als einer Wohnung vermieten sei mit 10% relativ gering, so hei\u00dft es.\n\n### Fragestellung\nWas in den Ergebnissen der AirBnB-Studie nicht zum Ausdruck kommt, ist die unterschiedliche Wohnsituation in den besonders betroffenen Mikrolagen Berlins (z.B. Friedrichshain, Kreuzberg, Neuk\u00f6lln), also den Stadtbezirken mit einem erh\u00f6hten Preisdruck auf dem Wohnungsmarkt. Hier nimmt die angespannte Situation durch eine zunehmende Professionalisierung der Vermietungsverh\u00e4ltnisse weiter zu. Einige Fragen, die sich in diesem Kontext stellen sind somit: Wie viele Wohnungen werden innerhalb eines gegebenen Zeitraums (z.B. ein Monat) in den verschiedenen Berliner Bezirken und v.a. diesen Mikrolagen angeboten und dadurch dem gew\u00f6hnlichen Mietmarkt entzogen? Wieviele Wohnungen stehen in diesen Bezirken Mietsuchenden \u00fcberhaupt noch bereit? \n\nEin Projekt von <a href=\"https://twitter.com/alsinosko\">Alsino Skowronnek</a>, <a href=\"http://www.vogelino.ch/\">Lucas Vogel</a> und <a href=\"http://jonasparnow.de/\">Jonas Parnow</a> \u2014 Betreuung durch <a href=\"http://idl.fh-potsdam.de/people/jan-erik-stange/\">Jan-Erik Stange</a> und <a href=\"http://www.michael-hoerz.de/\">Michael H\u00f6rz</a> \u2014 <a href=\"http://www.fh-potsdam.de/studieren/design/\">FH Potsdam</a> \u2014 Wintersemester 2014/15</p>\n"}
{"url": "https://github.com/alsino/berlindru", "owner": "alsino", "repository_name": "berlindru", "date_all_variable_collection": "2023-09-11", "description": "Test of a very simple D3 viz technique", "size": 292, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "gh-pages", "contributors": [{"contributor": "alsino", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 6434}], "readme": "# berlindru\nTest of a very simple D3 viz technique\n"}
{"url": "https://github.com/alsino/bob-ross-images", "owner": "alsino", "repository_name": "bob-ross-images", "date_all_variable_collection": "2023-09-11", "description": "Getting beautiful Bob Ross paintings", "size": 244, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "alsino", "contributions": 18}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1242}], "readme": "# Bob Ross Image Scraper\n\n![A nice image](https://raw.githubusercontent.com/alsino/bob-ross-images/master/images/0.sample-image.png)\n\nThis is a simple and quick webscraper using node.js and the [request module](https://github.com/request/request#readme) to retrieve beautiful and happy paintings from Bob Ross from [this website](https://www.twoinchbrush.com/).\n\nThe [chalk module](https://github.com/chalk/chalk#readme) is used for syntax highlighting in the terminal.\n\n# Copyright Warning\nAll images by Bob Ross are copyright protected. This script is functional but should not be used without prior authorization by the image owners. Please consult their [terms of service](https://www.twoinchbrush.com/terms-of-service) before using this tool.\n\n# Usage\n\n1. Download or clone this repo with `git clone https://github.com/alsino/bob-ross-images.git`\n2. Install the project dependencies with `npm install`\n3. In your terminal navigate to the repo with `cd bob-ross-images-master`\n4. Run the scraper with `node scraper.js`\n\n# Happy Bob Ross'in...\n"}
{"url": "https://github.com/alsino/ckan_nigeria", "owner": "alsino", "repository_name": "ckan_nigeria", "date_all_variable_collection": "2023-09-11", "description": null, "size": 19611, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alsino", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 13448475}, {"language": "C", "num_chars": 519202}, {"language": "HTML", "num_chars": 208419}, {"language": "XSLT", "num_chars": 152770}, {"language": "C++", "num_chars": 73693}, {"language": "JavaScript", "num_chars": 38868}, {"language": "CSS", "num_chars": 6306}, {"language": "Shell", "num_chars": 3216}], "readme": "# ckan_nigeria"}
{"url": "https://github.com/alsino/corona-impact-analysis", "owner": "alsino", "repository_name": "corona-impact-analysis", "date_all_variable_collection": "2023-09-11", "description": "A quick interactive visualization of covid-19 scenarios (May 2020)", "size": 1262, "stargazers_count": 1, "watchers_count": 1, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 14, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 14, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "alsino", "contributions": 111}, {"contributor": "maximilianeber", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 26243}, {"language": "JavaScript", "num_chars": 13122}, {"language": "CSS", "num_chars": 4554}], "readme": "## Intro\n\nA quick visualization for a corona impact analysis. \n\nA continous live demo can be found here: [https://covid19-scenarios.netlify.com/](https://covid19-scenarios.netlify.com/)\n\nThe App uses the framework [Svelte.js](http://svelte.dev/). You will find the JavaScript code in the ***src*** folder. The data can be found in the ***public*** folder. If you just need to make changes to the data or add new ***PDFs*** to the ***public/pdf folder***, you will not have to install anything. Simply update the folder on your server and repository. \n\n## Setup / Installation\n\nIf you want to make changes to the code, you need to have Node.js installed on you machine. We recommend to install Node with NVM, which is a Node Version Manager: https://github.com/creationix/nvm\n\nBefore development, you will need to clone this repository to your target directory:\n```bash \ngit clone https://github.com/alsino/corona-impact-analysis.git\n```\n\nOpen your terminal and navigate to the repository: \n```bash\ncd Path_To_Target_Directory\n```\n\nThen install the necessary JavaScript dependencies with: \n```bash\nnpm install\n```\n\n## Data access\n\nIf you want to run the app locally, you will have to request access to the API_ENDPOINT and the API_KEY from us and add them to a .env file in the root directory, i.e. \n```\nAPI_URL='API_URL'\nAPI_KEY='MY_API_KEY'\n```\n\n\n## Development\nOpen your terminal and navigate to the repository. Then run the following command in your terminal:\n```bash\nnpm run dev\n```\n\nNavigate to [localhost:5000](http://localhost:5000). You should see your app running. Edit a component file in the `src` folder, then save it. The page will automatically reload and you should see your changes.\n\nIf you want to have a live preview of your app on the web, you can connect your repository to [Netlify](https://www.netlify.com/). Once this is done, the website will update each time you make changes to your repository.\n\n\n##  Troubleshooting\nIf the dev server fails, you might need to re-install the sirv cli again:\n```bash\nnpm install --save sirv-cli\n```\n\n## Deploying to the web\nWhen you are ready to deploy the app, you will need to run the following command to ***build*** it\n```bash\nnpm run build\n```\nThen copy the content of the ***public*** folder to the location where you want you website to be on your server.\n\n\n## Libraries in use\n\n* Charts: http://c3js.org/\n\n## Some practical links \n* Set up SASS for Svelte: https://daveceddia.com/svelte-with-sass-in-vscode/\n"}
{"url": "https://github.com/alsino/creative-applications-ml", "owner": "alsino", "repository_name": "creative-applications-ml", "date_all_variable_collection": "2023-09-11", "description": "All code and materials for the DAAD introductory workshop on machine learning", "size": 42477, "stargazers_count": 8, "watchers_count": 8, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 8, "default_branch": "master", "contributors": [{"contributor": "alsino", "contributions": 76}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 20198}, {"language": "HTML", "num_chars": 4064}], "readme": "# Creative Applications of Machine Learning \u2013  <br/> A Hands-On Workshop for (Absolute) Beginners\n\nThis is a repository with all the code and materials for the DAAD Alumni-Workshop at daadgalerie_studio, 21 October 2019, 10am - 4pm. \n\nThis workshops draws heavily on the friendly open source projects [ml5.js](https://ml5js.org/) and [p5.js](https://p5js.org/), which you should check out. \n\nA special and big shoutout to [Yining Shi](https://github.com/yining1023) who developed many of the materials provided here. The curriculum of this workshop was heavily inspired by Yining's introductiory course on [Bots and Machine Learning](https://schoolofma.org/bots) at the School of Machines in the summer of 2019 and her [Machine Learning for the Web's](https://github.com/yining1023/machine-learning-for-the-web) class at ITP in New York.\n\n![Workshop teaser](https://github.com/alsino/creative-applications-ml/blob/master/assets/img/teaser.jpeg)\n\n\n\n## Housekeping\n\nWe are collecting all links and non-code materials on our [EtherPad](https://etherpad.net/p/creative-applications-ml). This way we can exchange materials and links on the fly with everybody without having to set up a chat group or slack.  \n\n## Topics\n- What is Machine Learning (ML)? \n- What are some of the most important concepts in ML?\n- What are common applications of machine learning?\n- Why should we engage with creative applications of ML?\n- What are tools we can use in creative ML applications?\n\n## Agenda\n\n**10am - 12pm: Introduction to Machine Learning**\n- A Quick Introduction to Machine Learning ([Presentation](https://github.com/alsino/creative-applications-ml/blob/master/presentation/intro_compressed.pdf))\n- Hands-on 1: A very basic introduction to JavaScript and p5.js\n\n**12pm - 1pm: Lunch Break**\n\n**1pm - 4pm: Machine Learning with ml5.js and Runway**\n- Hands-on 2: Image classification with MobileNet\n- Hands-on 3: Pose estimation (PoseNet) with ml5.js\n- Hands-on 4: Generate images from text (AttnGan-Runway)\n- Next steps: Where to go from here? (Resources)\n- Feedback\n\n\n\n\n## Get started\nTo run each code example, open your terminal (HowTo: [Mac](https://www.idownloadblog.com/2019/04/19/ways-open-terminal-mac/) or [Windows](https://www.howtogeek.com/235101/10-ways-to-open-the-command-prompt-in-windows-10/#targetText=Open%20Command%20Prompt%20from%20the,open%20an%20administrator%20Command%20Prompt.)) and type in the following commands:\n```\nClone this repository (folder)\n$ git clone https://github.com/alsino/creative-applications-ml.git\n\nGo to the folder you have just downloaded\n$ cd creative-applications-ml\n\nGo to the specific example folder we are working in, i.e. for the first imageClassification example:\n$ cd 1-imageClassification\n\nStart up a simple web server in the current directory (note: you will need to have python installed on your machine)\n$ python -m SimpleHTTPServer     # $ python3 -m http.server (if you are using python 3)\n\n\n\n```\n\n## Install Python\nIn case you do not have python installed on your computer, here are the instructions for installation for both [Mac](https://realpython.com/installing-python/#macos-mac-os-x) and [Windows](https://realpython.com/installing-python/#windows).\n"}
{"url": "https://github.com/alsino/creative-applications-ml-dai", "owner": "alsino", "repository_name": "creative-applications-ml-dai", "date_all_variable_collection": "2023-09-11", "description": null, "size": 22040, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "alsino", "contributions": 16}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 20198}, {"language": "HTML", "num_chars": 4064}], "readme": "# Creative Applications of Machine Learning \u2013 <br/>\n## A Hands-On Workshop on the Web (for {Absolute} Beginners)\n\nThis is a repository with all the code and materials for the online dai workshop on 17 September 2020, 10am - 2pm. \n\nThis workshops draws heavily on the friendly open source projects [ml5.js](https://ml5js.org/) and [p5.js](https://p5js.org/), which you should check out. \n\nA special and big shoutout to [Yining Shi](https://github.com/yining1023) who developed many of the materials provided here. The curriculum of this workshop was heavily inspired by Yining's introductiory course on [Bots and Machine Learning](https://schoolofma.org/bots) at the School of Machines in the summer of 2019 and her [Machine Learning for the Web's](https://github.com/yining1023/machine-learning-for-the-web) class at ITP in New York.\n\n![Workshop teaser](https://github.com/alsino/creative-applications-ml-dai/blob/master/assets/img/image.jpeg)\n\n\n## Housekeping\n\nWe are collecting all links and non-code materials in our [Slack channel](https://join.slack.com/t/daicreativeml-ryp8974/shared_invite/zt-hddjfwo2-HZNMKyBPQw1TsiPkXV0_wQ). This way we can exchange materials and links on the fly with everybody.\n\n\n## Topics\n- What is machine learning (ML)?\n- What are some of the core concepts in ML?\n- What are common applications of ML?\n- Why engage with creative applications of ML?\n- What tools can we use in creative ML applications?\n\n## Agenda\n\n**10:00 - 10:30**  Welcome and introduction round  \n**10:30 - 11:00**  Quick intro to Machine Learning \n\n**10:30 - 11:00**  Runway ML  \n**11:00 - 12:00**  Experiments w/ ml5.js  \n\n**12:00 - 12:30**  Fast lunch ;)  \n\n**12:30 - 13:30**  Project work  \n**13:30 - 14:00**  Final presentation (Record on Zoom)  \n\n## ml5.js Examples\n- [Image Classification](https://codesandbox.io/s/1-imageclassification-zmey4)\n- [Image Classification Video](https://codesandbox.io/s/2-imageclassificationvideo-rp0eq)\n- [Object Detectioon YOLO](https://codesandbox.io/s/3-imagedetectionyolovideo-z0x8x)\n- [Pose Estimation](https://codesandbox.io/s/4-posenet-wkqr1)\n- [Pose Estimation Advanced](https://codesandbox.io/s/5-posenet-advanced-1l6xc)\n"}
{"url": "https://github.com/alsino/europe-map", "owner": "alsino", "repository_name": "europe-map", "date_all_variable_collection": "2023-09-11", "description": null, "size": 668, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "alsino", "contributions": 159}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 169553}, {"language": "Svelte", "num_chars": 12763}, {"language": "HTML", "num_chars": 3808}, {"language": "CSS", "num_chars": 58}], "readme": "# create-svelte\n\nEverything you need to build a Svelte project, powered by [`create-svelte`](https://github.com/sveltejs/kit/tree/master/packages/create-svelte).\n\n## Creating a project\n\nIf you're seeing this, you've probably already done this step. Congrats!\n\n```bash\n# create a new project in the current directory\nnpm init svelte@next\n\n# create a new project in my-app\nnpm init svelte@next my-app\n```\n\n> Note: the `@next` is temporary\n\n## Developing\n\nOnce you've created a project and installed dependencies with `npm install` (or `pnpm install` or `yarn`), start a development server:\n\n```bash\nnpm run dev\n\n# or start the server and open the app in a new browser tab\nnpm run dev -- --open\n```\n\n## Building\n\nTo create a production version of your app:\n\n```bash\nnpm run build\n```\n\nYou can preview the production build with `npm run preview`.\n\n> To deploy your app, you may need to install an [adapter](https://kit.svelte.dev/docs/adapters) for your target environment.\n"}
{"url": "https://github.com/alsino/imgbank", "owner": "alsino", "repository_name": "imgbank", "date_all_variable_collection": "2023-09-11", "description": null, "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/alsino/inflation-rate-september", "owner": "alsino", "repository_name": "inflation-rate-september", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1169, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "EuranetPlus", "contributions": 25}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 174131}, {"language": "Svelte", "num_chars": 22736}, {"language": "HTML", "num_chars": 3872}, {"language": "CSS", "num_chars": 1514}], "readme": "## About this project\n\nThis is the code repository for an interactive EuranetPlus choropleth map of European countries. The map can be updated with any data set from a CSV file. For more info see section [3. Update map with new data](#add-data).\n\nTo use the map for a new topic and populate it with new data and text please follow these steps:\n1. Make a copy of this map template: [Copy map template](#copy-map-template)\n2. Configure the map: [Configure map](#configure-the-map)\n3. Update map with new data: [Add or update data](#add-data)\n4. Update map titles and texts: [Updating texts](#updating-text)\n5. Translate texts into 24 EU languages [Translate texts](#translate-text)\n6. Publish the new map: [Publish map](#publish-map)\n\n\n![Screenshot](https://user-images.githubusercontent.com/8008434/171234651-268c6ed6-c62b-4f1f-b01f-a5009d922f19.png)\n\n_Left: Map with **\"values\"** data_  \n_Right: Map with **\"binary\"** data_\n\n## Copy map template\n\n1. **Copy repository**:  \nTo make a new map, we first need to copy this repository and use a fresh map template. To do this, please use the green \"Use this template\" button on the top right in this window. This will create a copy of the exact same code that can be used for a new map. You will be prompted to name the new repository according to the new topic of the map. Please use this nomenclature: _map-TOPIC_, e.g. _map-gdp_ or _map-generationz_. If more than two words are used, separtate them with a dash like so _map-military-spending_. \n\n2. **Add Google Credentials**:  \nIn order to be able to use the automatic translation service by the Google API, we need to provide the new repository with access to the service account API key. For this go to the **Settings** tab at the top of this repository and select the \"Secrets\" dropdown on the lower left side. Here select \"Actions\". On the top right side press the \"New repository secret\" button. Name the new secret **\"GOOGLE_CREDENTIALS\"** and as a value paste in the contents of the service account json file that can be downloaded from the Google Cloud Console. This file looks something like this (Note: This example file below here is fake and only for illustration purposes):\n\n```bash\n{\n  \"type\": \"service_account\",\n  \"project_id\": \"iron-moon-dgddg\",\n  \"private_key_id\": \"843dgj436fcf7bfab4sgg367235529\",\n  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvwIhdghgdBg\\n-----END PRIVATE KEY-----\\n\",\n  \"client_email\": \"maps@iron-moon-dgdgdgdgg.iam.gserviceaccount.com\",\n  \"client_id\": \"sgdgfdgdggdgggdgg\",\n  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/maps%40iron-moon-dgdgdgdgg.iam.gserviceaccount.com\"\n}\n```\n\n3. **Allow scripts**:  \nBy default every new repository is locked for running automated scripts. We need to enable this functionality first. Go to the **Settings** tab at the top of this repository and select \"Actions\" and then \"General\" from the dropdown on the lower left side. Then set the \"Workflow permissions\" to \"Read and write permissions\". Now we can change the texts and run the translations.\n\n4. **Connect to Vercel**:\nOnce the new repository is set up, you need to connect it to Vercel to deploy the map to the internet. Please go to https://vercel.com/dashboard, sign in with your GitHub account and do the following steps: \n- Press the \"New Project\" Button on the Vercel dashboard\n- Under \"Import Git Repository\" choose the name of the copied repository\n- Press the blue \"Deploy\" button (no need to change any settings here)\n- Press the \"Go to Dashboard\" button and copy the URL under the \"DOMAINS\" heading (the url should look something like this: https://map-test-seven.vercel.app/)\n- Go to the [map configuration file](src/lib/stores/config-features.js) (Folder: src -> lib -> stores -> config-features.js) and paste the URL on [line 3](https://github.com/EuranetPlus/map-europe/blob/e6f63675ae3706bc5337eb755ae58c61c1e27634/src/lib/stores/config-features.js#L3).\n\n## Configure the map\n\nIn order to configure the new project, please change the contents of this [map configuration file](src/lib/stores/config-features.js) (Folder: src -> lib -> stores -> config-features.js). The configuration has a number of parameters that you should specify.\n\nThe most important entries that you need to change for each project are the \"mapTitle\", the \"vercelURL\", \"datasetType\", \"datasetUnit\" and \"colourScheme\":\n\n```js\n  \"mapTitle\": \"europe\", // The title of the map, if more than one word, separate by dash, e.g. \"income-europe\"\n  \"vercelURL\": \"https://euranet-map-europe.vercel.app\", // The url provided when deploying the map on Vercel\n  \"datasetType\": \"values\", // \"values\" or \"binary\"; Does the data set contain numerical values or binary (0/1) values for countries?\n  \"datasetUnit\": \"percent\", // \"fullNumbers\" or \"percent\"; Is the data in percent (0.25 of GDP) or full numbers (25 people)?\n  \"colourScheme\": \"blue\", // one of the following: \"blue\", \"purple-blue\", \"green-blue\", \"orange-red\"\n  \"headlineAvailable\": true, // true or false; Should the map have a headline? \n  \"subheadlineAvailable\": true, // true or false; Should the map have a subheadline? \n  \"tooltipAvailable\": true, // true or false; Should the map show a tooltip when hovering over a country? \n  \"scaleBarAvailable\": true, // true or false; Should the map show a scale bar on the top? \n  \"legendAvailable\": true, // true or false; Should the map show a legend in the bottom right corner? \n  \"textSourceAvailable\": true, // true or false; Should the map show a source text below the map? \n  \"textNoteAvailable\": true, // true or false; Should the map show a text note below the map? \n  \"textDataAccessAvailable\": true, // true or false; Should the map show a link to the original data source below the map? \n  \"legend1Color\": \"#cad1d9\", // Specifies the color of the first round dot in the legend entry\n  \"legend2Color\": \"red\", // Specifies the color of the second round dot in the legend entry\n  \"legend3Color\": \"blue\", // Specifies the color of the third round dot in the legend entry\n  \"legend4Color\": \"green\" // Specifies the color of the fourt round dot in the legend entry\n```\n\n## Add data\n\nTo add or update the map data, please first decide whether the data set you are using shows \"values\", i.e. continous numbers on a color scale or whether it is \"binary\", i.e. the map shows only a few countries in the same color (\"dark blue\") as a category (0 = there is no data for this country, 1 = there is data for this country). \n\n1. Set the dataset type in the [map configuration file](src/lib/stores/config-features.js) (Folder: src -> lib -> stores -> config-features.js) under \"datasetType\". If your dataset consists of **values data**, please use this [csv values template](https://docs.google.com/spreadsheets/d/1fzicMw_LiFGrdtzloXZFbM2FFgVc-GYtavvxPJFZ5Yo/edit?usp=sharing). If it consists of **binary data**, please use this [csv binary template](https://docs.google.com/spreadsheets/d/1YL_5aVY9zaaxwhI6-cEgcwO8k01Fzu2FzsPMtvppYfg/edit?usp=sharing).\n\n2. Then you need to decide whether the data consists of **full numbers** (i.e. 45 people) or **percent values**, (i.e. 45% of GDP). In the [map configuration file](src/lib/stores/config-features.js) (Folder: src -> lib -> stores -> config-features.js) this can be set under \"datasetUnit\".\n\n3. Please copy the respective csv template to your own computer (or Google Drive) and fill in the desired data point for each country. Please make sure that values are formatted with dots (.) as a comma separator and **not commas**, i.e. 0.45 for percentage values instead of 0,45. In the template, all percentage values are always written as fractions of 1, **i.e. 0.45 and not 45**.  \n\n4. For any country you can add additional content information (i.e. text, audio, image and video) that will show up once you click on a country. If you want to do this for a specific country, set the value in the column \"extraInfo\" to **TRUE**, otherwise to **FALSE**.  \n***Important: The column \"extraInfo\" needs to be included in every data set and either be set to TRUE or FALSE for each country. Otherwise the map will not work. The following columns only need to contain content if extraInfo is set to TRUE***.\n\n| Column Name      | Description |\n| :----------- | :----------- |\n| **text_content**     | A text for each country. Should ideally not be more than 1 small to medium-sized paragraph       |\n| **link_text**   | The text of a link that redirects to an outside resource. Usually this text would be something like \"Read more\" or \"Link to article\" |\n| **link_url_target**   | The URL to which the link should refer to (e.g. https://euranetplus-inside.eu/exodus-education-and-elections/) |\n| **audio_url_1**   | The link to the **first** audio resource (spotify or soundcloud) (in the format https://open.spotify.com/embed/episode/37AK0KI06D6027Pwv96Bvk?utm_source=generator) |\n| **audio_url_2**   | The link to the **second** audio resource (spotify or soundcloud) (in the format https://open.spotify.com/embed/episode/37AK0KI06D6027Pwv96Bvk?utm_source=generator) |\n| **audio_url_3**   | The link to the **third** audio resource (spotify or soundcloud) (in the format https://open.spotify.com/embed/episode/37AK0KI06D6027Pwv96Bvk?utm_source=generator) |\n| **image_url_source**   | The URL to an image that should be displayed (e.g. in the format https://euranetplus-inside.eu/wp-content/uploads/2022/05/2-kuku.png) |\n| **image_url_target**     | The URL that the above image should point to as a link when clicking on it (e.g. in the format https://www.100komma7.lu/article/aktualiteit/49-propose-mat-326-mesuren-fir-eng-besser-eu)       |\n| **video_url**     | The URL to a video that should be displayed (e.g. in the format https://www.youtube.com/embed/asWW2pvhaJQ)      |\n\n\n\n\n**Warning:  \nPlease make sure not to delete any country names or ids.  \nAlso make sure the CSV file is formatted with commas (,) as delimiters, not semicolons (;) or other symbols. Otherwise the map will not work. Google sheets uses commas by default, so this might be the easiest solution to use.**\n\n4. Once you have updated the values, download the google sheet / excel file as a CSV file under >File > Download > Comma-separated-values (.csv), open it in a text editor (e.g. notepad, textEdit or similar) and copy all the contents of the csv file (Note: It is important that you do not paste the contents of the csv file directly from the google sheet, but instead from the downloaded file as text, because it will otherwise result in incorrect file formatting).\n\n5. Open this [data file](static/data/thematic/data.csv) (Folder: static -> data -> thematic -> data.csv) and click on the pen symbol on the top right side of the file preview window where it says \"Edit this file\". Then paste the contents of the CSV file as text here.\n\nAfter this, save the changes by pressing the green **Commit changes** button.  \nYour data should now be updated and after a while show on the map. Check the Vercel URL after a few minutes to see the updated data. \n\n## Updating text\n\nTo change the map heading, subheading, source and text note, please change the text contents of this [text configuration file](src/lib/stores/config-text.json) (Folder: src -> lib -> stores -> config-text.js). It contains the entries for all textual elements in English.\n\nExample:  \nTo change the text of the heading of the map, change the \"heading\" entry (text in quotation marks, i.e. \"\" behind the :). To do this, simply click on the pen symbol on the top right side of the file preview window where it says \"Edit this file\". **_Warning: Please make sure to always enclose the text elemets with quotation marks and do not forget to add a comma after the entry. Otherwise the file will not be able to be read and the app may brake._**\n\nThis is **correct**:  \n``\"heading\": \"Military spending up across all EU states\",``\n\nThis is **not correct** (comma is missing and no quotation marks, i.e. \"\" enclosing the text):  \n``\"heading\": Military spending up across all EU states``\n\nAfter this, save the changes by entering a title for the commit, e.g. \"Create config-text.json\" and press the green __Commit changes__ button.\n\n## Translate text\n\nAll text elements in the map are by default in English and are taken from the [text configuration file](src/lib/stores/config-text.json) (Folder: src -> lib -> stores -> config-text.js). In order to translate the text into all other EU languages, you simply need to go to the Actions tab above. Here under \"workflows\" select the \"Translate text\" workflow and press the \"Run workflow\" button on the right side and again the green \"Run workflow\" button from the dropdown menu. This will run the translate script and request the translated 24 language files from the Google API. This process may take up to a few minutes. Once this process has finished sucessfully, you should see a green check mark \u2705. \n\n**Note: It is important that you update the data first before running the automatic translations. The reason is that the additional country information is pulled directly from the csv file and thus only available for translation once the data has been added.**\n\n\n## Publish map\n\nTo embed the map on any website as a responsive widget, you need to create an iFrame code, which then can be shared. The iFrame code has to be unique for each map, bacause it details the title of the map and the Vercel URL where the map is hosted. To create the iFrame code, please follow these three steps:\n\n1. Change the \"mapTitle\" for the map in the [feature configuration file](src/lib/stores/config-features.js) (Folder: src -> lib -> stores -> config-features.js) (only if you have not done so yet in step [2](#configure-the-map))\n2. Change the \"vercelURL\" in the in the [feature configuration file](src/lib/stores/config-features.js) (Folder: src -> lib -> stores -> config-features.js) (only if you have not done so yet in step [2](#configure-the-map))\n3. Run the \"Create iFrame code\" workflow in the Actions tab above\n\nThe correct iframe code can then be copied from this [IFRAME.md file](IFRAME.md), which is generated uniquely for each project when running the script. Share this code to see the map in action on any website.\n\n## Changing translations manually\n\nAll text elements on the map (e.g. country names, heading, subheading, source text, notes, etc.) are automatically translated into the 24 official EU languages using the Google Translate API by running an automated node script. The translations returned by Google are a good first approach, but manual edits of the text in different languages may be necessary. To do this, please go to the [language folder](static/languages) (Folder: static -> languages) and edit the contents of the respective language file.\n\nExample:  \nTo change the text of the subheading of the map in Hungarian, open the [hu.json](static/languages/hu.json) file (Folder: static -> languages -> hu.json) and change the \"subheading\" entry (text in quotation marks, i.e. \"\" behind the :). To do this, simply click on the pen symbol on the top right side of the file preview window where it says \"Edit this file\". **_Warning: Please do not change the headings as these are automatically generated every day, based on the latest data. Also make sure to always enclose the text elemets with quotation marks and do not forget to add a comma after the entry. Otherwise the file will not be able to be read and the app may brake._**\n\nThis is **correct**:  \n`\"heading\": \"M\u00e1r t\u00f6bb mint 5,2 milli\u00f3 menek\u00fclt menek\u00fclt el Ukrajn\u00e1b\u00f3l\",`\n\nThis is **not correct** (comma is missing and no quotation marks, i.e. \"\" enclosing the text):  \n`\"heading\": M\u00e1r t\u00f6bb mint 5,2 milli\u00f3 menek\u00fclt menek\u00fclt el Ukrajn\u00e1b\u00f3l`\n\nAfter this, save the changes by entering a title for the commit, e.g. \"Create hu.json\" and press the green **Commit changes** button.\n\n## Development\n\nTo locally develop this map on your computer, please do the following steps in your terminal/command line:\n\n1. Clone the repo: `git clone https://github.com/EuranetPlus/map-europe.git`\n2. Open cloned folder: `cd map-europe`\n3. Install all dependencies: `npm install`\n4. Start a local development server:\n\n```bash\nnpm run dev\n\n# or start the server and open the app in a new browser tab\nnpm run dev -- --open\n```\n\n## Production\n\nBefore creating a production version of your app, please install an [adapter](https://kit.svelte.dev/docs#adapters) for your target environment. Usually this would be the static adapter provided by SvelteKit or any adapter suiting your platform (i.e. Vercel, Netlify, etc.). Please see more info here: https://kit.svelte.dev/docs#adapters\n\nTo build the app for production, run\n\n```bash\nnpm run build\n```\n\nThis will create a static folder called **build** in the root folder of the repository, which contains all the files necessary for deployment on a web server.\n\n> You can also preview the built app with `npm run preview`, regardless of whether you installed an adapter. This should _not_ be used to serve your app in production.\n"}
{"url": "https://github.com/alsino/introtodataviz", "owner": "alsino", "repository_name": "introtodataviz", "date_all_variable_collection": "2023-09-11", "description": "Final presentation for intro course at FH Potsdam", "size": 140, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "gh-pages", "contributors": [{"contributor": "alsino", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 3013}, {"language": "JavaScript", "num_chars": 2820}, {"language": "CSS", "num_chars": 616}, {"language": "Makefile", "num_chars": 126}], "readme": "# introtodataviz\nFinal presentation for intro course at FH Potsdam\n"}
{"url": "https://github.com/alsino/map-test", "owner": "alsino", "repository_name": "map-test", "date_all_variable_collection": "2023-09-11", "description": null, "size": 305, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "alsino", "contributions": 6}, {"contributor": "EuranetPlus", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 174317}, {"language": "Svelte", "num_chars": 23430}, {"language": "HTML", "num_chars": 3872}, {"language": "CSS", "num_chars": 1514}], "readme": "## About this project\n\nThis is the code repository for an interactive EuranetPlus choropleth map of European countries. The map can be updated with any data set from a CSV file. For more info see section [3. Update map with new data](#add-data).\n\nTo use the map for a new topic and populate it with new data and text please follow these steps:\n\n1. Make a copy of this map template: [Copy map template](#copy-map-template)\n2. Configure the map: [Configure map](#configure-the-map)\n3. Update map with new data: [Add or update data](#add-data)\n4. Update map titles and texts: [Updating texts](#updating-text)\n5. Translate texts into 24 EU languages [Translate texts](#translate-text)\n6. Publish the new map: [Publish map](#publish-map)\n\n![Screenshot](https://user-images.githubusercontent.com/8008434/171234651-268c6ed6-c62b-4f1f-b01f-a5009d922f19.png)\n\n_Left: Map with **\"values\"** data_  \n_Right: Map with **\"binary\"** data_\n\n## Copy map template\n\n1. **Copy repository**:  \n   To make a new map, we first need to copy this repository and use a fresh map template. To do this, please use the green \"Use this template\" button on the top right in this window. This will create a copy of the exact same code that can be used for a new map. You will be prompted to name the new repository according to the new topic of the map. Please use this nomenclature: _map-TOPIC_, e.g. _map-gdp_ or _map-generationz_. If more than two words are used, separtate them with a dash like so _map-military-spending_.\n\n2. **Add Google Credentials**:  \n   In order to be able to use the automatic translation service by the Google API, we need to provide the new repository with access to the service account API key. For this go to the **Settings** tab at the top of this repository and select the \"Secrets\" dropdown on the lower left side. Here select \"Actions\". On the top right side press the \"New repository secret\" button. Name the new secret **\"GOOGLE_CREDENTIALS\"** and as a value paste in the contents of the service account json file that can be downloaded from the Google Cloud Console. This file looks something like this (Note: This example file below here is fake and only for illustration purposes):\n\n```bash\n{\n  \"type\": \"service_account\",\n  \"project_id\": \"iron-moon-dgddg\",\n  \"private_key_id\": \"843dgj436fcf7bfab4sgg367235529\",\n  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvwIhdghgdBg\\n-----END PRIVATE KEY-----\\n\",\n  \"client_email\": \"maps@iron-moon-dgdgdgdgg.iam.gserviceaccount.com\",\n  \"client_id\": \"sgdgfdgdggdgggdgg\",\n  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/maps%40iron-moon-dgdgdgdgg.iam.gserviceaccount.com\"\n}\n```\n\n3. **Allow scripts**:  \n   By default every new repository is locked for running automated scripts. We need to enable this functionality first. Go to the **Settings** tab at the top of this repository and select \"Actions\" and then \"General\" from the dropdown on the lower left side. Then set the \"Workflow permissions\" to \"Read and write permissions\". Now we can change the texts and run the translations.\n\n4. **Connect to Vercel**:\n   Once the new repository is set up, you need to connect it to Vercel to deploy the map to the internet. Please go to https://vercel.com/dashboard, sign in with your GitHub account and do the following steps:\n\n- Press the \"New Project\" Button on the Vercel dashboard\n- Under \"Import Git Repository\" choose the name of the copied repository\n- Press the blue \"Deploy\" button (no need to change any settings here)\n- Press the \"Go to Dashboard\" button and copy the URL under the \"DOMAINS\" heading (the url should look something like this: https://map-test-seven.vercel.app/)\n- Go to the [map configuration file](src/lib/stores/config-features.js) (Folder: src -> lib -> stores -> config-features.js) and paste the URL on [line 3](https://github.com/EuranetPlus/map-europe/blob/e6f63675ae3706bc5337eb755ae58c61c1e27634/src/lib/stores/config-features.js#L3).\n\n## Configure the map\n\nIn order to configure the new project, please change the contents of this [map configuration file](src/lib/stores/config-features.js) (Folder: src -> lib -> stores -> config-features.js). The configuration has a number of parameters that you should specify.\n\nThe most important entries that you need to change for each project are the \"mapTitle\", the \"vercelURL\", \"datasetType\", \"datasetUnit\" and \"colourScheme\":\n\n```js\n  \"mapTitle\": \"europe\", // The title of the map, if more than one word, separate by dash, e.g. \"income-europe\"\n  \"vercelURL\": \"https://euranet-map-europe.vercel.app\", // The url provided when deploying the map on Vercel\n  \"datasetType\": \"values\", // \"values\" or \"binary\"; Does the data set contain numerical values or binary (0/1) values for countries?\n  \"datasetUnit\": \"percent\", // \"fullNumbers\" or \"percent\"; Is the data in percent (0.25 of GDP) or full numbers (25 people)?\n  \"percentRounded\": false, // true or false; Should the percent values be rounded to full numbers (i.e. 26%, false) or 1-decimal place (i.e. 25.9%, true)\n  \"colourScheme\": \"blue\",  // one of the following: \"blue\", \"purple-blue\", \"green-blue\", \"orange-red\", \"yellow-green\"\n  \"headlineAvailable\": true, // true or false; Should the map have a headline?\n  \"subheadlineAvailable\": true, // true or false; Should the map have a subheadline?\n  \"tooltipAvailable\": true, // true or false; Should the map show a tooltip when hovering over a country?\n  \"scaleBarAvailable\": true, // true or false; Should the map show a scale bar on the top?\n  \"legendAvailable\": true, // true or false; Should the map show a legend in the bottom right corner?\n  \"textSourceAvailable\": true, // true or false; Should the map show a source text below the map?\n  \"textNoteAvailable\": true, // true or false; Should the map show a text note below the map?\n  \"textDataAccessAvailable\": true, // true or false; Should the map show a link to the original data source below the map?\n  \"legend1Color\": \"#cad1d9\", // Specifies the color of the first round dot in the legend entry\n  \"legend2Color\": \"red\", // Specifies the color of the second round dot in the legend entry\n  \"legend3Color\": \"blue\", // Specifies the color of the third round dot in the legend entry\n  \"legend4Color\": \"green\" // Specifies the color of the fourt round dot in the legend entry\n```\n\n## Add data\n\nTo add or update the map data, please first decide whether the data set you are using shows \"values\", i.e. continous numbers on a color scale or whether it is \"binary\", i.e. the map shows only a few countries in the same color (\"dark blue\") as a category (0 = there is no data for this country, 1 = there is data for this country).\n\n1. Set the dataset type in the [map configuration file](src/lib/stores/config-features.js) (Folder: src -> lib -> stores -> config-features.js) under \"datasetType\". If your dataset consists of **values data**, please use this [csv values template](https://docs.google.com/spreadsheets/d/1fzicMw_LiFGrdtzloXZFbM2FFgVc-GYtavvxPJFZ5Yo/edit?usp=sharing). If it consists of **binary data**, please use this [csv binary template](https://docs.google.com/spreadsheets/d/1YL_5aVY9zaaxwhI6-cEgcwO8k01Fzu2FzsPMtvppYfg/edit?usp=sharing).\n\n2. Then you need to decide whether the data consists of **full numbers** (i.e. 45 people) or **percent values**, (i.e. 45% of GDP). In the [map configuration file](src/lib/stores/config-features.js) (Folder: src -> lib -> stores -> config-features.js) this can be set under \"datasetUnit\".\n\n3. Please copy the respective csv template to your own computer (or Google Drive) and fill in the desired data point for each country. Please make sure that values are formatted with dots (.) as a comma separator and **not commas**, i.e. 0.45 for percentage values instead of 0,45. In the template, all percentage values are always written as fractions of 1, **i.e. 0.45 and not 45**.\n\n4. For any country you can add additional content information (i.e. text, audio, image and video) that will show up once you click on a country. If you want to do this for a specific country, set the value in the column \"extraInfo\" to **TRUE**, otherwise to **FALSE**.  \n   **_Important: The column \"extraInfo\" needs to be included in every data set and either be set to TRUE or FALSE for each country. Otherwise the map will not work. The following columns only need to contain content if extraInfo is set to TRUE_**.\n\n| Column Name          | Description                                                                                                                                                                               |\n| :------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **text_content**     | A text for each country. Should ideally not be more than 1 small to medium-sized paragraph                                                                                                |\n| **link_text**        | The text of a link that redirects to an outside resource. Usually this text would be something like \"Read more\" or \"Link to article\"                                                      |\n| **link_url_target**  | The URL to which the link should refer to (e.g. https://euranetplus-inside.eu/exodus-education-and-elections/)                                                                            |\n| **audio_url_1**      | The link to the **first** audio resource (spotify or soundcloud) (in the format https://open.spotify.com/embed/episode/37AK0KI06D6027Pwv96Bvk?utm_source=generator)                       |\n| **audio_url_2**      | The link to the **second** audio resource (spotify or soundcloud) (in the format https://open.spotify.com/embed/episode/37AK0KI06D6027Pwv96Bvk?utm_source=generator)                      |\n| **audio_url_3**      | The link to the **third** audio resource (spotify or soundcloud) (in the format https://open.spotify.com/embed/episode/37AK0KI06D6027Pwv96Bvk?utm_source=generator)                       |\n| **image_url_source** | The URL to an image that should be displayed (e.g. in the format https://euranetplus-inside.eu/wp-content/uploads/2022/05/2-kuku.png)                                                     |\n| **image_url_target** | The URL that the above image should point to as a link when clicking on it (e.g. in the format https://www.100komma7.lu/article/aktualiteit/49-propose-mat-326-mesuren-fir-eng-besser-eu) |\n| **video_url**        | The URL to a video that should be displayed (e.g. in the format https://www.youtube.com/embed/asWW2pvhaJQ)                                                                                |\n\n**Warning:  \nPlease make sure not to delete any country names or ids.  \nAlso make sure the CSV file is formatted with commas (,) as delimiters, not semicolons (;) or other symbols. Otherwise the map will not work. Google sheets uses commas by default, so this might be the easiest solution to use.**\n\n4. Once you have updated the values, download the google sheet / excel file as a CSV file under >File > Download > Comma-separated-values (.csv), open it in a text editor (e.g. notepad, textEdit or similar) and copy all the contents of the csv file (Note: It is important that you do not paste the contents of the csv file directly from the google sheet, but instead from the downloaded file as text, because it will otherwise result in incorrect file formatting).\n\n5. Open this [data file](static/data/thematic/data.csv) (Folder: static -> data -> thematic -> data.csv) and click on the pen symbol on the top right side of the file preview window where it says \"Edit this file\". Then paste the contents of the CSV file as text here.\n\nAfter this, save the changes by pressing the green **Commit changes** button.  \nYour data should now be updated and after a while show on the map. Check the Vercel URL after a few minutes to see the updated data.\n\n## Updating text\n\nTo change the map heading, subheading, source and text note, please change the text contents of this [text configuration file](src/lib/stores/config-text.json) (Folder: src -> lib -> stores -> config-text.js). It contains the entries for all textual elements in English.\n\nExample:  \nTo change the text of the heading of the map, change the \"heading\" entry (text in quotation marks, i.e. \"\" behind the :). To do this, simply click on the pen symbol on the top right side of the file preview window where it says \"Edit this file\". **_Warning: Please make sure to always enclose the text elemets with quotation marks and do not forget to add a comma after the entry. Otherwise the file will not be able to be read and the app may brake._**\n\nThis is **correct**:  \n`\"heading\": \"Military spending up across all EU states\",`\n\nThis is **not correct** (comma is missing and no quotation marks, i.e. \"\" enclosing the text):  \n`\"heading\": Military spending up across all EU states`\n\nAfter this, save the changes by entering a title for the commit, e.g. \"Create config-text.json\" and press the green **Commit changes** button.\n\n## Translate text\n\nAll text elements in the map are by default in English and are taken from the [text configuration file](src/lib/stores/config-text.json) (Folder: src -> lib -> stores -> config-text.js). In order to translate the text into all other EU languages, you simply need to go to the Actions tab above. Here under \"workflows\" select the \"Translate text\" workflow and press the \"Run workflow\" button on the right side and again the green \"Run workflow\" button from the dropdown menu. This will run the translate script and request the translated 24 language files from the Google API. This process may take up to a few minutes. Once this process has finished sucessfully, you should see a green check mark \u2705.\n\n**Note: It is important that you update the data first before running the automatic translations. The reason is that the additional country information is pulled directly from the csv file and thus only available for translation once the data has been added.**\n\n## Publish map\n\nTo embed the map on any website as a responsive widget, you need to create an iFrame code, which then can be shared. The iFrame code has to be unique for each map, bacause it details the title of the map and the Vercel URL where the map is hosted. To create the iFrame code, please follow these three steps:\n\n1. Change the \"mapTitle\" for the map in the [feature configuration file](src/lib/stores/config-features.js) (Folder: src -> lib -> stores -> config-features.js) (only if you have not done so yet in step [2](#configure-the-map))\n2. Change the \"vercelURL\" in the in the [feature configuration file](src/lib/stores/config-features.js) (Folder: src -> lib -> stores -> config-features.js) (only if you have not done so yet in step [2](#configure-the-map))\n3. Run the \"Create iFrame code\" workflow in the Actions tab above\n\nThe correct iframe code can then be copied from this [IFRAME.md file](IFRAME.md), which is generated uniquely for each project when running the script. Share this code to see the map in action on any website.\n\n## Changing translations manually\n\nAll text elements on the map (e.g. country names, heading, subheading, source text, notes, etc.) are automatically translated into the 24 official EU languages using the Google Translate API by running an automated node script. The translations returned by Google are a good first approach, but manual edits of the text in different languages may be necessary. To do this, please go to the [language folder](static/languages) (Folder: static -> languages) and edit the contents of the respective language file.\n\nExample:  \nTo change the text of the subheading of the map in Hungarian, open the [hu.json](static/languages/hu.json) file (Folder: static -> languages -> hu.json) and change the \"subheading\" entry (text in quotation marks, i.e. \"\" behind the :). To do this, simply click on the pen symbol on the top right side of the file preview window where it says \"Edit this file\". **_Warning: Please do not change the headings as these are automatically generated every day, based on the latest data. Also make sure to always enclose the text elemets with quotation marks and do not forget to add a comma after the entry. Otherwise the file will not be able to be read and the app may brake._**\n\nThis is **correct**:  \n`\"heading\": \"M\u00e1r t\u00f6bb mint 5,2 milli\u00f3 menek\u00fclt menek\u00fclt el Ukrajn\u00e1b\u00f3l\",`\n\nThis is **not correct** (comma is missing and no quotation marks, i.e. \"\" enclosing the text):  \n`\"heading\": M\u00e1r t\u00f6bb mint 5,2 milli\u00f3 menek\u00fclt menek\u00fclt el Ukrajn\u00e1b\u00f3l`\n\nAfter this, save the changes by entering a title for the commit, e.g. \"Create hu.json\" and press the green **Commit changes** button.\n\n## Development\n\nTo locally develop this map on your computer, please do the following steps in your terminal/command line:\n\n1. Clone the repo: `git clone https://github.com/EuranetPlus/map-europe.git`\n2. Open cloned folder: `cd map-europe`\n3. Install all dependencies: `npm install`\n4. Start a local development server:\n\n```bash\nnpm run dev\n\n# or start the server and open the app in a new browser tab\nnpm run dev -- --open\n```\n\n## Production\n\nBefore creating a production version of your app, please install an [adapter](https://kit.svelte.dev/docs#adapters) for your target environment. Usually this would be the static adapter provided by SvelteKit or any adapter suiting your platform (i.e. Vercel, Netlify, etc.). Please see more info here: https://kit.svelte.dev/docs#adapters\n\nTo build the app for production, run\n\n```bash\nnpm run build\n```\n\nThis will create a static folder called **build** in the root folder of the repository, which contains all the files necessary for deployment on a web server.\n\n> You can also preview the built app with `npm run preview`, regardless of whether you installed an adapter. This should _not_ be used to serve your app in production.\n"}
{"url": "https://github.com/alsino/map-today-test", "owner": "alsino", "repository_name": "map-today-test", "date_all_variable_collection": "2023-09-11", "description": null, "size": 313, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "alsino", "contributions": 10}, {"contributor": "EuranetPlus", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 174327}, {"language": "Svelte", "num_chars": 23430}, {"language": "HTML", "num_chars": 3872}, {"language": "CSS", "num_chars": 1514}], "readme": "## About this project\n\nThis is the code repository for an interactive EuranetPlus choropleth map of European countries. The map can be updated with any data set from a CSV file. For more info see section [3. Update map with new data](#add-data).\n\nTo use the map for a new topic and populate it with new data and text please follow these steps:\n\n1. Make a copy of this map template: [Copy map template](#copy-map-template)\n2. Configure the map: [Configure map](#configure-the-map)\n3. Update map with new data: [Add or update data](#add-data)\n4. Update map titles and texts: [Updating texts](#updating-text)\n5. Translate texts into 24 EU languages [Translate texts](#translate-text)\n6. Publish the new map: [Publish map](#publish-map)\n\n![Screenshot](https://user-images.githubusercontent.com/8008434/171234651-268c6ed6-c62b-4f1f-b01f-a5009d922f19.png)\n\n_Left: Map with **\"values\"** data_  \n_Right: Map with **\"binary\"** data_\n\n## Copy map template\n\n1. **Copy repository**:  \n   To make a new map, we first need to copy this repository and use a fresh map template. To do this, please use the green \"Use this template\" button on the top right in this window. This will create a copy of the exact same code that can be used for a new map. You will be prompted to name the new repository according to the new topic of the map. Please use this nomenclature: _map-TOPIC_, e.g. _map-gdp_ or _map-generationz_. If more than two words are used, separtate them with a dash like so _map-military-spending_.\n\n2. **Add Google Credentials**:  \n   In order to be able to use the automatic translation service by the Google API, we need to provide the new repository with access to the service account API key. For this go to the **Settings** tab at the top of this repository and select the \"Secrets\" dropdown on the lower left side. Here select \"Actions\". On the top right side press the \"New repository secret\" button. Name the new secret **\"GOOGLE_CREDENTIALS\"** and as a value paste in the contents of the service account json file that can be downloaded from the Google Cloud Console. This file looks something like this (Note: This example file below here is fake and only for illustration purposes):\n\n```bash\n{\n  \"type\": \"service_account\",\n  \"project_id\": \"iron-moon-dgddg\",\n  \"private_key_id\": \"843dgj436fcf7bfab4sgg367235529\",\n  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvwIhdghgdBg\\n-----END PRIVATE KEY-----\\n\",\n  \"client_email\": \"maps@iron-moon-dgdgdgdgg.iam.gserviceaccount.com\",\n  \"client_id\": \"sgdgfdgdggdgggdgg\",\n  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/maps%40iron-moon-dgdgdgdgg.iam.gserviceaccount.com\"\n}\n```\n\n3. **Allow scripts**:  \n   By default every new repository is locked for running automated scripts. We need to enable this functionality first. Go to the **Settings** tab at the top of this repository and select \"Actions\" and then \"General\" from the dropdown on the lower left side. Then set the \"Workflow permissions\" to \"Read and write permissions\". Now we can change the texts and run the translations.\n\n4. **Connect to Vercel**:\n   Once the new repository is set up, you need to connect it to Vercel to deploy the map to the internet. Please go to https://vercel.com/dashboard, sign in with your GitHub account and do the following steps:\n\n- Press the \"New Project\" Button on the Vercel dashboard\n- Under \"Import Git Repository\" choose the name of the copied repository\n- Press the blue \"Deploy\" button (no need to change any settings here)\n- Press the \"Go to Dashboard\" button and copy the URL under the \"DOMAINS\" heading (the url should look something like this: https://map-test-seven.vercel.app/)\n- Go to the [map configuration file](src/lib/stores/config-features.js) (Folder: src -> lib -> stores -> config-features.js) and paste the URL on [line 3](https://github.com/EuranetPlus/map-europe/blob/e6f63675ae3706bc5337eb755ae58c61c1e27634/src/lib/stores/config-features.js#L3).\n\n## Configure the map\n\nIn order to configure the new project, please change the contents of this [map configuration file](src/lib/stores/config-features.js) (Folder: src -> lib -> stores -> config-features.js). The configuration has a number of parameters that you should specify.\n\nThe most important entries that you need to change for each project are the \"mapTitle\", the \"vercelURL\", \"datasetType\", \"datasetUnit\" and \"colourScheme\":\n\n```js\n  \"mapTitle\": \"europe\", // The title of the map, if more than one word, separate by dash, e.g. \"income-europe\"\n  \"vercelURL\": \"https://euranet-map-europe.vercel.app\", // The url provided when deploying the map on Vercel\n  \"datasetType\": \"values\", // \"values\" or \"binary\"; Does the data set contain numerical values or binary (0/1) values for countries?\n  \"datasetUnit\": \"percent\", // \"fullNumbers\" or \"percent\"; Is the data in percent (0.25 of GDP) or full numbers (25 people)?\n  \"percentRounded\": false, // true or false; Should the percent values be rounded to full numbers (i.e. 26%, false) or 1-decimal place (i.e. 25.9%, true)\n  \"colourScheme\": \"blue\",  // one of the following: \"blue\", \"purple-blue\", \"green-blue\", \"orange-red\", \"yellow-green\"\n  \"headlineAvailable\": true, // true or false; Should the map have a headline?\n  \"subheadlineAvailable\": true, // true or false; Should the map have a subheadline?\n  \"tooltipAvailable\": true, // true or false; Should the map show a tooltip when hovering over a country?\n  \"scaleBarAvailable\": true, // true or false; Should the map show a scale bar on the top?\n  \"legendAvailable\": true, // true or false; Should the map show a legend in the bottom right corner?\n  \"textSourceAvailable\": true, // true or false; Should the map show a source text below the map?\n  \"textNoteAvailable\": true, // true or false; Should the map show a text note below the map?\n  \"textDataAccessAvailable\": true, // true or false; Should the map show a link to the original data source below the map?\n  \"legend1Color\": \"#cad1d9\", // Specifies the color of the first round dot in the legend entry\n  \"legend2Color\": \"red\", // Specifies the color of the second round dot in the legend entry\n  \"legend3Color\": \"blue\", // Specifies the color of the third round dot in the legend entry\n  \"legend4Color\": \"green\" // Specifies the color of the fourt round dot in the legend entry\n```\n\n## Add data\n\nTo add or update the map data, please first decide whether the data set you are using shows \"values\", i.e. continous numbers on a color scale or whether it is \"binary\", i.e. the map shows only a few countries in the same color (\"dark blue\") as a category (0 = there is no data for this country, 1 = there is data for this country).\n\n1. Set the dataset type in the [map configuration file](src/lib/stores/config-features.js) (Folder: src -> lib -> stores -> config-features.js) under \"datasetType\". If your dataset consists of **values data**, please use this [csv values template](https://docs.google.com/spreadsheets/d/1N7cKYXA-YnrqBI4Na7EehTbtELH2IGUDAe9wWQiPLDo/edit#gid=0). If it consists of **binary data**, please use this [csv binary template](https://docs.google.com/spreadsheets/d/1YL_5aVY9zaaxwhI6-cEgcwO8k01Fzu2FzsPMtvppYfg/edit?usp=sharing).\n\n2. Then you need to decide whether the data consists of **full numbers** (i.e. 45 people) or **percent values**, (i.e. 45% of GDP). In the [map configuration file](src/lib/stores/config-features.js) (Folder: src -> lib -> stores -> config-features.js) this can be set under \"datasetUnit\".\n\n3. Please copy the respective csv template to your own computer (or Google Drive) and fill in the desired data point for each country. Please make sure that values are formatted with dots (.) as a comma separator and **not commas**, i.e. 0.45 for percentage values instead of 0,45. In the template, all percentage values are always written as fractions of 1, **i.e. 0.45 and not 45**.\n\n4. For any country you can add additional content information (i.e. text, audio, image and video) that will show up once you click on a country. If you want to do this for a specific country, set the value in the column \"extraInfo\" to **TRUE**, otherwise to **FALSE**.  \n   **_Important: The column \"extraInfo\" needs to be included in every data set and either be set to TRUE or FALSE for each country. Otherwise the map will not work. The following columns only need to contain content if extraInfo is set to TRUE_**.\n\n| Column Name          | Description                                                                                                                                                                               |\n| :------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **text_content**     | A text for each country. Should ideally not be more than 1 small to medium-sized paragraph                                                                                                |\n| **link_text**        | The text of a link that redirects to an outside resource. Usually this text would be something like \"Read more\" or \"Link to article\"                                                      |\n| **link_url_target**  | The URL to which the link should refer to (e.g. https://euranetplus-inside.eu/exodus-education-and-elections/)                                                                            |\n| **audio_url_1**      | The link to the **first** audio resource (spotify or soundcloud) (in the format https://open.spotify.com/embed/episode/37AK0KI06D6027Pwv96Bvk?utm_source=generator)                       |\n| **audio_url_2**      | The link to the **second** audio resource (spotify or soundcloud) (in the format https://open.spotify.com/embed/episode/37AK0KI06D6027Pwv96Bvk?utm_source=generator)                      |\n| **audio_url_3**      | The link to the **third** audio resource (spotify or soundcloud) (in the format https://open.spotify.com/embed/episode/37AK0KI06D6027Pwv96Bvk?utm_source=generator)                       |\n| **image_url_source** | The URL to an image that should be displayed (e.g. in the format https://euranetplus-inside.eu/wp-content/uploads/2022/05/2-kuku.png)                                                     |\n| **image_url_target** | The URL that the above image should point to as a link when clicking on it (e.g. in the format https://www.100komma7.lu/article/aktualiteit/49-propose-mat-326-mesuren-fir-eng-besser-eu) |\n| **video_url**        | The URL to a video that should be displayed (e.g. in the format https://www.youtube.com/embed/asWW2pvhaJQ)                                                                                |\n\n**Warning:  \nPlease make sure not to delete any country names or ids.  \nAlso make sure the CSV file is formatted with commas (,) as delimiters, not semicolons (;) or other symbols. Otherwise the map will not work. Google sheets uses commas by default, so this might be the easiest solution to use.**\n\n4. Once you have updated the values, download the google sheet / excel file as a CSV file under >File > Download > Comma-separated-values (.csv), open it in a text editor (e.g. notepad, textEdit or similar) and copy all the contents of the csv file (Note: It is important that you do not paste the contents of the csv file directly from the google sheet, but instead from the downloaded file as text, because it will otherwise result in incorrect file formatting).\n\n5. Open this [data file](static/data/thematic/data.csv) (Folder: static -> data -> thematic -> data.csv) and click on the pen symbol on the top right side of the file preview window where it says \"Edit this file\". Then paste the contents of the CSV file as text here.\n\nAfter this, save the changes by pressing the green **Commit changes** button.  \nYour data should now be updated and after a while show on the map. Check the Vercel URL after a few minutes to see the updated data.\n\n## Updating text\n\nTo change the map heading, subheading, source and text note, please change the text contents of this [text configuration file](src/lib/stores/config-text.json) (Folder: src -> lib -> stores -> config-text.js). It contains the entries for all textual elements in English.\n\nExample:  \nTo change the text of the heading of the map, change the \"heading\" entry (text in quotation marks, i.e. \"\" behind the :). To do this, simply click on the pen symbol on the top right side of the file preview window where it says \"Edit this file\". **_Warning: Please make sure to always enclose the text elemets with quotation marks and do not forget to add a comma after the entry. Otherwise the file will not be able to be read and the app may brake._**\n\nThis is **correct**:  \n`\"heading\": \"Military spending up across all EU states\",`\n\nThis is **not correct** (comma is missing and no quotation marks, i.e. \"\" enclosing the text):  \n`\"heading\": Military spending up across all EU states`\n\nAfter this, save the changes by entering a title for the commit, e.g. \"Create config-text.json\" and press the green **Commit changes** button.\n\n## Translate text\n\nAll text elements in the map are by default in English and are taken from the [text configuration file](src/lib/stores/config-text.json) (Folder: src -> lib -> stores -> config-text.js). In order to translate the text into all other EU languages, you simply need to go to the Actions tab above. Here under \"workflows\" select the \"Translate text\" workflow and press the \"Run workflow\" button on the right side and again the green \"Run workflow\" button from the dropdown menu. This will run the translate script and request the translated 24 language files from the Google API. This process may take up to a few minutes. Once this process has finished sucessfully, you should see a green check mark \u2705.\n\n**Note: It is important that you update the data first before running the automatic translations. The reason is that the additional country information is pulled directly from the csv file and thus only available for translation once the data has been added.**\n\n## Publish map\n\nTo embed the map on any website as a responsive widget, you need to create an iFrame code, which then can be shared. The iFrame code has to be unique for each map, bacause it details the title of the map and the Vercel URL where the map is hosted. To create the iFrame code, please follow these three steps:\n\n1. Change the \"mapTitle\" for the map in the [feature configuration file](src/lib/stores/config-features.js) (Folder: src -> lib -> stores -> config-features.js) (only if you have not done so yet in step [2](#configure-the-map))\n2. Change the \"vercelURL\" in the in the [feature configuration file](src/lib/stores/config-features.js) (Folder: src -> lib -> stores -> config-features.js) (only if you have not done so yet in step [2](#configure-the-map))\n3. Run the \"Create iFrame code\" workflow in the Actions tab above\n\nThe correct iframe code can then be copied from this [IFRAME.md file](IFRAME.md), which is generated uniquely for each project when running the script. Share this code to see the map in action on any website.\n\n## Changing translations manually\n\nAll text elements on the map (e.g. country names, heading, subheading, source text, notes, etc.) are automatically translated into the 24 official EU languages using the Google Translate API by running an automated node script. The translations returned by Google are a good first approach, but manual edits of the text in different languages may be necessary. To do this, please go to the [language folder](static/languages) (Folder: static -> languages) and edit the contents of the respective language file.\n\nExample:  \nTo change the text of the subheading of the map in Hungarian, open the [hu.json](static/languages/hu.json) file (Folder: static -> languages -> hu.json) and change the \"subheading\" entry (text in quotation marks, i.e. \"\" behind the :). To do this, simply click on the pen symbol on the top right side of the file preview window where it says \"Edit this file\". **_Warning: Please do not change the headings as these are automatically generated every day, based on the latest data. Also make sure to always enclose the text elemets with quotation marks and do not forget to add a comma after the entry. Otherwise the file will not be able to be read and the app may brake._**\n\nThis is **correct**:  \n`\"heading\": \"M\u00e1r t\u00f6bb mint 5,2 milli\u00f3 menek\u00fclt menek\u00fclt el Ukrajn\u00e1b\u00f3l\",`\n\nThis is **not correct** (comma is missing and no quotation marks, i.e. \"\" enclosing the text):  \n`\"heading\": M\u00e1r t\u00f6bb mint 5,2 milli\u00f3 menek\u00fclt menek\u00fclt el Ukrajn\u00e1b\u00f3l`\n\nAfter this, save the changes by entering a title for the commit, e.g. \"Create hu.json\" and press the green **Commit changes** button.\n\n## Development\n\nTo locally develop this map on your computer, please do the following steps in your terminal/command line:\n\n1. Clone the repo: `git clone https://github.com/EuranetPlus/map-europe.git`\n2. Open cloned folder: `cd map-europe`\n3. Install all dependencies: `npm install`\n4. Start a local development server:\n\n```bash\nnpm run dev\n\n# or start the server and open the app in a new browser tab\nnpm run dev -- --open\n```\n\n## Production\n\nBefore creating a production version of your app, please install an [adapter](https://kit.svelte.dev/docs#adapters) for your target environment. Usually this would be the static adapter provided by SvelteKit or any adapter suiting your platform (i.e. Vercel, Netlify, etc.). Please see more info here: https://kit.svelte.dev/docs#adapters\n\nTo build the app for production, run\n\n```bash\nnpm run build\n```\n\nThis will create a static folder called **build** in the root folder of the repository, which contains all the files necessary for deployment on a web server.\n\n> You can also preview the built app with `npm run preview`, regardless of whether you installed an adapter. This should _not_ be used to serve your app in production.\n"}
{"url": "https://github.com/alsino/nyt-headlines", "owner": "alsino", "repository_name": "nyt-headlines", "date_all_variable_collection": "2023-09-11", "description": "A test on github actions", "size": 1457, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "alsino", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 2509}], "readme": "# nyt-headlines\nA test on github actions\n"}
{"url": "https://github.com/alsino/one-click-hugo-cms", "owner": "alsino", "repository_name": "one-click-hugo-cms", "date_all_variable_collection": "2023-09-11", "description": null, "size": 41967, "stargazers_count": 0, "watchers_count": 0, "language": "CSS", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "biilmann", "contributions": 74}, {"contributor": "renovate[bot]", "contributions": 30}, {"contributor": "erquhart", "contributions": 15}, {"contributor": "calavera", "contributions": 10}, {"contributor": "Benaiah", "contributions": 4}, {"contributor": "verythorough", "contributions": 4}, {"contributor": "darindimitroff", "contributions": 3}, {"contributor": "jwithington", "contributions": 2}, {"contributor": "MadeByMike", "contributions": 2}, {"contributor": "ojn", "contributions": 2}, {"contributor": "wiesson", "contributions": 1}, {"contributor": "tech4him1", "contributions": 1}, {"contributor": "DavidRayner", "contributions": 1}, {"contributor": "easherma", "contributions": 1}, {"contributor": "joe6pack", "contributions": 1}, {"contributor": "okabrionz", "contributions": 1}, {"contributor": "dhrp", "contributions": 1}, {"contributor": "TomDeS", "contributions": 1}, {"contributor": "alsino", "contributions": 1}, {"contributor": "imorente", "contributions": 1}, {"contributor": "talves", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "CSS", "num_chars": 94418}, {"language": "HTML", "num_chars": 15367}, {"language": "JavaScript", "num_chars": 14963}], "readme": "# Hugo template for Netlify CMS with Netlify Identity\n\nThis is a small business template built with [Victor Hugo](https://github.com/netlify/victor-hugo) and [Netlify CMS](https://github.com/netlify/netlify-cms), designed and developed by [Darin Dimitroff](http://www.darindimitroff.com/), [spacefarm.digital](https://www.spacefarm.digital).\n\n## Getting started\n\nUse our deploy button to get your own copy of the repository. \n\n[![Deploy to Netlify](https://www.netlify.com/img/deploy/button.svg)](https://app.netlify.com/start/deploy?repository=https://github.com/netlify-templates/one-click-hugo-cms&stack=cms)\n\nThis will setup everything needed for running the CMS:\n\n* A new repository in your GitHub account with the code\n* Full Continuous Deployment to Netlify's global CDN network\n* Control users and access with Netlify Identity\n* Manage content with Netlify CMS\n\nOnce the initial build finishes, you can invite yourself as a user. Go to the Identity tab in your new site, click \"Invite\" and send yourself an invite.\n\nNow you're all set, and you can start editing content!\n\n## Local Development\n\nClone this repository, and run `yarn` or `npm install` from the new folder to install all required dependencies.\n\nThen start the development server with `yarn start` or `npm start`.\n\n## Layouts\n\nThe template is based on small, content-agnostic partials that can be mixed and matched. The pre-built pages showcase just a few of the possible combinations. Refer to the `site/layouts/partials` folder for all available partials.\n\nUse Hugo\u2019s `dict` functionality to feed content into partials and avoid repeating yourself and creating discrepancies.\n\n## CSS\n\nThe template uses a custom fork of Tachyons and PostCSS with cssnext and cssnano. To customize the template for your brand, refer to `src/css/imports/_variables.css` where most of the important global variables like colors and spacing are stored.\n\n## SVG\n\nAll SVG icons stored in `site/static/img/icons` are automatically optimized with SVGO (gulp-svgmin) and concatenated into a single SVG sprite stored as a a partial called `svg.html`. Make sure you use consistent icons in terms of viewport and art direction for optimal results. Refer to an SVG via the `<use>` tag like so:\n\n```\n<svg width=\"16px\" height=\"16px\" class=\"db\">\n  <use xlink:href=\"#SVG-ID\"></use>\n</svg>\n```\n"}
{"url": "https://github.com/alsino/p5sound", "owner": "alsino", "repository_name": "p5sound", "date_all_variable_collection": "2023-09-11", "description": "A short test of the p5.js library with sound import", "size": 2320, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "gh-pages", "contributors": [{"contributor": "alsino", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 2361371}, {"language": "HTML", "num_chars": 594}], "readme": "# p5sound\nA short test of the p5.js library with sound import (http://p5js.org/)\n"}
{"url": "https://github.com/alsino/sapper-dynamicRoutes", "owner": "alsino", "repository_name": "sapper-dynamicRoutes", "date_all_variable_collection": "2023-09-11", "description": null, "size": 286, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 8, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 8, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alsino", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 8316}, {"language": "HTML", "num_chars": 4269}, {"language": "CSS", "num_chars": 584}], "readme": "# sapper-template\n\nThe default [Sapper](https://github.com/sveltejs/sapper) template, with a setup for dynamic routes, based on a demo dataset in the store.\n\n\n## Getting started\n\n\n### Using `degit`\n\n[`degit`](https://github.com/Rich-Harris/degit) is a scaffolding tool that lets you create a directory from a branch in a repository. Use either the `rollup` or `webpack` branch in `sapper-template`:\n\n```bash\n# for Rollup\nnpx degit \"sveltejs/sapper-template#rollup\" my-app\n# for webpack\nnpx degit \"sveltejs/sapper-template#webpack\" my-app\n```\n\n\n### Using GitHub templates\n\nAlternatively, you can use GitHub's template feature with the [sapper-template-rollup](https://github.com/sveltejs/sapper-template-rollup) or [sapper-template-webpack](https://github.com/sveltejs/sapper-template-webpack) repositories.\n\n\n### Running the project\n\nHowever you get the code, you can install dependencies and run the project in development mode with:\n\n```bash\ncd my-app\nnpm install # or yarn\nnpm run dev\n```\n\nOpen up [localhost:3000](http://localhost:3000) and start clicking around.\n\nConsult [sapper.svelte.dev](https://sapper.svelte.dev) for help getting started.\n\n\n## Structure\n\nSapper expects to find two directories in the root of your project \u2014  `src` and `static`.\n\n\n### src\n\nThe [src](src) directory contains the entry points for your app \u2014 `client.js`, `server.js` and (optionally) a `service-worker.js` \u2014 along with a `template.html` file and a `routes` directory.\n\n\n#### src/routes\n\nThis is the heart of your Sapper app. There are two kinds of routes \u2014 *pages*, and *server routes*.\n\n**Pages** are Svelte components written in `.svelte` files. When a user first visits the application, they will be served a server-rendered version of the route in question, plus some JavaScript that 'hydrates' the page and initialises a client-side router. From that point forward, navigating to other pages is handled entirely on the client for a fast, app-like feel. (Sapper will preload and cache the code for these subsequent pages, so that navigation is instantaneous.)\n\n**Server routes** are modules written in `.js` files, that export functions corresponding to HTTP methods. Each function receives Express `request` and `response` objects as arguments, plus a `next` function. This is useful for creating a JSON API, for example.\n\nThere are three simple rules for naming the files that define your routes:\n\n* A file called `src/routes/about.svelte` corresponds to the `/about` route. A file called `src/routes/blog/[slug].svelte` corresponds to the `/blog/:slug` route, in which case `params.slug` is available to the route\n* The file `src/routes/index.svelte` (or `src/routes/index.js`) corresponds to the root of your app. `src/routes/about/index.svelte` is treated the same as `src/routes/about.svelte`.\n* Files and directories with a leading underscore do *not* create routes. This allows you to colocate helper modules and components with the routes that depend on them \u2014 for example you could have a file called `src/routes/_helpers/datetime.js` and it would *not* create a `/_helpers/datetime` route\n\n\n### static\n\nThe [static](static) directory contains any static assets that should be available. These are served using [sirv](https://github.com/lukeed/sirv).\n\nIn your [service-worker.js](src/service-worker.js) file, you can import these as `files` from the generated manifest...\n\n```js\nimport { files } from '@sapper/service-worker';\n```\n\n...so that you can cache them (though you can choose not to, for example if you don't want to cache very large files).\n\n\n## Bundler config\n\nSapper uses Rollup or webpack to provide code-splitting and dynamic imports, as well as compiling your Svelte components. With webpack, it also provides hot module reloading. As long as you don't do anything daft, you can edit the configuration files to add whatever plugins you'd like.\n\n\n## Production mode and deployment\n\nTo start a production version of your app, run `npm run build && npm start`. This will disable live reloading, and activate the appropriate bundler plugins.\n\nYou can deploy your application to any environment that supports Node 10 or above. As an example, to deploy to [ZEIT Now](https://zeit.co/now) when using `sapper export`, run these commands:\n\n```bash\nnpm install -g now\nnow\n```\n\nIf your app can't be exported to a static site, you can use the [now-sapper](https://github.com/thgh/now-sapper) builder. You can find instructions on how to do so in its [README](https://github.com/thgh/now-sapper#basic-usage).\n\n\n## Using external components\n\nWhen using Svelte components installed from npm, such as [@sveltejs/svelte-virtual-list](https://github.com/sveltejs/svelte-virtual-list), Svelte needs the original component source (rather than any precompiled JavaScript that ships with the component). This allows the component to be rendered server-side, and also keeps your client-side app smaller.\n\nBecause of that, it's essential that the bundler doesn't treat the package as an *external dependency*. You can either modify the `external` option under `server` in [rollup.config.js](rollup.config.js) or the `externals` option in [webpack.config.js](webpack.config.js), or simply install the package to `devDependencies` rather than `dependencies`, which will cause it to get bundled (and therefore compiled) with your app:\n\n```bash\nnpm install -D @sveltejs/svelte-virtual-list\n```\n\n\n## Bugs and feedback\n\nSapper is in early development, and may have the odd rough edge here and there. Please be vocal over on the [Sapper issue tracker](https://github.com/sveltejs/sapper/issues).\n"}
{"url": "https://github.com/alsino/schoolofmaa_code", "owner": "alsino", "repository_name": "schoolofmaa_code", "date_all_variable_collection": "2023-09-11", "description": "all the code from school of maa bots and ml workshop", "size": 48607, "stargazers_count": 3, "watchers_count": 3, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "alsino", "contributions": 54}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 81734}, {"language": "HTML", "num_chars": 7501}], "readme": "## Bots and Machine Learning\n\nA Little Test Repo for the Bots and Machine Learning course at The School of Machines, Making & Make Believe\n\n### 1. Image Classifier\nA quick test of using an image classifier from ml5.js \n\n### 2. Image Classifier Video\nA quick test of using an image classifier on a vifdeo file from ml5.js \n\nImage Classifier with ml5.js\n[Code](./ImageClassification)\n"}
{"url": "https://github.com/alsino/sotmus", "owner": "alsino", "repository_name": "sotmus", "date_all_variable_collection": "2023-09-11", "description": "A short presentation sotmus2015", "size": 144, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "gh-pages", "contributors": [{"contributor": "alsino", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 2972}, {"language": "JavaScript", "num_chars": 2820}, {"language": "CSS", "num_chars": 616}, {"language": "Makefile", "num_chars": 126}], "readme": "# sotmus\nA short presentation sotmus2015\n"}
{"url": "https://github.com/alsino/strapi-test", "owner": "alsino", "repository_name": "strapi-test", "date_all_variable_collection": "2023-09-11", "description": null, "size": 463, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "alsino", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 8917}, {"language": "Svelte", "num_chars": 1225}, {"language": "CSS", "num_chars": 890}, {"language": "HTML", "num_chars": 393}, {"language": "Shell", "num_chars": 23}], "readme": "*Looking for a shareable component template? Go here --> [sveltejs/component-template](https://github.com/sveltejs/component-template)*\n\n---\n\n# svelte app\n\nThis is a project template for [Svelte](https://svelte.dev) apps. It lives at https://github.com/sveltejs/template.\n\nTo create a new project based on this template using [degit](https://github.com/Rich-Harris/degit):\n\n```bash\nnpx degit sveltejs/template svelte-app\ncd svelte-app\n```\n\n*Note that you will need to have [Node.js](https://nodejs.org) installed.*\n\n\n## Get started\n\nInstall the dependencies...\n\n```bash\ncd svelte-app\nnpm install\n```\n\n...then start [Rollup](https://rollupjs.org):\n\n```bash\nnpm run dev\n```\n\nNavigate to [localhost:5000](http://localhost:5000). You should see your app running. Edit a component file in `src`, save it, and reload the page to see your changes.\n\nBy default, the server will only respond to requests from localhost. To allow connections from other computers, edit the `sirv` commands in package.json to include the option `--host 0.0.0.0`.\n\nIf you're using [Visual Studio Code](https://code.visualstudio.com/) we recommend installing the official extension [Svelte for VS Code](https://marketplace.visualstudio.com/items?itemName=svelte.svelte-vscode). If you are using other editors you may need to install a plugin in order to get syntax highlighting and intellisense.\n\n## Building and running in production mode\n\nTo create an optimised version of the app:\n\n```bash\nnpm run build\n```\n\nYou can run the newly built app with `npm run start`. This uses [sirv](https://github.com/lukeed/sirv), which is included in your package.json's `dependencies` so that the app will work when you deploy to platforms like [Heroku](https://heroku.com).\n\n\n## Single-page app mode\n\nBy default, sirv will only respond to requests that match files in `public`. This is to maximise compatibility with static fileservers, allowing you to deploy your app anywhere.\n\nIf you're building a single-page app (SPA) with multiple routes, sirv needs to be able to respond to requests for *any* path. You can make it so by editing the `\"start\"` command in package.json:\n\n```js\n\"start\": \"sirv public --single\"\n```\n\n## Using TypeScript\n\nThis template comes with a script to set up a TypeScript development environment, you can run it immediately after cloning the template with:\n\n```bash\nnode scripts/setupTypeScript.js\n```\n\nOr remove the script via:\n\n```bash\nrm scripts/setupTypeScript.js\n```\n\n## Deploying to the web\n\n### With [Vercel](https://vercel.com)\n\nInstall `vercel` if you haven't already:\n\n```bash\nnpm install -g vercel\n```\n\nThen, from within your project folder:\n\n```bash\ncd public\nvercel deploy --name my-project\n```\n\n### With [surge](https://surge.sh/)\n\nInstall `surge` if you haven't already:\n\n```bash\nnpm install -g surge\n```\n\nThen, from within your project folder:\n\n```bash\nnpm run build\nsurge public my-project.surge.sh\n```\n"}
{"url": "https://github.com/alsino/style-transfer-subway-art", "owner": "alsino", "repository_name": "style-transfer-subway-art", "date_all_variable_collection": "2023-09-11", "description": "Training a neural network on subway art - style transfer", "size": 12874, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alsino", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 1405}, {"language": "JavaScript", "num_chars": 1199}], "readme": "# Style Transfer Example - Subway Art\n\nThis is a simple example of training a neural network (style transfer) from an image to webcam output.\n\nA instruction how the model was trained can be found below. These instructions were composed by [Yining Shi](https://github.com/yining1023) and shared with me at the \"Bots and Machine Learning\" class at the School of Machines in July 2019.\n\n\n# Using Style Transfer with Spell - Instructions\nStyle Transfer example with [ml5.js](http://ml5js.org/), training the model with [Spell.run](https://learn.spell.run/)\n\n#### Demo: [https://yining1023.github.io/styleTransfer_spell/](https://yining1023.github.io/styleTransfer_spell/.)\n\nHere are some [slides](https://bit.ly/2xB9t8K) that introduce what is style transfer and how does it work.\n\n## Training a style transfer model with Spell!\n\nCheck out [Transferring Style Tutorial from Spell](https://learn.spell.run/transferring_style) for more info about steps 1 - 3.\n1. Preparing your environment\n2. Downloading Datasets\n3. Training with style.py\n4. Converting model to ml5js (Read more at [reiinakano](https://github.com/reiinakano)'s [fast-style-transfer-deeplearnjs](https://github.com/reiinakano/fast-style-transfer-deeplearnjs#adding-your-own-styles))\n\n## Credits\nI used the [TensorFlow implementation of fast style tranfer](https://github.com/lengstrom/fast-style-transfer) developed by [Logan Engstrom](https://github.com/lengstrom). And the [fast-style-transfer-deeplearnjs](https://github.com/reiinakano/fast-style-transfer-deeplearnjs) by [Reiichiro Nakano](https://github.com/reiinakano) to convert the tensforflow model to a tf.js model that can used in ml5.js\n\n### 0. Setup Spell.run\nSign up on Spell.run, login\n\nYou can skip the following two steps if you have pip installed already.\n```\n$ curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n$ python get-pip.py\n\n```\nInstall spell, and log into spell\n```\n$ pip install spell\n$ spell\n$ spell login\n\n```\n\n### 1. Preparing your environment\nClone [the fast-style-transfer git repo from github](https://github.com/lengstrom/fast-style-transfer).\n```\n$ git clone https://github.com/lengstrom/fast-style-transfer\n$ cd fast-style-transfer\n\n```\n\nCreate some folders and files\n```\n$ mkdir ckpt/\n$ touch ckpt/.gitignore\n$ mkdir images\n$ mkdir images/style\n\n```\n\nPut a \"style\" image into the images/style directory. There needs to be at least one image in this folder.\n\nAdd the changes and commit it to git.\n```\n$ git add images ckpt\n$ git commit -m \"Added required folders and images\"\n\n```\n\n### 2. Downloading Datasets\n```\n$ spell run --machine-type CPU ./setup.sh\n```\nIt took me 1.5 hours to finish this run. The dataset is large, it takes time to save to Spell.\n\n### 3. Training with style.py\n```\nspell run --mount runs/THE_RUN_NUMBER_OF_YOUR_SETUP_RUN/data:datasets \\\n            --machine-type V100 \\\n            --framework tensorflow \\\n            --apt ffmpeg \\\n            --pip moviepy \\\n  \"python style.py \\\n  --checkpoint-dir ckpt \\\n  --style images/style/YOUR_STYLE_IMAGE_NAME.jpg \\\n  --style-weight 1.5e2 \\\n  --train-path datasets/train2014 \\\n  --vgg-path datasets/imagenet-vgg-verydeep-19.mat\"\n  \n```\nRemember to replace the `THE_RUN_NUMBER_OF_YOUR_SETUP_RUN` and `YOUR_STYLE_IMAGE_NAME`.\nI used V100 machine. This run took me ~2 hours. And it created files in the `ckpt` folder.\n\nTo list and download these resulting checkpoint files use the `spell ls` and `spell cp` commands.\nYou can go to any directory that you want to save the files in and run -\n```\nspell ls runs/YOUR_RUN_NUMBER\nspell ls runs/YOUR_RUN_NUMBER/ckpt\nspell cp runs/YOUR_RUN_NUMBER/ckpt\n\n```\nRemember to replace YOUR_RUN_NUMBER.\n\n### 4. Converting model to ml5js\nGo to a new directory,\n```\ngit clone https://github.com/reiinakano/fast-style-transfer-deeplearnjs.git\ncd fast-style-transfer-deeplearnjs\n```\n\nPut the checkpoint files we downloaded from spell into the current directory,\n```\npython scripts/dump_checkpoint_vars.py --output_dir=src/ckpts/YOUR_FOLDER_NAME --checkpoint_file=./YOUR_FOLDER_NAME/fns.ckpt\n\npython scripts/remove_optimizer_variables.py --output_dir=src/ckpts/YOUR_FOLDER_NAME\n\n```\nRemember to replace `YOUR_FOLDER_NAME`, the folder that holds all the checkpoint files.\nIt will create a new folder in `src/ckpts` with 49 items including a manifest.json file.\n\n### 5. Run the model in ml5js\nCopy the folder we got from step 4 and put it into /models.\nChange `style = ml5.styleTransfer('models/fuchun', modelLoaded);` to your model file path.\nRun the code\n```\npython -m SimpleHTTPServer\n\n```\nGo to `localhost:8000`, you should be able to see the model working!\n\n# style-transfer-subway-art\n"}
{"url": "https://github.com/alsino/svelte-leaflet-template", "owner": "alsino", "repository_name": "svelte-leaflet-template", "date_all_variable_collection": "2023-09-11", "description": "A simple boilerplate template for a simple map application with svelte and leaflet", "size": 550, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 8, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 8, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alsino", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 4960}, {"language": "JavaScript", "num_chars": 1959}, {"language": "CSS", "num_chars": 913}], "readme": "# svelte-leaflet-template\nA simple boilerplate template for a simple map application with svelte and leaflet\n\n\n# svelte app\n\nThis is a project template for [Svelte](https://svelte.dev) apps. It lives at https://github.com/sveltejs/template.\n\nTo create a new project based on this template using [degit](https://github.com/Rich-Harris/degit):\n\n```bash\nnpx degit sveltejs/template svelte-app\ncd svelte-app\n```\n\n*Note that you will need to have [Node.js](https://nodejs.org) installed.*\n\n\n## Get started\n\nInstall the dependencies...\n\n```bash\ncd svelte-app\nnpm install\n```\n\n...then start [Rollup](https://rollupjs.org):\n\n```bash\nnpm run dev\n```\n\nNavigate to [localhost:5000](http://localhost:5000). You should see your app running. Edit a component file in `src`, save it, and reload the page to see your changes.\n\nBy default, the server will only respond to requests from localhost. To allow connections from other computers, edit the `sirv` commands in package.json to include the option `--host 0.0.0.0`.\n\n\n## Deploying to the web\n\n### With [now](https://zeit.co/now)\n\nInstall `now` if you haven't already:\n\n```bash\nnpm install -g now\n```\n\nThen, from within your project folder:\n\n```bash\ncd public\nnow\n```\n\nAs an alternative, use the [Now desktop client](https://zeit.co/download) and simply drag the unzipped project folder to the taskbar icon.\n\n### With [surge](https://surge.sh/)\n\nInstall `surge` if you haven't already:\n\n```bash\nnpm install -g surge\n```\n\nThen, from within your project folder:\n\n```bash\nnpm run build\nsurge public\n```\n"}
{"url": "https://github.com/alsino/taktile-test", "owner": "alsino", "repository_name": "taktile-test", "date_all_variable_collection": "2023-09-11", "description": null, "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/alsino/themagicsquare_typography", "owner": "alsino", "repository_name": "themagicsquare_typography", "date_all_variable_collection": "2023-09-11", "description": null, "size": 168, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "gh-pages", "contributors": [{"contributor": "alsino", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 3702}, {"language": "CSS", "num_chars": 753}], "readme": "# themagicsquare_typography\n\nThis is a simple exercise in web typography at the university of Applied Sciences Potsdam in the course 'Digital Typography'\n"}
{"url": "https://github.com/alsino/tphc-website", "owner": "alsino", "repository_name": "tphc-website", "date_all_variable_collection": "2023-09-11", "description": null, "size": 48322, "stargazers_count": 0, "watchers_count": 0, "language": "CSS", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "alsino", "contributions": 52}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "CSS", "num_chars": 12433}, {"language": "Svelte", "num_chars": 12133}, {"language": "JavaScript", "num_chars": 851}, {"language": "HTML", "num_chars": 486}], "readme": "# create-svelte\n\nEverything you need to build a Svelte project, powered by [`create-svelte`](https://github.com/sveltejs/kit/tree/master/packages/create-svelte).\n\n## Creating a project\n\nIf you're seeing this, you've probably already done this step. Congrats!\n\n```bash\n# create a new project in the current directory\nnpm init svelte@next\n\n# create a new project in my-app\nnpm init svelte@next my-app\n```\n\n> Note: the `@next` is temporary\n\n## Developing\n\nOnce you've created a project and installed dependencies with `npm install` (or `pnpm install` or `yarn`), start a development server:\n\n```bash\nnpm run dev\n\n# or start the server and open the app in a new browser tab\nnpm run dev -- --open\n```\n\n## Building\n\nTo create a production version of your app:\n\n```bash\nnpm run build\n```\n\nYou can preview the production build with `npm run preview`.\n\n> To deploy your app, you may need to install an [adapter](https://kit.svelte.dev/docs/adapters) for your target environment.\n"}
{"url": "https://github.com/alsino/ufosightings", "owner": "alsino", "repository_name": "ufosightings", "date_all_variable_collection": "2023-09-11", "description": "A small semester project on vizualizing UFO sightings in Germany in the summer term 2015 at FH Potsdam", "size": 2852, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 9, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 9, "watchers": 0, "default_branch": "gh-pages", "contributors": [{"contributor": "alsino", "contributions": 25}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 107242}, {"language": "JavaScript", "num_chars": 97399}, {"language": "CSS", "num_chars": 6610}], "readme": "# ufosightings\nA small semester project on vizualizing UFO sightings in Germany with D3.js in the summer term 2015 at FH Potsdam\n"}
{"url": "https://github.com/alsino/ukraine-map", "owner": "alsino", "repository_name": "ukraine-map", "date_all_variable_collection": "2023-09-11", "description": null, "size": 975, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "alsino", "contributions": 660}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 169687}, {"language": "Svelte", "num_chars": 18764}, {"language": "HTML", "num_chars": 3810}, {"language": "CSS", "num_chars": 58}], "readme": "# create-svelte\n\nEverything you need to build a Svelte project, powered by [`create-svelte`](https://github.com/sveltejs/kit/tree/master/packages/create-svelte).\n\n## Creating a project\n\nIf you're seeing this, you've probably already done this step. Congrats!\n\n```bash\n# create a new project in the current directory\nnpm init svelte@next\n\n# create a new project in my-app\nnpm init svelte@next my-app\n```\n\n> Note: the `@next` is temporary\n\n## Developing\n\nOnce you've created a project and installed dependencies with `npm install` (or `pnpm install` or `yarn`), start a development server:\n\n```bash\nnpm run dev\n\n# or start the server and open the app in a new browser tab\nnpm run dev -- --open\n```\n\n## Building\n\nTo create a production version of your app:\n\n```bash\nnpm run build\n```\n\nYou can preview the production build with `npm run preview`.\n\n> To deploy your app, you may need to install an [adapter](https://kit.svelte.dev/docs/adapters) for your target environment.\n"}
{"url": "https://github.com/alsino/visitmytent", "owner": "alsino", "repository_name": "visitmytent", "date_all_variable_collection": "2023-09-11", "description": "Visitmyorbit is a portal into the life of contemporary artists working in various fields. The site shows artists' motivations, studio locations as well as 773 connections among them \u2013 creating an inside view into the networks of 150 artists presented on visitmytent.", "size": 98241, "stargazers_count": 0, "watchers_count": 0, "language": "Svelte", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "texanewman", "contributions": 629}, {"contributor": "alsino", "contributions": 278}, {"contributor": "dependabot[bot]", "contributions": 16}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Svelte", "num_chars": 29915}, {"language": "JavaScript", "num_chars": 24919}, {"language": "HTML", "num_chars": 2745}, {"language": "SCSS", "num_chars": 1866}], "readme": "## Visitmyorbit - Exploring Artists\u2019 Networks\n\nVisitmyorbit is a portal into the life of contemporary artists working in various fields. The site shows artists' motivations, studio locations as well as 773 connections among them \u2013 creating an inside view into the networks of 150 artists presented on visitmytent. \n\nHighlighting individual artists points out their relation and closeness to other artists \u2013 socially in the network and physically on the map \u2013 giving a glimpse into the different artists' milieus \u2013 predominantly in Berlin. Additionally you can deep dive into individual studio visits and interviews.\n\nAll data was collected manually and evaluated in a constant dialogue with the artists over a period of more than one year. visitmyorbit is a visualization by Stephanie Neumann and Alsino Skowronnek crafted in Berlin, 2021.\n\n## Demo\n\nSee the live version here: [https://visitmyorbit.vercel.app/](https://visitmyorbit.vercel.app/)\n\n<img width=\"1552\" alt=\"04\" src=\"https://user-images.githubusercontent.com/8008434/155753579-1a188058-d174-4953-99d4-68648d873a4f.png\">\n\n\n\n\n\nThe visualization was developed as a collaboration between [Stephanie Neumann](https://stephanieneumann.com/) and [Alsino Skowronnek](https://alsino.io) in Berlin, 2020.\n\n\n\n\n\n\n----\n\n\n## Getting started\n\nThis application is build on the default [Sapper](https://github.com/sveltejs/sapper) template, available for Rollup and webpack.\n\n### Using `degit`\n\n[`degit`](https://github.com/Rich-Harris/degit) is a scaffolding tool that lets you create a directory from a branch in a repository. Use either the `rollup` or `webpack` branch in `sapper-template`:\n\n```bash\n# for Rollup\nnpx degit \"sveltejs/sapper-template#rollup\" my-app\n# for webpack\nnpx degit \"sveltejs/sapper-template#webpack\" my-app\n```\n\n\n### Using GitHub templates\n\nAlternatively, you can use GitHub's template feature with the [sapper-template-rollup](https://github.com/sveltejs/sapper-template-rollup) or [sapper-template-webpack](https://github.com/sveltejs/sapper-template-webpack) repositories.\n\n\n### Running the project\n\nHowever you get the code, you can install dependencies and run the project in development mode with:\n\n```bash\ncd my-app\nnpm install # or yarn\nnpm run dev\n```\n\nOpen up [localhost:3000](http://localhost:3000) and start clicking around.\n\nConsult [sapper.svelte.dev](https://sapper.svelte.dev) for help getting started.\n\n\n## Structure\n\nSapper expects to find two directories in the root of your project \u2014  `src` and `static`.\n\n\n### src\n\nThe [src](src) directory contains the entry points for your app \u2014 `client.js`, `server.js` and (optionally) a `service-worker.js` \u2014 along with a `template.html` file and a `routes` directory.\n\n\n#### src/routes\n\nThis is the heart of your Sapper app. There are two kinds of routes \u2014 *pages*, and *server routes*.\n\n**Pages** are Svelte components written in `.svelte` files. When a user first visits the application, they will be served a server-rendered version of the route in question, plus some JavaScript that 'hydrates' the page and initialises a client-side router. From that point forward, navigating to other pages is handled entirely on the client for a fast, app-like feel. (Sapper will preload and cache the code for these subsequent pages, so that navigation is instantaneous.)\n\n**Server routes** are modules written in `.js` files, that export functions corresponding to HTTP methods. Each function receives Express `request` and `response` objects as arguments, plus a `next` function. This is useful for creating a JSON API, for example.\n\nThere are three simple rules for naming the files that define your routes:\n\n* A file called `src/routes/about.svelte` corresponds to the `/about` route. A file called `src/routes/blog/[slug].svelte` corresponds to the `/blog/:slug` route, in which case `params.slug` is available to the route\n* The file `src/routes/index.svelte` (or `src/routes/index.js`) corresponds to the root of your app. `src/routes/about/index.svelte` is treated the same as `src/routes/about.svelte`.\n* Files and directories with a leading underscore do *not* create routes. This allows you to colocate helper modules and components with the routes that depend on them \u2014 for example you could have a file called `src/routes/_helpers/datetime.js` and it would *not* create a `/_helpers/datetime` route\n\n\n### static\n\nThe [static](static) directory contains any static assets that should be available. These are served using [sirv](https://github.com/lukeed/sirv).\n\nIn your [service-worker.js](src/service-worker.js) file, you can import these as `files` from the generated manifest...\n\n```js\nimport { files } from '@sapper/service-worker';\n```\n\n...so that you can cache them (though you can choose not to, for example if you don't want to cache very large files).\n\n\n## Bundler config\n\nSapper uses Rollup or webpack to provide code-splitting and dynamic imports, as well as compiling your Svelte components. With webpack, it also provides hot module reloading. As long as you don't do anything daft, you can edit the configuration files to add whatever plugins you'd like.\n\n\n## Production mode and deployment\n\nTo start a production version of your app, run `npm run build && npm start`. This will disable live reloading, and activate the appropriate bundler plugins.\n\nYou can deploy your application to any environment that supports Node 10 or above. As an example, to deploy to [ZEIT Now](https://zeit.co/now) when using `sapper export`, run these commands:\n\n```bash\nnpm install -g now\nnow\n```\n\nIf your app can't be exported to a static site, you can use the [now-sapper](https://github.com/thgh/now-sapper) builder. You can find instructions on how to do so in its [README](https://github.com/thgh/now-sapper#basic-usage).\n\n\n## Using external components\n\nWhen using Svelte components installed from npm, such as [@sveltejs/svelte-virtual-list](https://github.com/sveltejs/svelte-virtual-list), Svelte needs the original component source (rather than any precompiled JavaScript that ships with the component). This allows the component to be rendered server-side, and also keeps your client-side app smaller.\n\nBecause of that, it's essential that the bundler doesn't treat the package as an *external dependency*. You can either modify the `external` option under `server` in [rollup.config.js](rollup.config.js) or the `externals` option in [webpack.config.js](webpack.config.js), or simply install the package to `devDependencies` rather than `dependencies`, which will cause it to get bundled (and therefore compiled) with your app:\n\n```bash\nnpm install -D @sveltejs/svelte-virtual-list\n```\n\n\n## Bugs and feedback\n\nSapper is in early development, and may have the odd rough edge here and there. Please be vocal over on the [Sapper issue tracker](https://github.com/sveltejs/sapper/issues).\n"}
{"url": "https://github.com/alsino/vmt-network", "owner": "alsino", "repository_name": "vmt-network", "date_all_variable_collection": "2023-09-11", "description": "A quick sketch for a network visualization for vmt using d3 force-directed network and d3 symbols.", "size": 31866, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "texanewman", "contributions": 567}, {"contributor": "alsino", "contributions": 229}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 69650}, {"language": "CSS", "num_chars": 2962}, {"language": "HTML", "num_chars": 1229}], "readme": "# Visitmytent.com - A Network Visualization\n\nA quick sketch and work-in-progress for a network visualization for vmt using d3 force-directed network and d3 symbols.\n\n![alt text](https://github.com/alsino/vmt-network/blob/master/assets/teaser/teaser.png)\n\n\n## About\nConstellations - Exploring Artists\u2019 Networks\nConstellations visualizes the relationships between contemporary artists working in various fields, creating an inside view into the networks of selected artists presented on visitmytent. Different vectors connect individuals depending on the manner of their relation. The depth of their relationship influences their proximity in the network. Selecting a specific artist points out connected artists as well as the related interview and studio visit.\n\nThe visualization was developed as a collaboration between [Stephanie Neumann](https://stephanieneumann.com/) and [Alsino Skowronnek](https://alsino.io) in Berlin, 2019.\n\n\n## Demo\n\nSee the live version here: [Prototype](https://visitmyorbit.vercel.app/)\n\n\n"}
{"url": "https://github.com/alsino/webpack-starterkit", "owner": "alsino", "repository_name": "webpack-starterkit", "date_all_variable_collection": "2023-09-11", "description": "Slim Webpack Starterkit with ES6, SCSS, Jade, HMR, Normalize, PureCSS, YAML", "size": 12, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 2468}, {"language": "HTML", "num_chars": 1655}, {"language": "CSS", "num_chars": 804}], "readme": "# Slim Webpack Starterkit\n\nA lightweight foundation for your next webpack based frontend project.\n\nBased on [Webkid](http://webkid.io/)\u2019s [yet-another-webpack-es6-starterkit](https://github.com/wbkd/yet-another-webpack-es6-starterkit) but extended with Jade support (with separated YAML file) and some CSS.\n\n### Installation\n\n1. Clone this repo using `git clone https://github.com/z3to/webpack-starterkit.git`.\n2. Change the folder name and `cd foo`\n3. Delete the existing git repository by running `rm -rf .git`.\n4. Initialize a new git repository with `git init`, `git add .` and `git commit -m \"Initial commit\"`.\n5. Run `npm install` to install the dependencies.\n6. Run `npm run dev` to start the local web server.\n7. Go to `http://localhost:1337` and you should see the app running!\n8. Run `npm run build` to build a deployment ready website.\n\n### Features:\n\n* ES6 Support via [babel-loader](https://github.com/babel/babel-loader)\n* SASS Support via [sass-loader](https://github.com/jtangelder/sass-loader)\n* Linting via [eslint-loader](https://github.com/MoOx/eslint-loader)\n* Hot Module Replacement\n\n### New Features:\n\n* [Normalize.CSS](https://necolas.github.io/normalize.css/) and [PureCSS](http://purecss.io/) integrated\n* Jade support via [jade-loader](https://github.com/webpack/jade-loader) (no HMR yet)\n* [YAML](http://www.yaml.org/spec/1.2/spec.html) support via [yaml-loader](https://github.com/okonet/yaml-loader) (no HMR yet)\n\nWhen you run `npm run build` we use the [extract-text-webpack-plugin](https://github.com/webpack/extract-text-webpack-plugin) to move the css to a separate file and included in the head of your `index.html`, so that the styles are applied before any javascript gets loaded. We disabled this function for the dev version, because the loader doesn't support hot module replacement.\n"}
{"url": "https://github.com/alyonavyshnevska/advanced_natural_language_processing", "owner": "alyonavyshnevska", "repository_name": "advanced_natural_language_processing", "date_all_variable_collection": "2023-09-11", "description": "Advanced Natural Language Processing course. MS Cognitive Systems at Uni Potsdam. WS2018/19", "size": 2, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alyonavyshnevska", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Advanced Natural Language Processing\nMini-projects for the Advanced Natural Language Processing course as part of the MS Cognitive Systems program \nat Uni Potsdam. Winter term 2018/19.\n"}
{"url": "https://github.com/alyonavyshnevska/Advent-of-Code", "owner": "alyonavyshnevska", "repository_name": "Advent-of-Code", "date_all_variable_collection": "2023-09-11", "description": "little fun scripts", "size": 61, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alyonavyshnevska", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 85646}], "readme": "# Advent-of-Code\nlittle fun scripts\n"}
{"url": "https://github.com/alyonavyshnevska/angular_explorations", "owner": "alyonavyshnevska", "repository_name": "angular_explorations", "date_all_variable_collection": "2023-09-11", "description": null, "size": 782, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alyonavyshnevska", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 26678}, {"language": "TypeScript", "num_chars": 7629}, {"language": "JavaScript", "num_chars": 1427}, {"language": "CSS", "num_chars": 178}], "readme": "# Angular101\n\nThis project was generated with [Angular CLI](https://github.com/angular/angular-cli) version 12.1.1.\n\n## Development server\n\nRun `ng serve` for a dev server. Navigate to `http://localhost:4200/`. The app will automatically reload if you change any of the source files.\n\n## Code scaffolding\n\nRun `ng generate component component-name` to generate a new component. You can also use `ng generate directive|pipe|service|class|guard|interface|enum|module`.\n\n## Build\n\nRun `ng build` to build the project. The build artifacts will be stored in the `dist/` directory.\n\n## Running unit tests\n\nRun `ng test` to execute the unit tests via [Karma](https://karma-runner.github.io).\n\n## Running end-to-end tests\n\nRun `ng e2e` to execute the end-to-end tests via a platform of your choice. To use this command, you need to first add a package that implements end-to-end testing capabilities.\n\n## Further help\n\nTo get more help on the Angular CLI use `ng help` or go check out the [Angular CLI Overview and Command Reference](https://angular.io/cli) page.\n"}
{"url": "https://github.com/alyonavyshnevska/bert_exploration", "owner": "alyonavyshnevska", "repository_name": "bert_exploration", "date_all_variable_collection": "2023-09-11", "description": "Exploring the Huggingface implementation for a PyTorch interface for BERT", "size": 9, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alyonavyshnevska", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 38067}], "readme": "# bert_exploration\nExploring the Huggingface implementation for a PyTorch interface for BERT\n"}
{"url": "https://github.com/alyonavyshnevska/bert_for_coreference_resolution", "owner": "alyonavyshnevska", "repository_name": "bert_for_coreference_resolution", "date_all_variable_collection": "2023-09-11", "description": "Exploring Span Representations in Neural Coreference Resolution", "size": 9750, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 7, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 7, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alyonavyshnevska", "contributions": 120}, {"contributor": "pkhdipraja", "contributions": 81}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 523637}, {"language": "Jupyter Notebook", "num_chars": 173544}, {"language": "TeX", "num_chars": 117193}, {"language": "Perl", "num_chars": 46068}, {"language": "Shell", "num_chars": 14256}, {"language": "JavaScript", "num_chars": 7072}, {"language": "C++", "num_chars": 5562}, {"language": "HTML", "num_chars": 2150}], "readme": "# Exploring Span Representations in Neural Coreference Resolution\n\nThis repository contains code for our paper. We attempt to probe to what extent can span representations encode coreference relations. We also question whether if span representations are able to encode long-range coreference phenomena effectively, or are they just simply modelling local coreference relations. We extend the implementation of [BERT for Coreference Resolution](https://github.com/mandarjoshi90/coref). The source code is located under `src`.\n\n## Setup\n* Install python3 requirements: `pip install -r requirements.txt`\n* Export path to OntoNotes directory: `export data_dir=</path/to/data_dir>`\n* `/setup_all.sh`: This script builds the custom kernels.\n* `setup_training.sh`: This script preprocesses the OntoNotes corpus and download the original BERT models.\n\n## Pre-trained Models\nThe pretrained models can be downloaded using `download_pretrained.sh <model_name>` (i.e. `bert_base` or `bert_large`; this assumes that `$data_dir` is set).\n\n## Extracting Span Representations\nTo extract the span representations in .h5 format, run `extract_span.py` and `extract_span_baseline.py` for the baseline. Here is a sample code:\n```\npython3 extract_span.py bert_base $data_dir/<input.jsonlines> $data_dir span_representation_bert_base\n```\n\n## Running Probing Experiments\nThe extracted .h5 files can be used to run probing experiments using `train_baseline.py` and `train_probe.py`. Here is a sample code:\n```\npython3 train_baseline.py --train_data </path/to/train_data> --val_data </path/to/val_data> --test_data </path/to/test_data> --exp_name <test_experiment_name> --cnn_context 1 --embed_dim 1024\n```"}
{"url": "https://github.com/alyonavyshnevska/databases", "owner": "alyonavyshnevska", "repository_name": "databases", "date_all_variable_collection": "2023-09-11", "description": "Exploring relational and non-relational databases", "size": 1636, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alyonavyshnevska", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# databases\nExploring relational and non-relational databases\n"}
{"url": "https://github.com/alyonavyshnevska/datasets", "owner": "alyonavyshnevska", "repository_name": "datasets", "date_all_variable_collection": "2023-09-11", "description": "Easy way to host small csv files and diagrams for my workshops", "size": 4180, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "alyonavyshnevska", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 862507}]}
{"url": "https://github.com/alyonavyshnevska/docker_REST_Flask_exploration", "owner": "alyonavyshnevska", "repository_name": "docker_REST_Flask_exploration", "date_all_variable_collection": "2023-09-11", "description": "Docker, Flask, REST_API and co.", "size": 17, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 2, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alyonavyshnevska", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 5486}, {"language": "PHP", "num_chars": 505}, {"language": "Dockerfile", "num_chars": 269}], "readme": "# Definitions\n\n- **Container** is a running instance of an image\n- **Image** is a template for creating the environment you want. Snapshop of a system at a particular time\n  - OS\n  - Software\n  - Application \n- Images are defined in a **Dockerfile**. When you run an image you get a container. \n\n\n\nDockerfile    -----*build*--->  Image   ---*run*--->      Container\n\n\n **Virtual Machines vs. Docker**\n- Docker shares a kernel. VMs each have its own kernel\n\n# Writing a dockerfile\n- Go to Dokerhub. Find an image you need. \nE.g. php official\n\n- Simple Dockerfile:\n\nFROM php:7.0-apache  \nCOPY src/ /var/www/html  \nEXPOSE 80   \n\nDownload php. \nCopy our files from src/ to this location inside of the image.   \nTell running containers to listen on port 80. \nOutput a new image -- which we will be able to run. \n\n\n# Commands\n\n- `docker build -t hello-word . ` : build an image\n\n    - -t  names the image \"hello-world\"\n    - .  location of Dockerfile\n\n- Run an instance of an image = a container\n`docker run -p 80:80 hello-world`\nfirst 80: local host.  \nsecond 80: what docker container is listening to (in the Dockerfile: EXPOSE 80. (port).   \n\n- Runs an instance of an image, exits. We don't see the container running. \n\n`docker stop name` : to stop running container\n\n`docker rm name` : remove container permanently \n\n- Volumes: live changes \nmount local folder inside the container.  \n`docker run -p 80:80 -v /Users/which/folder/to/mount:/var/www/html hello-world`\n\n- `FROM python:3-onbuild`\ninstalls requirements file\n\n- `docker images` to list all images\n- `docker rmi name` to remove an image. Make sure no container is running off that image\n\n- `docker pull`: pulls an image, stores it on host, doesn't run the container\n\n- `docker exec name command`: execute action inside a container\n\n- `docker run -d name` : run container in a detached mode. Container continues to run in the background, access to terminal \n    - `docker attack id` : back to the detached container\n\n- `docker container stop $(docker container ls -aq)` stop all containers\n    - same for rm  \n\n\n# docker-compose.yml\n- specifies what you would otherwise say with docker build and docker run \n- one dir above the docker file\n- `docker-compose up` from a dir where `docker-compose.yml` lives. Builds, runs everything\n\n- `docker-compose build --no-cache`. \nif was a dummy and misspelt api.py\n\n- Detached mode. In the background. can still use terminal:\n`docker-compose -d`\n- to ctrl+c: `docker-compose stop` \n\n\n# Commands\n`docker ps` : list all running containers\n`docker ps -a` : list all containers running or previously stopped\n"}
{"url": "https://github.com/alyonavyshnevska/dynamic_programming_levenshtein_distance", "owner": "alyonavyshnevska", "repository_name": "dynamic_programming_levenshtein_distance", "date_all_variable_collection": "2023-09-11", "description": "\u2705 Dynamic Programming with unit tests and Travis CI", "size": 42, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alyonavyshnevska", "contributions": 19}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 7541}], "readme": "# Levenshtein Edit Distance\n\nIn information theory, linguistics and computer science, the Levenshtein distance is a string metric for measuring the difference between two sequences. Informally, the Levenshtein distance between two words is the minimum number of single-character edits (insertions, deletions or substitutions) required to change one word into the other.\n\nMathematically, the Levenshtein distance between two strings _a_, _b_ (of length | a | and | b | respectively) is given by _lev_ <sub> _a,b_ </sub> (|_a_|,|_b_|) where\n\n\n\n\n![levenshtein formula](docs/levenshtein-formula.svg)\n\n![levenshtein formula_explain](docs/levenshtein-formula-explain.jpeg)\n\nNote that the first element in the minimum corresponds to deletion (from _a_ to _b_), the second to insertion and the third to match or mismatch, depending on whether the respective symbols are the same.\n\n\nThere are two ways to calculate this distance:\n\n- naive recursive implementation of the math formula\n- dynamic programming algorithm that uses a table to avoid extra computations\n\nHere, I implement the second way because it is more efficient.\n\n## Design\n\n1. Construct an empty table: list of lists of ints.\n    -  Num of rows = target string seq2. len(seq2) + 1 (plus one in case the input is 0)\n    - Num of cols = original string seq1. len(seq1) + 1 (plus one in case the input is 0)\n\n2. For each char in target string (row):\n\n        For each char in original string (column):\n            if row is 0:\n                set cell to the value of column (insertion needed, no char in row to edit)\n            if column is 0:\n                set cell to the value of row (insertion needed, no char in column to edit)\n            if the chars align:\n                copy the min edit distance from char at previous row and char at previous column\n            if chars don's allign:\n                choose either to edit, to delete or to insert (whichever option yiels\n                the smallest edit distance)\n\n\n 3. Return last value at last row, last column\n\n\n\n### Data Structures\n\n1. Table: list of lists of ints.   \nRows: chars of \"To\" string (seq2).\nColumns: chars of \"From\" string (seq1).\n\n2. Sequence: string.\n"}
{"url": "https://github.com/alyonavyshnevska/homemade_bread", "owner": "alyonavyshnevska", "repository_name": "homemade_bread", "date_all_variable_collection": "2023-09-11", "description": "\ud83e\udd56  super lightweight api with mongoDB integration to get recipe links to my favourite homemade sourdough breads", "size": 56729, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 2, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alyonavyshnevska", "contributions": 21}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1806}, {"language": "Python", "num_chars": 1570}, {"language": "HTML", "num_chars": 889}, {"language": "CSS", "num_chars": 819}], "readme": "A small tool that shows a few of my favourite bread recipes.\n\n- Simple API with Python's Flask micro web framework.\n- Super lightweight css grid front-end.\n- Yet performant integration with a mongoDB database. \n\n-----\n\nUsage: \n\n- Run mongoDB: [guide here](https://docs.mongodb.com/manual/tutorial/install-mongodb-on-os-x/#run-mongodb-community-edition)\n\n- Import json or csv file into running mongoDB:\n\n```\nmongoimport --db homemade_bread --collection bread --file bread.json\n```\n\t\t\t\nor\n\n```\nmongoimport --db homemade_bread --collection bread --type csv --fields _id, name, link --file bread.csv\n```\n\n- Install python requirements: `pip3 install -r requirements.txt` \n\n- Run `python3 app.py` \n\n- Open `home.html` and click on images to get links to their recipes\n\n\nThe interation with grid csv can be seen here, without the connection to the database: [Link](https://alyonavyshnevska.github.io/assets/projects/homemade_bread/). \n\n\n![img](img/grid.png)\n"}
{"url": "https://github.com/alyonavyshnevska/intelligent_data_analysis", "owner": "alyonavyshnevska", "repository_name": "intelligent_data_analysis", "date_all_variable_collection": "2023-09-11", "description": "Projects for the Machine Learning class. University of Potsdam, SS2019. ", "size": 7034, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alyonavyshnevska", "contributions": 103}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 2215955}, {"language": "Python", "num_chars": 19130}], "readme": "# Machine Learning  \n\n*University of Potsdam*  \n*Summer Term 2019*   \n*Lecturer: Prof. Dr. Tobias Scheffer*   \n\nTopics covered:\n- Learning Problems, Loss Functions, Regularizations\n- Data Pre-processing, Feature Engineering, Feature Selection\n- Evaluation of Models\n- Decision Trees\n- Random Forests\n- Linear Classification\n- Linear Regression\n- Logistic Regression\n- Kernel Methods\n- Bayesian Learning, Gaussian Processes\n- Neural Networks (from scratch and with Keras)\n\nThis repo includes my solutions to the excercise labs for each of the topics.\n"}
{"url": "https://github.com/alyonavyshnevska/malware_detection_dataset_explore", "owner": "alyonavyshnevska", "repository_name": "malware_detection_dataset_explore", "date_all_variable_collection": "2023-09-11", "description": "Exploring the CIDDS-001 data set gathered by Hochschule Coburg", "size": 29, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alyonavyshnevska", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 54579}], "readme": "The CIDDS-001 data set gathered by Hochschule Coburg was captured over a period of four weeks and contains nearly 32 millions flows.\n\nThereof, about 31 millions flows were captured within the OpenStack environment. About 0.7 million flows were captured at the external server.\n\n92 attacks.\n70 attacks were executed within the OpenStack environment and 22 attacks targeted the external server.\n\nLearn more [here](https://www.hs-coburg.de/forschung/forschungsprojekte-oeffentlich/informationstechnologie/cidds-coburg-intrusion-detection-data-sets.html). \n"}
{"url": "https://github.com/alyonavyshnevska/problem_solving_walkthrough", "owner": "alyonavyshnevska", "repository_name": "problem_solving_walkthrough", "date_all_variable_collection": "2023-09-11", "description": "In this mini-project I guide you through my journey from facing a problem to solving it", "size": 227, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alyonavyshnevska", "contributions": 28}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 76538}, {"language": "Python", "num_chars": 36}], "readme": "## Incremental Development: Step-by-Step Problem Solving\n\n## Walkthrough\nThe problem solving **walkthrough** is a written **guided description** of the journey from a problem to a solution. Detailed reasoning is performed and written for each one of the phases. For example, in the first phase, besides stating the problem in own words I include a few input-output pairs. Also, a design phase contains several drafts showing gradual improvements. The choice of data structures is justified. \n\n**Incremental development** is the heart of this mini-project. The motto here is \"Get something working and keep it working\". \n\n## Problem to Solve\n[AoC 2018 - Day 7](https://adventofcode.com/2018/day/7)\n"}
{"url": "https://github.com/alyonavyshnevska/pyTorch_playground", "owner": "alyonavyshnevska", "repository_name": "pyTorch_playground", "date_all_variable_collection": "2023-09-11", "description": null, "size": 11, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alyonavyshnevska", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 23749}], "readme": "# pyTorch_playground"}
{"url": "https://github.com/alyonavyshnevska/react_explorations", "owner": "alyonavyshnevska", "repository_name": "react_explorations", "date_all_variable_collection": "2023-09-11", "description": "Exploring React library, building a simple task tracker", "size": 1099, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alyonavyshnevska", "contributions": 15}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 8326}, {"language": "HTML", "num_chars": 1781}, {"language": "CSS", "num_chars": 1553}], "readme": "### A simple task manager \n\n![demo](https://github.com/alyonavyshnevska/react_explorations/blob/master/demo/demo.gif?raw=true)\n\nTools used:\n\n- React library\n- React-router-dom\n- json server to simulate backend\n\nThis project was bootstrapped with [Create React App](https://github.com/facebook/create-react-app).\n\n\n--------\n\n### Mock Backend\n\nFor mock backend I use 'json server', which allows me to create REST API with my own data.\nThe way ot works:\n\n1. Install [json-server](https://github.com/typicode/json-server)\n1. Create a db.json file with some data\n2. Start JSON Server\n3. make POST, PUT, PATCH or DELETE requests and changes will be automatically and safely saved to db.json using [lowdb](https://github.com/typicode/lowdb)\n\n----------\n\nIn the project directory, you can run:\n\n### `npm start`\n\nRuns the app in the development mode.\\\nOpen [http://localhost:3000](http://localhost:3000) to view it in the browser.\n\nThe page will reload if you make edits.\\\nYou will also see any lint errors in the console.\n\n### `npm test`\n\nLaunches the test runner in the interactive watch mode.\\\nSee the section about [running tests](https://facebook.github.io/create-react-app/docs/running-tests) for more information.\n\n### `npm run build`\n\nBuilds the app for production to the `build` folder.\\\nIt correctly bundles React in production mode and optimizes the build for the best performance.\n\nThe build is minified and the filenames include the hashes.\\\nYour app is ready to be deployed!\n\nSee the section about [deployment](https://facebook.github.io/create-react-app/docs/deployment) for more information.\n"}
{"url": "https://github.com/alyonavyshnevska/simple_http_server", "owner": "alyonavyshnevska", "repository_name": "simple_http_server", "date_all_variable_collection": "2023-09-11", "description": "A simple http server in python that runs locally and returns valid status codes", "size": 5, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alyonavyshnevska", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 686}, {"language": "HTML", "num_chars": 449}], "readme": "\n##### A simple http server in python that runs locally and returns valid status codes\n\nPython comes with a simple builtin HTTP server. With the help of this little HTTP server you can turn any directory in your system into your web server directory. The only thing you need to have installed is Python.  \nIf the directory has a file named index.html, that file will be served as the initial file. If there is no index.html, then the files in the directory will be listed.\n\n`python -m http.server 8000`\n\nSpecifying port is optional. \n\nBy default, server uses the current directory. The option -d/--directory specifies a directory to which it should serve the files.\n\n`python -m http.server --directory /tmp/`\n\n\n-------- \n\nMy tiny utility lets you customize error messages, e.g. the 404 page not found messages when running a simple http server built-in in python standard library. To see an example of that run: \n\n`python simple_python_http_server.py`\n\nthen go to the `localhost:port/whatever_nonexisting_page` in your browser and see my example customizable error message.\n\nEdit the message to your desired one in the `simple_python_http_server.py`\n\n"}
{"url": "https://github.com/alyonavyshnevska/starting_point_for_new_projects", "owner": "alyonavyshnevska", "repository_name": "starting_point_for_new_projects", "date_all_variable_collection": "2023-09-11", "description": "Templates and code snippets that I often use when starting a new project", "size": 25, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alyonavyshnevska", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 35849}, {"language": "Python", "num_chars": 576}], "readme": "# starting_point_for_new_projects\nTemplates and code snippets that I often use when starting a new project\n"}
{"url": "https://github.com/alyonavyshnevska/test_js", "owner": "alyonavyshnevska", "repository_name": "test_js", "date_all_variable_collection": "2023-09-11", "description": null, "size": 33, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 13531}], "readme": "# Cloud Development ASE Prerequisite Test for Node.js\n\nInstructions have moved to [here](https://pages.github.tools.sap/cloud-curriculum/materials/pretest/ase-nodejs/)\n"}
{"url": "https://github.com/alyonavyshnevska/text_visualization_course", "owner": "alyonavyshnevska", "repository_name": "text_visualization_course", "date_all_variable_collection": "2023-09-11", "description": "Projects completed for Text Visualization Seminar, HPI, SS2019", "size": 6094, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alyonavyshnevska", "contributions": 107}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 154507}, {"language": "Python", "num_chars": 17401}, {"language": "JavaScript", "num_chars": 3889}, {"language": "CSS", "num_chars": 193}], "readme": "## Text Visualization in Practice\n\nThe repository contains weekly assignments for the seminar: code and blog posts about the results. \n\n### Course Description\n\n> With the ever increasing volume of data in the modern world, data visualization has become an essential component of every data analysis task. Visualization is an effective way to convey complex information and acts as a bridge between data and decisions.\n> \n> This seminar will discuss the techniques and tools for creating efficient visualizations for the most important tasks related to large textual datasets.\n> The seminar is geared to be a series of highly interactive sessions with the students, seeking active classroom participations. The sessions will comprise of topic introductions, brainstorming for ideas, short group activities and active discussions. To maximize the practical learning, students will be expected to submit short practical assignments for the individual topics every week.\n> The second part of the seminar will consist of a project to be chosen by the student teams.\n\n### Learning Objectives\n\n> Students will learn to...\n> \n> - perform common text analytics tasks to explore and understand a given text dataset.\n> - represent large text corpora in visual form.\n> - use various tools to process and visualize text data.\n> - understand research papers and report on their own projects' progress.\n> \n\n[Course Website](https://hpi.de/naumann/teaching/teaching/ss-19/text-visualization.html)"}
{"url": "https://github.com/AnjaKatzenberger/CMIP-6-Very-wet-monsoon-seasons-in-India", "owner": "AnjaKatzenberger", "repository_name": "CMIP-6-Very-wet-monsoon-seasons-in-India", "date_all_variable_collection": "2023-09-11", "description": "Analysis of the projected very wet monsoon seasons on the Indian subcontinent using 32 CMIP6 models. Codes for publication: https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2022GL098856", "size": 149, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "AnjaKatzenberger", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 343974}], "readme": "# CMIP-6-Very-wet-monsoon-seasons-in-India\n\nCODES FOR FIGURES OF PUBLICATION\nKatzenberger et al. (2022): Intensification of Very Wet Monsoon Seasons in India Under Global Warming\nhttps://agupubs.onlinelibrary.wiley.com/doi/10.1029/2022GL098856\n\nIn the following, an overview of the underlying codes for the figures in the manuscript (A) and Supplementary Information (B) is given. The author of all listed codes is Anja Katzenberger. The preprocessing was done with preprocessing.py.\n\n(A) MANUSCRIPT-FIGURES\n\nFIG01: General increase from mean annual summer rainfall [mm/day] of the Indian monsoon toward wetter years between the historical (1965\u20132015) and the future period (2050\u20132100) in the Indian monsoon region under unabated climate change (SSP5-8.5).\n-> data_analysis_GRL.py\n\nFIG02a: Increase of very wet Indian summer monsoon (ISM) seasons (JJAS) in the 21st century under unabated climate change (SSP5-8.5).\n-> data_analysis_GRL.py\n\nFIG02b&c: Increase of very wet Indian summer monsoon (ISM) seasons (JJAS) in the 21st century under unabated climate change (SSP5-8.5).\n-> percentiles_fig.py\n\nFIG03: Increase in the number of very wet Indian summer monsoon (ISM) seasons by the second half of the 21st century in comparison to 1965\u20132015 in the Indian monsoon region under sustainable development (SSP1-2.6), modest mitigation (SSP2-4.5) and unabated climate change (SSP5-8.5).\n-> Other\n\n\nFIG04a-d: Change in (a.) wet days (>0.1 mm) and days with (b.) light (10 mm > x > 0.1 mm), (c.) moderate (10 mm > x > 40 mm) and (d.) heavy (>40 mm) rainfall between 1965\u20132015 and 2050\u20132100 under SSP5-8.5.\n-> wetdays_fig.py, wetdays_CDO.py, lightdays_fig.py, lightdays_CDO.py, moderatedays_fig.py, moderatedays_CDO.py, heavydays_fig.py, heavydays_CDO.py\n\nFIG04e:  In (e.) the results for the single models as well as the multi-model mean are summarized (mean from monsoon region).\n-> boxplots.py\n\n\n\n\n(B) SUPPLEMENTARY INFORMATION - FIGURES\nFIGS1: De\ufb01nition of Indian monsoon region (longitude 67 \u25e6 - 98 \u25e6 E; latitude 6 \u25e6 - 36 \u25e6 N)\n-> area_of_interest.py\n\nFIGS2: Increase in very wet seasons during the Indian monsoon between 1965-2015 and 2050-2100 as a function of global mean temperature (GMT; K) under unabated climate change (SSP5-8.5).\n-> data_analysis_GRL.py\n\nFIGS3: Change in wet days (> 0.1mm) per season between 1965-2015 and 2050-2100 under unabated climate change (SSP5-8.5) for the six models with best monsoon performance in the past.\n-> wetdays_fig.py, wetdays_CDO.py\n\nFIGS4: Change in in days with light (10mm> x > 0.1mm), moderate (10mm> x > 40mm) and heavy (40mm>) rainfall per season between 1965-2015 and 2050-2100 under unabated climate change (SSP5-8.5) for the six models with best monsoon performance in the past.\n-> lightdays_fig.py, lightdays_CDO.py, moderatedays_fig.py, moderatedays_CDO.py, heavydays_fig.py, heavydays_CDO.py\n\nFIGS5: Change in Simple Daily Intensity Index (SDII) between 1965-2015 and 2050-2100 under unabated climate change (SSP5-8.5) for the six models with best monsoon performance in the past (right) and their multi-model mean (left).\n-> SDII_fig.py, SDII_CDO.py\n"}
{"url": "https://github.com/AnjaKatzenberger/CMIP6-Indian-Monsoon", "owner": "AnjaKatzenberger", "repository_name": "CMIP6-Indian-Monsoon", "date_all_variable_collection": "2023-09-11", "description": "Analysis of the projected changes of the Indian summer monsoon using 32 CMIP6 models", "size": 922, "stargazers_count": 6, "watchers_count": 6, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 6, "default_branch": "main", "contributors": [{"contributor": "AnjaKatzenberger", "contributions": 16}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["cdo", "climate-change", "climate-model", "cmip6", "india", "monsoon"], "languages": [{"language": "Python", "num_chars": 1027678}]}
{"url": "https://github.com/annameide/como-map-workshop", "owner": "annameide", "repository_name": "como-map-workshop", "date_all_variable_collection": "2023-09-11", "description": "map box interactive map tryouts", "size": 721, "stargazers_count": 0, "watchers_count": 0, "language": "CSS", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "annameide", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "CSS", "num_chars": 14661}, {"language": "HTML", "num_chars": 8629}], "readme": "# Map box experiment\r\n\r\nA trial implementation published with guthub pages\r\nhttps://annameide.github.io/como-map-workshop/\r\n\r\n\r\n# Map Templates\r\n\r\n## How To\r\nI recommend installing Live Server from the VS-Code extensions, to view and edit the code.\r\n\r\n## Maps\r\n\r\nLet's start off with some basic web-map examples. There are different JavaScript Map-Libraries out there you can use. The most common ones I have added as an example to this repo. Each map includes a simple slippy map, with a base map, a marker and a popup for that marker.\r\n\r\n- [Leaflet](https://leafletjs.com/reference.html)\r\n- [Mapbox](https://docs.mapbox.com/mapbox-gl-js/)\r\n- [MapLibre](https://maplibre.org/maplibre-gl-js-docs/api/)\r\n- [OpenLayers](https://openlayers.org/en/latest/apidoc/)\r\n\r\nYou can get other basemaps from:\r\n\r\n- [Mapbox](https://www.mapbox.com/)\r\n- [OpenStreetMap](https://wiki.openstreetmap.org/wiki/Tile_servers)\r\n- [Maptiler](https://openmaptiles.org/styles/)\r\n\r\nVector tile layer styles can also be created using the [Maputnik editor](https://github.com/maputnik/editor).\r\n"}
{"url": "https://github.com/annameide/HtmlCssProject", "owner": "annameide", "repository_name": "HtmlCssProject", "date_all_variable_collection": "2023-09-11", "description": "Learning version control and github along my first html and css steps.", "size": 2693, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "annameide", "contributions": 8}, {"contributor": "kuzminadya", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 4317}, {"language": "CSS", "num_chars": 389}], "readme": "# HtmlCssProject\nLearning version control and github along my first html and css steps.\n\n![my illustration](website_process.png)\n"}
{"url": "https://github.com/annameide/lucas-code", "owner": "annameide", "repository_name": "lucas-code", "date_all_variable_collection": "2023-09-11", "description": null, "size": 7778, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 1, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "annameide", "contributions": 82}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 67110}, {"language": "HTML", "num_chars": 62976}, {"language": "CSS", "num_chars": 20193}, {"language": "Nix", "num_chars": 3271}], "readme": "# Visuelle Geschichten mit Code und Daten\n\nThe mini code projects as well as the final website were created as part of the \"Visuelle Geschichten mit Code und Daten\" course during the winter term 22|23 under the supervision of Lucas Vogel. The solo work consist of creative coding algorithms written with p5js, a final website presenting the results and a GitHub repository containing the code.\n"}
{"url": "https://github.com/annameide/map-scrollytelling", "owner": "annameide", "repository_name": "map-scrollytelling", "date_all_variable_collection": "2023-09-11", "description": "A scrollytelling website with a focus on mapping.", "size": 47100, "stargazers_count": 2, "watchers_count": 2, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 1, "watchers": 2, "default_branch": "main", "contributors": [{"contributor": "annameide", "contributions": 78}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 63275}, {"language": "JavaScript", "num_chars": 58047}, {"language": "CSS", "num_chars": 28008}], "readme": "# map-scrollytelling\nA scrollytelling website with a focus on mapping.\n\n## The Seed Tracker\nA sci-fi short story inspired by data journalism\n\n\u2192 Take a look at the final project for yourself here: https://annameide.github.io/map-scrollytelling/ \n\n## Concept\n\u201cThe Seed Tracker\u201d project was developed as part of the \u201cKarten der Macht. Macht der Karten\u201d course by Prof. Sebastian Meier. The solo work consists of a scrollytelling website which presents the reader with a dystopian science-fiction short story accompanied by a dynamic map, illustrated with photocollages.\n\nThe concept of The Seed Tracker aims to convey a serious topic - the climate disaster and the accompanying change in local food production - in a way that is cognitively as easy to absorb as possible.\n\nThe means used to achieve this goal are a fictional text style, a dynamic map, and illustrations. The form of a sci-fi short story is intended to convey the content on a textual level more lightly than a scientific text, such as the IPCC report for example. The dynamic map, which changes in relation to the text sections, is intended to create a sense of local connection to the site. The illustrations are intended to support impressions of change on an emotional \u201eat-a-glance\u201c level that work differently than rational, linear texts.\n\nIdeally, this dystopian exaggeration leads to the conclusion that such a future is not desirable for anyone and motivates the reader to engage in protection of the environment in the here and now.\n"}
{"url": "https://github.com/annameide/p5js-experiments", "owner": "annameide", "repository_name": "p5js-experiments", "date_all_variable_collection": "2023-09-11", "description": "Trying out creative coding with p5js. ", "size": 64, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "annameide", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 956}, {"language": "CSS", "num_chars": 234}, {"language": "JavaScript", "num_chars": 170}], "readme": "# p5js-experiments\nTrying out creative coding with p5js. \n"}
{"url": "https://github.com/annameide/processing_fhp", "owner": "annameide", "repository_name": "processing_fhp", "date_all_variable_collection": "2023-09-11", "description": "Selection of projects created during the winter term 2018/19 in \"Processing for Designers\" class at the University of Applied Sciences Potsdam", "size": 9582, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "annameide", "contributions": 28}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# processing for designers\n_Selection of projects created during the winter term 2018/19 in \"Processing for Designers\" class at the University of Applied Sciences Potsdam._\n\n\n## variables\nimplementation of several variables in order to move a bee over blossoming flowers as well as the change of the background sky color. \n\n![variables](https://user-images.githubusercontent.com/46717848/51380375-e7de2480-1b11-11e9-9d0e-f562aa945e24.jpg)\n\n\n## pong_game\nhere you can play pong versus the computer. sound appers everytime the ball is shot from the middle. \n\n![pong_game](https://user-images.githubusercontent.com/46717848/51380440-0f34f180-1b12-11e9-984a-56a2f4788340.jpg)\n\n\n\n\n\n## video\nimport of the macs own live camera stream and display of the video. additional use of different video filters.\n\n![video](https://user-images.githubusercontent.com/46717848/51379850-b153da00-1b10-11e9-8580-e09f95084682.jpg)\n"}
{"url": "https://github.com/annameide/werkschau", "owner": "annameide", "repository_name": "werkschau", "date_all_variable_collection": "2023-09-11", "description": "Werkschauseite zur Bachelorpr\u00fcfung", "size": 14317, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "annameide", "contributions": 17}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 58362}, {"language": "CSS", "num_chars": 45138}, {"language": "JavaScript", "num_chars": 5636}], "readme": "# Werkschau\n\nDie Werkschau im Rahmen der Bachelorarbeit besteht in Form einer \u00f6ffentlich zug\u00e4nglichen Webseite. Die Seite wurde im visuellen Webseitenbuilder Webflow erstellt und wird auf GitHub Pages gehosted. Der Code kann jederzeit transparent eingesehen werden. Aufgrund der zeitlichen Rahmenbedingungen ist die Webseite ausschlie\u00dflich f\u00fcr eine Desktopanwendung ausgelegt.\n"}
{"url": "https://github.com/aodenweller/green-h2-upscaling", "owner": "aodenweller", "repository_name": "green-h2-upscaling", "date_all_variable_collection": "2023-09-11", "description": "Model code and input data of the technology diffusion model for electrolysis capacity", "size": 3721, "stargazers_count": 5, "watchers_count": 5, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 3, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 3, "open_issues": 0, "watchers": 5, "default_branch": "master", "contributors": [{"contributor": "aodenweller", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 53106}], "readme": "# Green hydrogen upscaling\n\nThis repository contains the full model code to run the technology diffusion simulation and reproduce all figures of the article:\n\nOdenweller, A., Ueckerdt, F., Nemet, G. F., Jensterle, M., and Luderer, G.: *Probabilistic feasibility space of scaling up green hydrogen supply*\n\n## Contents\n* `main.Rmd` - The main R Markdown file\n* `01_input_data` - Input data files\n* `02_output_plots` - Output folder for simulation data and plots\n* `03_functions` - Helper functions\n* `04_plotting` - Plotting functions\n\n## Instructions\nThere are two options to use this code, which are controlled by a switch in `main.Rmd`\n* Reproduction mode (default)\n  * Download the [pre-run simulation output from Zenodo](https://doi.org/10.5281/zenodo.6567669) and put all files into `02_output_plots`\n  * Run `main.Rmd`\n  * This imports the simulation output, reproduces all article figures, and saves them into `02_output_plots` \n* Simulation mode\n  * Set `model.mode = \"simulation\"` in `main.Rmd`\n  * Adjust the sample size `n` of the simulation as desired\n  * Run `main.Rmd`\n  * This starts the simulation, which will take some time, depending on the sample size\n  * Figures are saved into `02_output_plots` and might deviate slightly from article figures due to randomness"}
{"url": "https://github.com/aodenweller/remind-pypsa", "owner": "aodenweller", "repository_name": "remind-pypsa", "date_all_variable_collection": "2023-09-11", "description": "Scripts for the REMIND-PyPSA model coupling", "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "develop", "contributors": [{"contributor": "aodenweller", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/arne-cl/abspath", "owner": "arne-cl", "repository_name": "abspath", "date_all_variable_collection": "2023-09-11", "description": "get the absolute paths of files on the command line", "size": 4, "stargazers_count": 2, "watchers_count": 2, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "BSD 3-Clause \"New\" or \"Revised\" License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": true, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["cli", "file-path", "path", "python"], "languages": [{"language": "Python", "num_chars": 1607}], "readme": "abspath\n=======\n\n.. image:: http://img.shields.io/pypi/dm/abspath.svg\n   :alt: PyPI download counter\n   :align: right\n   :target: https://pypi.python.org/pypi/abspath#downloads\n.. image:: http://img.shields.io/pypi/v/abspath.svg\n   :alt: Latest version\n   :align: right\n   :target: https://pypi.python.org/pypi/abspath\n.. image:: http://img.shields.io/badge/license-BSD-yellow.svg\n   :alt: BSD License\n   :align: right\n   :target: http://opensource.org/licenses/BSD-3-Clause\n\n\n``abspath`` is a command line tool that prints the absolute paths of all given\nfiles. File names can be piped via ``STDIN`` or given as arguments.\n\nUsage\n-----\n\n::\n\n    abspath file1.txt path/to/file2.pdf\n    abspath Desktop/*\n    find . -name *.pdf | abspath\n\nInstallation\n------------\n\nInstallation from PyPI\n~~~~~~~~~~~~~~~~~~~~~~\n\n::\n\n    sudo pip install abspath\n\nInstallation from the repository\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n::\n\n    git clone https://github.com/arne-cl/abspath.git\n    cd abspath\n    sudo python setup.py install\n\nLicense\n-------\n\n3-clause BSD.\n"}
{"url": "https://github.com/arne-cl/alt-mulig", "owner": "arne-cl", "repository_name": "alt-mulig", "date_all_variable_collection": "2023-09-11", "description": "A place for experimental/educational code", "size": 76261, "stargazers_count": 9, "watchers_count": 9, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 27, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 27, "watchers": 9, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 367}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 31872477}, {"language": "HTML", "num_chars": 414067}, {"language": "C++", "num_chars": 366266}, {"language": "Python", "num_chars": 128536}, {"language": "JavaScript", "num_chars": 28527}, {"language": "SCSS", "num_chars": 23945}, {"language": "Go", "num_chars": 17271}, {"language": "R", "num_chars": 10916}, {"language": "Erlang", "num_chars": 7908}, {"language": "Clojure", "num_chars": 7581}, {"language": "CSS", "num_chars": 5608}, {"language": "Pug", "num_chars": 3845}, {"language": "COBOL", "num_chars": 3258}, {"language": "Shell", "num_chars": 2421}, {"language": "Lex", "num_chars": 1802}, {"language": "Makefile", "num_chars": 705}, {"language": "Tcl", "num_chars": 522}, {"language": "Idris", "num_chars": 287}, {"language": "Dockerfile", "num_chars": 268}, {"language": "TeX", "num_chars": 138}], "readme": "alt-mulig\n=========\n\n.. image:: https://api.travis-ci.org/arne-cl/alt-mulig.svg\n   :alt: Travis CI Build status\n   :target: https://travis-ci.org/arne-cl/alt-mulig\n\n.. image:: https://scan.coverity.com/projects/2272/badge.svg\n   :alt: Coverity Scan Build Status\n   :target: https://scan.coverity.com/projects/2272\n\n\nA place for experimental/educational code\n"}
{"url": "https://github.com/arne-cl/apt-downgrade", "owner": "arne-cl", "repository_name": "apt-downgrade", "date_all_variable_collection": "2023-09-11", "description": "downgrade packages to those available in your repository. fork of http://code.google.com/p/apt-downgrade/", "size": 120, "stargazers_count": 3, "watchers_count": 3, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 3}, {"contributor": "anacrolix", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 4173}]}
{"url": "https://github.com/arne-cl/balie-ner-cli", "owner": "arne-cl", "repository_name": "balie-ner-cli", "date_all_variable_collection": "2023-09-11", "description": "Balie (Named Entity Recognition) commandline interface", "size": 112, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 6314}], "readme": "Balie Commandline Interface\n===========================\n\n`balie-ner-cli` provides a commandline interface to the named-entity\nrecognition features of [Balie](http://balie.sourceforge.net/\n \"baseline information extraction\") \u2014 a Java library that can be used\nto perform various NLP tasks.  \n\n\nINSTALLATION\n============\n\nDownload and install Balie if you haven't done so. Switch back to the\n`balie-ner-cli` directory. Edit the `balie_dir` variable in `config.yml` to\npoint to your Balie installation directory.\n\n\nUSAGE\n=====\n\n`python balie-cli.py -i input.txt` will read text from *input.txt* and print a\nlist of named entities to STDOUT (one NE per line).\n\n`python balie-cli.py -i input.txt -o output.txt` will read text from\n*input.txt* and write a list of named entities to *output.txt* (one NE per\nline).\n\nExample\n-------\n\n    $ cat input.txt \n    Barack Obama, Hillary Clinton and George Bush met in a bar in Wisconsin. They\n    were discussing issues regarding the Netherlands, the Queen of England and\n    Boy George.\n\n    $ python ./balie-cli.py -i input.txt\n    ('Hillary Clinton', 'PERSON')\n    ('George Bush', 'PERSON')\n    ('Wisconsin', 'LOCATION')\n    ('Queen', 'PERSON')\n    ('England', 'LOCATION')\n    ('Boy George', 'PERSON')\n\nNote that *Barack Obama* wasn't recognized, as the training data that Balie\ncomes with is already a few years old (ca. 2007).\n\n\nLICENCE\n=======\n\nGPL 2 or later.\n\nCONTACT\n=======\n\nArne Neumann <neumann.arne@gmail.com>\n\n\n\n"}
{"url": "https://github.com/arne-cl/bart-coreference-python-wrapper", "owner": "arne-cl", "repository_name": "bart-coreference-python-wrapper", "date_all_variable_collection": "2023-09-11", "description": "BART (Beautiful Anaphora Resolution Toolkit) Python wrapper", "size": 136, "stargazers_count": 3, "watchers_count": 3, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 1308}], "readme": "pybart\n======\n\nSimple Python wrapper for `BART`_ (Beautiful Anaphora Resolution Toolkit).\n\n.. _`BART`: http://bart-coref.org/\n\nUsage\n-----\n\n::\n\n    bart.py input.txt output.xml\n\nLicense\n-------\n\n3-Clause BSD.\n"}
{"url": "https://github.com/arne-cl/bibnorm", "owner": "arne-cl", "repository_name": "bibnorm", "date_all_variable_collection": "2023-09-11", "description": "bibliography normalization (uppercase/lowercase) for BibTeX files", "size": 144, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 2174}], "readme": "bibnorm\n=======\n\nbibliography normalization (uppercase/lowercase) for BibTeX files\n"}
{"url": "https://github.com/arne-cl/bislama-resources", "owner": "arne-cl", "repository_name": "bislama-resources", "date_all_variable_collection": "2023-09-11", "description": "Bislama language resources", "size": 256, "stargazers_count": 2, "watchers_count": 2, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Creative Commons Zero v1.0 Universal", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["bislama", "corpora", "language", "language-resources", "underresourced-languages", "vanuatu"], "languages": [], "readme": "# bislama-resources\n\nResources for the language Bislama (Bichelamar), an English-based creole,\nwhich is one of the official languages of Vanuatu.\n\n## Language learning\n\n* [Pidginise your English](http://www.pentecostisland.net/languages/bislama/guide.htm), a short, written introduction\nto the language for speakers of English\n\n## Media\n\n* [Liahona magazine in Bislama](https://www.lds.org/liahona/2014?lang=bis).  \n  Liahona is a monthly religious magazine published by the Latter Day Saints. Many issues (but not all of them)\n  are translated into lots of underresourced languages.\n* [Vanuatu Daily Post](http://www.dailypost.vu/), mostly in English but has some short articles in Bislama\n* [Vanuatu Daily Digest](https://vanuatudaily.wordpress.com/), a blog summarizing news from Vanuatu;  \n  lots of links to local media outlets, blogs etc. (mostly English, though)\n\n\n## Corpora\n\nI couldn't find any compiled corpora, but here are some sources to get you started:\n\n* [The bible in Bislama](http://www.bible.is/BISBSP/Matt/1)\n* [Jehovah\u2019s Witnesses website in Bislama](http://www.jw.org/bi)\n* [Tweets in Bislama](http://indigenoustweets.com/bi/) and [blog posts in Bislama](http://indigenoustweets.com/blogs/bi/) from [Indigenous Tweets](http://indigenoustweets.com/)\n* [Primary texts in Bislama](http://www.language-archives.org/language/bis), compiled by the [Open Language Archives Community](http://www.language-archives.org)\n* [Universal Declaration of Human Rights in Bislama](http://www.ohchr.org/EN/UDHR/Pages/Language.aspx?LangID=bcy)\n* [Wikipedia in Bislama](http://bi.wikipedia.org/wiki/Wikipedia), 480+ articles\n* [Speech recordings in Bislama](http://lacito.vjf.cnrs.fr/pangloss/tools/list_rsc_en.php?lg=Bislama&aff=bislama) from the [Pangloss Collection](http://lacito.vjf.cnrs.fr/pangloss/index_en.htm)\n* [Working Together in Vanuatu: Research Histories, Collaborations, Projects and Reflections](http://press.anu.edu.au/apps/bookworm/view/Working+Together+in+Vanuatu%3A+Research+Histories%2C+Collaborations%2C+Projects+and+Reflections/7241/Text/upfront.html), an ebook (HTML) about fieldwork in Vanuatu, with some chapters available in English and Bislama\n* [Yumi Toktok Stret](https://www.facebook.com/pages/Yumi-Toktok-Stret/499289030134214) ('we talk straight') is said to be Vanuatus biggest Facebook group,  \n  its discussions (mostly in Bislama) are archived and categorized in the [Yumi Toktok Stret Opinions](https://yumitoktokstret.wordpress.com/) blog\n\n\n## Dictionaries, word lists etc.\n\n* [Bislama spelling dictionary](http://www.bislama.org/bislama-dictionary), available for MS Word and Firefox (6500 words)\n* the same [spelling dictionary](http://www.bislama.org/images/dictionary/BislamaSpellingDictionary-v1.1.pdf) as a list   in PDF format with coarse-grained POS tags and English translations for each word (both licensed under GPLv2)\n* [Bislama word frequency lists](http://crubadan.org/ws/bi.html) (unigrams, bigrams and character trigrams)  \n  from the [An Cr\u00fabad\u00e1n](http://crubadan.org/index.html) project\n"}
{"url": "https://github.com/arne-cl/brat-embedded-visualization-examples", "owner": "arne-cl", "repository_name": "brat-embedded-visualization-examples", "date_all_variable_collection": "2023-09-11", "description": "minimal examples of brat annotation visualizations", "size": 524, "stargazers_count": 17, "watchers_count": 17, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 6, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 6, "open_issues": 1, "watchers": 17, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["annotation", "brat", "javascript", "nlp", "visualization"], "languages": [{"language": "JavaScript", "num_chars": 186792}, {"language": "CSS", "num_chars": 51080}], "readme": "brat-embedded-visualization-examples\n====================================\n\nminimal examples of brat annotation visualizations\n"}
{"url": "https://github.com/arne-cl/discoursegraphs", "owner": "arne-cl", "repository_name": "discoursegraphs", "date_all_variable_collection": "2023-09-11", "description": "linguistic converter / merging tool for multi-level annotated corpora. graph-based (using Python and NetworkX).", "size": 2949, "stargazers_count": 49, "watchers_count": 49, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 5, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 49, "license": "BSD 3-Clause \"New\" or \"Revised\" License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 5, "open_issues": 49, "watchers": 49, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 1075}, {"contributor": "hernan-erasmo", "contributions": 8}, {"contributor": "dependabot[bot]", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": true, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["conversion", "converter", "natural-language-processing", "networkx", "nlp", "python"], "languages": [{"language": "Python", "num_chars": 650491}, {"language": "XSLT", "num_chars": 2457}, {"language": "Dockerfile", "num_chars": 906}, {"language": "Makefile", "num_chars": 679}], "readme": "DiscourseGraphs\n===============\n\n.. image:: http://img.shields.io/pypi/v/discoursegraphs.svg\n   :alt: Latest version\n   :align: right\n   :target: https://pypi.python.org/pypi/discoursegraphs\n.. image:: http://img.shields.io/badge/license-BSD-yellow.svg\n   :alt: BSD License\n   :align: right\n   :target: http://opensource.org/licenses/BSD-3-Clause\n\n.. image:: https://travis-ci.org/arne-cl/discoursegraphs.svg?branch=master\n   :alt: Build status\n   :align: right\n   :target: https://travis-ci.org/arne-cl/discoursegraphs\n.. image:: https://codecov.io/github/arne-cl/discoursegraphs/coverage.svg?branch=master\n   :alt: Test coverage\n   :align: right\n   :target: https://codecov.io/github/arne-cl/discoursegraphs?branch=master\n.. image:: https://www.quantifiedcode.com/api/v1/project/3076854b9ea74bed867f12808d98f437/badge.svg\n   :alt: Code Issues\n   :align: right\n   :target: https://www.quantifiedcode.com/app/project/3076854b9ea74bed867f12808d98f437\n.. image:: https://img.shields.io/docker/build/nlpbox/charniak.svg\n   :alt: Docker build status\n   :align: right\n   :target: https://hub.docker.com/r/nlpbox/charniak\n\n\nThis library enables you to process linguistic corpora with multiple levels\nof annotations by:\n\n1. converting the different annotation formats into separate graphs and\n2. merging these graphs into a single multidigraph (based on the common\n   tokenization of the annotation layers)\n3. exporting your (merged) graphs into several output formats\n4. `visualizing linguistic graphs`_ directly in an `IPython notebook`_\n\n.. _`visualizing linguistic graphs`: http://nbviewer.ipython.org/github/arne-cl/alt-mulig/blob/master/python/discoursegraphs-visualization-examples.ipynb\n.. _`IPython notebook`: http://ipython.org/notebook.html\n\nImport formats\n--------------\n\nSo far, the following formats can be imported and merged:\n\n* `TigerXML`_ (a format for representing tree-like syntax graphs with\n  secondary edges)\n* `NeGra Export Format`_ (a format used i.a. for the T\u00fcBa-D/Z Treebank)\n* `Penn Treebank <http://www.cis.upenn.edu/~treebank/>`_ format (an s-expressions/lisp/brackets format for representing syntax trees)\n* a number of formats for Rhetorical Structure Theory:\n\n  - RS3 (a format used by `RSTTool`_ to annotate documents with Rhetorical Structure Theory)\n  - the .dis \"LISP\" format used by the RST-DT corpus\n  - `URML`_ (a format for underspecified rhetorical structure trees)\n  \n* `MMAX2`_ (a format / GUI tool for annotating spans and connections between\n  them (e.g. coreferences)\n* `CoNLL 2009`_ and `CoNLL 2010`_ formats (used for annotating i.a. dependency parses\n  and coreference links)\n* ConanoXML (a format for annotating connectives, used by `Conano`_)\n* Decour (an XML format used by a corpus of\n  `DEceptive statements in Italian COURts <http://www.lrec-conf.org/proceedings/lrec2012/pdf/377_Paper.pdf>`_)\n* `EXMARaLDA <http://exmaralda.org/>`_, a format for annotating spans in spoken\n  or written language\n* an ad-hoc plain text format for annotating expletives (you're probably not\n  interested in)\n\n.. _`TigerXML`: http://www.ims.uni-stuttgart.de/forschung/ressourcen/werkzeuge/TIGERSearch/doc/html/TigerXML.html\n.. _`NeGra Export Format`: http://www.sfs.uni-tuebingen.de/resources/exformat3.ps \n.. _`RSTTool`: http://www.wagsoft.com/RSTTool/\n.. _`URML`: http://www.david-reitter.com/compling/urml/index.html\n.. _`MMAX2`: http://mmax2.sourceforge.net/\n.. _`CoNLL 2009`: http://ufal.mff.cuni.cz/conll2009-st/task-description.html\n.. _`CoNLL 2010`: http://web.archive.org/web/20130119013221/http://www.inf.u-szeged.hu/rgai/conll2010st\n.. _`Conano`: http://www.ling.uni-potsdam.de/acl-lab/Forsch/pcc/pcc.html\n\nExport formats\n--------------\n\ndiscoursegraphs can export graphs into the following formats /\nfor the following tools:\n\n* dot format, which is used by the open source graph visualization software `graphviz`_\n* geoff format, used by the `neo4j`_ graph database\n* `GEXF <http://gexf.net/format/>`_  and `GraphML <http://graphml.graphdrawing.org/>`_\n  (common interchange formats for graphs used by various tools such as\n  `Gephi <https://gephi.github.io/>`_ and `Cytoscape <http://www.cytoscape.org/>`_)\n* `PAULA XML 1.1 <https://www.sfb632.uni-potsdam.de/en/paula.html>`_, an exchange format\n  for linguistic data (exporter is still buggy)\n* `EXMARaLDA <http://exmaralda.org/>`_, a tool for annotating spans in spoken\n  or written language\n* `CoNLL 2009`_ (so far, only tokens, sentence boundaries and coreferences are exported)\n\n\nInstallation\n------------\n\nThis should work on both Linux and Mac OSX using `Python 2.7`_ and\neither `pip`_ or easy_install.\n\n.. _`Python 2.7`: https://www.python.org/downloads/\n.. _`pip`: https://pip.pypa.io/en/latest/installing.html\n\nInstall from PyPI\n~~~~~~~~~~~~~~~~~\n\n::\n\n    pip install discoursegraphs # prepend 'sudo' if needed\n\nor, if you're oldschool:\n\n::\n\n    easy_install discoursegraphs # prepend 'sudo' if needed\n\n\nInstall from source\n~~~~~~~~~~~~~~~~~~~\n\n::\n\n    sudo apt-get install python-dev libxml2-dev libxslt-dev pkg-config graphviz-dev libgraphviz-dev -y\n    sudo easy_install -U setuptools\n    git clone https://github.com/arne-cl/discoursegraphs.git\n    cd discoursegraphs\n    sudo python setup.py install\n\n\nUsage\n-----\n\nThe command line interface of DiscourseGraphs allows you to\nmerge syntax, rhetorical structure, connectives and expletives\nannotation files into one graph and to  store this graph in one of several\noutput formats (e.g. the `geoff`_ format used by the `neo4j`_ graph database\nor the `dot`_ format used by the graphviz plotting tool).\n\n.. _`neo4j`:  http://www.neo4j.org/\n.. _`dot`: http://www.graphviz.org/content/dot-language\n.. _`geoff`: http://www.neo4j.org/develop/python/geoff\n\n\n\n::\n\n    discoursegraphs -t syntax/maz-13915.xml -r rst/maz-13915.rs3 -c connectors/maz-13915.xml -a anaphora/tosik/das/maz-13915.txt -o dot\n    dot -Tpdf doc.dot > discoursegraph.pdf # generates a PDF from the dot file\n\nIf you're interested in working with just one of those layers, you'll\nhave to call the code directly::\n\n    import discoursegraphs as dg\n    tiger_docgraph = dg.read_tiger('syntax/doc.xml')\n    rst_docgraph = dg.read_rs3('rst/doc.rs3')\n    expletives_docgraph = dg.read_anaphoricity('expletives/doc.txt')\n\nAll the document graphs generated in this example are derived from the\n`networkx.MultiDiGraph`_ class, so you should be able to use all of its\nmethods.\n\n.. _`networkx.MultiDiGraph`: http://networkx.lanl.gov/reference/classes.multidigraph.html\n\n\nDocumentation\n-------------\n\nSource code documentation is available\n`here <https://pythonhosted.org/pypolibox/>`_, but you can always get an\nup-to-date local copy using `Sphinx`_.\n\nYou can generate an HTML or PDF version by running these commands in\nthe ``docs`` directory::\n\n    make latexpdf\n\nto produce a PDF (``docs/_build/latex/discoursegraphs.pdf``) and ::\n\n    make html\n\nto produce a set of HTML files (``docs/_build/html/index.html``).\n\n.. _`Sphinx`: http://sphinx-doc.org/\n\n\nRequirements\n------------\n\n- `lxml <http://lxml.de/>`_\n- `networkx <http://networkx.github.io/>`_\n\nIf you'd like to visualize your graphs, you will also need:\n\n- `graphviz <http://graphviz.org/>`_\n- `pygraphviz <http://pygraphviz.github.io/>`_\n\n\nLicense and Citation\n--------------------\n\nThis software is released under a 3-Clause BSD license. If you use\ndiscoursegraphs in your academic work, please cite the following paper:\n\nNeumann, A. 2015. discoursegraphs: A graph-based merging tool and converter\nfor multilayer annotated corpora. In *Proceedings of the 20th Nordic Conference\nof Computational Linguistics (NODALIDA 2015)*, pp. 309-312.\n\n::\n\n    @inproceedings{neumann2015discoursegraphs,\n      title={discoursegraphs: A graph-based merging tool and converter for multilayer annotated corpora},\n      author={Neumann, Arne},\n      booktitle={Proceedings of the 20th Nordic Conference of Computational Linguistics (NODALIDA 2015)},\n      pages={309-312},\n      year={2015}\n    }\n\nAuthor\n------\nArne Neumann\n\n\nPeople who downloaded this also like\n------------------------------------\n\n- `SaltNPepper`_: a converter framework for various linguistic data formats\n- `educe`_: a library for handling discourse-annotated corpora (SDRT, RST and PDTB)\n- `treetools`_: a library for converting treebanks and grammar extraction (supports\n  i.a. TigerXML and Negra/T\u00fcba-Export formats)\n- `TCFnetworks`_: library for creating graphs from annotated text corpora (based on TCF).\n\n.. _`SaltNPepper`: https://korpling.german.hu-berlin.de/p/projects/saltnpepper/wiki/\n.. _`educe`: https://github.com/irit-melodi/educe\n.. _`treetools`: https://github.com/wmaier/treetools\n.. _`TCFnetworks`: https://github.com/SeNeReKo/TCFnetworks\n"}
{"url": "https://github.com/arne-cl/discoursekernels", "owner": "arne-cl", "repository_name": "discoursekernels", "date_all_variable_collection": "2023-09-11", "description": "a collection of kernel functions for natural language processing", "size": 1120, "stargazers_count": 2, "watchers_count": 2, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 2, "license": "BSD 3-Clause \"New\" or \"Revised\" License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 84}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 54135}, {"language": "Makefile", "num_chars": 312}], "readme": "DiscourseKernels\n================\n\n.. image:: under_construction.gif\n   :alt: under construction\n\nThis repository contains a number of kernel functions implemented in pure\nPython. So far the code is optimised for readability, not speed.\n\n\nSpectrum kernels\n----------------\n\n- p-spectrum kernel\n- blended spectrum kernel\n\nSubsequence kernels\n-------------------\n\n- all-subsequences kernel\n"}
{"url": "https://github.com/arne-cl/djangosaml2-sso-example-docker", "owner": "arne-cl", "repository_name": "djangosaml2-sso-example-docker", "date_all_variable_collection": "2023-09-11", "description": "trying to build a running djangosaml2 Single Sign On service provider example", "size": 2, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/arne-cl/docker-nginx-env-example", "owner": "arne-cl", "repository_name": "docker-nginx-env-example", "date_all_variable_collection": "2023-09-11", "description": "How to use env variables in ngxinx inside docker-compose.", "size": 3, "stargazers_count": 0, "watchers_count": 0, "language": "Dockerfile", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Dockerfile", "num_chars": 227}], "readme": "# docker-compose-nginx-env-example\n\nThis repo demonstrates how to use an environment variable in `nginx`,\nwhen you run `nginx` inside a Docker container with `docker-compose`.\n\nIn this example, `docker-compose` passes the `HOST` env to the `Dockerfile`\nto build the container using:\n\n```\nbuild:\n  args:\n  - HOST\n```\n\nTo make the `HOST` env variable available at run-time, `docker-compose` uses:\n\n```\nenvironment:\n- HOST\n```\n\nIn both cases, the `HOST` env is picked up by the `Dockerfile` using:\n\n```\nARG HOST\n```\n\nThe `Dockerfile` also overwrites the default `nginx` config file with our own:\n\n```\nADD nginx.conf /etc/nginx/nginx.conf\n```\n\nBy default, `nginx` doesn't allow env variables to be used, so we have to\nmake this explicit in `nginx.conf`:\n\n```\nenv HOST;\n```\n\nFor some reason, we can't use the env variable directly, but need to extract it\nusing one of the supported scripting languages (here: Perl):\n\n```\nload_module modules/ngx_http_perl_module.so;\nperl_set $ext_hostname 'sub { return $ENV{\"HOST\"}; }';\n```\n\nThis will make the `HOST` env available inside `nginx` as `$ext_hostname`,\ne.g. with a directive like:\n\n```\nserver {\n    listen         80;\n    location / {\n        return 200 'HOST at run-time: ${ext_hostname}\\n';\n    }\n}\n```\n\n\n# Usage examples\n\n## docker build\n\nTo make the env variable `HOST` available at built-time, use:\n\n```\n$ docker build --build-arg HOST=example.com -t docker-nginx-env .\n[...]\nStep 6/6 : RUN echo \"HOST at build-time: $HOST\"\n ---> Running in ebb80aff9255\nHOST at build-time: example.com\n[...]\n```\n\n## docker run\n\nThe `HOST` env variable used at build-time is **not available** at run-time, though:\n\n```\n$ docker run -p 80:80 -d docker-nginx-env\n5ce21faf4cebb35383af19171a4359c1449b1dff92c0552ef75143d24021ef22\n\n$ curl localhost\nHOST at run-time: \n```\n\nIf you want to set the `HOST` env variable inside `nginx` at Docker run-time, do this:\n\n```\n$ docker run -p 80:80 -d --env HOST=foo docker-nginx-env\n710b70aef5edfd5b5ccc13e954f57e1d407a2156adea7b989d55678a247503be\n\n$ curl localhost\nHOST at run-time: foo\n```\n\n\n## docker-compose\n\nWith `docker-compose`, the `HOST` env is set like this:\n\n```\n$ HOST=foo docker-compose -f docker-compose.yml up --build --force-recreate\n[...]\nStep 6/6 : RUN echo \"HOST at build-time: $HOST\"\n ---> Running in d1f9023e2797\nHOST at build-time: foo\n```\n\nThis command will both build and run the container, so calling `nginx` works as expected:\n\n$ curl localhost\nHOST at run-time: foo\n\n"}
{"url": "https://github.com/arne-cl/errorfuncs", "owner": "arne-cl", "repository_name": "errorfuncs", "date_all_variable_collection": "2023-09-11", "description": "Golang helper functions to avoid typing if err != nil { ... } 100 times per day.", "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": "Go", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Go", "num_chars": 251}]}
{"url": "https://github.com/arne-cl/fangorn", "owner": "arne-cl", "repository_name": "fangorn", "date_all_variable_collection": "2023-09-11", "description": "Automatically exported from code.google.com/p/fangorn", "size": 19991, "stargazers_count": 1, "watchers_count": 1, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": false, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "sparcs", "contributions": 52}, {"contributor": "ned2", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 966665}, {"language": "JavaScript", "num_chars": 74263}, {"language": "Shell", "num_chars": 6454}, {"language": "HTML", "num_chars": 3936}, {"language": "CSS", "num_chars": 2349}], "readme": "**********************************\nOverview\n**********************************\n\nFangorn runs within a Jetty webserver present in the \"server\" directory. The \n\"index\" directory contains the search indexes and \"db\" contains an apache derby \nembedded database. The database is only used to manage corpora state. We use \nthe term application synonymously with the server, because starting the server \nstarts the application.\n\n\n**********************************\nInstallation instructions\n**********************************\n\nRead INSTALL file in the root directory.\nAll commands listed below are to be executed from the install directory and \nnot from the root directory which contains this file.\n\n\n**********************************\nData\n**********************************\n\nThe data should be present in the Penn Treebank bracketed style. An example \nannotation looks like this:\n\n((S(NP-SBJ(EX There))(VP(VBZ is)(NP-PRD(DT no)(NN asbestos))(PP-LOC(IN in)(NP(PR\nP$ our)(NNS products)))(ADVP-TMP(RB now)))(. .)('' '')))\n\nA file can contain one or more sentences, and could be present in any directory\nhierarchy under a main corpus directory. A corpus file is identified by its \nextension .mrg, or .gz if gzipped.\n\nA line starting with a '*' is treated as a comment and is ignored.\n\nThe application is distributed with sample data from the Penn Treebank Corpus\navailable in NLTK's data distribution.\n\n\n**********************************\nRunning the application\n**********************************\n\nRun the script start-app.sh\n\nNOTE: \nA. Software requirements: Java 5 SE JRE (runtime env) or JDK (dev kit) or \nabove. Please note that this distribution has been compiled without\noptimization in order to make it run on several distributions of Java. For\nfaster querying you could send an email to: sghodke@csse.unimelb.edu.au \nasking for the Java 5/6/7 optimised version.\nB. The application is distributed with an example set of 343 sentences from \nThe Penn Treebank corpus.\n\n\n**********************************\nStopping the application\n**********************************\n\nPress Ctrl + c in the terminal where the application is running.\n\n\n**********************************\nAccessing the application\n**********************************\n\n* If accessing the application on the same machine as the server: Start a\n browser and type in http://localhost:9090 or http://localhost:9090/index\nin the address bar.\n\n* The application could be accessed on a network using \nhttp://<machine-name>:9090 or http://<machine-name>:9090/index\n\n\n**********************************\nAdding a Corpus to Fangorn\n**********************************\n\n1. Run the script create-index-GZ.sh or create-index-MRG.sh based on whether the\ncorpus files are gizpped and have the extension .gz or if they are plain text \nfiles with the extension .mrg\nBoth scripts require 3 compulsory parameters and 1 optional parameter that \nshould be specified in the order mentioned below:\n\t(1) The complete path to the corpus directory.\n\t(2) The directory where the index is stored (should be different from the \n\t    ones already present).\n\t(3) The name of the corpus as should be displayed in the UI.\n\t(4) [Optional] Total number of sentences to be indexed from the corpus. All \n\t    sentences in the directory are indexed if this parameter is not \n\t    specified.  \n\t\n2. Example usages:\n\nsh create-index-MRG.sh /home/test/Corpora/Penn/WSJ pwsj Penn_Treebank_WSJ\n\nIndexes all sentences in the directory /home/test/Corpora/Penn/WSJ and displays \nthe corpus as \"Penn Treebank WSJ\" in the user interface.\n\nsh create-index-MRG.sh /home/test/Corpora/Penn/Br pbrn PT_Brown_100 100\n\nIndexes first 100 sentences in the directory /home/test/Corpora/Penn/Br and \ndisplays it as \"PT Brown 100\" in the user interface.\n\nNOTE:\nA. The create-index-GZ.sh file expects each corpus file to be gzip compressed \nand available with an extension .gz.\nB. If a corpus is added while the application is running it will only be visible\nafter re-starting the application.\nC. If the index directory supplied is not unique the script will report it and \nterminate. Previous data will not be overwritten. You could avoid this by \nviewing a current listing of all corpora (See Listing all Corpora section below).\n\n\n**********************************\nDeleting a Corpus from Fangorn\n**********************************\n\n1. This should be performed when the application is not running.\n\n2. Run the script delete-index.sh with the name of the directory where the index\nis stored. The term should be the same as that mentioned in Step 2. (2) in the \nAdd a Corpus instructions.\n\nNOTE:\nA. If unsure about the dir name, check a listing of all corpora (See Listing all\n Corpora section below).\n\n\n**********************************\nListing all Corpora\n**********************************\n\n1. Run the script list-db.sh.\n\nNOTE: This only lists the contents of the database.\n"}
{"url": "https://github.com/arne-cl/feng-hirst-rst-parser", "owner": "arne-cl", "repository_name": "feng-hirst-rst-parser", "date_all_variable_collection": "2023-09-11", "description": "fork of Vanessa Wei Feng's RST-style discourse parser", "size": 110043, "stargazers_count": 11, "watchers_count": 11, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 8, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 2, "license": "BSD 2-Clause \"Simplified\" License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 8, "open_issues": 2, "watchers": 11, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 23}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["rhetorical-parser", "rhetorical-structure-theory", "rst"], "languages": [{"language": "Shell", "num_chars": 634665}, {"language": "C++", "num_chars": 598370}, {"language": "C", "num_chars": 585483}, {"language": "Makefile", "num_chars": 373905}, {"language": "Python", "num_chars": 203587}, {"language": "Perl", "num_chars": 14720}, {"language": "Dockerfile", "num_chars": 1493}], "readme": "# feng-hirst-rst-parser\n\n[![Travis Build Status](https://travis-ci.org/arne-cl/feng-hirst-rst-parser.svg?branch=master)](https://travis-ci.org/arne-cl/feng-hirst-rst-parser)\n[![Docker Build Status](https://img.shields.io/docker/cloud/build/nlpbox/feng-hirst-rst-parser.svg)](https://hub.docker.com/r/nlpbox/feng-hirst-rst-parser)\n\nThis repository contains my fork of the RST parser published by\nVanessa Wei Feng and Graeme Hirst. I updated some of its dependencies,\ndockerized the application, added some end-to-end tests and changed its\noutput format to make it simpler to parse (e.g. by [discoursegraphs](https://github.com/arne-cl/discoursegraphs)\nor the [rst-converter-service](https://arne-cl@github.com/NLPbox/rst-converter-service)).\n\nIf you want to run the parser as a web service, have a look at\n[nlpbox/feng-hirst-service](https://github.com/nlpbox/feng-hirst-service).\n\nThe [original source code](http://www.cs.toronto.edu/~weifeng/software.html)\nis still part of this repository. (The version published in Feng and Hirst (2012)\nis tagged `1.01`, Feng and Hirst (2014) is tagged `2.01`\u2014both are\nin the `master` branch. The original README is kept in the file\n`README-original.txt`.)\n\n\n\n# Installation\n\n```\ndocker build -t feng-hirst .\n```\n\n# Usage\n\nIf your input text is in `/tmp/input.txt`:\n\n```\ncat /tmp/input.txt\nAlthough they didn't like it, they accepted the offer.\n```\n\nyou can map the `/tmp` directory into the container and parse the text like\nthis:\n\n```\ndocker run -v /tmp:/tmp -ti feng-hirst /tmp/input.txt\nParseTree('Contrast[S][N]', [\"Although they did n't like it ,\", 'they accepted the offer .'])\n```\n\n**NOTE**: For my convenience as a developer, this fork does not use the\noriginal output, which looks like this:\n\n```\n(Contrast[S][N]\n  _!Although they did n't like it ,!_\n  _!they accepted the offer . <P>!_)\n```\n\nbut the one seen above (based on / parsed by the Python nltk Tree implementation).\n\n\n# Citation\n\nIf you use the Feng/Hirst RST parser in your academic work, please cite the following paper:\n\nVanessa Wei Feng and Graeme Hirst, 2014.  \n[A Linear-Time Bottom-Up Discourse Parser with Constraints and Post-Editing.](http://aclweb.org/anthology/P14-1048)  \nIn _Proceedings of the 52th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-2014)_, Baltimore, USA. \n\nFor more technical details, see:\n\nVanessa Wei Feng and Graeme Hirst, 2014.  \n[Two-pass Discourse Segmentation with Pairing and Global Features.](http://arxiv.org/abs/1407.8215)  \narXiv:1407.8215v1.\n"}
{"url": "https://github.com/arne-cl/fernbus", "owner": "arne-cl", "repository_name": "fernbus", "date_all_variable_collection": "2023-09-11", "description": "commandline interface to busliniensuche.de", "size": 152, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": "GNU Affero General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 15}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 10737}, {"language": "Makefile", "num_chars": 182}]}
{"url": "https://github.com/arne-cl/flickr-album-embed-codes", "owner": "arne-cl", "repository_name": "flickr-album-embed-codes", "date_all_variable_collection": "2023-09-11", "description": "extract HTML embed codes from all images of a Flickr album", "size": 244, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 14}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 11506}, {"language": "Makefile", "num_chars": 250}], "readme": "flickr-album-embed-codes\n========================\n\n.. image:: http://img.shields.io/badge/license-BSD-yellow.svg\n   :alt: BSD License\n   :align: left\n   :target: http://opensource.org/licenses/BSD-3-Clause\n\n.. image:: https://www.quantifiedcode.com/api/v1/project/06c5b36327504bccbff940da5603c527/badge.svg\n   :alt: Code issues\n   :align: left\n   :target: https://www.quantifiedcode.com/app/project/06c5b36327504bccbff940da5603c527\n\n\n\nThe ``flickr-album-embed-codes`` script lets you embed all the pictures of a Flickr\nalbum into your website or (wordpress) blog by extracting their HTML embed codes.\n\n.. image:: usage.gif\n   :alt: Usage example\n   :align: center\n\n\nInstallation\n------------\n\nDownload or clone the repository, then follow the OS-specific instructions.\n\n::\n\n    git clone https://github.com/arne-cl/flickr-album-embed-codes.git\n    cd flickr-album-embed-codes\n\nUbuntu 14.04\n~~~~~~~~~~~~\n\n::\n\n    sudo apt-get install firefox git python-setuptools xvfb\n    sudo python setup.py install\n\ndocker\n~~~~~~\n\nBuild the docker container using the ``Dockerfile`` in this directory.\nAfterwards just run the container with the same parameters you would run the\n``flickr-album-embed-codes`` script.\n\n::\n\n    docker build -t flickr-album-embed-codes .\n    docker run -ti flickr-album-embed-codes https://www.flickr.com/photos/USER/sets/ALBUM_ID\n\n\nUsage\n-----\n\n::\n\n    flickr-album-embed-codes -h\n    usage: extract HTML embed codes from a Flickr album [-h] [--debug]\n                                                  album_url [output_file]\n\n    positional arguments:\n      album_url    URL of the Flickr album/photoset to extract embed codes from\n      output_file  output file for photo embed codes\n\n    optional arguments:\n      -h, --help   show this help message and exit\n      --debug      enable debug mode\n\nUsage example\n~~~~~~~~~~~~~\n\nThis will extract the HTML embed codes of all the images in the given Flickr album\nand store them in the file ``embed.html``:\n\n::\n\n    flickr-album-embed-codes https://www.flickr.com/photos/USER/sets/ALBUM_ID embed.html\n"}
{"url": "https://github.com/arne-cl/fosay", "owner": "arne-cl", "repository_name": "fosay", "date_all_variable_collection": "2023-09-11", "description": "Automatically exported from code.google.com/p/fosay", "size": 508, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": false, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 5, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 5, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "zkochan", "contributions": 71}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 357258}]}
{"url": "https://github.com/arne-cl/frodo-wii", "owner": "arne-cl", "repository_name": "frodo-wii", "date_all_variable_collection": "2023-09-11", "description": "Automatically exported from code.google.com/p/frodo-wii", "size": 4072, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": false, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 16, "license": "GNU General Public License v2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 16, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "SimonKagstrom", "contributions": 74}, {"contributor": "Oibaf66", "contributions": 14}, {"contributor": "arne-cl", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 916986}, {"language": "C", "num_chars": 184929}, {"language": "HTML", "num_chars": 59218}, {"language": "Python", "num_chars": 47126}, {"language": "Makefile", "num_chars": 1173}], "readme": "# frodo-wii\nAutomatically exported from code.google.com/p/frodo-wii\n\n# Prerequisites\n\n* libsdl-ttf-dev (provides `/usr/include/SDL/SDL_ttf.h`), e.g. `libsdl-ttf2.0-dev` in Ubuntu\n* libsdl-image-dev (provides `/usr/include/SDL/SDL_image.h`), e.g. `libsdl-image1.2-dev` in Ubuntu\n"}
{"url": "https://github.com/arne-cl/go-abspath", "owner": "arne-cl", "repository_name": "go-abspath", "date_all_variable_collection": "2023-09-11", "description": "command-line tool to print absolute paths of all given files", "size": 5, "stargazers_count": 1, "watchers_count": 1, "language": "Go", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["abspath", "cli", "filepath", "golang", "path"], "languages": [{"language": "Go", "num_chars": 2093}], "readme": "go-abspath\n==========\n\n`go-abspath` is a command line tool that prints the absolute paths of all\ngiven files. File names can be piped via `STDIN` or given as arguments.\nThis implementation is in Golang. For a Python version, check out\n[arne-cl/abspath](https://github.com/arne-cl/abspath).\n\nUsage\n-----\n\nPrint the absolute paths of all paths given as arguments:\n\n    abspath file1.txt path/to/file2.pdf\n\nPrint the absolute paths of all files and directories in `./Desktop`:\n\n    abspath Desktop/*\n\nPrint the absolute paths of all files and directories in `Desktop`\n**and** its subdirectories:\n\n    abspath -r Desktop\n\nPrint the absolute paths of all `.pdf` files in `~/Documents`\n\n    find ~/Documents -name *.pdf | abspath\n\n\nInstallation\n------------\n\n    go get github.com/arne-cl/go-abspath\n    go build -o abspath github.com/arne-cl/go-abspath\n    \nThis will get you the binary, that you can call as `./abspath`.\nYou can make this available on your `$PATH`, e.g. like this:\n\n    sudo mv abspath /usr/local/bin/\n\n\nLicense\n-------\n\nMIT\n"}
{"url": "https://github.com/arne-cl/go-grepurl", "owner": "arne-cl", "repository_name": "go-grepurl", "date_all_variable_collection": "2023-09-11", "description": null, "size": 4, "stargazers_count": 0, "watchers_count": 0, "language": "Go", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Go", "num_chars": 3038}]}
{"url": "https://github.com/arne-cl/knitr2notebook", "owner": "arne-cl", "repository_name": "knitr2notebook", "date_all_variable_collection": "2023-09-11", "description": "convert knitr R documents into interactive IPython notebooks", "size": 128, "stargazers_count": 1, "watchers_count": 1, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 286}, {"language": "Shell", "num_chars": 125}], "readme": "knitr2notebook\n==============\n\nknitr2notebook converts knitr documents (R markdown *.Rmd files) to\nIpython notebooks. The code is based on https://gist.github.com/ramnathv/9334834 .\n\nUsage\n-----\n\n::\n\n    knitr2notebook input.Rmd output.ipynb\n\nDependencies\n------------\n\n- R\n- knitr\n- rpy2\n- notedown\n\n"}
{"url": "https://github.com/arne-cl/language_models", "owner": "arne-cl", "repository_name": "language_models", "date_all_variable_collection": "2023-09-11", "description": null, "size": 100, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 2276}]}
{"url": "https://github.com/arne-cl/learn-node-from-scratch", "owner": "arne-cl", "repository_name": "learn-node-from-scratch", "date_all_variable_collection": "2023-09-11", "description": "My notes on Wes Bos' \"Learn Node\" online course (Node.js, Express, MongoDB).", "size": 13678, "stargazers_count": 1, "watchers_count": 1, "language": "CSS", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 11, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 11, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 29}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["es6", "expressjs", "javascript", "mongodb", "nodejs"], "languages": [{"language": "CSS", "num_chars": 23945}, {"language": "JavaScript", "num_chars": 14591}, {"language": "HTML", "num_chars": 6366}], "readme": "Learn Node\n==========\n\nThese are my notes for Wes Bos' [Learn Node](https://learnnode.com/) online\nclass. Its goal is to teach you to build a restaurant reviewing web app\n(front- and back-end) using [NodeJS](https://nodejs.org/),\n[Express](http://expressjs.com/) and [MongoDB](https://www.mongodb.com/).\n\nHe is teaching the class from the perspective of a front-end developer wanting\nto become \"full stack\". As such, he provides a huge number of \"starter files\"\nincluding custom javascript helper functions, tons of dependencies and CSS\n\"magic\".\n\nAs my background is in back-end development and I prefer to learn from first\nprinciples, I reduced the codebase to the minimum needed for the\nconcepts/examples taught in the given lesson.\n(You can check out the respective state of the codebase / course by looking\nat the git tags, e.g. `video-10` will contain all the code you'll need to\nrun the examples up to and including the 10th video of the course.)\n\n\nTable of Contents\n=================\n\n- [Learn Node](#learn-node)\n- [01 - Getting Setup](#01---getting-setup)\n  * [Install NodeJS](#install-nodejs)\n  * [Install packages in the starter files directory](#install-packages-in-the-starter-files-directory)\n  * [Configure IDE](#configure-ide)\n- [02 - Setting up Mongo DB](#02---setting-up-mongo-db)\n  * [Install on Ubuntu / Linux Mint](#install-on-ubuntu---linux-mint)\n  * [Install on arch linux](#install-on-arch-linux)\n  * [Configure MongoDB](#configure-mongodb)\n- [03 - Starter Files and Environmental Variables](#03---starter-files-and-environmental-variables)\n  * [app.js](#appjs)\n  * [start.js](#startjs)\n  * [Start our example app](#start-our-example-app)\n- [04 - Core Concept - Routing](#04---core-concept---routing)\n  * [routes/index.js](#routes-indexjs)\n- [05 - Core Concept - Templating](#05---core-concept---templating)\n  * [hello.pug](#hellopug)\n  * [Put variables / request params into template](#put-variables---request-params-into-template)\n  * [Use base templates](#use-base-templates)\n- [06 - Core Concept - Template Helpers](#06---core-concept---template-helpers)\n  * [moment.js](#momentjs)\n- [07 - Core Concept - Controllers and the MVC Pattern](#07---core-concept---controllers-and-the-mvc-pattern)\n- [08 - Core Concept - Middleware and Error Handling](#08---core-concept---middleware-and-error-handling)\n  * [Route-specific middleware](#route-specific-middleware)\n  * [Global middleware](#global-middleware)\n  * [app.js](#appjs-1)\n  * [cookie-parser](#cookie-parser)\n- [09 - Creating our Store Model](#09---creating-our-store-model)\n  * [models/Store.js](#models-storejs)\n- [10 - Saving Stores and using Mixins](#10---saving-stores-and-using-mixins)\n  * [Mixins](#mixins)\n  * [Sending and parsing HTML forms](#sending-and-parsing-html-forms)\n- [11 - Using Async Await](#11---using-async-await)\n- [12 - Flash Messages](#12---flash-messages)\n- [13 - Querying our Database for Stores](#13---querying-our-database-for-stores)\n- [14 - Creating an Editing Flow for Stores](#14---creating-an-editing-flow-for-stores)\n- [15 - Saving Lat and Lng for each store](#15---saving-lat-and-lng-for-each-store)\n- [16 - Geocoding Data with Google Maps](#16---geocoding-data-with-google-maps)\n- [17 - Quick Data Visualization Tip](#17---quick-data-visualization-tip)\n- [18 - Uploading and Resizing Images with Middleware](#18---uploading-and-resizing-images-with-middleware)\n- [19 - Routing and Templating Single Stores](#19---routing-and-templating-single-stores)\n- [20 - Using Pre-Save hooks to make Unique Slugs](#20---using-pre-save-hooks-to-make-unique-slugs)\n- [21 - Custom MongoDB Aggregations](#21---custom-mongodb-aggregations)\n- [22 - Multiple Query Promises with Async Await](#22---multiple-query-promises-with-async-await)\n- [Hints for creating the whole thing from scratch](#hints-for-creating-the-whole-thing-from-scratch)\n  * [Get rid of MongoDB warnings](#get-rid-of-mongodb-warnings)\n  * [Hot reloading](#hot-reloading)\n  * [Slug creation](#slug-creation)\n\n<small><i><a href='http://ecotrust-canada.github.io/markdown-toc/'>Table of contents generated with markdown-toc</a></i></small>\n\n\n\n01 - Getting Setup\n==================\n\nInstall NodeJS\n--------------\n\n- install NodeJS 7.6 or above with npm 4 or above\n\n```\n# check node version\n$ node -v\nv10.15.3\n\n$ npm -v\n6.10.3\n```\n\n- download course materials from https://courses.wesbos.com\n- download starter files from https://github.com/wesbos/Learn-Node\n\n\nInstall packages in the starter files directory\n-----------------------------------------------\n\n```\n$ sudo npm install -g npm\n$ npm install\n...\nadded 1179 packages from 817 contributors and audited 10758 packages in 166.636s\nfound 27 vulnerabilities (10 low, 10 moderate, 7 high)\n  run `npm audit fix` to fix them, or `npm audit` for details\n\n$ npm audit fix\n+ express-session@1.17.0\n+ pug@2.0.4\n+ axios@0.19.0\n+ body-parser@1.19.0\n+ express@4.17.1\n+ moment@2.24.0\n+ mongoose@5.7.4\nadded 13 packages from 14 contributors, removed 17 packages and updated 38 packages in 44.992s\nfixed 22 of 27 vulnerabilities in 10758 scanned packages\n  2 vulnerabilities required manual review and could not be updated\n  2 package updates for 3 vulnerabilities involved breaking changes\n  (use `npm audit fix --force` to install breaking changes; or refer to `npm audit` for steps to fix these manually)\n\n$ npm audit fix --force\n+ css-loader@3.2.0\n+ juice@5.2.0\nadded 83 packages from 69 contributors, removed 75 packages and updated 16 packages in 39.571s\nfixed 3 of 5 vulnerabilities in 10800 scanned packages\n  2 vulnerabilities required manual review and could not be updated\n  2 package updates for 3 vulnerabilities involved breaking changes\n  (installed due to `--force` option)\n\n# With NodeJS, you're always doomed!\n$ npm audit\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Low           \u2502 Regular Expression Denial of Service                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Package       \u2502 timespan                                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Patched in    \u2502 No patch available                                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Dependency of \u2502 forever                                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Path          \u2502 forever > timespan                                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 More info     \u2502 https://npmjs.com/advisories/533                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Low           \u2502 Regular Expression Denial of Service                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Package       \u2502 braces                                                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Patched in    \u2502 >=2.3.1                                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Dependency of \u2502 forever                                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Path          \u2502 forever > forever-monitor > chokidar > anymatch > micromatch \u2502\n\u2502               \u2502 > braces                                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 More info     \u2502 https://npmjs.com/advisories/786                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nfound 2 low severity vulnerabilities in 10315 scanned packages\n  2 vulnerabilities require manual review. See the full report for details.\n```\n\n\nConfigure IDE\n-------------\n\n- we need support for ``.pug`` (HTML template) files\n    - [vscodium](https://github.com/VSCodium/vscodium) (free/libre version of Micro$oft VSCode) provides this\n\n\n02 - Setting up Mongo DB\n========================\n\n- we'll use MongoDB 3.2+ as our document store / database\n- set up MongoDB locally\n\nInstall on Ubuntu / Linux Mint\n------------------------------\n\n- [how to install on ubuntu with mongodb-maintained packages](https://docs.mongodb.com/manual/tutorial/install-mongodb-on-ubuntu/#install-mongodb-community-edition-using-deb-packages)\n- [how to set a password in MongoDB](https://www.scaleway.com/en/docs/install-and-secure-mongodb-on-ubuntu/)\n\nInstall on arch linux\n---------------------\n\nhttps://wiki.archlinux.org/index.php/MongoDB\n\n```\nsudo mkdir -p /data/db\nsudo mongod --fork --logpath /tmp/mongo.log\n```\n\nConfigure MongoDB\n-----------------\n\n- default local URL: ``mongodb://127.0.0.1:27017``\n\n- copy ``variables.env.samples`` to ``variables.env``\n- in ``variables.env``, replace ``DATABASE`` value with ``mongodb://$USERNAME:$PASSWORD@127.0.0.1:27017/$DATABASENAME``\n    - add a user/password using the guide above\n    - add a database using either MongoDB Compass or robo3t (and add the user to it)\n- add ``variables.env`` to your ``.gitignore`` file\n\n- test, if mongodb is working\n\n```\n$ mongo -u $USERNAME -p --authenticationDatabase admin\n> exit\nbye\n```\n\n- installl [MongoDB Compass](https://www.mongodb.com/download-center/compass) GUI and connect to the database\n    - this is an Electron app\n    - try [robo3t](https://robomongo.org/) instead (open-source, writting in C++/Qt)\n\n\n03 - Starter Files and Environmental Variables\n==============================================\n\n- we'll use [ExpressJS](http://expressjs.com/) as our web framework\n\napp.js\n------\n\n- imports all the JS/node libraries that we'll use\n- loads environment variables from ``variables.env``\n\nstart.js\n--------\n\n- entrypoint for the app\n- connects to our MongoDB database, writes errors to console\n- listens for ``GET`` requests on the configured port (default: ``7777``)\n\nStart our example app\n---------------------\n\n- ``npm start``\n    - looks up ``scripts`` section in ``package.json\n    - calls ``node ./start.js`` and lots of other stuff (a file-change watcher, webpack etc)\n\n\n04 - Core Concept - Routing\n===========================\n\nHow are URLs routed in ExpressJS?\n\nroutes/index.js\n--------\n\n- contains a route for ``/``\n\n```\nconst express = require('express');\nconst router = express.Router();\n\nrouter.get('/', (req, res) => {\n  res.send('Hey! It works!');\n});\n\nmodule.exports = router;\n```\n\n- the routes are then imported into ``app.js`` and used there\n\n```\nconst routes = require('./routes/index');\n\nconst app = express();\n\n# all routes starting with '/' will be handled by these routes\napp.use('/', routes);\n\n# we could have multiple route handlers:\n# app.use('/admin', adminRoutes);\n```\n\n- URL query params are available in `req.query`\n\n\n05 - Core Concept - Templating\n==============================\n\n- `res.render` renders templates in a response\n- we'll use the pug templating language (original name: jade)\n    - templates are stored in `./views` folder\n\n- pug uses significant whitespace for nesting tags\n- comments must be on their own line\n\nhello.pug\n---------\n```\nh1 Hello, world!\n\n// comment shown in HTML\n//- comment not shown in HTML\n\n//- <div class=\"wrapper\">\ndiv.wrapper \n  p This is a simple paragraph.\n\n  //- <p id=\"second\"></p>\n  p#second Yet another paragraph.\n  \n  //- <img class=\"animal\" src=\"dog.jpg\" alt=\"Dog\"/>\n  img.animal(src=\"dog.jpg\" alt=\"Dog\")\n```\n\nPut variables / request params into template\n--------------------------------------------\n\n```\n// take a param from the render function and put it into a string\nh2 #{name} is #{age} years old.\n\n// when putting params into tags, we need to use ES6 string literals.\nimg.animal(src=\"dog.jpg\" alt=`This is ${name}'s dog.`)\n```\n\nUse base templates\n------------------\n\nIf you have a `layout.pug` template with a section ``block content``,\nyou can fill/override it in another template like this:\n\n```\nextends layout\n\nblock content\n  h1 This is the headline!\n```\n\n\n06 - Core Concept - Template Helpers\n====================================\n\n`helpers.js` contains functions and constants that can be used as variables\nin pug templates.\n\n- is imported in `app.js` and stored in the variable `h`\n- helpers are made available in templates by putting them into a middleware\n\n```\nconst helpers = require('./helpers');\n\napp.use((req, res, next) => {\n  res.locals.h = helpers;\n  next();\n});\n```\n\nFor example, `siteName` from `helpers.js`\n\n```\nexports.siteName = `Now That's Delicious!`;\n```\n\nis now available in templates by using:\n\n```\nhtml\n  head\n    title= `${h.siteName}`\n```\n\nmoment.js\n---------\n\n- relative date/timestamp library, can be used in templates like this:\n\n```\np The sale ends in #{h.moment().endOf('day').fromNow()}\n```\n\n\n07 - Core Concept - Controllers and the MVC Pattern\n===================================================\n\nTo follow the MVC pattern, we will outsource the functions that are called\nin the routes into `./controllers`, i.e. we turn this:\n\n```\nrouter.get('/', (req, res) => {\n  res.render('hello', {\n    name: req.query.name,\n    age: req.query.age\n  });\n});\n```\n\ninto this:\n\n```\nconst storeController = require('../controllers/storeController')\nrouter.get('/', storeController.homePage);\n```\n\nand putting the function into `./controllers/storeController.js`:\n\n```\nexports.homePage = (req, res) => {\n  res.render('hello', {\n    name: req.query.name,\n    age: req.query.age,\n  });\n}\n```\n\n\n08 - Core Concept - Middleware and Error Handling\n=================================================\n\n- **middleware**: function that get called for each incoming request\n  before the response is sent back\n    - the output of one middleware is handed over to the input of the next\n      middleware by calling `next()`\n\nRoute-specific middleware\n-------------------------\n\n- is only called for specific routes\n\n```\n// example middleware that adds a name to each incoming request\nexports.myMiddleware = (req, res, next) => {\n  req.name = 'John';\n  next();\n};\n```\n\nThis can now be called in a route before the actual response:\n\n```\nrouter.get('/', storeController.myMiddleware, storeController.homePage);\n```\n\nSince ``myMiddleware`` hands over its output using `next()` and is called\nbefore ``homePage``, the latter function can access the `req.name` value:\n\n```\nexports.homePage = (req, res) => {\n  console.log(req.name);\n  res.render('index');\n};\n```\n\nGlobal middleware\n-----------------\n\n- is called for every request that comes into the application\n  before it get to the router\n\napp.js\n------\n\n- contains all global middleware for this app, i.e. all calls to `app.use(...)`\n  are invoking some kind of middleware for each incoming request\n\ncookie-parser\n-------------\n\nWe can set a cookie in any middleware like this:\n\n```\nexports.myMiddleware = (req, res, next) => {\n  req.name = 'John';\n  res.cookie('name', 'evil-cookie', {maxAge: 1000000});\n  next();\n};\n```\n\nIt will be added to `res.cookies` (which can be viewed in Chrome DevTools\n>> Application >> Storage >> Cookies) by `cookie-parser`, which is added as\na global middleware in `app.js`:\n\n```\nconst cookieParser = require('cookie-parser');\n\napp.use(cookieParser());\n```\n\n\n09 - Creating our Store Model\n=============================\n\n- unlike Elasticsearch, MongoDB uses schema by default\n\nmodels/Store.js\n---------------\n\n```\nconst storeSchema = new mongoose.Schema({\n  name: {\n    type: String,\n    trim: true,\n    required: 'Please enter a store name!' // true would work, but emits an unhelpful error msg\n  },\n  slug: String,\n  description: {\n    type: String,\n    trim: true\n  },\n  tags: [String]\n});\n```\n\nWe add middleware to create slugs for userfriendly URLs automatically.\nOur model(s) are then imported once in `start.js` as a singleton.\n\n```\nrequire('./models/Store');\n```\n\n\n10 - Saving Stores and using Mixins\n===================================\n\n- goal: create the `/add` page with a form for adding stores/restaurants to our database\n- we'll not yet store it in the db, but merely return the form data back\n  as JSON after the form is `POST`ed\n\nMixins\n------\n\nMixins are templates that can be imported into other templates and used like\nfunctions with parameters, e.g. the mixin `views/mixins/_storeForms.pug`:\n\n```\nmixin storeForm(store = {})\n    p #{store.name}\n```\n\nhas a `store` parameter. It can be used in `views/editStore.pug` like this:\n\n```\nextends layout\ninclude mixins/_storeForm\n\nblock content\n    div\n        +storeForm({name: 'Joe's Pizza'})\n```\n\nSending and parsing HTML forms\n------------------------------\n\nWe can create a form in `pug` that `POST`s data to the URL `/add`:\n\n```\nmixin storeForm(store = {})\n    form(action=\"/add\" method=\"POST\")\n\n        label(for=\"name\") Store Name\n        // 'name' field value has to correspond to the schema we want to store\n        // this in later on\n        input(type=\"text\" name=\"name\")\n        \n        input(type=\"submit\" value=\"Save\")\n```\n\nTo make this work, we need to add a `post` handler to the `/add` route:\n\n```\nrouter.get('/add', storeController.addStore);\nrouter.post('/add', storeController.createStore);\n```\n\nFor now, the `createStore` controller will just respond with the form fields/values:\n\n```\nexports.createStore = (req, res) => {\n    // will not work without the 'body-parser' middleware in app.js\n    res.json(req.body);\n};\n```\n\n\n11 - Using Async Await\n======================\n\nWe need to look at `async` and `await`, before we can work with the\n`mongogoose` MongoDB client.\n\nSince we're using ES Promises with mongoose:\n\n```\n// start.js\nmongoose.Promise = global.Promise;\n```\n\nwe can use async/await when saving data to MongoDB.\n(We don't necessarily want to wait for it to finish, and we also want to\navoid \"callback hell\".)\n\nHere's our controller. It reads the form data from the request body.\nSince we use a strict schema, we don't have to validate the data\n(at least for now):\n\n```\n// Import our database schema from models/Store.js.\nconst Store = mongoose.model('Store');\n\nexports.createStore = async (req, res) => {\n   const store = new Store(req.body);\n   await store.save();\n    res.redirect('/');\n};\n```\n\nThe `save()` operation might fail, but Wes doesn't want to wrap it\nin a try/catch block, so he uses some middleware error catching magic\nto avoid it. It is defined in `handlers/errorHandlers.js`:\n\n```\nrts.catchErrors = (fn) => {\n  return function(req, res, next) {\n    return fn(req, res, next).catch(next);\n  };\n};\n```\n\nand is imported and wrapped around the `createStore` controller in\n`routes/index.js`:\n\n```\n// { foo } object destructuring: allows us to just import 'catchErrors'\n// instead of importing 'errorHandlers' and then referencing 'errorHandlers.catchErrors'\nconst { catchErrors } = require('../handlers/errorHandlers')\n\nrouter.post('/add', catchErrors(storeController.createStore));\n```\n\n\n12 - Flash Messages\n===================\n\n- goal: add color-highlighted messages to an existing page (e.g. to signal\n  that an order has been submitted successfully) -- in contrast to\n  creating/redirecting the user to a new page\n\nWe need to add the `connect-flash` middleware to `app.js`\n(it depends on session support, which depends on a session store):\n\n```\nconst session = require('express-session');\nconst mongoose = require('mongoose');\nconst MongoStore = require('connect-mongo')(session); // MongoDB session store\nconst flash = require('connect-flash');\n\n// Sessions allow us to store data on visitors from request to request\n// This keeps users logged in and allows us to send flash messages\napp.use(session({\n  secret: process.env.SECRET,\n  key: process.env.KEY,\n  resave: false,\n  saveUninitialized: false,\n  store: new MongoStore({ mongooseConnection: mongoose.connection })\n}));\n\napp.use(flash());\n```\n\nTo make the `flash` messages trigger our CSS, we need to store them where\nthey can be checked by our templates (i.e. in our pass-variables-to-templates\nmiddleware):\n\n```\napp.use((req, res, next) => {\n  [...]\n  res.locals.flashes = req.flash();\n  next();\n});\n```\n\nWes built his own flash message handling in `layout.pug`, which looks like this:\n\n```\n    block messages\n      if locals.flashes\n        .inner\n          .flash-messages\n            - const categories = Object.keys(locals.flashes)\n            each category in categories\n              each message in flashes[category]\n                .flash(class=`flash--${category}`)\n\n                  // \"!= message\" means HTML-parse \"message\" instead of showing it verbatim\n                  p.flash__text!= message\n\n                  // remove the message on button click\n                  button.flash__remove(onClick=\"this.parentElement.remove()\") &times;\n```\n\nAfter all this setup, we can use finally flashes, but they will only show up\nin the response to the **next** request (or when we redirect the current request)!\n\n```\nexports.createStore = async (req, res) => {\n    const store = new Store(req.body);\n    await store.save();\n    \n    req.flash('success', `Successfully Created ${store.name}. Care to leave a review?`);\n    // redirect to the page of the store we just created\n    res.redirect(`/store/${store.slug}`);\n};\n```\n\n\n\n13 - Querying our Database for Stores\n=====================================\n\n- goal: list all stores when hitting the homepage or `/stores`\n\nFirst, we create a reusable \"store overview\" as a mixin (`views/mixins/_storeCard.pug`):\n\n```\nmixin storeCard(store = {})\n    .store\n        //- String interpolation with fallback: ${store.photo || 'store.png'} .\n        //- If the store has no photo, show store.png instead.\n        img(src=`/uploads/${store.photo || 'store.png'}`)\n        \n        h2.title\n            a(href=`/store/${store.slug}`)\n\n        .store__details\n            p= store.description\n\n```\n\nWe can now use it in the `stores.pug` view:\n\n```\nextends layout\n\ninclude mixins/_storeCard\n\nblock content\n    .inner\n    h2= title\n\n    .stores\n        each store in stores\n            +storeCard(store)\n```\n\n\nThe `getStores` controller retrieves all stores from the db and\nrenders them in the `stores` template:\n\n```\nexports.getStores = async (req, res) => {\n    const stores = await Store.find();\n    res.render('stores', {title: 'Stores', stores: stores});\n};\n```\n\nFinally, we make the `stores` view available under the `/` and `/stores`\nroutes. Since our db query is async, we need to wrap the controllers\nin our `catchErrors()` middleware:\n\n```\nrouter.get('/', catchErrors(storeController.getStores));\nrouter.get('/stores', catchErrors(storeController.getStores));\n```\n\n\n14 - Creating an Editing Flow for Stores\n========================================\n\n- goal: edit existing stores and update them in the database\n\nThis lesson introduces **wildcard routes**, e.g. `/stores/:id/edit` which use\nURLs like `/stores/123/edit`. The ID `123` will be stored in `req.params.id`.\n\nWe'll add two such routes, one for GETting the editable page of a store\nand another for POSTing the edited store (thereby updating the store's\ninformation in the database):\n\n```\nrouter.get('/stores/:id/edit', catchErrors(storeController.editStore));\nrouter.post('/add/:id', catchErrors(storeController.updateStore));\n```\n\nNow, we need to add the controllers that these routes call. `editStore`\nfetches the store with the given ID and renders it in the `editStore`\nview:\n\n```\nexports.editStore = async (req, res) => {\n   // .findOne() returns (a Promise of ) the store with the given ID from MongoDB\n    const store = await Store.findOne({ _id: req.params.id });\n\n    res.render('editStore', {\n        title: `Edit ${store.name}`,\n        store: store,\n    });\n};\n```\n\nWe can use the existing `editStore` view without change for both adding new\nand editing existing stores:\n\n```\nextends layout\n\ninclude mixins/_storeForm\n\nblock content\n    .inner\n        h2= title\n        +storeForm(store)\n```\n\nbut we need to adapt the `storeForm` mixin slightly to make it work for both cases.\n\nThe action `/add/${store._id || ''}` means that the form is POSTed to `/add/` if\nthe given store has no `_id` field (i.e. if it is a new store) and to \n`/add/${store._id} otherwise.\nIn the case of an existing store, we prefill the `input` and `textarea` fields\nand set the checkboxes for all tags that were previously checked:\n\n```\nmixin storeForm(store = {})\n    form(action=`/add/${store._id || ''}` method=\"POST\" class=\"card\")\n\n        label(for=\"name\") Store Name\n        input(type=\"text\" name=\"name\" value=store.name)\n\n        label(for=\"description\") Description\n        //- unlike <input>, <textarea> has no \"value\" field\n        textarea(name=\"description\" value=store.description)= store.description\n\n        //- define choices of tags to add to the restaurant (list of checkboxes)\n        - const choices = ['Wifi', 'Open Late', '24/7', 'Vegan', 'Cats']\n\n        //- store all existing tags in an array. create a new array if\n        //- this is a new store.\n        - const tags = store.tags || []\n\n        ul.tags\n            each choice in choices\n                .tag.tag__choice\n\n                    //- checked=(tags.includes(choice)) means we're calling JS\n                    //- to see if the tags array includes the given choice.\n                    //- If so, the box will be checked.\n                    input(type=\"checkbox\" id=choice value=choice name=\"tags\" checked=(tags.includes(choice)))\n                    label(for=choice) #{choice}\n        input(type=\"submit\" value=\"Save\" class=\"button\")\n```\n\nThe `updateStore` controller updates the given store (req.params.id) in MongoDB\nand redirects to that store's edit page afterwards:\n\n```\nexports.updateStore = async (req, res) => {\n    // MongoDB: find and update the store in one go\n    const query = { _id: req.params.id };\n    const update = req.body;\n    const options = {\n        new: true, // return updated store instead of the old one\n        runValidators: true // always run the model validators\n                            // (by default, they're only run during model creation!)\n    }\n\n    // findOneAndUpdate() does only run, if we call exec() on it\n    const store = await Store.findOneAndUpdate(query, update, options).exec();\n\n    res.redirect(`/stores/${store._id}/edit`);\n};\n```\n\nFinally, we will add an \"edit\" button to each store card, which links to that\nstore's edit page:\n\n```\nmixin storeCard(store = {})\n    .store\n        .store__hero\n            .store__actions\n                a(href=`/stores/${store._id}/edit`)\n                    button edit\n```\n\n\n15 - Saving Lat and Lng for each store\n======================================\n\n- custom data types in MongoDB\n\n\nIn the `storeForm` mixin, we use `location[address]` for the `name` field\nof the `<input>` element.\n\n```\n        label(for=\"address\")\n        input(type=\"text\" id=\"address\" name=\"location[address]\")\n```\n\nWe can only do this because we use the `body-parser` middleware in `app.js`\nwith the `extended: tree` setting, which allows us to use inputs with nested\ndata in them (`location[address]` refers to `location.address` in our `Store`\nMongoDB schema).\n\n```\napp.use(bodyParser.urlencoded({ extended: true }));\n```\n\nWhat if we try to access `store.location.address` but `store.location`\ndoesn't exist?\n\n```\ninput(type=\"text\" id=\"address\" name=\"location[address]\" value=store.location.address)\n```\n\n\n\n16 - Geocoding Data with Google Maps\n====================================\n\n17 - Quick Data Visualization Tip\n=================================\n\n18 - Uploading and Resizing Images with Middleware\n==================================================\n\n19 - Routing and Templating Single Stores\n=========================================\n\n20 - Using Pre-Save hooks to make Unique Slugs\n==============================================\n\n21 - Custom MongoDB Aggregations\n================================\n\n22 - Multiple Query Promises with Async Await\n=============================================\n\n\n\n\nHints for creating the whole thing from scratch\n===============================================\n\n- run ``npm init`` to create a ``package.json``\n- create a route and a minimal start.js\n\nGet rid of MongoDB warnings\n---------------------------\n\n```\nDeprecationWarning: current URL string parser is deprecated, and will be removed in a future version. To use the new parser, pass option { useNewUrlParser: true } to MongoClient.connect.\n\nDeprecationWarning: current Server Discovery and Monitoring engine is deprecated, and will be removed in a future version. To use the new Server Discover and Monitoring engine, pass option { useUnifiedTopology: true } to the\n MongoClient constructor.\n```\n\n- can be avoided by setting\n\n```\nmongoose.connect(process.env.DATABASE, {\n  useNewUrlParser: true,\n  useUnifiedTopology: true\n});\n```\n\nHot reloading\n-------------\n\n- uneccessary bloat: we need `nodemon` to make this work, but neither `concurrently`\n  (adds 59 packages) or `webpack` (adds 178 packages) are needed\n\n\nSlug creation\n-------------\n\nIn Video 12, Wes claims that we need to combine store creation and saving into\n``const store = await (new Store(req.body)).save()`` in order to make\n`store.slug` available. This is not true. It will just work the way it was:\n\n```\nexports.createStore = async (req, res) => {\n    const store = new Store(req.body);\n    await store.save();\n\n    req.flash('success', `Successfully Created ${store.name}. Care to leave a review?`);\n    // redirect to the page of the store we just created\n    res.redirect(`/store/${store.slug}`);\n};\n```\n\n"}
{"url": "https://github.com/arne-cl/lingconv", "owner": "arne-cl", "repository_name": "lingconv", "date_all_variable_collection": "2023-09-11", "description": "a bunch of linguistic converter scripts", "size": 292, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 14725}, {"language": "Shell", "num_chars": 1477}], "readme": "lingconv\n========\n\na bunch of linguistic preprocessing scripts to\n\n* convert CoNLL 2009 format into CoNLL-X format\n* convert one-word-per-line tokenized files into CoNLL 2009 (e.g. to parse them with [mate-tools](https://code.google.com/p/mate-tools/))\n* convert one-word-per-line tokenized files to one-sentence-per-line format\n* convert the Tiger treebank into CoNLL-X format\n* convert the Tiger treebank into plain text files\n* convert tokenized (whitespace separated) text into one-word-per-line output\n* convert TreeTagger output files into CoNLL-X format\n* parse a pre-tokenized file with [TurboParser](http://www.ark.cs.cmu.edu/TurboParser/) (and the German language model trained on the Tiger corpus)\n"}
{"url": "https://github.com/arne-cl/nlgserv", "owner": "arne-cl", "repository_name": "nlgserv", "date_all_variable_collection": "2023-09-11", "description": "A lightweight JSON wrapper for simplenlg", "size": 25980, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 20, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 20, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "mnestis", "contributions": 48}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": true, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 163210}], "readme": "nlgserv is a simple server that accepts JSON representations of sentences and generated English sentences from those.\n\nIt uses SimpleNLG (under the [MPL 2.0 licence](https://www.mozilla.org/MPL/)) available [on code.google.com](https://code.google.com/p/simplenlg/) for natural language generation.\n\nIn order to use SimpleNLG (which is implemented in Java), [Jython 2.7beta3](http://www.jython.org) is also bundled, under the terms of the [PSF v.2](http://www.jython.org/license.html).\n\nAdditionally, it uses Bottle v0.12.7 (under the [MIT licence](https://github.com/defnull/bottle/blob/0.12.7/LICENSE) available [on github.com](https://github.com/defnull/bottle/tree/0.12.7) for handling HTTP requests.\n\nBuild status\n------------\n\n[![Build Status](https://travis-ci.org/mnestis/nlgserv.svg?branch=master)](https://travis-ci.org/mnestis/nlgserv)\n[![Latest Version](https://pypip.in/version/nlgserv/badge.png)](https://pypi.python.org/pypi/nlgserv/)"}
{"url": "https://github.com/arne-cl/nltk-maxent-pos-tagger", "owner": "arne-cl", "repository_name": "nltk-maxent-pos-tagger", "date_all_variable_collection": "2023-09-11", "description": "maximum entropy based part-of-speech tagger for NLTK", "size": 13, "stargazers_count": 46, "watchers_count": 46, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 21, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 21, "open_issues": 1, "watchers": 46, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 7}, {"contributor": "mrdrozdov", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["maximum-entropy", "nltk", "pos", "pos-tagger"], "languages": [{"language": "Python", "num_chars": 20125}], "readme": "nltk-maxent-pos-tagger\n======================\n\n`nltk-maxent-pos-tagger` is a part-of-speech (POS) tagger based on Maximum\nEntropy (ME) principles written for [NLTK](http://nltk.org/ \"Python's Natural Language Toolkit\").\nIt is based on NLTK's Maximum Entropy classifier\n(`nltk.classify.maxent.MaxentClassifier`), which uses\n[MEGAM](http://hal3.name/megam \"Hal Daume's MEGA Model Optimization Package\") for number\ncrunching.\n\nPart-of-Speech Tagging\n----------------------\n\n`nltk-maxent-pos-tagger` uses the set of features proposed by \n[Ratnaparki (1996)](http://www.aclweb.org/anthology-new/W/W96/W96-0213.pdf \n\"A Maximum Entropy Model for Part-of-Speech Tagging\"), which are also used \nin his [MXPOST](ftp://ftp.cis.upenn.edu/pub/adwait/jmx/) implementation (Java).\n\n\nInstallation\n------------\n\n1.  Install Python and NLTK.\n\nNLTK offers lots of data sets, which you might download and install from within\na Python shell:\n\n    import nltk\n    nltk.download()\n\nDownload at least `brown` or `treebank`, as nltk-maxent-pos-tagger uses them\nfor its `demo()` function.\n\n2. (Mac) Install MEGAM.\n\nOn Mac, it is easy to install MEGAM using brew:\n\n    brew tap homebrew/science\n    brew install megam\n\nUsage\n-----\n\nHave a look at the example given in the `demo()` function in `mxpost.py`.\nBasically, you just have to import the tagger and train it with labelled data\nto use it:\n\n    import mxpost\n    maxent_tagger = mxpost.MaxentPosTagger()\n    maxent_tagger.train(tagged_training_sentences)\n\n    for sentence in unlabeled_sentences:\n        maxent_tagger.tag(sentence)\n\n\nMeta\n----\n\nStatus: Beta. I wrote this in 2008 as a semester project for a class on NLP tools.  \nLicence: GPL Version 3  \nOriginal Author: Arne Neumann  \nContributors: Arne Neumann, Andrew Drozdov\n\n\nTODO\n----\n\n1.   *speed / memory consumption*   \n     As you can expect, a Python implementation is much slower and consumes\n     much more RAM than similar tools written in Java or C/C++ (MXPOST,\n     acopost, C&C etc.). This being said, most of the time isn't spend in\n     Python but rather in MEGAM (which is written in O'Caml and therefore\n     shouldn't have such issues).  NLTK currently is only able to encode POS\n     features explicitly when converting data for MEGAM. According to the MEGAM\n     website, using implicit feature encoding should be much faster.\n    \n2.  *accuracy*  \n    I trained several taggers on the WSJ corpus (90% training / 10% test data).\n    nltk-maxent-pos-tagger achieved an accuracy of 93.64% (100 iterations, rare\n    feature cutoff = 5) while MXPOST reached 96.93% (100 iterations). Since\n    both implementations use the same feature set, results shouldn't be that\n    different.  Unfortunately, there's no source code available for `MXPOST`,\n    but comparing `nltk-maxent-pos-tagger` with OpenNLP's implementation should\n    be helpful.  \n\n"}
{"url": "https://github.com/arne-cl/pandas-gotchas", "owner": "arne-cl", "repository_name": "pandas-gotchas", "date_all_variable_collection": "2023-09-11", "description": "List of gotchas in Pandas (the Python data analysis library).", "size": 8, "stargazers_count": 2, "watchers_count": 2, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["list", "pandas", "python"], "languages": [], "readme": "# pandas-gotchas\n\nThis is a list of gotchas I found in [Pandas](https://pandas.pydata.org/) (the Python data analysis library).\n\n## grouping / aggregation\n\n- [Dropping nuisance columns in groupby is a nuisance #21664](https://github.com/pandas-dev/pandas/issues/21664)\n  - Pandas silently drops a column if the chosen aggregation method doesn't work on it.\n- [pandas GroupBy columns with NaN (missing) values](https://stackoverflow.com/questions/18429491/pandas-groupby-columns-with-nan-missing-values)\n  - Pandas silently drops rows when grouping by a column that contains `NaN`.\n  - You can avoid this behaviour by using .`groupby(..., dropna=False)`.\n  \n## membership in series\n\n- [How to determine whether a Pandas Column contains a particular value](https://stackoverflow.com/questions/21319929/how-to-determine-whether-a-pandas-column-contains-a-particular-value)\n  - `x in series` tells you if `x` is in the `index` of `series`\n  - use `x in series.values` to check if `x` is in the actual `series`\n\n## filter series / column by substring\n\nTo check which elements of a column start with the prefix `field_`,  \nrun `df.my_column.str.startswith('field_')`. To avoid the error  \n`ValueError: Cannot mask with non-boolean array containing NA / NaN values`,  \nsimply add `na=False` (which will ignore NA values):\n\n```\ndf.my_column.str.startswith('field_', na=False)\n```\n\n## joining / merging\n\n- [values in a Pandas index column **do not have to be unique**](https://stackoverflow.com/questions/20199129/pandas-get-duplicated-indexes/52449411) (unlike values in a PRIMARY_KEY column in SQL)\n  - If you do a LEFT JOIN on two tables, you expect the result to have as many rows as the left table.\n  - In Pandas, for a `.join()` or `.merge()` to work the same way, you have to remove duplicate rows,\n    e.g. by calling `df_right.drop_duplicates()` before `pd.merge(df_left, df_right, on='common_column_name', how='left')`.\n\n# See also\n\n[Prabhant Sing. Gotchas of Pandas (Pydata Delhi).](https://github.com/prabhant/Talk-Pandas-Gotchas/blob/master/Pandas%20Gotchas.ipynb)\n"}
{"url": "https://github.com/arne-cl/ppi_graphkernel", "owner": "arne-cl", "repository_name": "ppi_graphkernel", "date_all_variable_collection": "2023-09-11", "description": "all-paths graph kernel for protein-protein interaction extraction", "size": 4520, "stargazers_count": 12, "watchers_count": 12, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 4, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 4, "open_issues": 0, "watchers": 12, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 27}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["graph-kernel", "natural-language-processing", "nlp", "ppi", "protein-protein-interaction", "python"], "languages": [{"language": "Python", "num_chars": 114059}], "readme": "PPI-learning with all-dependency-paths kernel\n=============================================\n\nThis is my \"fork\" of the graph kernel implemented in Python by\nAirola et al. (2008), which is described\n`on their website <http://mars.cs.utu.fi/PPICorpora/GraphKernel.html>`_.\nMy intention for playing with the original code is to understand graph kernels\non dependency graphs better.\n\nSo far, I have made the following changes:\n\n- structured the codebase into a package `ppi_graphkernels` and subpackages\n- added a setup.py to install the package system-wide with dependencies\n- added documentation to some methods/functions\n- replaced some JAVAisms with more 'pythonic' code\n\nThe rest of this document contains the original README (converted to\nrestructuredText).\n\n\nSOFTWARE FOR PPI-EXTRACTION WITH GRAPH KERNELS\n----------------------------------------------\n\nThis package contains an implementation of the all-dependency-paths graph kernel\ndescribed in the paper \"A Graph Kernel for Protein-Protein Interaction\nExtraction\", presented at the ACL 2008 BioNLP Workshop. In addition, many of the\nscripts used in experiments done with the kernel are provided, including software\nfor preprocessing the data, an implementation of the Sparse RLS learning\nalgorithm, and software for doing efficient cross-validation using the algorithm.\n\nThe graph kernel is based on calculating the similarities of dependency graph\nrepresentations of sentences. Thus prior to running the system you should parse\nyour sentences with a parser capable of supplying such analysis, and supply\nthis infomation in the xml format used by the system. The system has been\ndeveloped based on the collapsed Stanford format.\n\nThe analysis xml format that the graph kernel software processes is derived from\nthe xml format used for the transformations introduced in the paper \"Comparative\nAnalysis of Five Protein-protein Interaction Corpora\" presented at the LBM07\nconference. The transformation software for five publicly available corpora is\navailable at\n\nhttp://mars.cs.utu.fi/PPICorpora/\n\nThese are the same corpora for which the test results for the graph-kernel are\nreported for. The fold-split used when cross-validating on the full corpora\nis also provided. \n\nNote that many of the scripts assume that the input and output files are compressed\nin the gzip format.\n\nThis is research software, provided as is without express or implied warranties\netc. see licence.txt for more details. We have tried to make it reasonably usable and\nprovided help options, but adapting the system to new environments or transforming\na corpus to the format used by the system may require significant effort. \nContact us in case of having problems or requiring further information about the\nexperimental procedure used when testing the kernel.\n\nQUICKSTART\n----------\n\nNote that most of the scripts used here have -h (help) option you can use\nto check available options.\n\nExample files, such as the binarized version of the BioInfer corpus are provided in\nthe xml format processed by the system. To train a system on a file CORPUS.XML, which\ncontains a parse produced by MYPARSER and a tokenization produced by MYTOKENIZER,\nproceed as follows (in the example file MYPARSER = split_parse and\nMYTOKENIZER = split).\n\nScript named ConvertCorpus.py can be used to transform the xml format used\nin the aforementioned LBM07 paper to the format used by the graph kernel\nsoftware. The resulting file will still need parses and tokenizations.\nOnce they are in the script HyphenSplitter.py can be used to modify the\ntokenization and parse so that tokens such as \"actin-binding\" are split in\ntwo, so that words such as \"binding\" in this case will not be blinded when protein\nnames are blinded.\n\nFirst, build a dictionary that maps the possible features to a running indexing.\n\n::\n\n    python BuildDictionaryMapping.py -i CORPUS.XML.gz -p MYPARSER -t MYTOKENIZER\n    -o dictionary.txt.gz\n\nSecond, compute the graph kernels for your data, producing a linearized feature\nrepresentation corresponding to the graph kernels.\n\n::\n\n    python LinearizeAnalysis.py -i CORPUS.XML.gz -o LinearCorpus.gz -p MYPARSER\n    -t MYTOKENIZER\n\nThe software can be run in two modes, which affect how the G matrix is\nconstructed. \"-m max\" is the default option which corresponds to how\n\n\nShould you wish to convert a data file containing separate test\ndata, linearize it using the dictionary produced from the training\ndata. Still, there is no harm in creating the dictionary from a file that\ncontains both the training and test data, the features that appear only in\nthe test data will not affect the learned hypothesis for the RLS learner.\nThus for cross-validation the dictionary doesn't have to be reformed for\neach split.\n\nThird, you can normalize the data vectors to unit length. Sometimes this\ncan boost the results, sometimes it makes them worse.\n\n::\n\n    python NormalizeData.py -i LinearCorpus.gz -o NormalizedCorpus.gz\n\nFrom now on, let us assume that you have created two data files linearized\nusing a dictionary created from the training data. One of them is the\nTRAIN_SET, and one the TEST_SET.\n\nTo choose optimal parameters (according to F-score), you can do leave-one\ndocument-out cross-validation on the TRAIN_SET.\n\n::\n\n    python CrossValidate.py -i TRAIN_SET -o CV_predictions.o -p Parameters.p\n    -r -10_10 -b 500\n\nThis command will run cross-validation on the sparse RLS algorithm using\n500 basis vectors (or less, if your data set is smaller that that).\nThe predictions for each data point are written to CV_predictions.o\nfile, and the F-score results with different parameter values to file\nParameters.p. The serached grid for the regularization parameter is\nin this example 2^-10 ... 2^10.\n\nTo build a model using these learned parameters you can run\n\n::\n\n    python TrainLinearized.py -i TRAIN_SET -p Parameters.p -b 500\n    -o Model.m\n\nAlternatively you can supply the value of the regularization\nparemeter directly with the r -option.\n\nTo make predictions with this model run\n\n::\n\n    python TestLinearized.py -i TEST_SET -m Model.m -o Predictions\n\nWhen calculating the performance, use the threshold selected\nin cross-validation, if your performance metric needs such a\nthing. Separating the classes at zero can produce quite bad results.\nBe aware that selecting the threshold on the training data can\nalso fail, if the \"identically distributed\" assumption does not\nhold between the training and test data.\n"}
{"url": "https://github.com/Askir/bachelor-thesis-template", "owner": "Askir", "repository_name": "bachelor-thesis-template", "date_all_variable_collection": "2023-09-11", "description": "A simple latex template for bachelor theses", "size": 314, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Askir", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 20697}], "readme": "# Readme plz\n## Getting Started\n1. Clone this repository. Or check it out and change the origin to your personal github repository.\n2. To get started with latex checkout the generated pdf file in the root folder.  \n3. After that add your configuration in `content_extra/properties`.\n4. The root file is `bachelor_thesis_template.tex`. Get somewhat comfortable with how that one works.\n5. Then you can start writing your content in the folder `content/`.\n\n## Furter Reading\nIf you need more guidance on Latex (and trust me you will). The [Overleaf wiki pages](https://www.overleaf.com/learn) are pretty decent most of the time. Otherwise the [Wikibooks latex wiki](https://en.wikibooks.org/wiki/LaTeX) is pretty useful as well.\n\n## Questions?\nIf you have any questions feel free to ask me. But please have read the initial pdf first :P"}
{"url": "https://github.com/Askir/earthquakerice", "owner": "Askir", "repository_name": "earthquakerice", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1831, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 23, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 23, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "Askir", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 11644}, {"language": "CSS", "num_chars": 1699}, {"language": "HTML", "num_chars": 1662}], "readme": "This project was bootstrapped with [Create React App](https://github.com/facebook/create-react-app).\n\nAnd is deployed via github pages at https://askir.github.io/earthquakerice.\n\n## Features\n\nThe application shows a map of all earthquakes in the last 24 hours. The data is loaded via the API from https://earthquake.usgs.gov/ and displayed on a custom google map. Eartquakes with a higher magnitude are displayed with larger circles on the map.\n\nIn addition all earthquakes are also listed below the map with exact magnitude, location and time of occurence.\n\n\nIf you want to check the code out run: `git clone https://github.com/Askir/earthquakerice.git`.\n\n## Available Scripts\n\nIn the project directory, you can run:\n\n### `yarn start`\n\nRuns the app in the development mode.<br />\nOpen [http://localhost:3000](http://localhost:3000) to view it in the browser.\n\nThe page will reload if you make edits.<br />\nYou will also see any lint errors in the console.\n\n### `yarn test`\n\nLaunches the test runner in the interactive watch mode.<br />\n**Note: This project is currently partially untested as React testing seems to have some intricacies. And I didn't have the time to get into it yet.**\n\n### `yarn build`\n\nBuilds the app for production to the `build` folder.<br />\nIt correctly bundles React in production mode and optimizes the build for the best performance.\n\nThe build is minified and the filenames include the hashes.<br />\nYour app is ready to be deployed!\n\nSee the section about [deployment](https://facebook.github.io/create-react-app/docs/deployment) for more information."}
{"url": "https://github.com/Askir/ecplise-cdt", "owner": "Askir", "repository_name": "ecplise-cdt", "date_all_variable_collection": "2023-09-11", "description": null, "size": 187733, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "sprigogin", "contributions": 3002}, {"contributor": "mikhailkhod", "contributions": 1439}, {"contributor": "angvoz", "contributions": 1434}, {"contributor": "elaskavaia", "contributions": 676}, {"contributor": "vivkong", "contributions": 655}, {"contributor": "HighCommander4", "contributions": 633}, {"contributor": "sukidog", "contributions": 603}, {"contributor": "aniefer", "contributions": 580}, {"contributor": "jonahgraham", "contributions": 321}, {"contributor": "MarkZ3", "contributions": 284}, {"contributor": "crecoskie", "contributions": 238}, {"contributor": "teddotnet", "contributions": 218}, {"contributor": "bogg", "contributions": 203}, {"contributor": "jamesblackburn", "contributions": 186}, {"contributor": "treggiari", "contributions": 180}, {"contributor": "jjohnstn", "contributions": 176}, {"contributor": "RandyRohrbach", "contributions": 158}, {"contributor": "akurtakov", "contributions": 115}, {"contributor": "marcdumais-work", "contributions": 77}, {"contributor": "simark", "contributions": 75}, {"contributor": "norbert-p", "contributions": 51}, {"contributor": "dschaefer", "contributions": 48}, {"contributor": "fchouinard", "contributions": 38}, {"contributor": "jld01", "contributions": 29}, {"contributor": "pchuong", "contributions": 29}, {"contributor": "havogt", "contributions": 28}, {"contributor": "Kummallinen", "contributions": 26}, {"contributor": "alexruiz", "contributions": 18}, {"contributor": "alblue", "contributions": 13}, {"contributor": "sergebeauchamp", "contributions": 12}, {"contributor": "ManishKhurana11", "contributions": 11}, {"contributor": "Torbjorn-Svensson", "contributions": 10}, {"contributor": "eugeneo", "contributions": 9}, {"contributor": "mhussein", "contributions": 9}, {"contributor": "ruspl-afed", "contributions": 8}, {"contributor": "cwalther", "contributions": 8}, {"contributor": "felu", "contributions": 8}, {"contributor": "vprus", "contributions": 8}, {"contributor": "XavierRaynaud", "contributions": 8}, {"contributor": "bbelyavsky-ti", "contributions": 8}, {"contributor": "mbooth101", "contributions": 7}, {"contributor": "trancexpress", "contributions": 7}, {"contributor": "jarrah42", "contributions": 6}, {"contributor": "stepavich", "contributions": 6}, {"contributor": "iulia-vasii", "contributions": 5}, {"contributor": "slhultgren", "contributions": 5}, {"contributor": "brgirgis", "contributions": 4}, {"contributor": "ChinHuatAng", "contributions": 4}, {"contributor": "dmitry-d-kozlov", "contributions": 4}, {"contributor": "ilg-ul", "contributions": 4}, {"contributor": "MatthewKhouzam", "contributions": 4}, {"contributor": "PierreSachot", "contributions": 4}, {"contributor": "rgdoliveira", "contributions": 4}, {"contributor": "sba1", "contributions": 4}, {"contributor": "teodormadan", "contributions": 4}, {"contributor": "Kos", "contributions": 4}, {"contributor": "umairsair", "contributions": 4}, {"contributor": "vlad-ivanov-name", "contributions": 4}, {"contributor": "cartu38", "contributions": 4}, {"contributor": "ravithejaintel", "contributions": 4}, {"contributor": "romibi", "contributions": 4}, {"contributor": "dannyferreira", "contributions": 3}, {"contributor": "srcejon", "contributions": 3}, {"contributor": "kolipakakondal", "contributions": 3}, {"contributor": "mishila", "contributions": 3}, {"contributor": "rudolfovic", "contributions": 3}, {"contributor": "T-Svensson", "contributions": 3}, {"contributor": "waqasilyas", "contributions": 3}, {"contributor": "maestrosoft", "contributions": 3}, {"contributor": "iloveeclipse", "contributions": 2}, {"contributor": "belkassaby", "contributions": 2}, {"contributor": "bruno-medeiros", "contributions": 2}, {"contributor": "davmac314", "contributions": 2}, {"contributor": "ifurnadjiev", "contributions": 2}, {"contributor": "eblen", "contributions": 2}, {"contributor": "JosephDHenry", "contributions": 2}, {"contributor": "mario-pi", "contributions": 2}, {"contributor": "Bananeweizen", "contributions": 2}, {"contributor": "MortenKristiansen", "contributions": 2}, {"contributor": "planger", "contributions": 2}, {"contributor": "rgrunber", "contributions": 2}, {"contributor": "culcasis", "contributions": 2}, {"contributor": "sflynn-dell", "contributions": 2}, {"contributor": "devtoolsInge", "contributions": 2}, {"contributor": "abeerbagul", "contributions": 2}, {"contributor": "bradchiu", "contributions": 2}, {"contributor": "aleem-rehman", "contributions": 1}, {"contributor": "AlissonLinhares", "contributions": 1}, {"contributor": "majic79", "contributions": 1}, {"contributor": "bergstr11", "contributions": 1}, {"contributor": "cleitner", "contributions": 1}, {"contributor": "dai-github", "contributions": 1}, {"contributor": "dayson", "contributions": 1}, {"contributor": "ddscharfe", "contributions": 1}, {"contributor": "eldosrado", "contributions": 1}, {"contributor": "ewoest", "contributions": 1}, {"contributor": "fabrizioiannetti", "contributions": 1}, {"contributor": "iannetti-intel", "contributions": 1}, {"contributor": "copelnug", "contributions": 1}, {"contributor": "GaetanoSanST", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 60030244}, {"language": "HTML", "num_chars": 2580933}, {"language": "JavaScript", "num_chars": 435220}, {"language": "Makefile", "num_chars": 171857}, {"language": "C", "num_chars": 153844}, {"language": "G-code", "num_chars": 149012}, {"language": "C++", "num_chars": 144688}, {"language": "Assembly", "num_chars": 23839}, {"language": "GAP", "num_chars": 21236}, {"language": "Shell", "num_chars": 17103}, {"language": "CSS", "num_chars": 16591}, {"language": "XSLT", "num_chars": 1918}, {"language": "QML", "num_chars": 930}, {"language": "Batchfile", "num_chars": 889}, {"language": "M4", "num_chars": 615}, {"language": "Fortran", "num_chars": 570}, {"language": "Python", "num_chars": 414}, {"language": "QMake", "num_chars": 333}, {"language": "CMake", "num_chars": 114}, {"language": "Meson", "num_chars": 81}]}
{"url": "https://github.com/Askir/elija-rails", "owner": "Askir", "repository_name": "elija-rails", "date_all_variable_collection": "2023-09-11", "description": null, "size": 5058, "stargazers_count": 1, "watchers_count": 1, "language": "Ruby", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "Askir", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Ruby", "num_chars": 25444}, {"language": "HTML", "num_chars": 242}], "readme": "# README\n\nThis README would normally document whatever steps are necessary to get the\napplication up and running.\n\nThings you may want to cover:\n\n* Ruby version\n\n* System dependencies\n\n* Configuration\n\n* Database creation\n\n* Database initialization\n\n* How to run the test suite\n\n* Services (job queues, cache servers, search engines, etc.)\n\n* Deployment instructions\n\n* ...\n"}
{"url": "https://github.com/Askir/pt2-uebungen", "owner": "Askir", "repository_name": "pt2-uebungen", "date_all_variable_collection": "2023-09-11", "description": "meine pt2 uebungen", "size": 2, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Askir", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 3427}]}
{"url": "https://github.com/Askir/Texas-Holdem-Android", "owner": "Askir", "repository_name": "Texas-Holdem-Android", "date_all_variable_collection": "2023-09-11", "description": null, "size": 9086, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Askir", "contributions": 90}, {"contributor": "MarcelHofi", "contributions": 61}, {"contributor": "R4NGGOD", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 134795}]}
{"url": "https://github.com/Askir/tourneytuesday", "owner": "Askir", "repository_name": "tourneytuesday", "date_all_variable_collection": "2023-09-11", "description": "A small Vue App with express backend for Lancemenots tournament tuesday", "size": 434, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 20503}, {"language": "Vue", "num_chars": 17496}, {"language": "HTML", "num_chars": 689}]}
{"url": "https://github.com/Askir/Wiiteboard", "owner": "Askir", "repository_name": "Wiiteboard", "date_all_variable_collection": "2023-09-11", "description": null, "size": 13180, "stargazers_count": 1, "watchers_count": 1, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "Askir", "contributions": 13}, {"contributor": "Funnyach", "contributions": 2}, {"contributor": "CutyCupy", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 276502}, {"language": "C", "num_chars": 2411}], "readme": "========================================================================\n    CONSOLE APPLICATION : Wiiteboard Project Overview\n========================================================================\n\nAppWizard has created this Wiiteboard application for you.\n\nThis file contains a summary of what you will find in each of the files that\nmake up your Wiiteboard application.\n\n\nWiiteboard.vcxproj\n    This is the main project file for VC++ projects generated using an Application Wizard.\n    It contains information about the version of Visual C++ that generated the file, and\n    information about the platforms, configurations, and project features selected with the\n    Application Wizard.\n\nWiiteboard.vcxproj.filters\n    This is the filters file for VC++ projects generated using an Application Wizard. \n    It contains information about the association between the files in your project \n    and the filters. This association is used in the IDE to show grouping of files with\n    similar extensions under a specific node (for e.g. \".cpp\" files are associated with the\n    \"Source Files\" filter).\n\nWiiteboard.cpp\n    This is the main application source file.\n\n/////////////////////////////////////////////////////////////////////////////\nOther standard files:\n\nStdAfx.h, StdAfx.cpp\n    These files are used to build a precompiled header (PCH) file\n    named Wiiteboard.pch and a precompiled types file named StdAfx.obj.\n\n/////////////////////////////////////////////////////////////////////////////\nOther notes:\n\nAppWizard uses \"TODO:\" comments to indicate parts of the source code you\nshould add to or customize.\n\n/////////////////////////////////////////////////////////////////////////////\n"}
{"url": "https://github.com/AvitBhowmik/ATRIC", "owner": "AvitBhowmik", "repository_name": "ATRIC", "date_all_variable_collection": "2023-09-11", "description": "ATRIC: automated Accumulation Threshold selection and RIparian Corridor delineation", "size": 60352, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Creative Commons Zero v1.0 Universal", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "AvitBhowmik", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 34645}], "readme": "## ATRIC ##\n\nAutomated Accumulation Threshold selection and RIparian Corridor delineation (ATRIC) is a combination of two algorithms that allows for automated accumulation threshold selection for stream network extraction, and watershed and riparian corridor delineation for given points on streams, from digital elevation models. It is also useful for quantification of stressors such as land use and climate change components, pollutants, insecticide and pesticide runoff within the watersheds and upstream riparian zones of stream sampling points, where stream communities, e.g. macroinvertebrates are sampled. ATRIC is the first open source tool of its kind, the algorithms are developed by co-interfacing R and GRASS GIS.\n\nFor details on ATRIC, please read the published paper: http://www.sciencedirect.com/science/article/pii/S1364815214003077 (copies available upon request).\n\n\n## Note for users ##\n\nYou need to have the latest version of R and GRASS GIS version 6.4 installed in your computer. Details on how to initiate GRASS GIS from R interface for different operating systems are available in the commented R script \"ATRIC_script.R\". Note that a new stable version of GRASS GIS (7.0) is now available where parameter names for some modules have been changed. Consequently, the script might not work if you install or update your GRASS GIS 6.4 with GRASS GIS 7.0. I will release a script for GRASS GIS 7.0 soon.\n\nCurrently ATRIC works only with the projected spatial coordinate system (you will get errors if you use geographic coordinates, e.g. WGS 1984) with 'meter' unit, e.g. DHDN Gauss Krueger. I will also adapt the script for geographic coordinates.\n\n## Reproduce results of the paper ##\n\nIf you would like to reproduce our results in the paper or just would like to get familiar with the functionalities of ATRIC, download the \"ATRIC_Data.zip\" and run the script.  \n\n\n"}
{"url": "https://github.com/AvitBhowmik/avitbhowmik", "owner": "AvitBhowmik", "repository_name": "avitbhowmik", "date_all_variable_collection": "2023-09-11", "description": "Official website for Avit Bhowmik", "size": 101405, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "gh-pages", "contributors": [{"contributor": "AvitBhowmik", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 1328195}, {"language": "TeX", "num_chars": 220754}, {"language": "SCSS", "num_chars": 128650}, {"language": "JavaScript", "num_chars": 13467}, {"language": "Ruby", "num_chars": 2858}], "readme": "# Barber\nBarber is a minimal blog theme built for Jekyll. The blog theme features a masonry grid, endless scrolling, and page transitions. \ud83d\udc88 Barber is also available for [Ghost](https://github.com/samesies/barber-ghost).\n\n![Barber](https://raw.githubusercontent.com/samesies/barber-jekyll/master/barber.jpg \"Barber\")\n\n## Initial Setup\n* [Installation](#installation)\n* [Update Settings](#update-settings)\n* [Create Posts](#create-posts)\n* [Create Pages](#create-pages)\n* [Create Navigation](#create-navigation)\n\n## Customization\n* [Contact Form](#contact-form)\n* [Social Media Links](#social-media-links)\n* [Disqus Comments](#disqus-comments)\n\n## Additional Development\n* [Deployment](#deployment)\n* [Source Code](#source-code)\n* [Donations](#donations)\n* [Support](#support)\n\n### Installation\nJekyll requires all dependencies to be saved in the ````Gemfile````. Run ````bundle install```` (Install [Bundler](http://bundler.io/) if it is not already) on your command line after downloading or cloning the theme. You can then run ````bundle exec jekyll serve```` or ````npm start```` to see your development site. Run ````bundle exec jekyll build```` or ````npm run build```` to build a production ready site for deployment.\n\n### Update Settings\nAlmost everything to personalize your site is in the ````_config.yml````. \n\n```\n# Site/SEO settings\nemail: okay@samesies.io\nbaseurl: \"\"\npermalink: /:year/:month/:day/:title/\ngoogle_analytics: \n\nname: Thomas Vaeth\ntitle: The Barber Theme\ndescription: >\n  Barber is a blog theme for Jekyll built by Thomas Vaeth for Samesies using HTML, Sass, and JavaScript.\nurl: http://barber.samesies.io\ntwitter_username: thomasvaeth\ndefault_img: /assets/images/seo.jpg\nsocial:\n  - name: twitter\n    url: https://twitter.com/thomasvaeth\n  - name: instagram\n    url: https://www.instagram.com/thomas.vaeth/\n  - name: linkedin\n    url: https://www.linkedin.com/in/thomasvaeth/\n  - name: github\n    url: https://github.com/samesies\n  - name: codepen\n    url: https://codepen.io/thomasvaeth/\n\n# Contact settings\ncontact_img: /assets/images/placeholder-28.jpg\nformcarry: https://formcarry.com/s/HkIo0nMb7\n\n# Disqus settings\ndisqus: test-apkdzgmqhj\n\n# MailChimp settings\nmailchimp_action: https://samesies.us17.list-manage.com/subscribe/post-json?u=66ddf555dab480e6a8606430b&amp;id=89b3ee034f\nmailchimp_input: b_66ddf555dab480e6a8606430b_89b3ee034f\n\n# Author settings\nauthor:\n  - name: Thomas Vaeth\n    bio: Thomas Vaeth was born in New York, raised in Pennsylvania, and transplanted in Washington. He was a Web Developer at Urban Influence, but now he's a Software Engineer at Getty Images.\n    url: http://thomasvaeth.com\n\n# Pagination settings\npagination:\n  enabled: true\n  debug: false\n  per_page: 12\n  permalink: '/page/:num/'\n  title: ':title'\n  limit: 0\n  sort_field: 'date'\n  sort_reverse: true\nautopages:\n  enabled: true\n  categories:\n    enabled: false\n  collections:\n    enabled: false\n  tags:\n    layouts: \n      - 'tag.html'\n    title: 'The Barber Theme'\n    permalink: '/tag/:tag'\n    slugify:\n      mode: raw\n      cased: true\n```\n\nYou can change the URL the [contact form](#contact-form) is sent to, add Google Analytics, change the SEO settings, grow your website with additional authors, and much more.\n\n### Create Posts\nAll posts go upder the ````_posts```` directory. You can also have a ````_drafts```` directory with posts that will on your development page, but not in production.\n\n```\n---\nlayout: post\ntitle: \"Brunch Swag\"\ndate: 2017-02-18\ndescription: \nimage: /assets/images/placeholder-15.jpg\nauthor: Thomas Vaeth\ntags: \n  - XOXO\n  - La Croix\n---\n```\n\nThe front matter has to have a layout of page. All the other fields are completely optional. If you have an ````author```` variable, then it must match an author's name in ````_config.yml```` (see [Update Settings](#update-settings)). The ````tag```` variable will add a related section to the post and popular tags to the footer.\n\n### Create Pages\nCreating a static page is the same as creating a post. The only difference is a page is in the root of the directory rather than the ````_posts```` directory.\n\n```\n---\nlayout: page\ntitle: Style Guide\nimage: /assets/images/placeholder-18.jpg\n---\n```\n\nYou just have to make sure the front matter has a layout of page instead of post. If there is no title or image, then the page will default to the site configuration.\n\n### Create Navigation\nYou can create a navigation in ````_includes/navigation.html````. Visitors can be linked directly to pages right on the top of your website.\n\n***\n\n### Contact Form\nThe form uses [Formcarry](https://formcarry.com/) to send submitted messages straight to your inbox. The image on the popup is the the ````contact_img```` variable and the URL the forms sends to is the ````formcarry```` variable in ````_config.yml```` (see [Update Settings](#update-settings)).\n\n![Contact Form](http://samesies.io/assets/images/barber/doc/framed-contact-form.jpg \"Contact Form\")\n\nThis file can be found in ````_includes/formscarry.html````. You can change the labels of the form here. After everything is set you will need to submit a message to yourself to confirm everything is correct.\n\n### Social Media Links\n[Font Awesome](http://fontawesome.io/) is used for the social media icons. The icons in the theme can be found in ````_includes/share.html```` and ````_includes/social.html````. The icons in ````_includes/share.html```` do not need to be edited unless you want to remove a certain website; however, the ones in ````_includes/social.html```` do have to be changed. You can follow the example that has been provided in ````_config.yml```` for you to link to all of your social media accounts  (see [Update Settings](#update-settings)). The naming convention has not changed from the instructions provided on Font Awesome.\n\n### Disqus Comments\nComments can be enabled on every blog post in a few steps steps. The first step is to register your website with [Disqus](https://disqus.com/). Disqus will provide you with a shortname that you need for the next step. Once you have that the second step is to replace the ````disqus```` variable in ````_config.yml```` (see [Update Settings](#update-settings)). The third step is to open ````_includes/disqus.html```` and remove all the instructions. The final step is to visit a blog post and verify that your comments are there.\n\n***\n\n### Deployment\nGitHub Pages [does not support]((https://help.github.com/articles/adding-jekyll-plugins-to-a-github-pages-site/)) custom plugins. The tag list and tag pagination are built using custom plugins. There are several options to avoid any errors while deploying to production.\n* Run ````bundle exec jekyll build```` or ````npm run build```` and manually add the contents of the ```_site``` folder to the ```gh-pages``` branch.\n* Link the repository to [Netlify](https://www.netlify.com/). Netlify will then rebuild the theme every time a commit is pushed to the repo.\n* Finish setting up the [s3-website](https://github.com/klaemo/s3-website) package that is already included in the theme. This would deploy the theme to AWS S3 when ```npm run deploy``` is run.\n\n### Source Code\nThe source code is broken down to make finding what you need as easy as possible. Almost everything runs through ````gulpfile.js````, so you will need to run ````npm install```` on your command line before doing any additional development. You can then run ````gulp```` or ````npm run gulp```` to compile everything.\n\n```\n.\n\u251c\u2500\u2500 _assets\n|   \u251c\u2500\u2500 js\n|       \u251c\u2500\u2500 components\n|       \u251c\u2500\u2500 vendor\n|       \u251c\u2500\u2500 _inits.js\n|       \u2514\u2500\u2500 app.js\n|   \u2514\u2500\u2500 scss\n|       \u251c\u2500\u2500 base\n|       \u251c\u2500\u2500 components\n|       \u251c\u2500\u2500 fonts\n|       \u251c\u2500\u2500 regions\n|       \u251c\u2500\u2500 tools\n|       \u251c\u2500\u2500 utils\n|       \u251c\u2500\u2500 vendor\n|       \u2514\u2500\u2500 app.scss\n\u251c\u2500\u2500 _includes\n|   \u251c\u2500\u2500 contact.html\n|   \u251c\u2500\u2500 disqus.html\n|   \u251c\u2500\u2500 footer.html\n|   \u251c\u2500\u2500 formcarry.html\n|   \u251c\u2500\u2500 head.html\n|   \u251c\u2500\u2500 header.html\n|   \u251c\u2500\u2500 navigation.html\n|   \u251c\u2500\u2500 pagination.html\n|   \u251c\u2500\u2500 post-card.html\n|   \u251c\u2500\u2500 share.html\n|   \u251c\u2500\u2500 social.html\n|   \u2514\u2500\u2500 subscribe_form.html\n\u251c\u2500\u2500 _layouts\n|   \u251c\u2500\u2500 compress.html\n|   \u251c\u2500\u2500 default.html\n|   \u251c\u2500\u2500 page.html\n|   \u251c\u2500\u2500 post.html\n|   \u2514\u2500\u2500 tag.html\n\u251c\u2500\u2500 _plugins\n\u251c\u2500\u2500 _posts\n\u251c\u2500\u2500 _site\n\u251c\u2500\u2500 assets\n|   \u251c\u2500\u2500 css\n|   \u251c\u2500\u2500 images\n|   \u251c\u2500\u2500 js\n\u251c\u2500\u2500 .eslintrc\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .stylelintrc\n\u251c\u2500\u2500 404.html\n\u251c\u2500\u2500 _config.yml\n\u251c\u2500\u2500 Gemfile\n\u251c\u2500\u2500 Gemfile.lock\n\u251c\u2500\u2500 gulpfile.js\n\u251c\u2500\u2500 index.html\n\u251c\u2500\u2500 package.json\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 style-guidle.html\n\u2514\u2500\u2500 subscribe.html\n```\n\nThe CSS is written in Sass. The JavaScript is written in ES6, so your code is up to date with the newest standards.\n\n### Donations\nBarber has been released for free. Similar themes cost around $29 on [ThemeForest](https://themeforest.net/category/static-site-generators/jekyll). Any donations would be greatly appreciated after the work that went into releasing Barber.\n\n* PayPal \u2013 <https://www.paypal.me/samesies>\n* Bitcoin \u2013 1PSzNmcfAFJY1PtBK5u9R5bTGfF7KAuLcq\n* Ethereum \u2013 0x392F7116e4171F1D740397B6000EadD2e4bb9670\n* Litecoin \u2013 LSH9AnjcUTV5T7PUxXQuxPqb9W5aSR9GEP\n\n### Support\nEmail <okay@samesies.io> if you need any additional support with Barber.\n"}
{"url": "https://github.com/AvitBhowmik/Countdown_to_Drawdown", "owner": "AvitBhowmik", "repository_name": "Countdown_to_Drawdown", "date_all_variable_collection": "2023-09-11", "description": null, "size": 93780, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "AvitBhowmik", "contributions": 536}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Countdown_to_Drawdown"}
{"url": "https://github.com/AvitBhowmik/gisapp17", "owner": "AvitBhowmik", "repository_name": "gisapp17", "date_all_variable_collection": "2023-09-11", "description": "This is the GitHub repository for the block course \"Geoinformation Systems (GIS) Application\" offered by the Institute for Environmental Sciences, University of Koblenz-Landau at the Winter Semester 2016/2017. Please scroll below to read the instructions.", "size": 28782, "stargazers_count": 1, "watchers_count": 1, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "AvitBhowmik", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["ecology", "geostatistics", "spatial-analysis", "spatial-statistics"], "languages": [{"language": "TeX", "num_chars": 18508}, {"language": "R", "num_chars": 4796}], "readme": "Course: Geoinformation Systems (GIS) Application\n--------------------------------\n\n* Date: Monday -- Tuesday, **March 20-21, 2017**\n* Time: **9.30 -- 16.30** \n* Location:  Building **E III**, room **PC-I** (in front of the Audimax).\n\n\n## Lecturer\n\n* [Dr. Avit K. Bhowmik](https://avitbhowmik.ml/)\n\n\n## Before we start\n\n### Install R\n\nYou may use the computers at PC-I, where R and necessary packages are already installed. However, I would encourage you to bring your own computers. If you don't already have R installed in your computers, please download and install it from [here](http://cran.rstudio.com/). \n\nYou can use the code editor of your choice. However, I recommend using [RStudio Desktop](http://www.rstudio.com/products/rstudio/download/).\n\n\n### Installing spatial packages\n\nPackages extend the basic functionality of R and add functions and datasets.\nFor this course we will need a few extra packages developed for spatial analyses. Please install the following packages - simply paste and run this command in your R prompt:\n\n```{R}\ninstall.packages(c(\"maptools\", \"raster\", \"rgeos\", \"moments\", \"gstat\"), \n                 dependencies = TRUE)\n```\n\n\n### Downloading course materials\n\n1. [Click here](https://github.com/AvitBhowmik/gisapp17/archive/master.zip) to download the course materials.\n2. Unzip the file - The unzipped folder contains all files and folders of this on-line repository.\n\n\n## Structure of the course\n\nThe course constitutes theoretical and practical parts. In the theoretical part, I will cover:\n\n* Introduction to Geographic Information Systems (GIS)\n* Introduction to Spatial Statistics and Spatial Interpolation \n* Application of spatial interpolation to ecotoxicological analyses\n\nIn the practical part, I will demonstrate the application of spatial interpolation for the prediction of heavy metal concentrations in groundwater of Bangladesh using R. Subsequently, I will show the process of ecotoxicological risk mapping by comparing the predicted concentrations with guideline values.\n\n\n## Participants' evaluation\n\nThe performance of the participants will be evaluated though [group projects](https://github.com/AvitBhowmik/gisapp17/tree/master/project). The projects and groups will be announced on Tuesday.\n\n\n## Course evaluation\n\nYou will receive a course evaluation form from the university. However, I would appreciate your feedback on my part of the course. You comments will help me to improve the course. Please use [this form](https://goo.gl/forms/8JDk97hKWsUWLQYx1) for your feedback. **Your feedback will remain anonymous**."}
{"url": "https://github.com/AvitBhowmik/gisapp18", "owner": "AvitBhowmik", "repository_name": "gisapp18", "date_all_variable_collection": "2023-09-11", "description": "This is the GitHub repository for the block course \"Geoinformation Systems (GIS) Application\" offered by the Institute for Environmental Sciences, University of Koblenz-Landau at the Winter Semester 2018. Please scroll below to read the instructions.", "size": 32260, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "AvitBhowmik", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["ecotoxicology", "geostatistics", "spatial-analysis", "spatial-data-analysis", "spatial-statistics"], "languages": [{"language": "TeX", "num_chars": 15274}, {"language": "R", "num_chars": 12137}], "readme": "Course: Geoinformation Systems (GIS) Application\n--------------------------------\n\n* Date: Thursday -- Friday, **March 15-16, 2018**\n* Time: **9.00 -- 16.00** \n* Location:  Building **E III**, room **PC-I** (in front of the Audimax).\n\n\n## Lecturer\n\n* [Dr. Avit K. Bhowmik](http://www.futureearth.org/avit-k-bhowmik)\n\n\n## Before we start\n\n### Install R\n\nYou may use the computers at PC-I, where R and necessary packages are already installed. However, I would encourage you to bring your own computers. If you don't already have R installed in your computers, please download and install it from [here](http://cran.rstudio.com/). \n\nYou can use the code editor of your choice. However, I recommend using [RStudio Desktop](http://www.rstudio.com/products/rstudio/download/).\n\n\n### Installing spatial packages\n\nPackages extend the basic functionality of R and add functions and datasets.\nFor this course we will need a few extra packages developed for spatial analyses. Please install the following packages - simply paste and run this command in your R prompt:\n\n```{R}\ninstall.packages(c(\"maptools\", \"raster\", \"rgeos\", \"moments\", \"gstat\"), \n                 dependencies = TRUE)\n```\n\n\n### Downloading course materials\n\n1. [Click here](https://github.com/AvitBhowmik/gisapp18/archive/master.zip) to download the course materials.\n2. Unzip the file - The unzipped folder contains all files and folders of this on-line repository.\n\n\n## Structure of the course\n\nThe course constitutes theoretical and practical parts. In the theoretical part, I will cover:\n\n* Introduction to Geographic Information Systems (GIS)\n* Introduction to Spatial Statistics and Spatial Interpolation \n* Application of spatial interpolation to ecotoxicological risk analyses\n\nIn the practical part, I will demonstrate the application of spatial interpolation for the prediction of heavy metal concentrations in groundwater of Bangladesh using R. Subsequently, I will show the process of ecotoxicological risk mapping by comparing the predicted concentrations with guideline values.\n\n\n## Participants' evaluation\n\nThe performance of the participants will be evaluated though a final examination and [group projects](https://github.com/AvitBhowmik/gisapp17/tree/master/project). The projects and groups will be announced on Thursday.\n\n\n## Course evaluation\n\nYou will receive a course evaluation form from the university. However, I would appreciate your feedback on my part of the course. You comments will help me to improve the course. Please use [this form](https://goo.gl/forms/8JDk97hKWsUWLQYx1) for your feedback. **Your feedback will remain anonymous**."}
{"url": "https://github.com/AvitBhowmik/GridClimNig", "owner": "AvitBhowmik", "repository_name": "GridClimNig", "date_all_variable_collection": "2023-09-11", "description": "Gridded climate datasets for Nigeria", "size": 255883, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "AvitBhowmik", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# GridClimNig\nGridded climate datasets for Nigeria\n"}
{"url": "https://github.com/AvitBhowmik/PhD_Defense_Slides_Bhowmik", "owner": "AvitBhowmik", "repository_name": "PhD_Defense_Slides_Bhowmik", "date_all_variable_collection": "2023-09-11", "description": "This repository contains the slides from my Ph.D. defense on December 2, 2015.", "size": 57568, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Creative Commons Zero v1.0 Universal", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "AvitBhowmik", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 39611}], "readme": "# Slides from my Ph.D. Defense\nThis repository contains the slides from my Ph.D. defense on December 2, 2015. The slides were created using Latex Beamer package and mtheme.\n\n## Human and Ecological Impacts of Freshwater Degradation on Large Scales. Development and Integration of Spatial Models with Ecological Models for Spatial-ecological Analyses\n\n### Summary\nIn the new epoch of Anthropocene, global freshwater resources are experiencing extensive degradation from a multitude of stressors. Consequently, freshwater ecosystems are threatened by a considerable loss of biodiversity as well as substantial decrease in adequate and secured freshwater supply for human usage, not only on local scales, but also on regional to global scales. Large scale assessments of human and ecological impacts of freshwater degradation enable an integrated freshwater management as well as complement small scale approaches. Geographic information systems (GIS) and spatial statistics (SS) have shown considerable potential in ecological and ecotoxicological research to quantify stressor impacts on humans and ecological entitles, and disentangle the relationships between drivers and ecological entities on large scales through an integrated spatial-ecological approach. However, integration of GIS and SS with ecological and ecotoxicological models are scarce and hence the large scale spatial picture of the extent and magnitude of freshwater stressors as well as their human and ecological impacts is still opaque. This Ph.D. thesis contributes novel GIS and SS tools as well as adapts and advances available spatial models and integrates them with ecological models to enable large scale human and ecological impacts identification from freshwater degradation. The main aim was to identify and quantify the effects of stressors, i.e climate change and trace metals, on the freshwater assemblage structure and trait composition, and human health, respectively, on large scales, i.e. European and Asian freshwater networks.\n\nThe thesis starts with an introduction to the conceptual framework and objectives (chapter 1). It proceeds with outlining two novel open-source algorithms for quantification of the magnitude and effects of catchment scale stressors (chapter 2). The algorithms, i.e. jointly called ATRIC, automatically select an accumulation threshold for stream network extraction from digital elevation models (DEM) by assuring the highest concordance between DEM-derived and traditionally mapped stream networks. Moreover, they delineate catchments and upstream riparian corridors for given stream sampling points after snapping them to the DEM-derived stream network. ATRIC showed similar or better performance than the available comparable algorithms, and is capable of processing large scale datasets. It enables an integrated and transboundary management of freshwater resources by quantifying the magnitude of effects of catchment scale stressors. Spatially shifting temporal points (SSTP), outlined in chapter 3, estimates pooled within-time series (PTS) variograms by spatializing temporal data points and shifting them. Data were pooled by ensuring consistency of spatial structure and temporal stationarity within a time series, while pooling sufficient number of data points and increasing data density for a reliable variogram estimation. SSTP estimated PTS variograms showed higher precision than the available method. The method enables regional scale stressors quantification by filling spatial data gaps integrating temporal information in data scarce regions. In chapter 4, responses of the assumed climate-associated traits from six grouping features to 35 bioclimatic indices for five insect orders were compared, their potential for changing distribution pattern under future climate change was evaluated and the most influential climatic aspects were identified (chapter 4). Traits of temperature preference grouping feature and the insect order Ephemeroptera exhibited the strongest response to climate as well as the highest potential for changing distribution pattern, while seasonal radiation and moisture were the most influential climatic aspects that may drive a change in insect distribution pattern. The results contribute to the trait based freshwater monitoring and change prediction. In chapter 5, the concentrations of 10 trace metals in the drinking water sources were predicted and were compared with guideline values. In more than 53% of the total area of Pakistan, inhabited by more than 74 million people, the drinking water was predicted to be at risk from multiple trace metal contamination. The results inform freshwater management by identifying potential hot spots. The last chapter (6) synthesizes the results and provides a comprehensive discussion on the four studies and on their relevance for freshwater resources conservation and management.\n"}
{"url": "https://github.com/AvitBhowmik/PhD_Dissertation_Bhowmik", "owner": "AvitBhowmik", "repository_name": "PhD_Dissertation_Bhowmik", "date_all_variable_collection": "2023-09-11", "description": "This repository contains my Ph.D. dissertation. The dissertation has been written and compiled using \"Maggi Memoir Thesis\" (http://www.latextemplates.com/template/maggi-memoir-thesis) template and XeLaTeX, respectively. People, who are not used to or familiar with LaTeX, please download the .pdf file only.", "size": 136985, "stargazers_count": 1, "watchers_count": 1, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "AvitBhowmik", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 780579}], "readme": "# Ph.D. Dissertation\n\n## Avit Kumar Bhowmik\n\nThis repository contains my Ph.D. dissertation. The dissertation has been written and compiled using \"Maggi Memoir Thesis\" (<http://www.latextemplates.com/template/maggi-memoir-thesis>) template and XeLaTeX, respectively. People, who are not used to or familiar with LaTeX, please download the .pdf file only. \n"}
{"url": "https://github.com/AvitBhowmik/Poster-on-Spatial-Statistics-2015", "owner": "AvitBhowmik", "repository_name": "Poster-on-Spatial-Statistics-2015", "date_all_variable_collection": "2023-09-11", "description": "This repository contains my poster presented at Spatial Statistics: Emerging Patterns 2015 conference, in Avignon, France on June 12, 2015. The title of the poster is \"Estimating pooled within-time series variograms with spatially shifted temporal points\", reference number: P3.03, abstract sequel: SPAT2015_0024. The poster was created using Latex a0poster and multicol packages.", "size": 6816, "stargazers_count": 1, "watchers_count": 1, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Creative Commons Zero v1.0 Universal", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "AvitBhowmik", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 36917}], "readme": "# Poster-on-Spatial-Statistics-2015\nThis repository contains my poster presented at Spatial Statistics: Emerging Patterns 2015 conference, in Avignon, France on June 12, 2015. The title of the poster is \"Estimating pooled within-time series variograms with spatially shifted temporal points\", reference number:  P3.03, abstract sequel: SPAT2015_0024. The poster was created using Latex a0poster and multicol packages.\n\n#Abstract\nPooled within-time series (PTS) variograms are frequently used for geostatistical interpolation in spatial data-scarce regions if time series are available. The only available method for PTS variograms estimation averages semivariances computed for individual time steps over each spatial lag within a pooled time series. However, semivariances computed by a few paired comparisons in individual time steps are erratic and hence they may hamper precision of PTS variogram estimation. We developed an alternative method for estimating PTS variograms by spatializing temporal data points and shifting them. The pooled spatial data point sets from different time steps were assigned to different coordinate sets on the same space. Then a semivariance was computed for each spatial lag by comparing all point pairs separable by that spatial lag within a pooled time series. Finally, a PTS variogram was estimated by controlling the lower and upper boundary of spatial lags. Our method showed higher precision than the available method for PTS variogram estimation and was developed by using the freely available R open source software environment.\n\nAn article on this topic is currently under review in Hydrology and Earth System Sciences. Please refer to the \"SSTP\" repository to access the tool.\n"}
{"url": "https://github.com/AvitBhowmik/Presentation-at-SEFS9", "owner": "AvitBhowmik", "repository_name": "Presentation-at-SEFS9", "date_all_variable_collection": "2023-09-11", "description": "This repository contains my slides presented at 9th Symposium of European Freshwater Sciences - SEFS 9 2015 conference, in Geneva, Switzerland on July 6, 2015. The title of the oral presentation is \"Are aerial dispersers good adapters? Association of large scale spatial autocorrelation of semi-aquatic insect trait distribution with climate\", reference number: 00570, session: RS02-Impacts of climate change on freshwater ecosystems. The slides were created using Latex Beamer package and mtheme.", "size": 13336, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Creative Commons Zero v1.0 Universal", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "AvitBhowmik", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 19205}], "readme": "# Presentation slides on 9th Symposium of European Freshwater Sciences - SEFS 9 2015\nThis repository contains my slides presented at 9th Symposium of European Freshwater Sciences - SEFS 9 2015 conference, in Geneva, Switzerland on July 6, 2015. The title of the oral presentation is \"Are aerial dispersers good adapters? Association of large scale spatial autocorrelation of semi-aquatic insect trait distribution with climate\", reference number: 00570, session: RS02-Impacts of climate change on freshwater ecosystems. The slides were created using Latex Beamer package and mtheme.\n\n# Abstract\nTraits of freshwater organisms have shown potential to identify and disentangle impacts of stressors. Although several studies suggested traits that may indicate vulnerability to climate change, the empirical relationship between assemblage trait composition and climate has been rarely examined. We investigated and compared the association of the spatial autocorrelation of semi-aquatic insect assemblage trait composition with climate on a large scale (Germany). Six assumed climate-responsive traits from five different orders of semi-aquatic invertebrates that are areal dispersers were selected, comprising 782 species and 395 genera sampled in 4,752 stream sites during 2006 and 2007. We checked for the amount of spatial autocorrelation in trait composition that is associated with 35 bioclimatic indices. On an average, bioclimatic indices explained more than 50% of the significant spatial autocorrelation for the majority of the traits while explaining the highest amount of spatial autocorrelation for temperature preference and maximal body size, and the insect orders Plecoptera, Diptera and Ephemeroptera. We show that climate is the predominant driver of large scale spatial autocorrelation of the semi-aquatic insect assemblage trait composition and thus climate change may alter their spatial pattern, especially for large insects and insects inhabiting cold water streams.\n\nAn article on this topic is available here: http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130025.\n"}
{"url": "https://github.com/AvitBhowmik/Presentation-slides-on-Spatial-Statistics-2015", "owner": "AvitBhowmik", "repository_name": "Presentation-slides-on-Spatial-Statistics-2015", "date_all_variable_collection": "2023-09-11", "description": "This repository contains my slides presented at Spatial Statistics: Emerging Patterns 2015 conference, in Avignon, France on June 12, 2015. The title of the oral presentation is \"Mapping human risk from contamination of drinking water sources in developing countries\", reference number: O2.24, abstract sequel: SPAT2015_0024.", "size": 4540, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Creative Commons Zero v1.0 Universal", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "AvitBhowmik", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 21200}], "readme": "# Presentation slides on Spatial Statistics 2015\nThis repository contains my slides presented at Spatial Statistics: Emerging Patterns 2015 conference, in Avignon, France on June 12, 2015. The title of the oral presentation is \"Mapping human risk from contamination of drinking water sources in developing countries\", reference number: O2.24, abstract sequel: SPAT2015_0024. The slides (Presentation_SPAT_Bhowmik.pdf) were created using Latex Beamer package and mtheme.\n\n# Abstract\nThe consumption of contaminated drinking water is one of the major causes of mortality in developing countries, where the principal drinking water sources, i.e. ground and surface water, are subject to geogenic and anthropogenic contamination. However, water quality monitoring activities have been limited to a few administrative areas and a nationwide human risk assessment is often lacking. Using geographically weighted regression (GWR), we calculated nationwide human risk maps by predicting the concentration of 10 trace metals in the drinking water sources of Pakistan and comparing them to guideline values. Global soil properties, land cover and digital elevation models were fitted as spatial predictors. The GWR model predictions showed good agreement with observed values, while more than 53% of the total area of Pakistan was predicted to be at risk of drinking water contamination from arsenic, chromium, iron, nickel and lead. Moreover, more than 74 million people inhabit the area with elevated risk. These predictions demonstrate the power of GWR for risk assessment and can inform disease mitigation and water resources management regarding potential hot spots.\n\nAn article on this topic is currently under review in Science of the Total Environment.\n"}
{"url": "https://github.com/AvitBhowmik/SA17", "owner": "AvitBhowmik", "repository_name": "SA17", "date_all_variable_collection": "2023-09-11", "description": null, "size": 22047, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Creative Commons Zero v1.0 Universal", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "AvitBhowmik", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 30648}, {"language": "R", "num_chars": 14568}], "readme": "# International Summer Academy on Spatial Ecotoxicology and Ecotoxicological Risk Assessment \u2013 Using an Open Commmunity Approach\n\n10 \u2013 24 September 2017, at University of Koblenz-Landau, Landau in der Pfalz, Germany\n\nsupported by Germany Academic Exchange Service (DAAD)\n\nThis repository contains the materials for two courses, i.e. \"Introduction to open source Spatial Analysis Tools and R\" and \"Spatial(temporal) interpolation with R\", which will take place on 18th and 19th of September 2017. The folders are named according to the course names and contain materials for the corresponding courses.\n\nIf you have questions or comments, please contact: avit.bhowmik@su.se  \n"}
{"url": "https://github.com/AvitBhowmik/SSTP", "owner": "AvitBhowmik", "repository_name": "SSTP", "date_all_variable_collection": "2023-09-11", "description": "SSTP: Spatially Shifting Temporal Points", "size": 140, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Creative Commons Zero v1.0 Universal", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "AvitBhowmik", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 10380}], "readme": "## SSTP ##\n\nSpatially Shifting Temporal Points (SSTP) is an alternative pooled within-time series (e.g. years) variogram estimation tool. This is particularly useful for spatially data-scarce regions, where abundant time series are available. For example,  climate databases in developing countries are generally spatially scarce, i.e. only a few (< 50) meteorological stations data, but abundant in time, i.e. long (> 50 years) time series are available. A temporally constant spatial variogram can be estimated using SSTP that outperforms the erratic spatial variogram estimation for individual years and the available pooled within-time series variogram estimation technique.\n\nA discussion paper on SSTP is available via: http://www.hydrol-earth-syst-sci-discuss.net/12/2243/2015/hessd-12-2243-2015-discussion.html\n\n\n## Instructions for usage ##\n\nYou should have the latest version of R and the required packages installed as demonstrated in the \"SSTP_script.R\". Download the \"SSTP_data.Rdata\" and \"SSTP_script.R\" and follow the instructions in the script.   \n"}
{"url": "https://github.com/AvitBhowmik/summer_academy_15", "owner": "AvitBhowmik", "repository_name": "summer_academy_15", "date_all_variable_collection": "2023-09-11", "description": "\"International Summer Academy on Spatial Ecotoxicology and Ecotoxicological Risk Assessment \u2013 Using an Open Commmunity Approach\", 07 \u2013 20 September 2015, in University of Koblenz-Landau, Landau in der Pfalz, Germany", "size": 14076, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Creative Commons Zero v1.0 Universal", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "AvitBhowmik", "contributions": 13}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 40477}, {"language": "R", "num_chars": 14318}], "readme": "# International Summer Academy on Spatial Ecotoxicology and Ecotoxicological Risk Assessment \u2013 Using an Open Commmunity Approach\n\n07 \u2013 20 September 2015, in University of Koblenz-Landau, Landau in der Pfalz, Germany\n\nsupported by Germany Academic Exchange Service (DAAD)\n\nThis repository contains the materials for two courses, i.e. \"Introduction to open source Spatial Analysis Tools and R\" and \"Spatial(temporal) interpolation with R\", to be held on 11th and 14th of September. The folders are named according to the course names and contain materials for the corresponding courses.\n\nIf you have questions or comments, please contact: bhowmik@uni-landau.de  \n"}
{"url": "https://github.com/AvitBhowmik/teaching_materials", "owner": "AvitBhowmik", "repository_name": "teaching_materials", "date_all_variable_collection": "2023-09-11", "description": null, "size": 38325, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "AvitBhowmik", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 89463}, {"language": "R", "num_chars": 39696}], "readme": "# teaching_materials"}
{"url": "https://github.com/AvitBhowmik/testGU", "owner": "AvitBhowmik", "repository_name": "testGU", "date_all_variable_collection": "2023-09-11", "description": "This repository contains the trial lecture and homework for the students in Hochschule Geisenheim University", "size": 52802, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "AvitBhowmik", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 15516}]}
{"url": "https://github.com/AvitBhowmik/testUP", "owner": "AvitBhowmik", "repository_name": "testUP", "date_all_variable_collection": "2023-09-11", "description": "This repository contains the materials for the trial lecture in University of Potsdam. ", "size": 45683, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "AvitBhowmik", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 17123}]}
{"url": "https://github.com/Azarozo19/ICESat-2_DEM_Internship", "owner": "Azarozo19", "repository_name": "ICESat-2_DEM_Internship", "date_all_variable_collection": "2023-09-11", "description": "Internship I RSIV", "size": 33619, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "Azarozo19", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 83917135}, {"language": "Python", "num_chars": 7336}]}
{"url": "https://github.com/Baschdl/hci-robot", "owner": "Baschdl", "repository_name": "hci-robot", "date_all_variable_collection": "2023-09-11", "description": null, "size": 6, "stargazers_count": 0, "watchers_count": 0, "language": "Arduino", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Blubl", "contributions": 4}, {"contributor": "Baschdl", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Arduino", "num_chars": 10004}]}
{"url": "https://github.com/Baschdl/jax-random_projections", "owner": "Baschdl", "repository_name": "jax-random_projections", "date_all_variable_collection": "2023-09-11", "description": "sklearn's random projections but fast (using JAX on a GPU)", "size": 7, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "Baschdl", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 3213}], "readme": "# JAX Random Projection Transformers\nUsing JAX to speed up sklearn's random projection transformers\n\n## Installation\n\n**Note: Installation with pip will install the CPU-only version of JAX**\n\nTo use a GPU follow [JAX's installation guide](https://github.com/google/jax#installation) before installing `jax-random_projections`.\n```\npip install jax-random_projections\n```\n\n## Usage\n```python\nfrom jax_random_projections.sparse import SparseRandomProjectionJAX\n\ntransfomer = SparseRandomProjectionJAX()\ntransfomer.fit_transform(X)\n```\n\nFor the API documentation, refer to [sklearn's SparseRandomProjection documentation](https://scikit-learn.org/stable/modules/generated/sklearn.random_projection.SparseRandomProjection.html).\nThe only difference is that `jax-random_projections` currently only supports `xla.DeviceArray` and doesn't support `dense_output=False` and `y` for `fit()`\nThis library currently only includes the `SparseRandomProjection` but a future release will also include `GaussianRandomProjection`.\n\n`jax-random_projections` also includes `SparseRandomProjectionJAXCached` which uses a lru cache (`maxsize=5`) to speed up repeated calls by caching the random matrix for data with the same input dimension.\n"}
{"url": "https://github.com/Baschdl/metapath-embedding", "owner": "Baschdl", "repository_name": "metapath-embedding", "date_all_variable_collection": "2023-09-11", "description": null, "size": 38, "stargazers_count": 3, "watchers_count": 3, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "Baschdl", "contributions": 62}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 21261}, {"language": "Shell", "num_chars": 5683}], "readme": "# Own algorithm\n\n## Build meta-path mining algorithm\n- Checkout `mps-between-instances-per_startnode` from https://github.com/KDD-OpenSource/neo4j-graph-algorithms\n- `cd neo4j-graph-algorithms && mvn clean install`\n- Copy `graph-....jar` to plugins folder\n\n## Import data into neo4j\nImport two different wikidata dumps into neo4j instances using https://github.com/findie/wikidata-neo4j-importer\n\n- Mount built neo4j-graph-algorithms plugin\n- Allow execution of plugin\n\n## Map wikidata class hierarchy into nodes\n- Checkout `multiTypesConversion` from https://github.com/KDD-OpenSource/neo4j-graph-algorithms\n- Run hierarchy algorithm\n- Run algorithm to copy types from classes to instances\n\n## Clean data\n- Remove test label\n- Delete all nodes with types != Entity\n\n## Mine meta-paths on t_1 and t_2\n- Mount /tmp/between_instances from docker container into local file system\n- Optional: Load graph\n- Run mining algorithm\n- **TODO:** Build training examples with converted meta-paths\n- Convert files with `python3 transform_texts.py`\n- Concatenate converted meta-path files `echo data/*_converted.txt | xargs cat > data/all.txt`\n\n## Train embeddings on t_1\n- Install fastText with `git clone https://github.com/facebookresearch/fastText.git && cd fastText && make`\n- Run fastText with `./fasttext skipgram -input data.txt -output model`\n\n## Find new edges in t_2 compared to t_1\n- Download the edge lists with `download_edgelist_Qid.sh`\n- **TODO:** Add bolder warning for failed downloads\n- Append the edge lists to one big list with `concat_edgelists_Qid.sh`\n- Find new edges with `python3 find_new_edges.py`\n\n## Mine meta-paths for positive and negative edges\n### Positive edges\n- Convert list with new edges from previous step to list of neo4j ids with `python3 convert_new_edges_to_neo4j_ids.py --new_edges_list ~/new_edges_t1_t3_undirected.txt --converted_new_edges_list new_edges_t1_t3_undirected_neo4j.txt --user user --password password --uri bolt://localhost:7687`.\nTakes around 1,5h.\n- Start mining with something like `CALL algo.computeAllMetaPathsBetweenInstances(5, 0, 0.999, {'edgelistFilepath':'/tmp/between_instances/positive_edgelist.txt'})`\n\n### Negative edges\n- **TODO:** Sample negative edges in t_1 by looping through mined meta-paths and look which nodes don't have a edge\n- **TODO:** Check that they are not in the list of new edges\n\n## Train link prediction classifier\n- Labels are the nodes with a new edge, features are the combined embeddings of the meta-paths between the two nodes\n\n# Competitors\n\n## Export edge lists\n- Download the edge lists with `download_edgelist.sh`\n- **TODO:** Add bolder warning for failed downloads\n- Append the edge lists to one big list with `concat_edgelists.sh`\n- If neccessary, subsample the nodelist with `shuf -n number_of_nodes all-edgelist.csv > all-edgelist-subsample.csv`\n\n## Convert edge list to bcsr\n- **TODO:** Add header line to big edge list\n- Install `verse` with `https://github.com/xgfs/verse.git && cd src && make;`\n- Convert list to bcsr with `convert-bcsr --format edgelist [--undirected / --directed] /path/to/edgelist /path/to/bcsr`\n\n## Train node embeddings with competitors\n- Verse: `verse -input data/karate.bcsr -output karate.bin -dim 128 -alpha 0.85 -threads 4 -nsamples 3`\n- DeepWalk: `git clone https://github.com/xgfs/deepwalk-c.git && cd src && make; && [./]deepwalk [...]`\n- node2vec: `git clone https://github.com/xgfs/node2vec-c.git && make && [./]node2vec [...]`\n\n## Train link prediction classifier\n- Build negative samples\n- Labels are the nodes with a new edge, features are the embedding of the two nodes\n"}
{"url": "https://github.com/Baschdl/RoboCup-Team-Nullpointer", "owner": "Baschdl", "repository_name": "RoboCup-Team-Nullpointer", "date_all_variable_collection": "2023-09-11", "description": "RoboCup Junior Rescue B - Team \"Nullpointer\"", "size": 1776, "stargazers_count": 3, "watchers_count": 3, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "Baschdl", "contributions": 196}, {"contributor": "schmo1337", "contributions": 123}, {"contributor": "samuscherer", "contributions": 106}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["mindstorms", "raspberry-pi", "robocup", "robocup-junior", "robotics-competition"], "languages": [{"language": "Java", "num_chars": 282589}], "readme": "# RoboCup-Team-Nullpointer\nRoboCup Junior Rescue B - Team \"Nullpointer\"\nCode for participating in the RoboCup Junior Rescue B. \"Pi-Server\" is running on a Raspberry Pi and \"Brick\" on 2 Lego Mindstorms NXT Bricks simultaneously. \n\n### Physical construction of robot\n- Raspberry Pi B+\n- USB-battery for Raspberry Pi\n- 2 Bricks with Lego battery\n- Mindsensors Absolute IMU-ACG (not really used)\n- Mindsensors DIST-Nx\n- 2x HiTechnic EOPD\n- Mindsensors Light Sensor Array\n- Dexter Industries (Thermal Infrared Sensor)\n- Lego Color Sensor (used to signal \"victim found\")\n"}
{"url": "https://github.com/Baschdl/test-signing", "owner": "Baschdl", "repository_name": "test-signing", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Baschdl", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# test-signing\n"}
{"url": "https://github.com/Baschdl/vaccination_checker", "owner": "Baschdl", "repository_name": "vaccination_checker", "date_all_variable_collection": "2023-09-11", "description": "Image-based vaccination checker and advisor", "size": 967, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Baschdl", "contributions": 38}, {"contributor": "MarvinThiele", "contributions": 32}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 332226}, {"language": "HTML", "num_chars": 34988}, {"language": "Python", "num_chars": 20550}], "readme": "# vaccination-checker \n## How to migrate from the paperwork legacy: Digitizing vaccination cards by camera.\nDeveloped during hackathon HackHPI 2017. Won the SAP challenge.\n"}
{"url": "https://github.com/Baschdl/varnish-ban-setup", "owner": "Baschdl", "repository_name": "varnish-ban-setup", "date_all_variable_collection": "2023-09-11", "description": "Setup to reproduce https://stackoverflow.com/questions/65632023/varnish-ban-is-added-but-old-object-is-returned", "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": "VCL", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Baschdl", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "VCL", "num_chars": 488}, {"language": "Dockerfile", "num_chars": 49}]}
{"url": "https://github.com/Baschdl/vimagick-django-cms", "owner": "Baschdl", "repository_name": "vimagick-django-cms", "date_all_variable_collection": "2023-09-11", "description": "Minimal setup for django-cms based on https://hub.docker.com/r/vimagick/django-cms/", "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Baschdl", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/benlowit/Digital-Sketching", "owner": "benlowit", "repository_name": "Digital-Sketching", "date_all_variable_collection": "2023-09-11", "description": "Digital Etch-A-Sketch style drawing system.  Two potentiometers are used to draw on a 255 x 255 pixel canvas.  A USB keyboard connected to the FPGA can change the cursor width, canvas size, and ink color.  The representation of the drawing surface is displayed on a VGA monitor connected to the FPGA and on a PC's screen through software that communicates via UART with the FPGA.", "size": 11269, "stargazers_count": 0, "watchers_count": 0, "language": "VHDL", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "benlowit", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "VHDL", "num_chars": 30279607}, {"language": "Verilog", "num_chars": 678045}, {"language": "Java", "num_chars": 8181}], "readme": "# CE-Junior-Lab-Project-5\nDigital Etch-A-Sketch style drawing system.  Two potentiometers are used to draw on a 255 x 255 pixel canvas.  A USB keyboard connected to the FPGA can change the cursor width, canvas size, and ink color.  The representation of the drawing surface is displayed on a VGA monitor connected to the FPGA and on a PC's screen through software that communicates via UART with the FPGA.\nHardware written using Vivado in VHDL.\nSoftware written using Eclipse in Java.\n"}
{"url": "https://github.com/benlowit/Microprocessor_Hex-Siren", "owner": "benlowit", "repository_name": "Microprocessor_Hex-Siren", "date_all_variable_collection": "2023-09-11", "description": "Hexadecimal sequence cycler and quad-tone siren generator.  Written with CodeWarrior in C.", "size": 52, "stargazers_count": 0, "watchers_count": 0, "language": "C", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "benlowit", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C", "num_chars": 98988}], "readme": "# Microprocessors-Exam-2\nHexadecimal sequence cycler and quad-tone siren generator.  Uses RTI interrupts as the timer module is disallowed.  Written with CodeWarrior in C.\n"}
{"url": "https://github.com/benlowit/Microprocessor_Multisource-Tone-Gen", "owner": "benlowit", "repository_name": "Microprocessor_Multisource-Tone-Gen", "date_all_variable_collection": "2023-09-11", "description": "Final Exam Project for EE360 Microprocessors", "size": 48, "stargazers_count": 0, "watchers_count": 0, "language": "C", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "benlowit", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C", "num_chars": 116119}, {"language": "C++", "num_chars": 42}], "readme": "# MicroProcessors-Final-Project\nFinal Exam Project for EE360 Microprocessors\n\nC code project written with CodeWarrior IDE.\nProject description included in \"EE360_Final_Project\".\n"}
{"url": "https://github.com/benlowit/Microprocessor_Timer-Siren", "owner": "benlowit", "repository_name": "Microprocessor_Timer-Siren", "date_all_variable_collection": "2023-09-11", "description": "Digital stopwatch with 10 millisecond resolution and a 3-tone siren.  Written with CodeWarrior in C.", "size": 51, "stargazers_count": 0, "watchers_count": 0, "language": "C", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "benlowit", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C", "num_chars": 99056}], "readme": "# Microprocessors-Project-6\nDigital stopwatch with 10 millisecond resolution and a 3-tone siren.  Written with CodeWarrior in C.\n"}
{"url": "https://github.com/benlowit/PS-2-Hangman", "owner": "benlowit", "repository_name": "PS-2-Hangman", "date_all_variable_collection": "2023-09-11", "description": "Hangman game played with PS/2 keyboard with scan codes decoded using IC chips on a breadboard and translated into ASCII.  ASCII characters are then sent via UART to this software to play hangman with a user-friendly GUI and pictures that indicate current game state.  The software also sends data via UART to control a breadboard-mounted LCD and 7-segment display to display game state and incorrect guesses remaining.  Written using Visual Studio in C#.", "size": 26, "stargazers_count": 0, "watchers_count": 0, "language": "C#", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "benlowit", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C#", "num_chars": 19283}], "readme": "# CE-Junior-Lab-Project-3\nHangman game played with PS/2 keyboard with scan codes decoded using IC chips on a breadboard and translated into ASCII.  ASCII characters are then sent via UART to this software to play hangman with a user-friendly GUI and pictures that indicate current game state.  The software also sends data via UART to control a breadboard-mounted LCD and 7-segment display to display game state and incorrect guesses remaining.  Written using Visual Studio in C#.\n"}
{"url": "https://github.com/benlowit/Waveform-Analyzer", "owner": "benlowit", "repository_name": "Waveform-Analyzer", "date_all_variable_collection": "2023-09-11", "description": "System made to sample, store, digitally recreate, and analyze waveforms.  Signals are sampled using an ADC, stored in RAM, and sent via UART to software that plots the data and performs analyses.", "size": 11397, "stargazers_count": 0, "watchers_count": 0, "language": "VHDL", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "benlowit", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "VHDL", "num_chars": 14948345}, {"language": "Verilog", "num_chars": 211042}], "readme": "# CD-Junior-Lab-Project-4\nSystem made to sample, store, digitally recreate, and analyze waveforms.  Signals are sampled using an ADC, stored in RAM, and sent via UART to software that plots the data and performs analyses.\nThis code is the hardware component of the project.  The software that analyzes the data was written by another group member.\nWritten using Vivado Design Suite in VHDL.\n"}
{"url": "https://github.com/bgailleton/CHONK", "owner": "bgailleton", "repository_name": "CHONK", "date_all_variable_collection": "2023-09-11", "description": "LEM prototype crossing Cellular Automata methods with graph theory", "size": 193086, "stargazers_count": 2, "watchers_count": 2, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "bgailleton", "contributions": 414}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 32827120}, {"language": "C++", "num_chars": 425793}, {"language": "Python", "num_chars": 137916}, {"language": "Makefile", "num_chars": 7904}, {"language": "Batchfile", "num_chars": 7265}, {"language": "CMake", "num_chars": 3733}, {"language": "Shell", "num_chars": 116}], "readme": "# CHONK prototype\r\n\r\nRepository accompanying the publication in GMD (ADD LINK and title). It contains the code used to run the simulations and generate the data behind the figures. \r\n\r\n\r\n#### What IS this code?\r\n A sandbox experimental Landscape Evolution Model developed to test a method crossing cellular automata and graph theory in given scenarios described in the companion paper.\r\n\r\n\r\n#### What is it NOT?\r\n A stable and efficient framework to run LEMs simulations or develop new ones. While usable, it is more a proof-of-concept than anything else.\r\n\r\n\r\n#### Why?\r\n It required a lot of trial-and-errors to get all the features working (especially the lake solver). The code is slow, require a lot of memory and is easily breakable.\r\n\r\n\r\n#### But what if I want to use the method?\r\n So do we, that's why we are working on two other exciting projects:\r\n\r\n- First, a stable, efficient and production-ready version of CHONK - now we learnt from all these errors. While not offering (yet) all the aspects of CHONK, the new code is already indescribably faster, cleaner and more flexible while requiring (way) less memory. It should be available in the coming months. \r\n\r\n- Then, a framework dedicated to building your own LEM following the philosophy described in the paper.\r\n\r\nIn any case, see (here for updates about the projects)[https://bgailleton.github.io/chonk/] or feel free to contact me if you have more questions.\r\n\r\n## Installation \r\n\r\nRight, let's say you still want to use this version to verify/reproduce the results from the manuscript.\r\n\r\n### Compiler\r\n\r\nYou first need to install a `c++` compiler (if you already have one able to compile with the standard `c++14` you are good to go), it can be quite heavy on `MacOS` and `Windows`, so I tried to keep the minimum requirements: \r\n\r\n\r\n- On Windows, look for \"Build Tools for Visual Studio 2022\" [here](https://visualstudio.microsoft.com/downloads/#build-tools-for-visual-studio-2022). It will install the minimum tools required to build `C++` projects on windows.\r\n\r\n- On MacOS, open a `Terminal` and run `xcode-select --install` to only install the command line tools to compile `c++` (already quite big...) and bypass the full installation of `Xcode`.\r\n\r\n- On linux, make sure you have `gcc/g++` > 8. \r\n\r\nNote that on both Windows and MacOS you can also install some versions of `gcc/g++` through various methods, but they are quite difficult to get to work properly.\r\n\r\n### Anaconda\r\n\r\nYou then need an `anaconda` environment manager. If you don't know what it is, let's say it creates small boxes in your computer and put all the code needed for a given application in the box so that it can find everything it needs, in hte right version, without interfering with the rest of the system. `Anaconda` is a company but license-free versions of their tool exist. I recommend `mambaforge` - you can find it [there](https://github.com/conda-forge/miniforge#mambaforge). \r\n\r\nFollow the installation instructions and start a new terminal: \r\n\r\n- First you need to create a box (ONLY NEEDED ONCE): `mamba create -n CHONK`\r\n- Then you need to \"enter\" the box (NEEDED AT EACH NEW SESSION): `mamba activate CHONK`\r\n- Install the dependencies (ONLY NEEDED ONCE, the last 2 package are only recommended to load/save `DEM`): `mamba install matplotlib git numpy scipy jupyterlab ipympl pybind11 cmake rasterio gdal xtensor-python ipyfastscape xarray-simlab`\r\n- Now, you need to clone or download the current repository. `cd` wherever you wanna place it and run `git clone https://github.com/bgailleton/CHONK`\r\n- Finally, `cd` to `CHONK` and run `python setup.py install` (only needed once).\r\n- Done!\r\n\r\n## Usage\r\n\r\nSee the `notebooks` folder for some examples.\r\n\r\n# Credits\r\n\r\nThis model was primarily developed by Boris Gailleton (boris.gailleton@univ-rennes1.fr) at the GFZ institute (Potsdam, Germany) with the help and advice of Luca Malatesta, Guillaume Cordonnier and Jean Braun.\r\n\r\n"}
{"url": "https://github.com/bgailleton/CV_Boris_Gailleton", "owner": "bgailleton", "repository_name": "CV_Boris_Gailleton", "date_all_variable_collection": "2023-09-11", "description": "My CV", "size": 409, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "bgailleton", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 20813}, {"language": "Python", "num_chars": 9782}], "readme": "Boris Gailleton CV\n=============================\n\nTemplate adapted from [Simon Mudd](https://github.com/simon-m-mudd/CV_SMudd) CV, see his page for details about compilation with XeLaTeX."}
{"url": "https://github.com/bgailleton/DAGGER", "owner": "bgailleton", "repository_name": "DAGGER", "date_all_variable_collection": "2023-09-11", "description": "Directed Acyclic Graph for digital topoGrahic manipulations Eventually cRoss-platform", "size": 78065, "stargazers_count": 1, "watchers_count": 1, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "bgailleton", "contributions": 208}, {"contributor": "rpurser47", "contributions": 1}, {"contributor": "dependabot[bot]", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 2546906}, {"language": "Python", "num_chars": 30411}, {"language": "MATLAB", "num_chars": 2917}, {"language": "Makefile", "num_chars": 2898}, {"language": "Batchfile", "num_chars": 804}, {"language": "CMake", "num_chars": 695}, {"language": "Shell", "num_chars": 352}, {"language": "Julia", "num_chars": 347}], "readme": "# DAGGER - Directed Acyclic Graph for digital topoGrahic manipulations Eventually cRoss-platform\n\n`DAGGER` is a library to process digital topography. It is designed as a flexible backend engine for Topographic Analysis and Landscape Evolution Models, providing a range of method to calculate flow routing (Single/Multiple flow, receivers,donors,links,...), resolve local minima (fill, carve, reroute, ...) and a lot of related problems. Coded in `c++`, we provide example on how to use them natively with `python` (+TODO: `R,Julia,MATLAB,Js`).\n\n## Quickstart\n\n- I want to use the [python version](https://github.com/bgailleton/DAGGER/tree/main/wrappers/python/deployment/dagger) (principal and most complete/maintained frontend),\n- I want to use the [c++ version](https://github.com/bgailleton/DAGGER/tree/main/wrappers/cpp) (the backend),\n- I am interested by the [MATLAB version](https://github.com/bgailleton/DAGGER/tree/main/wrappers/MATLAB) (still fiddling with the details, not working yet, see local README),\n- To do: the other bindings\n\n## Documentation\n\nDetailed documentation will be on a readthedoc website (WIP)\n\n## How to cite\n\nA paper describing the scope and overview of the library will be submitted in [`JOSS`](https://joss.theoj.org/), and can be currently found in the file `paper.md`.\n\n## Road map\n\nThe past and future development plan can be found in [this issue](https://github.com/bgailleton/DAGGER/issues/1) before being moved in the documentation.\n\n## Authors\n\nBoris Gailleton - boris.gailleton@univ-rennes1.fr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<!--  -->\n"}
{"url": "https://github.com/bgailleton/helplotlib", "owner": "bgailleton", "repository_name": "helplotlib", "date_all_variable_collection": "2023-09-11", "description": null, "size": 16, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 2, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "bgailleton", "contributions": 4}, {"contributor": "elsgraf", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": true, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 6843}, {"language": "Makefile", "num_chars": 2227}], "readme": "==========\nhelplotlib\n==========\n\n\n.. image:: https://img.shields.io/pypi/v/helplotlib.svg\n        :target: https://pypi.python.org/pypi/helplotlib\n\n.. image:: https://img.shields.io/travis/bgailleton/helplotlib.svg\n        :target: https://travis-ci.com/bgailleton/helplotlib\n\n.. image:: https://readthedocs.org/projects/helplotlib/badge/?version=latest\n        :target: https://helplotlib.readthedocs.io/en/latest/?badge=latest\n        :alt: Documentation Status\n\n\n.. image:: https://pyup.io/repos/github/bgailleton/helplotlib/shield.svg\n     :target: https://pyup.io/repos/github/bgailleton/helplotlib/\n     :alt: Updates\n\n\n\nHelper for matplotlib: tired of googling over and over again how to change my font size or make my axis semi-log, I am creating this helper to automate all of this\n\n\n* Free software: MIT license\n* Documentation: https://helplotlib.readthedocs.io.\n\n\nFeatures\n--------\n\n* TODO\n\nCredits\n-------\n\nThis package was created with Cookiecutter_ and the `audreyr/cookiecutter-pypackage`_ project template.\n\n.. _Cookiecutter: https://github.com/audreyr/cookiecutter\n.. _`audreyr/cookiecutter-pypackage`: https://github.com/audreyr/cookiecutter-pypackage\n"}
{"url": "https://github.com/bgailleton/random_tuto", "owner": "bgailleton", "repository_name": "random_tuto", "date_all_variable_collection": "2023-09-11", "description": "Read the title", "size": 39, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "bgailleton", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 2790}], "readme": "# random_tuto\n\nThis github repository contains various tuto/templates I am writing here and there sometimes.\nI started it few years ago and totally forgot about it, going back to it now, I'll try to populate it when I have time!\n\nBoris (2019)\n"}
{"url": "https://github.com/bgailleton/Subitop_GRANADA", "owner": "bgailleton", "repository_name": "Subitop_GRANADA", "date_all_variable_collection": "2023-09-11", "description": "Figure support for my poster at the conference TOPOEUROPE", "size": 33547, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "bgailleton", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Subitop_GRANADA\r\n\r\n**I am at the registration desk right now fi you scan my QR code and want more info**\r\n\r\nSupport git-hub repository for my poster in TopoEurope Conference, Granada, May 2019. It contains the animations correspondng to the figures on the right side. *Apparently the gif does not show up on mobile automatically, you can either download them or switch your internet browser to computer mode. (You can also call me and I'll have my computer.)*\r\n\r\n## Model outputs\r\n\r\nModel has been running for 2 millions years: Builduing the mountain range to steady-state and then ponding the northern forland basin. It get filled by sediments and slightly uplifted, before being captured.\r\n\r\n**Evolution of the topography:**\r\n\r\n![Alt Text](https://github.com/bgailleton/Subitop_GRANADA/raw/master/topo.gif)\r\n\r\n**Topographic Slope:**\r\n\r\n![Alt_Text](https://github.com/bgailleton/Subitop_GRANADA/raw/master/slope.gif)\r\n\r\n**k_sn and river evolution:**\r\n\r\n![Alt_Text](https://github.com/bgailleton/Subitop_GRANADA/raw/master/ksn_evolution.gif)\r\n\r\n**Long river profile of the central basins:**\r\n\r\nThis shows the evolution of the rivers in the central basins. The northern river gets aggraded and then captured by the south one.\r\nNote how the knickpoint is stationnary despite the abscence of lithologic contrasts.\r\n\r\n![Alt_Text](https://github.com/bgailleton/Subitop_GRANADA/raw/master/long_profile_captured.gif)\r\n\r\n## Method \r\n\r\nThe model uses Yuan et al., 2019 and Braun et Willett, 2013 to simulate erosion, continental deposition and linear hillslope processes. I'll upload the model parameters if anyone wants. I used an homemade python bindings to `fastscapelib-fortran` and `lsdtopytools` respectively for the modelling and topographic analysis of the output. All the code are open-source but early-development so just contact me if interested.\r\n\r\nIf you want to use fastscapelib-fortran:\r\n[fastscapelib-fortran](https://fastscape-lem.github.io/fastscapelib-fortran)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n## Test to display gif on github\r\n\r\nIgnore that:\r\n\r\n![Alt Text](https://media.giphy.com/media/vFKqnCdLPNOKc/giphy.gif)\r\n"}
{"url": "https://github.com/bgailleton/test_web_stuff", "owner": "bgailleton", "repository_name": "test_web_stuff", "date_all_variable_collection": "2023-09-11", "description": null, "size": 53811, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "bgailleton", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/bgailleton/three_test", "owner": "bgailleton", "repository_name": "three_test", "date_all_variable_collection": "2023-09-11", "description": "Playing with three.js. ignore", "size": 482, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "bgailleton", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1202954}, {"language": "HTML", "num_chars": 821}, {"language": "Shell", "num_chars": 97}]}
{"url": "https://github.com/bgailleton/TVD_Condat2013", "owner": "bgailleton", "repository_name": "TVD_Condat2013", "date_all_variable_collection": "2023-09-11", "description": "Python implementation of the 1D Total Variation Denoising algorithm A Direct Algorithm for 1D Total Variation Denoising (Sign. Proc. Letters, DOI:10.1109/LSP.2013.2278339) using xtensor and pybind11 to bind c++ and numpy.", "size": 2153, "stargazers_count": 11, "watchers_count": 11, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 6, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 2, "license": "BSD 3-Clause \"New\" or \"Revised\" License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 6, "open_issues": 2, "watchers": 11, "default_branch": "master", "contributors": [{"contributor": "bgailleton", "contributions": 16}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 15135}, {"language": "Python", "num_chars": 4598}, {"language": "CMake", "num_chars": 3733}], "readme": "TVDCondat2013\r\n==============\r\n\r\nTVDCondat2013 is a python portage of the 1D Total Variation Denoising algorithm from Condat 2013: _A Direct Algorithm for 1D Total Variation Denoising_ (Sign. Proc. Letters, DOI:10.1109/LSP.2013.2278339) using xtensor and pybind11 to bind c++ and numpy. \r\n\r\nThe `c++` core code has been adapted from `C` version available on the website of the manuscript orignal authors: http://www.gipsa-lab.grenoble-inp.fr/~laurent.condat/publications.html\r\n*Cite it if you use it.*\r\n\r\nThis package is mostly to train myself packging a python package from `c++` but also it is a really useful and efficient algorithm for:\r\n- Direct denoising for data that can be represented by flat segments\r\n- Indirect curve denoising using a detrend-denoise-retrend approach (Not implemented yet)\r\n\r\n*The package still is under active development*\r\n\r\nThis work\r\n\r\nQuick start\r\n------------\r\n\r\nSo far the following denoising of a `numpy` array are implemented:\r\n\r\n**Quick use of the original denoising**\r\n```\r\nfrom TVDCondat2013 import TVD\r\n...\r\ndenoised = TVD(MyNumpyArray,lambda_TVD)\r\n...\r\n\r\n```\r\n\r\n![Effect of regulation parameter lambda on the TVD](https://raw.githubusercontent.com/bgailleton/TVD_Condat2013/master/examples/Example.png)\r\n\r\n**More experimental: curve denoising. So far the boundary condition might shift up or down the data. I am working on it**\r\n\r\n```\r\nfrom TVDCondat2013 import D_TVD_R\r\n...\r\ncurve_denoised = D_TVD_R((MyNumpyArray_of_curve,lambda_TVD))\r\n...\r\n\r\n```\r\n![Curve denoising](https://raw.githubusercontent.com/bgailleton/TVD_Condat2013/master/examples/Example_curve.png)\r\n\r\nMore working examples in the `examples` folder.\r\n\r\nInstallation\r\n------------\r\n\r\nThis guide is directly from `xtensor` documentation, let me know if this doesn't work.\r\nI am working on developping a `pip` and a `conda` package at point.\r\n\r\n**On Unix (Linux, OS X)**\r\n\r\n - clone this repository\r\n - `pip install ./TVDCondat2013`\r\n\r\n**On Windows (Requires Visual Studio 2015)**\r\n\r\n - For Python 3.5:\r\n     - clone this repository\r\n     - `pip install ./TVDCondat2013`\r\n - For earlier versions of Python, including Python 2.7:\r\n\r\n   xtensor requires a C++14 compliant compiler (i.e. Visual Studio 2015 on\r\n   Windows). Running a regular `pip install` command will detect the version\r\n   of the compiler used to build Python and attempt to build the extension\r\n   with it. We must force the use of Visual Studio 2015.\r\n\r\n     - clone this repository\r\n     - `\"%VS140COMNTOOLS%\\..\\..\\VC\\vcvarsall.bat\" x64`\r\n     - `set DISTUTILS_USE_SDK=1`\r\n     - `set MSSdk=1`\r\n     - `pip install ./TVDCondat2013`\r\n\r\n   Note that this requires the user building `TVDCondat2013` to have registry edition\r\n   rights on the machine, to be able to run the `vcvarsall.bat` script.\r\n\r\n\r\nWindows runtime requirements\r\n----------------------------\r\n\r\nOn Windows, the Visual C++ 2015 redistributable packages are a runtime\r\nrequirement for this project. It can be found [here](https://www.microsoft.com/en-us/download/details.aspx?id=48145).\r\n\r\nIf you use the Anaconda python distribution, you may require the Visual Studio\r\nruntime as a platform-dependent runtime requirement for you package:\r\n\r\n```yaml\r\nrequirements:\r\n  build:\r\n    - python\r\n    - setuptools\r\n    - pybind11\r\n\r\n  run:\r\n   - python\r\n   - vs2015_runtime  # [win]\r\n```\r\n\r\n\r\nBuilding the documentation\r\n--------------------------\r\n\r\nDocumentation for the example project is generated using Sphinx. Sphinx has the\r\nability to automatically inspect the signatures and documentation strings in\r\nthe extension module to generate beautiful documentation in a variety formats.\r\nThe following command generates HTML-based reference documentation; for other\r\nformats please refer to the Sphinx manual:\r\n\r\n - `TVDCondat2013/docs`\r\n - `make html`\r\n\r\n\r\nRunning the tests\r\n-----------------\r\n\r\nRunning the tests requires `pytest`.\r\n\r\n```bash\r\npy.test .\r\n```\r\n"}
{"url": "https://github.com/bgailleton/webtopo_public", "owner": "bgailleton", "repository_name": "webtopo_public", "date_all_variable_collection": "2023-09-11", "description": null, "size": 11633, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "bgailleton", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 6752}, {"language": "JavaScript", "num_chars": 6420}]}
{"url": "https://github.com/bgailleton/wgt", "owner": "bgailleton", "repository_name": "wgt", "date_all_variable_collection": "2023-09-11", "description": "Testing web stuff. Please ignore.", "size": 7489, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "bgailleton", "contributions": 95}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 906464}, {"language": "C++", "num_chars": 517778}, {"language": "JavaScript", "num_chars": 23366}, {"language": "Python", "num_chars": 18388}, {"language": "HTML", "num_chars": 6103}, {"language": "CSS", "num_chars": 1044}], "readme": "# wgt\nTesting web stuff. Please ignore.\n"}
{"url": "https://github.com/bglaetzer/Intelligent-Logistics-Project", "owner": "bglaetzer", "repository_name": "Intelligent-Logistics-Project", "date_all_variable_collection": "2023-09-11", "description": "Github repo for the intelligent logistics project in the summer semester 2022 at potsdam university.", "size": 8769, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "bglaetzer", "contributions": 38}, {"contributor": "MertAkil", "contributions": 15}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 109257}, {"language": "Python", "num_chars": 15424}], "readme": "# Intelligent-Logistics-Project\nGithub repo for the intelligent logistics project in the summer semester 2022 at potsdam university.\nContributors: Benjamin Gl\u00e4tzer and Mert Akil\n\n\nExecute in Windows (example):\n```\npython Scripts\\cbs_main.py -i Instances\\corridor_2_instance.lp -o 25 -a Out\\out.lp\n```\n\nCommand for visualization with apsrilo viz:\n```\npython Scripts\\cbs_main.py -i Instances\\corridor_2_instance.lp -o 25 -a Out\\out.lp -v\n```\n\nFor benchmarking: \n```\npython Scripts\\cbs_main.py -i Instances\\corridor_2_instance.lp -o 25 -b out\\benchmark.csv\n```\n\nYou can change the behaviour at goal for the agents from disappear to stay at target (careful, not fully tested):\n```\npython Scripts\\cbs_main.py -i Instances\\corridor_2_instance.lp -o 25 -s\n```\n\nGeneral properties of the project:\n - non-anonymous MAPF\n - detection for vertex and edge conflicts\n - apply MetaAgent-CBS in ASP and extend it with some interesting features"}
{"url": "https://github.com/bgroenks96/2DX-GL", "owner": "bgroenks96", "repository_name": "2DX-GL", "date_all_variable_collection": "2023-09-11", "description": "The 2DX Open Source Project - Advanced 2D Graphics API for Java", "size": 45168, "stargazers_count": 1, "watchers_count": 1, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "bgroenks96", "contributions": 82}, {"contributor": "knightofiam", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 958702}, {"language": "C", "num_chars": 6290}, {"language": "GLSL", "num_chars": 5948}, {"language": "Shell", "num_chars": 65}], "readme": "###The 2DX Project - _Open Source 2D Java Graphics Library_\n\nThe 2DX Project aims to provide powerful, versatile, and felxible tools for 2D graphics programming in Java.\n\n**2DX-GL Core API**\n\n2DX-GL (Advanced 2-dimensional Graphics Library) is a standalone, dependency free library that extends the Java2D AWT API by adding more high-level functionality for rendering 2D geometry, effects, animations, physics, and general utilities.\n\n**Snap2D**\n\nA 2D Java game engine built on 2DX-GL.  Snap2D utilizes and extends the 2DX-GL API by re-applying its functionality and providing its own infrastructure for game development.  Snap2D aims to provide high performance 2D graphics rendering as well as a wide range of facilities for building games in Java.\n\nNotable features in Snap2D thus far:\n\n-Fast, efficient, high level rendering engines (separate Java2D and OpenGL frameworks)\n\n-99% cross-platform with expandable native library system\n\n-2D World management and conversion framework\n\n-2D timed animation framework (Java2D based)\n\n-OpenGL shader support (JOGL)\n\n-Built in image/texture management\n\n-SnapScript language for fast, portable game scripting\n\n-Physics framework (2DX + Snap2D expansion)\n\n-Built in sound library via Paul Lamb's SoundSystem API\n\n-Integration with NiftyGUI provides support for building effective, high-performance user interfaces\n\n-Math/geometry libraries\n\n-Numerous provided general utilities\n\nPlanned features:\n\n-2D lighting engine for JOGL renderer\n\n-Particle system\n\n-(?) Animation editor and bone system\n\nCode in the primary source folders ('snap2d' and 'x2d') is under development and may or may not be complete/working.\n\nIf you decide to use 2DX/Snap2D for actual application production, I would appreicate it if you let me know on GitHub or by any other means so that I know to be careful about making changes!  You can email me at: bgroe8@gmail.com\n\nThe 'builds' folder in the project directory contains the latest development builds.  All JARs in this folder include both the base 2DX-GL and Snap2D libraries.\n\n_NOTE: These JARs are typically stable, but may not have all features fully implemented or complete._\n\nRead the commit notes for detailed update information.\n\n**2DX-GL 1st Edition (v.1.0)**\n\nProject dev status: API-Stable\n\nTo-do (next commit):\n\n-\n\n**Snap2D**\n\nProject dev status: API-Alpha\n\nTo-do (in development):\n\n-2D Tile/Map system\n\n-Snap2D physics package (in development)\n\n-Continued improvements to OpenGL rendering engine\n\nFollow @The2DXProject on Twitter for real-time updates on development of the project!\n\n**Additional credits:**\n\nSnap2D Sound API utilizes SoundSystem for Java by Paul Lamb [www.paulscode.com]\n\nSnap2D integrates with NiftyGUI by void256 [http://nifty-gui.lessvoid.com/]\n\t\nOpenGL renderer utilizes JOGL 2.0 by JogAmp [www.jogamp.org]\n\n**Special Thanks**\n\nJulien Gouesse and Sven Gothel (JogAmp)\n"}
{"url": "https://github.com/bgroenks96/AutoMoL", "owner": "bgroenks96", "repository_name": "AutoMoL", "date_all_variable_collection": "2023-09-11", "description": "Automated Monadic Logic in the Scala programming language.", "size": 663, "stargazers_count": 0, "watchers_count": 0, "language": "Scala", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "develop", "contributors": [{"contributor": "bgroenks96", "contributions": 135}, {"contributor": "aetrudel", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Scala", "num_chars": 178412}, {"language": "Java", "num_chars": 11967}, {"language": "JavaScript", "num_chars": 1980}, {"language": "HTML", "num_chars": 1364}, {"language": "CSS", "num_chars": 266}], "readme": "# AutoMoL\nAutomated Monadic Logic in the Scala programming language.\n\n## Quick start\nTo use the first order evaluation theorem prover, clone the repo and run the following commands:\n\n    sbt compile\n    sbt fastOptJS\n    sbt server/run\n\nThen navigate to localhost:8080 in your favorite browser and enjoy the devilishly primitive (yet mostly functional) web interface.\n\n"}
{"url": "https://github.com/bgroenks96/cmip-embeddings", "owner": "bgroenks96", "repository_name": "cmip-embeddings", "date_all_variable_collection": "2023-09-11", "description": "Cross-model embedding for CMIP data", "size": 27496, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "bgroenks96", "contributions": 38}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 16362182}, {"language": "Python", "num_chars": 9110}], "readme": "# cmip-embeddings\nCross-model embedding for the Coupled Model Intercomparison Project (CMIP)\n"}
{"url": "https://github.com/bgroenks96/csci-5622-project", "owner": "bgroenks96", "repository_name": "csci-5622-project", "date_all_variable_collection": "2023-09-11", "description": "Survey of dimensionality reduction, regression, and deep learning techniques for climate modeling problems", "size": 182261, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 2, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "kegl", "contributions": 21}, {"contributor": "sophiegif", "contributions": 11}, {"contributor": "bgroenks96", "contributions": 6}, {"contributor": "aboucaud", "contributions": 5}, {"contributor": "glemaitre", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 711335}, {"language": "Python", "num_chars": 30435}], "readme": "# csci-5622-project\nSurvey of dimensionality reduction, regression, and deep learning techniques for climate modeling problems\n"}
{"url": "https://github.com/bgroenks96/dnn-community-detection", "owner": "bgroenks96", "repository_name": "dnn-community-detection", "date_all_variable_collection": "2023-09-11", "description": "Community detection in deep nerual networks", "size": 112409, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "mchifala", "contributions": 17}, {"contributor": "bgroenks96", "contributions": 15}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 3982212}, {"language": "Python", "num_chars": 6332}], "readme": "# dnn-community-detection\nCommunity detection in deep nerual networks\n\nThis project has the following dependences:\n\n - standard anaconda3 environment, and\n - graph-tool=2.29 (installed from conda-forge)\n - tensorflow=2.0.0\n - matplotlib=2.2.4\n \nNotes on getting graph-tool drawing to work:\n\n - matplotlib version **must** be < 3.0; use 2.2.4 as specified above\n - For some plotting features, GTK is required. Run the following commands to get it working:\n\n    conda install -c conda-forge pygobject\n    conda install -c pkgw/label/superseded gtk3\n\nTo make sure it's working: `from graph_tool.draw import draw_hierarchy` should succeed with no warnings.\n\n"}
{"url": "https://github.com/bgroenks96/fg-tools", "owner": "bgroenks96", "repository_name": "fg-tools", "date_all_variable_collection": "2023-09-11", "description": "Forerunner Games Utility Library", "size": 855, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "develop", "contributors": [{"contributor": "knightofiam", "contributions": 302}, {"contributor": "bgroenks96", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 473219}], "readme": "Simple Utility Library for Java Game Development\n\n[![Build Status](https://travis-ci.org/forerunnergames/fg-tools.svg?branch=master)](https://travis-ci.org/forerunnergames/fg-tools)\n[![Code Coverage](https://coveralls.io/repos/github/forerunnergames/fg-tools/badge.svg?branch=master)](https://coveralls.io/github/forerunnergames/fg-tools?branch=master)\n[![Code Quality](https://img.shields.io/codacy/7728d4130a9546cdb89cb15b74507ea0/master.svg)](https://www.codacy.com/app/forerunnergames/fg-tools)\n[![License: MIT](https://img.shields.io/badge/license-MIT-blue.svg)](/LICENSE.md)\n"}
{"url": "https://github.com/bgroenks96/generative-downscaling", "owner": "bgroenks96", "repository_name": "generative-downscaling", "date_all_variable_collection": "2023-09-11", "description": "Research and experiments for downscaling climate/weather data via generative learning", "size": 18436, "stargazers_count": 27, "watchers_count": 27, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 11, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 11, "open_issues": 0, "watchers": 27, "default_branch": "master", "contributors": [{"contributor": "bgroenks96", "contributions": 28}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 4225530}, {"language": "Python", "num_chars": 112179}, {"language": "Shell", "num_chars": 2282}], "readme": "## Generative downscaling\n\nThis repository contains experiment code for the Master's thesis, *ClimAlign: Unsupservised statistical downscaling of climate variables via normalizing flows* ([ProQuest](https://search.proquest.com/openview/716b86a33eb0f7a609be1dfa7f0bae8b/1?pq-origsite=gscholar&cbl=18750&diss=y), [Full text](https://drive.google.com/file/d/18BuGh3xHyLh8NDFyoI35WfE_aF2JcZQP/view)).\n\nPre-formatted datasets are not currently available from any public sources. However, the raw data for [ERA-interim](https://climatedataguide.ucar.edu/climate-data/era-interim) and [Rasmussen/WRF](https://rda.ucar.edu/datasets/ds612.0/#!) can be downloaded from NCAR's servers.\n\nThe code in this repository uses [`xarray`](http://xarray.pydata.org/en/stable/) and `dask`. The data is assumed to be in [ZARR](https://zarr.readthedocs.io/en/stable/) format. You can use `xarray` to convert NetCDF files into ZARR datasets.\n\n### Overview\n\nData loaders are provided by `datasource.py`. `EraiRasDataLoader` and `NoaaLivnehDataLoader` provide functions which return file mappings that can be passed to functions such as `xarray`'s `open_zarr`. See the source code in this file for the expected ZARR naming conventions. A Google Cloud service account key file with GCS access must be copied to the repository root directory and named `gcs.secret.json`.\n\nThe `*-downscaling-*` Jupyter notebooks contain experimental code for testing the baseline and ClimAlign models. The `qualitative-analysis` and `quantitative-analysis` notebooks contain the code used to produce the figures and tables in the paper. The `experiments` module contains the experiment scripts for each model and experiment set. The `core-experiment-suite.sh` runs all experiments for the primary quantiative results. Results are stored locally using MLflow.\n\nThe implementation of the ClimAlign model (referred to in this code as Joint Flow-based Latent Variable Model, JFLVM) can be found in the `normalizing-flows` git-submodule.\n\nBaseline implementations can be found in the `baselines` directory/module.\n\nNecessary packages are specified by the conda `envirionment.yml` file.\n\nPlease send any inquiries to brian.groenke@colorado.edu.\n"}
{"url": "https://github.com/bgroenks96/headerify", "owner": "bgroenks96", "repository_name": "headerify", "date_all_variable_collection": "2023-09-11", "description": "Short and simple python tool for batch prepending file headers.", "size": 3, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "bgroenks96", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 2869}], "readme": "# headerify\nShort and simple python tool for batch prepending file headers.\n"}
{"url": "https://github.com/bgroenks96/java-global-input-hook", "owner": "bgroenks96", "repository_name": "java-global-input-hook", "date_all_variable_collection": "2023-09-11", "description": "Global keyboard/mouse input event handling for Java.", "size": 587, "stargazers_count": 2, "watchers_count": 2, "language": "C", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "bgroenks96", "contributions": 19}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C", "num_chars": 148521}, {"language": "Java", "num_chars": 73337}, {"language": "C++", "num_chars": 9817}, {"language": "Shell", "num_chars": 2128}], "readme": "# java-global-input-hook\nGlobal keyboard/mouse input event handling for Java.\n\nOriginal project credit (Java API and Win32 hooks): [Kristian Kraljic](http://kra.lc/blog/2011/07/java-global-system-hook/)\n"}
{"url": "https://github.com/bgroenks96/kubezeug", "owner": "bgroenks96", "repository_name": "kubezeug", "date_all_variable_collection": "2023-09-11", "description": "Utilities for quick and easy distributed computing via dask-kubernetes, with a focus on ML applications.", "size": 8, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "bgroenks96", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 9686}], "readme": "# kubezeug\nUtilities for quick and easy distributed computing via dask-kubernetes, with a focus on ML applications.\n\nTensorflow integration is provided via the `kubezeug.tensorflow` module.\n"}
{"url": "https://github.com/bgroenks96/MHS-Collections-Project", "owner": "bgroenks96", "repository_name": "MHS-Collections-Project", "date_all_variable_collection": "2023-09-11", "description": "Madeira Historical Society project to digitally store historical artifacts for educational and informational use.", "size": 658, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "bgroenks96", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 325475}, {"language": "HTML", "num_chars": 39350}], "readme": "##Madeira Historical Society Collections Project##\n\nThis software is part of a project to digitize and publicize historical artifacts for the educational benefit of the Madeira community and anyone else interested in the city's history.  All components of this project are written in The Java Programming Language, and any native code (although there currently is none) written in The C Programming Language.\n\nWho is allowed to fork this project?\nAnyone!  This project has produced some very interesting and useful code.  The shared-library in particular has a very resourceful codebase that could be applied to many other things.\n\nWho is allowed to collaborate on this project?\nOnly selected individuals, probably involved with the Madeira Historical Society.  The information regarding server-handling and login is not public.\n\nProject Source Components:\n\nEditor -  The editor software for project participants to create, edit and upload artifact data to the database.  Uses the shared library.\nNote: the editor requires FTP server login information, so it's mostly useful for only project collaborators.\nProject status:  Stable\n\nEditor-Launcher - The launcher for the editor software.\nProject status:  Stable\n\nEditor-Updater - The updater for the editor software.\nProject status:  Stable\n\nShared-lib -  API containing classes shared/used by both the Editor and Applet.\nProject status:  Stable\n\nApplet - The front-end Java applet that will be loaded into the MHS webpage and utilized by end-users to view artifact information.  Uses the shared library.\nProject status:  Stable (Deprecated)\n"}
{"url": "https://github.com/bgroenks96/ml-basics", "owner": "bgroenks96", "repository_name": "ml-basics", "date_all_variable_collection": "2023-09-11", "description": "A small collection of basic machine learning method implementations written in Python", "size": 266, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "bgroenks96", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 469248}, {"language": "Python", "num_chars": 46745}], "readme": "# ml-basics\nA small collection of basic machine learning method implementations written in Python\n"}
{"url": "https://github.com/bgroenks96/nextcloud-kube", "owner": "bgroenks96", "repository_name": "nextcloud-kube", "date_all_variable_collection": "2023-09-11", "description": "NextCloud kubernetes deployment", "size": 34, "stargazers_count": 0, "watchers_count": 0, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "bgroenks96", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 43661}], "readme": "### NextCloud via Kubernetes\n\nThese scripts provide a straight-forward, preconfigured NextCloud deployment on a Kubernetes cluster.\n\nPrerequisities:\n\n- `kubectl` and `helm` are both accessible on the system PATH.\n\n- Default stable Helm repository has been added and updated. This can be done via:\n\n`helm repo add stable https://kubernetes-charts.storage.googleapis.com/`\n\nFirst initialize necessary cluster services by running\n\n`./init-cluster <EMAIL>`\n\nreplacing `<EMAIL>` with your email address (this is for TLS certificate registration). This script will install `nginx` and configure the certificate issuer for the cluster. It only needs to be run **once per cluster**.\n\nTo create a new NextCloud deployment, run:\n\n`./deploy <RELEASE> <DOMAIN>`\n\nreplacing `<RELEASE>` with the name of your release/deployment (e.g. \"nextcloud\") and `<DOMAIN>` with the domain name you will use to access it (e.g. nextcloud.example.com).\n\nThe script will output an IP address which must be the target of a DNS A-record for your domain.\n\nThe size of the data partition can be set as an argument to `deploy`:\n\n`./deploy -s 100Gi <RELEASE> <DOMAIN>`\n\nOther options can be supplied; `dry-run` will test the configuration without applying any changes, and `staging` will use the Let's Encrypt staging certificate endpoint to avoid exceeding the quotas for your domain:\n\n`./deploy --dry-run --staging <RELEASE> <DOMAIN>`\n\nAfter deployment, generated configuration files for that release will be placed in the `releases` directory. You can change the configuration options and upgrade the existing deployment using `./update <RELEASE>` where `<RELEASE>` is the same identifier you used when creating the deployment.\n\nNote that the persistent storage configuration options in `storage.yaml` and `nextcloud.values.yaml` currently assume storage type of `do-block-storage` which is specific to DigitalOcean Kubernetes deployments. If you are using another cloud provider, **you will need to change these values**. Check your provider's documentation on persistent storage.\n\nThese scripts and configuration files are provided WITHOUT WARRANTY and by using it you agree to release the author of any potential damages resulting from accidental loss or corruption of your data.\n"}
{"url": "https://github.com/bgroenks96/normalizing-flows", "owner": "bgroenks96", "repository_name": "normalizing-flows", "date_all_variable_collection": "2023-09-11", "description": "Implementations of normalizing flows using python and tensorflow", "size": 12633, "stargazers_count": 21, "watchers_count": 21, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 9, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 9, "open_issues": 0, "watchers": 21, "default_branch": "master", "contributors": [{"contributor": "bgroenks96", "contributions": 72}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["data-science", "machine-learning", "machine-learning-algorithms", "normalizing-flows"], "languages": [{"language": "Jupyter Notebook", "num_chars": 312648}, {"language": "Python", "num_chars": 122194}], "readme": "# normalizing-flows\n\nImplementations of normalizing flows for variational inference using Python (3.6+) and Tensorflow (2.0+).\n\n![flows_visualization](imgs/flows_example.png)\n\n## Installation\n\n    pip install git+https://github.com/bgroenks96/normalizing-flows\n    \n## Getting started\n\nTake a look at the [intro notebook](normalizing-flows-intro.ipynb) for a gentle introduction to normalizing flows.\n\nThis library currently implements the following flows:\n\n- Planar/radial flows [(Rezende and Mohamed, 2015)](https://arxiv.org/pdf/1505.05770.pdf)\n\n- Triangular Sylvester flows [(Van den Berg et al, 2018)](https://arxiv.org/pdf/1803.05649.pdf)\n\n- Glow [(Kingma et al, 2018)](https://papers.nips.cc/paper/8224-glow-generative-flow-with-invertible-1x1-convolutions.pdf)\n\n- AlignFlow<sup>1</sup> [(Grover et al, 2019)](https://arxiv.org/pdf/1905.12892.pdf)\n\n<sup>1</sup> *Implemented via [JointFlowLVM](normalizing_flows/models/joint_flvm.py); the flow architecture from the paper is not currently supported. However, Glow can (and possibly should) be used instead.*\n\n## API overview\n\nThe `normalizing_flows` package currently provides two interfaces for building flow-based models:\n\n1) Marginal inference ([FlowLVM](normalizing_flows/models/flvm.py), [JointFlowLVM](normalizing_flows/models/joint_flvm.py))\n\n2) Variational autoencoder ([GatedConvVAE](normalizing_flows/models/vae.py))\n\nMarginal inference models directly optimize the log-evidence $\\log p(x)$ via the inverse transform of the flow. Note that this requires the flow to support bidirectional (forward + inverse) evaluation. The only flow architecture in this package which supports this (currently) is [Glow](normalizing_flows/flows/glow/glow_flow.py).\n\nVAE inference minimizes the evidence lower bound (ELBO) and thus requires only forward evaluations, $z \\rightarrow z'$ (i.e. the inverse need not be tractable). For VAE inference, Planar, Radial, and Triangular Sylvester flows are all supported via `FlowLayer` (see [the intro notebook](normalizing-flows-intro.ipynb) for an example). In theory, Glow could also be used in a VAE, but this has not been tested and is not currently supported by `FlowLayer`, which assumes the latent space to be dense and non-spatial.\n\n### Exmaple: Planar vs Sylvester flows\n\n*t-SNE mapped latent space across 4 flow steps*\n\n![Planar vs. Sylvester](imgs/tsne_sylvester_planar_flows.png)\n\n## Future development\n\nPlease note that this package was developed for the purposes of the author's own research. As such, it might not be as fully featured or rounded out as other libraries. However, contributions and discussions about new features and flow implementations is both welcome and encouraged!\n\nAdditional types flows under consideration for future versions:\n\n- Orthogonal/Householder Sylvester flows\n\n- Inverse Autoregressive Flows (Kingma et al, 2016)\n\n- Neural Autoregressive Flows (Huang et al, 2018)\n\nCurrently, this library has no published documentation outside of docstrings in the code. This may change in the future.\n\nPlease feel free to create an issue if anything isn't clear or more documentation is needed on specific APIs.\n\n## License and use\n\nThis library is free and open source software under the MIT license."}
{"url": "https://github.com/bgroenks96/peril", "owner": "bgroenks96", "repository_name": "peril", "date_all_variable_collection": "2023-09-11", "description": null, "size": 334473, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "develop", "contributors": [{"contributor": "knightofiam", "contributions": 837}, {"contributor": "bgroenks96", "contributions": 89}, {"contributor": "3xp0n3nt", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 3209322}, {"language": "Shell", "num_chars": 28853}, {"language": "GLSL", "num_chars": 1175}], "readme": "<!---\n  ~ Copyright \u00a9 2011 - 2013 Aaron Mahan.\n  ~ Copyright \u00a9 2013 - 2016 Forerunner Games, LLC.\n  ~\n  ~ This program is free software: you can redistribute it and/or modify\n  ~ it under the terms of the GNU General Public License as published by\n  ~ the Free Software Foundation, either version 3 of the License, or\n  ~ (at your option) any later version.\n  ~\n  ~ This program is distributed in the hope that it will be useful,\n  ~ but WITHOUT ANY WARRANTY; without even the implied warranty of\n  ~ MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n  ~ GNU General Public License for more details.\n  ~\n  ~ You should have received a copy of the GNU General Public License\n  ~ along with this program. If not, see <http://www.gnu.org/licenses/>.\n  -->\n\n[![Travis CI Build Status](https://img.shields.io/travis/forerunnergames/peril/master.svg)][travis]\n[![Code Coverage](https://img.shields.io/codecov/c/github/forerunnergames/peril/master.svg)][codecov]\n[![Code Quality](https://img.shields.io/codacy/grade/bf2b210c63de4349827e7aadaf019825/master.svg)][codacy]\n[![License (code): GPLv3](https://img.shields.io/badge/license%20[code]-GPLv3-blue.svg)][gpl-v3]\n[![License (assets): CC BY-SA 4.0](https://img.shields.io/badge/license%20[assets]-CC%20BY--SA%204.0-blue.svg)][cc-by-sa-4]\n\n[travis]: https://travis-ci.org/forerunnergames/peril\n[codecov]: https://codecov.io/github/forerunnergames/peril?branch=master\n[codacy]: https://www.codacy.com/app/forerunnergames/peril\n[gpl-v3]: /legal/GPLv3.txt\n[cc-by-sa-4]: /legal/CC-BY-SA-4.txt\n\n```\nperil [per-uhl] (noun)\n\n1. A situation of serious and immediate danger.\n\nSee also: Risk\n\n[from Old French peril, from Latin per\u012bculum]\n```\n\n# Licenses\n\n#### Code\n\n[GNU General Public License Version 3](http://www.gnu.org/licenses/gpl.html)\n\n<a href=\"http://www.gnu.org/licenses/gpl.html\"><img alt=\"GPL v3 logo\" src=\"http://www.gnu.org/graphics/gplv3-127x51.png\" height=\"51\"></a>\n\n#### Assets\n[Creative Commons Attribution-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/)\n\n<a href=\"https://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"CC-BY-SA 4.0 Logo\" src=\"http://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-sa.png\" height=\"51\"></a>\n"}
{"url": "https://github.com/bgroenks96/pyclimdex", "owner": "bgroenks96", "repository_name": "pyclimdex", "date_all_variable_collection": "2023-09-11", "description": "Implementation of Climdex indices in Python/xarray/dask", "size": 15, "stargazers_count": 7, "watchers_count": 7, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 6, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 6, "open_issues": 0, "watchers": 7, "default_branch": "master", "contributors": [{"contributor": "bgroenks96", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 12667}, {"language": "Jupyter Notebook", "num_chars": 764}], "readme": "# pyclimdex\nImplementation of Climdex indices in Python/xarray/dask\n\n### Usage\n\n1. Install from pypi:\n\n```\npip install pyclimdex\n```\n\nor from GitHub:\n\n```\npip install git+https://github.com/bgroenks96/pyclimdex.git\n```\n\n2. Import either temperature or precipitation indices\n\n```python\nimport climdex.precipitation as pdex\n```\n\n3. Initialize indices and compute them on your xarray DataArray or Dataset\n\n```python\n   indices = pdex.indices(time_dim='time')\n   # compute total monthly precipitation;\n   # your data should be daily or sub-daily time scale\n   ptot = indices.prcptot(data, period='1M')\n```\n\nThat's it! You can find more info on the Climdex indices [here](https://climdex.org).\n\n`pyclimdex` currently supports the following indices for temperature and precipitation respectively:\n\n**Temperature**\n\n- Annual frost days\n- Annual tropical nights\n- Annual icing days\n- Annual summer days\n- Monthly max daily max temp (TXx)\n- Monthly min daily max temp (TXn)\n- Monthly max daily min temp (TNx)\n- Monthly min daily min temp (TNx)\n- Daily temperature range (DTR)\n\n**Precipitation**\n\n- Monthly 1-day precip (Rx1day)\n- Monthly 5-day precip (Rx5day)\n- Annual 10mm precip days\n- Annual 20mm precip days\n- Annual n mm precip days\n- Total precipitation (variable time period)\n- Simple intensity index (SDII)\n- Consecutive dry days (CDD)\n- Consecutive wet days (CWD)\n\nIndices which rely on historical data are not currently supported. Contributions are welcome!\n"}
{"url": "https://github.com/bgroenks96/SharpGameLib", "owner": "bgroenks96", "repository_name": "SharpGameLib", "date_all_variable_collection": "2023-09-11", "description": "A collection of libraries and utilities developed while making a 2D platformer in C# and MonoGame", "size": 84, "stargazers_count": 0, "watchers_count": 0, "language": "C#", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "bgroenks96", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C#", "num_chars": 309285}], "readme": "A simple 2D game library for C# Mono/.NET built on top of MonoGame.\n\nThe code in this project was produced for the purposes of an academic project and should be used for reference only. It is not being actively maintained.\n\n\n"}
{"url": "https://github.com/bgroenks96/SmartProperties.NET", "owner": "bgroenks96", "repository_name": "SmartProperties.NET", "date_all_variable_collection": "2023-09-11", "description": "Extension to the .NET INotifyPropertyChanged API that allows you to build a propagation tree for dependent properties.", "size": 18, "stargazers_count": 0, "watchers_count": 0, "language": "C#", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "bgroenks96", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C#", "num_chars": 22736}], "readme": "# SmartProperties.NET\nExtension to the .NET INotifyPropertyChanged API that allows you to build a propagation tree for dependent properties.\n\nA common problem in UI or event-based programming (especially MVVM) is that of _dependent properties_, i.e. those whose values are calculated from other properties in your object.\n\nOne solution to this problem is to manually call `OnPropertyChanged` in a property setter on behalf of all its dependencies:\n\n    public string MyProp\n    {\n      get\n      {\n        return this.myProp;\n      }\n      \n      set\n      {\n        this.myProp = value;\n        this.OnPropertyChanged(nameof(MyDependentProp));\n        this.OnPropertyChanged();\n      }\n    }\n    \nThis, however, gets unwieldy and hard to follow very quickly.\n\nSmartProperties is a simple tool that allows you to statically declare your property dependencies via _attributes_ and create a `PropertyModel` for your object implementing `INotifyPropertyChanged`.\n\nBasic usage looks like this:\n\n    using SmartProperties;\n\n    // MyObject extends SmartProperties type 'NotifyPropertyChangedBase' which takes care\n    // of wiring up your object's PropertyModel for you.\n    public class MyObject : NotifyPropertyChangedBase\n    {\n      public string MyProp\n      {\n        ... (normal property changed code here)\n      }\n      \n      [DependsOn(nameof(MyProp))]\n      public string MyDependentProp\n      {\n        ... (normal property changed code here)\n      }\n    }\n    \nAnd that's it! Now, whenever `MyProp` fires a `PropertyChanged` event, `OnPropertyChanged` will be invoked for `MyDependentProp` as well. This allows you to build dependency trees for your object properties using simple, easy-to-follow code without all of the boiler plate of managing those dependencies yourself.\n\nIt is also guaranteed that each property in the dependency tree **will only be invoked once** during a single property changed event propagation. The order of propagation is _breadth-first_ meaning that properties will only have their changed events fire _after_ each of their dependencies' events have been fired.\n\n## Other usage notes\nSince properties will only have their property changed events invoked once, dependency cycles are permitted:\n\n    [DependsOn(nameof(B))]\n    public string A\n    {\n      ...\n    }\n    \n    [DependsOn(nameof(A))]\n    public string B\n    {\n      ...\n    }\n    \nSelf-dependencies, however, are not allowed (for hopefully obvious reasons):\n\n    // Will throw exception at runtime\n    [DependsOn(nameof(A))]\n    public string A\n    {\n      ...\n    }\n\nIf you don't want to (or can't) inherit from `NotifyPropertyChangedBase`, you can initialize a `PropertyModel` for your object yourself in the constructor:\n\n    public class MyObject\n    {\n      public MyObject()\n      {\n        // OnPropertyChanged should have the standard signature for OnPropertyChanged implementations.\n        // 'Create' returns a PropertyModel reference, but this can be discarded unless you wish to\n        // explicitly deregister its event delegate via the Dispose() method.\n        PropertyModel.Create(this, this.OnPropertyChanged);\n      }\n    }\n    \nNote also that `PropertyModel` is NOT thread-safe. It is assumed that your property changed events will be fired in a single-threaded context (which is usually the case). Asynchronous event invocation (especially while propagation is already in progress) will lead to undefined behavior.\n"}
{"url": "https://github.com/bgroenks96/vol-rendering-research", "owner": "bgroenks96", "repository_name": "vol-rendering-research", "date_all_variable_collection": "2023-09-11", "description": "OSU/CSE Volume Rendering mini-project", "size": 132, "stargazers_count": 0, "watchers_count": 0, "language": "Scala", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "bgroenks96", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Scala", "num_chars": 12558}, {"language": "GLSL", "num_chars": 5133}]}
{"url": "https://github.com/blblblu/asami", "owner": "blblblu", "repository_name": "asami", "date_all_variable_collection": "2023-09-11", "description": "simple pixel sorter", "size": 6732, "stargazers_count": 0, "watchers_count": 0, "language": "Go", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 2, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "blblblu", "contributions": 60}, {"contributor": "caarlos0", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Go", "num_chars": 5864}], "readme": "# asami\n\n[![Powered By: GoReleaser](https://img.shields.io/badge/powered%20by-goreleaser-green.svg?style=flat-square)](https://github.com/goreleaser)\n\npixel sorter using simple brute sorting\n\n## installation\n\n`go get -u github.com/blblblu/asami`\n\n## usage\n\n```\n> asami --help\n```\n\n```\nsimple image corrupter\n\nUsage:\n  asami [command]\n\nAvailable Commands:\n  sort        simple brute pixel sorting\n\nUse \"asami [command] --help\" for more information about a command.\n```\n\n```\nasami sort --help\n```\n\n```\nsimple brute pixel sorting\n\nUsage:\n  asami sort [flags]\n\nFlags:\n  -i, --input string    the input file path to use\n      --inverted        inverts the sorting direction\n      --max int         the maximum chunk size to use (default 64)\n      --min int         the minimum chunk size to use (default 32)\n  -o, --output string   the output file path to use, must be a png file\n```\n"}
{"url": "https://github.com/blblblu/Clattr", "owner": "blblblu", "repository_name": "Clattr", "date_all_variable_collection": "2023-09-11", "description": "Clattr - Easily create LaTeX letters (lattr rewritten in C++)", "size": 136, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "blblblu", "contributions": 18}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 19006}, {"language": "TypeScript", "num_chars": 13460}, {"language": "Prolog", "num_chars": 804}], "readme": "Clattr - Easily create LaTeX letters\n====================================\n\nLicence\n-------\n\n>    Copyright (C) 2012  Sebastian Schulz\n>\n>    This program is free software: you can redistribute it and/or modify\n>    it under the terms of the GNU General Public License as published by\n>    the Free Software Foundation, either version 3 of the License, or\n>    (at your option) any later version.\n>\n>    This program is distributed in the hope that it will be useful,\n>    but WITHOUT ANY WARRANTY; without even the implied warranty of\n>    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n>    GNU General Public License for more details.\n>\n>    You should have received a copy of the GNU General Public License\n>    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n"}
{"url": "https://github.com/blblblu/esp8266_led_demo", "owner": "blblblu", "repository_name": "esp8266_led_demo", "date_all_variable_collection": "2023-09-11", "description": "Remotely control an led that is connected to an ESP8266 over wifi via smartphone app", "size": 99, "stargazers_count": 0, "watchers_count": 0, "language": "Dart", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "blblblu", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Dart", "num_chars": 2806}, {"language": "Arduino", "num_chars": 1674}, {"language": "Objective-C", "num_chars": 750}, {"language": "Java", "num_chars": 372}], "readme": "# ESP8266 LED Demo\n\nThis is a little example to show how to remotely control an ESP8266 over wifi with your smartphone.\n\n[![demo video](https://img.youtube.com/vi/CBABLYRuyJc/0.jpg)](https://www.youtube.com/watch?v=CBABLYRuyJc)\n\nThe [Arduino code](esp8266_server/main.ino) creates a web server which reacts to the routes `http://[url]/on` `http://[url]/off` which will turn a connected led on and off respectively.\n\nThe [smartphone app](flutter_app/lib/main.dart) consists of an input field for the url/ip address of your ESP and two buttons to turn your led on or off by requesting the corresponding url.\n"}
{"url": "https://github.com/blblblu/lattr", "owner": "blblblu", "repository_name": "lattr", "date_all_variable_collection": "2023-09-11", "description": "A little application to create letters in LaTeX easily", "size": 136, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "blblblu", "contributions": 26}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 10744}, {"language": "Prolog", "num_chars": 90}], "readme": "lattr - Easily create LaTeX letters\n===================================\n\nLicence\n-------\n\n>    Copyright (C) 2011  Sebastian Schulz\n>\n>    This program is free software: you can redistribute it and/or modify\n>    it under the terms of the GNU General Public License as published by\n>    the Free Software Foundation, either version 3 of the License, or\n>    (at your option) any later version.\n>\n>    This program is distributed in the hope that it will be useful,\n>    but WITHOUT ANY WARRANTY; without even the implied warranty of\n>    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n>    GNU General Public License for more details.\n>\n>    You should have received a copy of the GNU General Public License\n>    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nRequisites\n----------\n\nTo use lattr, you need\n\n- Git (just for the installation)\n- Python 3\n- PyQt\n- (pdf)LaTeX (if you want to convert your *.tex file directly in lattr)\n\nInstallation\n------------\n\n\tgit clone git://github.com/blblblu/lattr.git\n\tcd lattr/\n\tpython lattr.py\n\non systems with Python 2 as standard, the last line has to be\n\n\tpython3 lattr.py"}
{"url": "https://github.com/blblblu/leri", "owner": "blblblu", "repository_name": "leri", "date_all_variable_collection": "2023-09-11", "description": "generate markdown documents from source code comments", "size": 82, "stargazers_count": 2, "watchers_count": 2, "language": "Go", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "blblblu", "contributions": 15}, {"contributor": "caarlos0", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Go", "num_chars": 5778}], "readme": "# leri\n\n[![Powered By: GoReleaser](https://img.shields.io/badge/powered%20by-goreleaser-green.svg?style=flat-square)](https://github.com/goreleaser)\n\na small (and currently quite limited) command line tool to generate markdown files from source code comments\n\n## why?\n\nI used *leri* mainly to generate some tutorial-like documents from heavily documented source code.\n\n## features\n\n*leri* currently only supports `.go` and `.sas` files, but could be extended easily by defining own regular expressions to match comments that should be interpreted as documentation, (see: `lib/parsing/parser.go` and parser usage in file `lib/commands/genmd.go`).\n\n## installation\n\n```\ngo get github.com/blblblu/leri/cmd/leri\n```\n\n(or download a pre-compiled version from the [releases page](https://github.com/blblblu/leri/releases))\n\n## usage example\n\nLet's assume you have a file `lorem.go` with following content:\n\n```go\npackage ecs\n\nimport \"github.com/blblblu/reba/env\"\n\n// Initer is used for Systems or Entities that want to initialized based on the env.Context before the main loop\ntype Initer interface {\n\tInit(ctx *env.Context)\n}\n\n// Updater is used for Systems that want to be involved in the main loop\ntype Updater interface {\n\tUpdate(ctx *env.Context)\n}\n\n// Cleanuper is used for Systems that want to free resources (like e.g. deleting OpenGL buffers etc.)\ntype Cleanuper interface {\n\tCleanup(ctx *env.Context)\n}\n```\n\nWhen running `leri gen -i lorem.go -o lorem.md`, *leri* will recognize each `//` comment that starts at the beginning of the line as documentation, and will create the following `lorem.md` file:\n\n    ```go\n    package ecs\n\n    import \"github.com/blblblu/reba/env\"\n\n    ```\n\n    Initer is used for Systems or Entities that want to initialized based on the env.Context before the main loop\n\n    ```go\n    type Initer interface {\n      Init(ctx *env.Context)\n    }\n\n    ```\n\n    Updater is used for Systems that want to be involved in the main loop\n\n    ```go\n    type Updater interface {\n      Update(ctx *env.Context)\n    }\n\n    ```\n\n    Cleanuper is used for Systems that want to free resources (like e.g. deleting OpenGL buffers etc.)\n\n    ```go\n    type Cleanuper interface {\n      Cleanup(ctx *env.Context)\n    }\n\n    ```\n\nwhich will look as follows:\n\n---\n\n\n```go\npackage ecs\n\nimport \"github.com/blblblu/reba/env\"\n\n```\n\nIniter is used for Systems or Entities that want to initialized based on the env.Context before the main loop\n\n```go\ntype Initer interface {\n  Init(ctx *env.Context)\n}\n\n```\n\nUpdater is used for Systems that want to be involved in the main loop\n\n```go\ntype Updater interface {\n  Update(ctx *env.Context)\n}\n\n```\n\nCleanuper is used for Systems that want to free resources (like e.g. deleting OpenGL buffers etc.)\n\n```go\ntype Cleanuper interface {\n  Cleanup(ctx *env.Context)\n}\n\n```\n"}
{"url": "https://github.com/blblblu/mesa-error-test", "owner": "blblblu", "repository_name": "mesa-error-test", "date_all_variable_collection": "2023-09-11", "description": null, "size": 172, "stargazers_count": 0, "watchers_count": 0, "language": "CMake", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "blblblu", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "CMake", "num_chars": 4423}, {"language": "C++", "num_chars": 2773}]}
{"url": "https://github.com/blblblu/rgba-channel-merge", "owner": "blblblu", "repository_name": "rgba-channel-merge", "date_all_variable_collection": "2023-09-11", "description": "merge colour channels of multiple images", "size": 13, "stargazers_count": 0, "watchers_count": 0, "language": "Go", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "blblblu", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Go", "num_chars": 4708}], "readme": "# rgba-channel-merge\n\nA little command line tool to merge specific channels of multiple images into one RGBA image.\n\n## installation\n\n```\ngo get github.com/blblblu/rgba-channel-merge\n```\n\n## usage example\n\nUse the red, green and blue channel from first.png as green blue and red (in that order), and the alpha channel from second.png as alpha channel:\n\n```\n> rgba-channel-merge first.png gbrx second.png xxxa output.png\n```\n\nTODO: more readme...\n"}
{"url": "https://github.com/blblblu/simple-http-server", "owner": "blblblu", "repository_name": "simple-http-server", "date_all_variable_collection": "2023-09-11", "description": "really simple (and probably insecure) http server written in python using only tcp sockets", "size": 10, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "blblblu", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 8535}, {"language": "HTML", "num_chars": 3779}], "readme": "TODO: translate readme...\n\n# simple http server\n\nDer Wert f\u00fcr den zu verwendenden Port kann \u00fcber das Kommandozeilenargument\n`--port` bzw. `-p` angegeben werden, also zum Beispiel wie folgt:\n\n    >>> python3 server.py -p 3000\n    listening on port 3000\n    press CTRL-C to shut down the server\n    [...]\n\nWird kein bestimmter Port angegeben, wird ein beliebiger freier Port genutzt.\n\nDie auszuliefernden Daten sind im Unterordner `static` zu finden, die im Falle\nvon Fehler- oder Statusmeldungen auszuliefenden Daten befinden sich im\nUnterordner `status`. Sollte man diese Pfade \u00e4ndern wollen, so findet man die zu\n\u00e4ndernden Variablen in Zeile 24 und 25:\n\n    DOCUMENT_ROOT_DIR = 'static'\n    STATUS_DIR = 'status'\n\nBei einer Eingabe von `CTRL-C` wird der Server gestoppt. Dabei wartet der Server\nnoch auf den Abschluss von noch ausstehenden Anfragen. Besteht hierbei noch eine\nVerbindung von einem Client zum Server, w\u00fcrde dieser somit noch bis zum\nBeantworten dieser Anfrage warten, und erst danach herunterfahren. M\u00f6chte man\nein sofortiges Herunterfahren des Servers erzwingen, ist die erneute Eingabe von\n`CTRL-C` n\u00f6tig.\n"}
{"url": "https://github.com/blblblu/wigl-vorlage", "owner": "blblblu", "repository_name": "wigl-vorlage", "date_all_variable_collection": "2023-09-11", "description": null, "size": 140, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "blblblu", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 9728}, {"language": "Shell", "num_chars": 426}], "readme": "# wigl-vorlage\n"}
{"url": "https://github.com/blblblu/wiwi-latex-template", "owner": "blblblu", "repository_name": "wiwi-latex-template", "date_all_variable_collection": "2023-09-11", "description": null, "size": 329, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "blblblu", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 4987}]}
{"url": "https://github.com/blblblu/yasnake", "owner": "blblblu", "repository_name": "yasnake", "date_all_variable_collection": "2023-09-11", "description": null, "size": 2107, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "blblblu", "contributions": 42}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 49832}, {"language": "HTML", "num_chars": 18408}, {"language": "QMake", "num_chars": 2957}], "readme": "yaSnake\n======\n\nyet another snake clone\n"}
{"url": "https://github.com/bmarv/collaborative-online-music", "owner": "bmarv", "repository_name": "collaborative-online-music", "date_all_variable_collection": "2023-09-11", "description": null, "size": 568, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 7, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 7, "watchers": 0, "default_branch": "develop", "contributors": [{"contributor": "bmarv", "contributions": 138}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 59626}, {"language": "HTML", "num_chars": 4041}, {"language": "Pug", "num_chars": 3093}, {"language": "Shell", "num_chars": 343}, {"language": "CSS", "num_chars": 267}, {"language": "Makefile", "num_chars": 141}], "readme": "# collaborative-online-music\n\n## Development-Versions\n* 0.0.1-ws-architecture\n* 0.0.2-ws-file-transfer\n* 0.0.3-broadcast-server-message\n* 0.0.4-client-recording\n* 0.0.5-host-metronome\n* 0.0.6-local-network-hosting\n* 0.0.7-server-media-rendering\n* 0.0.8-server-media-synchronization\n\n<br><br>\n\n## Installation\nThis Program is build with the node-version 10.19 and requires as dependencies ffmpeg for server-side media-manipulation and openssl for hosting with an ssl-certificate, which is installable on debian-based systems with the following command:\n```bash\napt update\napt install -y ffmpeg openssl\n```\n\\\nTo build this node program, make sure, that the node package manager is installed and run the following command:\n```bash\nnpm install\n```\n\n## SSL-Certificate\nThe https-protocol is needed to run the program on the client-side with the usage of the usermedia. After installing openssl for the ssl-certificate, it is possible to automatically create and self-sign the certificate with the following make-target, which uses a shell-script:\n```bash\nmake configure-and-sign-ssl-cert\n```\n\\\nIf a new ssl-certificate is needed, it is possible to delete the created ssl-certificate and to create a new one using the following make-targets:\n```bash\nmake delete-certs\nmake configure-and-sign-ssl-cert\n```\n\n## Usage\nTo run the program on a linux system, use the following node-script to run it on port 3000:\n```bash\nnpm run dev\n```\nAfter the program is build, make sure to know the ip-address of the host system, which now runs the program. The ip-address can be found for every installed network-interface for example with the following command (make sure to use the ipv4 command of the interface that you are using):\n```bash\nifconfig\n```\nNow the hosted program is reachable on the entrypoint:\n`https://<ipv4-address>:3000/`\n\nIf it is needed to host the program exposed, then it is required to create a .env file containing the exposed ipv4-Address.\nThe Contents of the .env -File looks as follows:\n```\nIP_ADDRESS=::ffff:<ipv4-address>\n```\n\n### Host\nTo run the program as a host, please navigate to the endpoint `/host` and expect a warning from the site, as the ssl-certificate is self-signed, which offers a potential security-risk to the client. \\\nIf you trust the program, you will see a screen with your uuid, which is the unique identifier for the host during the whole session. \\\nNow it is needed to define the constraints for the **metronome**, which are safed to the session-context, once the metronome has started and stopped. It is also needed to define **start sounds**, that are separated by a commas. Again, it is needed to save the sounds to the session-context using the respective button. \n<br><br>\nWhen the clients have registered to the program it is possible to **start the recording** of the clients with the button *broadcast start* and to **end the recording** with the button *broadcast stop*.\\\nNow the clients need to send the created videofiles to the server; once these files have been uploaded to the server, the host needs to **prepare** the client video-files by adjusting the resolution to, by default, 480p in height and width.\\\nAs the client implicitly send meta-informations about their recording, it is possible to apply one of the following **merging strategies** by cutting the videos regarding the send timestamp from the meta-informations of each client: Recording Start, Metronome Start, Singing Start. Another merging strategy is merging by the first audio peak, where the client audio-tracks of the video files will be analyzed regarding the loudness for every timestep. These results are used to calculate the moving average of 7 neighbored timesteps, so that it is possible to find real loudness peaks in the audio. A hardcoded argument for a peak is, when the proceeding moving average has a positive change of 30db. The client-videos will then be cut from their first audio peak.\\\nAfter these steps have been applied, it is possible to **merge** the videos into one output file with the respective button. After the merge has been finalized, the host will receive the synchronized and merged video-file from the server automatically.\n<br><br>\n**Please note, that each step for modifying the videos results in a blocking state of the server, as this happens synchronous and therefore the host needs to be patient and should have access to the server-logs and resource-monitor.**\n\n### Client\nAs a client, it is possible to use this program using this endpoint: `/client`.\nAfter accepting the warning about a potential security-risk due to the self-signed ssl-certificate, the client will be prompted to give the site permissions for using the videostream and microphone. After the client has given these permissions, the client should see the uuid, which is the unique idenfier of the client for the whole session. Buttons for **stopping or muting the metronome** can be triggered, but are highly advised to not be used! \\\nAfter the host has configured the constraints for the program and starts the broadcast, the clients can see the broadcast-start message in the console on the top of the screen. A metronome starts counting in 2 bars and will be muted by default afterwards. A visually rendered metronome is shown additionally throughout the whole session, if the button to stop the metronome is not clicked. \\\nAfter the host stopped the broadcast, the recorded video will be saved to the client, which results mostly in a prompt message by the used browser. Now it is neccessary by the client to upload this video-file by using the **choose file** button below the rendered client-video-stream. The created file is named after the client-uuid and the current timestamp.\n\n\n## CLIENT OS x Browser-Compability:\n| OS x Browser  | Firefox     | Chrome| Safari    | Edge  |\n| ---           | ---         | ---   | ---       | ---   |\n| OSX            |  user-media not available | :heavy_check_mark: | :heavy_check_mark: | :radio_button: |\n| Linux   | :heavy_check_mark:    | :heavy_check_mark: |  :radio_button: | :radio_button:|\n| Windows | :heavy_check_mark: | :heavy_check_mark: | :radio_button: | :heavy_check_mark: | \n| iOS | ws-session not initialized  | ws-session not initialized | ws-session not initialized | :radio_button: |\n| Android   | :heavy_check_mark: | :heavy_check_mark: | :radio_button: | :radio_button: |\n\n<br><br>\n\n## SERVER OS-Compability:\n* ffmpeg:\n    * works on linux\n    * macos has a no measurable runtime (termination not encountered yet)\n* windows is not supported (filesystem)"}
{"url": "https://github.com/bmarv/Currency-Tracker", "owner": "bmarv", "repository_name": "Currency-Tracker", "date_all_variable_collection": "2023-09-11", "description": "A Currency Tracker for the most common 30 currencies, that shows also the progress of the last month", "size": 1055, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "bmarv", "contributions": 19}, {"contributor": "dependabot[bot]", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 28204}, {"language": "HTML", "num_chars": 1721}, {"language": "CSS", "num_chars": 135}], "readme": "# Currency Tracker\n\nA live version can be found [here](https://currency-tracker.netlify.app/).\n\n_build with ReactJS._\n\n## Overview\n\nThis program enables a precise currency conversion for the most common currencies.\n\n## Functionality\n\nOn the left side of the program, the base-currency and the second currency can be choosen from a list, initially the currencies are set as _EUR_ and _USD_. Below, the conversion-rate for the currency can be read as: _1_ EUR is worth _x_ USD. <br />\nOn the right side  a line-diagram maps the conversion-rate of the second currency for the preceeding month.\n\n## Data\n\nThis project uses the data from the API of [Rates API](https://ratesapi.io/), which includes over 30 currencies and daily real-time data published by the European Central Bank. <br />\nI do not guarantee the accuracy of the data.\n\n## Acknowledgement\n\nThis program was build purely with ReactJS. The development of this project was independent.\n"}
{"url": "https://github.com/bmarv/Intelligent-Editor-Environment-App", "owner": "bmarv", "repository_name": "Intelligent-Editor-Environment-App", "date_all_variable_collection": "2023-09-11", "description": "This Editor is a tool for reliable Textanalysis and Random Text Generation. Executable Files for Windows as well as a Documentation in German and a Jupyther-Notebook with relevant Code-Fragments are included in this Project.", "size": 79911, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "bmarv", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 255635}, {"language": "Python", "num_chars": 65240}], "readme": "# Intelligent-Editor-Environment\n\nDas Programm *Intelligent Editor Environment* bietet eine\nM\u00f6glichkeit zur Textanalyse hinsichtlich der Zipf-Verteilung der W\u00f6rter\ndes Textes. Unter anderem sind ein Texteditor, ein Tool zur Textgenerierung \nsowie die Berechnung der Probability-Mass-Function des Zipfschen Gesetzes implementiert. \n\nEine vollst\u00e4ndige [Dokumentation](https://github.com/bmarv/Intelligent-Editor-Environment/blob/master/Dokumentation/Simulation%20und%20Modellierung%20-%20Textstatistik%20-%20Intelligent%20Editor%20Environment-%20Marvin%20Beese.pdf) \nmit einer detaillierten Beschreibung aller Programmteile und der \nmathematischen Hintergr\u00fcnde ist unter [./Dokumentation/](https://github.com/bmarv/Intelligent-Editor-Environment/tree/master/Dokumentation) einsehbar. \n\nZudem ist ein [Jupyter-Notebook](https://github.com/bmarv/Intelligent-Editor-Environment/blob/master/Jupyter/IEE%20-%20Textstatistik.ipynb)\nmit relevanten Code-Fragmenten und einer Analyse unter [./Jupyter/](https://github.com/bmarv/Intelligent-Editor-Environment/tree/master/Jupyter) vorhanden.\n\n## Nutzung\n\n\u00dcber die herk\u00f6mmliche Ausf\u00fchrung von Python-Programmen hinaus ist auch eine ausf\u00fchrbare Windows-Executable Dateien\nim Verzeichnis [./dist/](https://github.com/bmarv/Intelligent-Editor-Environment/tree/master/dist) verf\u00fcgbar.\n\n## Installation\nDie f\u00fcr eine Installation ben\u00f6tigten Pakete sind in der Datei _requirements.txt_ beinhaltet und k\u00f6nnen mit pip installiert werden mithilfe des folgenden Befehls\n```bash\npip install -r requirements.txt\n```\nSollte es unter Debian-basierten Linuxdistributionen zu Problemen bei der Installation kommen, k\u00f6nnte die manuelle Installation von tkinter und wheels vonn\u00f6ten sein. _tkinter_ kann als apt-Installation und wheels als pip-Installation bezogen werden.\n\n## Programmteile\n\nDas Programm ist unterteilt in mehrere Bestandteile. Die Benutzeroberfl\u00e4che\nund elementare Programmteile sind im Package [Basic Gui](https://github.com/bmarv/Intelligent-Editor-Environment/tree/master/Basic_Gui) beinhaltet. \n\nDie Analysen zur Texteingabe, Dateiinformation und mathematischen Metriken sind im\nPackage [Statistics](https://github.com/bmarv/Intelligent-Editor-Environment/tree/master/Statistics) und die Textgenerierung im Package Generation implementiert.\nAlle relevanten mathematischen und Textgenerierungs-Funktionen wurden im Package [Testing](https://github.com/bmarv/Intelligent-Editor-Environment/tree/master/Testing) mithilfe von *Pytest* auf ihre Korrektheit getestet.\n\n## Zusammenfassung\n\nMithilfe dieses Programmes ist berechenbar, dass\nalle hinreichend gro\u00dfen Texte eine Wortverteilung haben, die einer Zipf-Verteilung\nentsprechen. Hierbei ist die Sprache des Textes nicht ausschlaggebend, da dies ein\nphysikalisches Ph\u00e4nomen ist, das auch in anderen Gebieten au\u00dferhalb der Linguistik Anwendung findet. \nIn diesem Programm kann die Steigung der Verteilung, der Exponent der Verteilung\nund mit der Probability-Mass-Function die Anzahl der Vorkommen berechnet werden.\n\nDieses Programm skaliert als Editor problemlos auch f\u00fcr gro\u00dfe Dokumente. \nBei der mathematischen Analyse gibt es eine deutliche Verz\u00f6gerung bei der Berechnung \nund grafischen Darstellung von gro\u00dfen Daten hohen Ranges, weswegen\nvon einer Limit-Setzung von \u00fcber 1000 dringend abgeraten wird. Die zuf\u00e4llige\nTextgenerierung skaliert hingegen auch bei einer Limitsetzung von \u00fcber 20000\nZeichen problemlos und mit einer sehr geringen Verz\u00f6gerung.\n\nEine Kurzfassung des Programmes gibt mittels [Jupyter-Dokument](https://github.com/bmarv/Intelligent-Editor-Environment/blob/master/Jupyter/IEE%20-%20Textstatistik.ipynb) Auskunft\n\u00fcber Programmabschnitte und Ergebnisse der Analyse von *Die Leiden des jungen Werthers*.\n"}
{"url": "https://github.com/bmarv/Psychology_Experiment", "owner": "bmarv", "repository_name": "Psychology_Experiment", "date_all_variable_collection": "2023-09-11", "description": "encoding during the stimulation of the vagus nerve, recognition in an unattended online session", "size": 49, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "bmarv", "contributions": 39}, {"contributor": "d-linkiewicz", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 31951}], "readme": "# Psychology_Experiment\n\n## Installation\n* Python-Version: 3.9 \n\nDie Installation von python-tk ist auf dem Zielsystem mit Unix vonn\u00f6ten. \nAndere Abh\u00e4ngigkeiten m\u00fcssen mit pip installiert werden.\n```bash\npip install -r requirements.txt\n```\n\n## Benutzung\nF\u00fcr einen Durchlauf mit Encoding-Daten bitte nach der Installation folgenden Befehl verwenden:\n```bash\npython -c 'import Main; Main.run_build_encoding_table()'\n```\nF\u00fcr Recognition-Daten erfolgt der analoge Befehl:\n```bash\npython -c 'import Main; Main.run_build_recognition_table()'\n```\nSollen sowohl die Encoding- als auch die Recognition-Daten in eine einheitliche Tabelle geb\u00fcndelt werden, so gilt der folgende Befehl:\n```bash\npython -c 'import Main; Main.run_build_unified_table()'\n```\n_Hinweis: Bei der geb\u00fcndelten Tabelle gibt es nachfolgend eine Abfrage f\u00fcr den Stimuluslisten-Pfad, 2 Abfragen f\u00fcr die Encoding- und 2 Abfragen f\u00fcr die Recognition-Pfade. Sollen nicht .csv sondern .xlsx -Dateien ausgegeben werden, so sind f\u00fcr die vorigen Befehle noch das Argument \"excel\" einzuf\u00fcgen._\n___\nIn dieser Readme wird erst kurz der Experimentablauf beschrieben, die Benutzerf\u00fchrung, sowie die allgemeine und die technische Struktur des Programms.\n\n## Ablauf des Experiment:\nDas Experiment zur Vagusnerv Stimulation ist in zwei Teile unterteilt, A und B. Diese unterteilen sich in nochmals in je zwei Versuche. Diese Versuche sind in das \u201eEncoding\u201c und das \u201eRecognition\u201c.\nDas \u201eEncoding\u201c erfolgt im Labor. Das \u201eRecognition\u201c f\u00fchrt der Proband 24-48 Stunden sp\u00e4ter am eigenen Rechner aus.\nBei dem \u201eEncoding\u201c werden erst Gesichtsausdr\u00fccke Stimmungen zu geordnet und anschlie\u00dfend werden Worte Stimmungen zugeordnet.\nBei dem \u201eRecognition\u201c versucht die Versuchsperson eben jene Gesichtsausdr\u00fccke und anschlie\u00dfend die Worte aus dem \"Encoding\" wieder zu erkennen und auf einer Skala von 1-11 anzugeben wie sicher sie sich der Antwort ist. \nAlle Werte werden dabei in .txt-Dateien gespeichert. Meta-Informationen \u00fcber die Probanden sind in  .csv und .xlsx Dateien hinterlegt. \nDas in diesem Rahmen entwickelte Programm liest die Dateien ein, ordnet die gefundenen Daten den Probanden und den Stimuli zu und gibt sie in einer gro\u00dfen Tabelle aus.\n\n\n## Benutzerf\u00fchrung des Programmes f\u00fcr die Ausf\u00fchrung:\nIm Folgenden wird der Ablauf der Benutzerf\u00fchrung des Programmes anhand des Beispiels f\u00fcr das Encoding (Recognition funktioniert analog). \nDer Benutzer wird nacheinander aufgefordert mehrere Verzeichnisse auszuw\u00e4hlen. \nBei der 1. Aufforderung soll das Verzeichnis, in dem die Stimuli Listen abgelegt sind, angegeben werden.\nBei der 2 Aufforderung soll das Verzeichnis, in dem die Datei Encodings Teil A (bzw. Recognition A) abgelegt ist, angegeben werden.\nBei der 3 Aufforderung soll das Verzeichnis, in dem die Datei Encodings Teil B (bzw. Recognition B) abgelegt ist, angegeben werden. \nBei der 4. Aufforderung soll das Verzeichnis gew\u00e4hlt werden in dem die Ausgabe Tabelle abgelegt wird.\n\n\n## Allgemeine Struktur:\nZu Beginn liest das Programm aus dem Verzeichnis der Stimulilisten alle Daten ein. D.h. die Bezeichnungen f\u00fcr \u201eFaces\u201c und \u201eWords\u201c werden aus den Listen f\u00fcr das Encoding und Recognition, hierbei jeweils f\u00fcr Faces und Words innerhalb dessen f\u00fcr die Teile A und B in jeweils eigenen Tabellen zwischengespeichert. Es entstehen also 8 Tabellen.\nAnschlie\u00dfend werden aus dem Verzeichnis Encoding (Recognition) die Meta-Daten der Versuchsperson, entsprechend auch die hinterlegten Datens\u00e4tze f\u00fcr das Encoding und Reconition, bzw. auch die Versuchspersons-Nummern, eingelesen. Diese Daten sind strukturiert nach den Versuchspersonen, und innerhalb dessen nach den Encoding und den Recognition-Werten. Auch Eintr\u00e4ge von Versuchspersonen, die nicht alle Teilexperimente abgeschlossen haben, werden ber\u00fccksichtigt.\nDie einzelnen Versuchsdaten werden dann eingelesen. Der Schritt des Verbindens der Versuchsperson-Daten und der Stimuluslisten erfolgt danach und erfolgt zun\u00e4chst f\u00fcr jede Versuchsperson einzeln. Somit wird eine Unabh\u00e4ngigkeit der Daten f\u00fcr jede Versuchsperson hergestellt, eigene Tabellen k\u00f6nnten entsprechend auch f\u00fcr jede Person ausgegeben werden. Abschlie\u00dfend werden alle Daten zusammengef\u00fchrt und es entsteht, je nach Programmaufruf, eine gesamte Zieltabell f\u00fcr das Encoding oder das Recognition. \nDiese Tabelle kann wahlweise als .csv oder als .xlsx Datei ausgegeben werden.\n\n## Technische Struktur:\nDie Datenverarbeitung erfolgt vorrangig mit Panda-Dataframes. Dar\u00fcber werden die Dateien eingelesen und verarbeitet. F\u00fcr die Zuordnung und Ausgabe der Meta-Daten, der Stimulus-Listen werden auf den Panda Datarames Operation durchgef\u00fchrt.\nDie Strukturierung der eingelesenen und verarbeiteten Daten erfolgt aufgeschl\u00fcsselt nach Versuchspersonen, Dateityp und Versuchsdurchf\u00fchrung. Hierf\u00fcr werden als Dateityp Python-Dictionaries verwendet, die eine effiziente und simple Umsetzung von Hashmaps mit Schl\u00fcssel- und Werte-Paaren ist. \n"}
{"url": "https://github.com/bmarv/relief-routing-models", "owner": "bmarv", "repository_name": "relief-routing-models", "date_all_variable_collection": "2023-09-11", "description": null, "size": 645, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "bmarv", "contributions": 23}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 1335848}, {"language": "Python", "num_chars": 41509}], "readme": "# Relief Routing Models\n## Project structure\n\n```\n|\n|-API\n|   |-Carthography\n|   |-Routing\n|   |-Seismic\n|\n|-Experiments\n|   |-API-Connections\n|   |-Graph\n|   |-Routing\n|\n|-Routing\n|   |-Directional\n|   |-Distancial\n|   |-Permutational\n|\n|-Solver\n|   |-MinSum\n|   |-MinMax\n|\n\n```\n## Installation\nThis project is build with Python3.10. Necessary packages can be installed using the PyPI-package manager for Python:\n```bash\npip install -r requirements.txt\n```\n\n## Usage\nThis project follows a predefined structure, that is visible above. For using this program, it is necessary to create a (free) account for the routing service [Open Route Service ](https://openrouteservice.org/) (ORS) to gain API-Usage rights. \nAfterwards a `.env`-file needs to be created to store the secret api-key of ORS as a string in the following format\n```bash\nORS_API_KEY=\"your-secret-key-string\"\n```\n\nTo operate a solver, it is possible to choose between the exact and the inexact implementation. Please note, that currently only the inexact solver supports Feasibilities and Deadlines for the Capacitated Vehicle Routing Problem using MinMax and MinSum. \nTo create an instance, please use a distance-matrix as a 2d-List indicating the distances, the demands as well as the deadlines as a 1d-List as values for every recipient. Feasibility is done by defining a dictionary with the vehicle as an integer key and as a value a list of not feasibile recipients. The number of vehicles and the (unified) vehicle capacity should be overloaded as simple integer values. \n\nUse the following commands to integrate a solver into your program:\n```python\nimport solver.inexact_solver\n\n# pre-define hyper-parameters distance_matrix, demands, vehicle_capacity, num_vehicles, deadlines, infeasible_nodes\n\n#---\n# capacitated minsum implementation using feasibilities and deadlines\nfeasibilities_deadlines = solver.inexact_solver.minsum_insertion_algorithm_feasibilities_deadlines(\n    distance_matrix, demands, vehicle_capacity, num_vehicles, deadlines, infeasible_nodes\n)\nsolver.inexact_solver.print_route_and_costs(distance_matrix, feasibilities_deadlines[0])\n\n#---\n# capacitated minmax implementation using feasibilities and deadlines\nminmax_feasibilities_deadlines = solver.inexact_solver.minmax_insertion_algorithm_feasibilities_deadlines(\n    distance_matrix, demands, vehicle_capacity, num_vehicles, deadlines, infeasible_nodes\n)\nsolver.inexact_solver.print_route_and_costs(distance_matrix, minmax_feasibilities_deadlines)\n\n```\n\nIt is also possible to use visualization options offered in the `carthography`-module or `routing.directional.display_directional_route_round_trip_on_map(...)`.\nThe visualizations are interactive and for the best used in a Jupyter-Notebook. \nExamples are included in the Notebook `demo.ipynb`\n\nSeismic Acitivies can also be sensed by invoking `api.seismic.get_earthquakes_within_start_and_endtime(...)`. For this external API no keys have to be gained. \n"}
{"url": "https://github.com/bmarv/SmaliCode-Exploiter", "owner": "bmarv", "repository_name": "SmaliCode-Exploiter", "date_all_variable_collection": "2023-09-11", "description": "Decompilation of APK-files into .smali Format for Debugging and Analyzing fully compiled Android-APKs.", "size": 5122, "stargazers_count": 6, "watchers_count": 6, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 6, "default_branch": "master", "contributors": [{"contributor": "bmarv", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 21137}], "readme": "# SmaliCode-Exploiter\n\nThe SmaliCode Exploiter is a program that decompiles APK files of Android Apps and reveals the byte-code in .smali format.\nThe source files of an Android App normally are not visible as they are compiled into an APK file. By decompiling it into \nthe .smali format, the files can be analyzed for security vulnerabilities especially regarding falsely declared *Intents*.\nAs an output, this program inspects the Android-Manifest file besides other data for *Intents, Broadcasts* and *Permissions*\nand gives an overview.\n\n## Background Information\n\nAndroid APKs contain *.dex* files, which are binary Dalvik bytecodes, that the machine can understand. \nTo analyze the code in a human readable format, the APK can be decompiled into a format called Smali, \nwhich has many similarities to Assemblercode. This [documentation](http://pallergabor.uw.hu/androidblog/dalvik_opcodes.html)\nis a firm guideline for interpreting the .smali format.\n\nThe Datastructures of this program are documented in this [file](https://github.com/bmarv/SmaliCode-Exploiter/blob/master/Documentation_SmaliCodeExploiter.pdf).\n\n## Installation\n\nThis program was developed using *Java 11* on *Linux*. The installation of *apktool 2.4.0* on Linux/Ubuntu is necessary via \n```bash\nsudo apt install apktool\n```\n\n## Usage\n\nAs the main-Method is located in [SmaliExploiter.java](https://github.com/bmarv/SmaliCode-Exploiter/blob/master/src/SmaliExploiter.java), this Class has to be compiled with the java-Compiler.\nFor executing the Program, the directory containing the APK needs to be passed as an argument\n```bash\ncd src/\njavac SmaliExploiter.java\njava SmaliExploiter ../testAPK1/\n```\n\n## Acknowledgement\n\nThis Program was developed in 2019 for the Module *Mobile Security* at the University of Potsdam.\nThe authors of this Program are Marvin Beese and Jan Christoph Glinzer.\n"}
{"url": "https://github.com/bmarv/Summaries-on-AI-topics", "owner": "bmarv", "repository_name": "Summaries-on-AI-topics", "date_all_variable_collection": "2023-09-11", "description": "Collection of Summaries for a research module at the University of Potsdam in the winter-semester 2019/2020.", "size": 3917, "stargazers_count": 1, "watchers_count": 1, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "bmarv", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Summaries-on-AI-topics\nCollection of Summaries for the research module *Agent-Technology/Current Topics of Computational Intelligence* at the University of Potsdam in the winter-semester 2019/2020.\n\nThe Summaries refer to a programming paradigm called [Answer Set Programming](https://en.wikipedia.org/wiki/Answer_set_programming). \nThe main concepts are introduced in [Answer Set Solvers and the Basics of Answer Sets](https://github.com/bmarv/Summaries-on-AI-topics/blob/master/1.%20Answer%20Set%20Solvers%20and%20the%20Basics%20of%20Answer%20Sets.pdf).\n\nVarious Topics are studied including *Knowledge Representation, Reasoning, Grounding and Solving, Timetabling, Planning with Multiple Agents, Automatic Music Composition, AI based Game Design, Semantic Parsing, Bioinformatics Problems* and as a final Paper [Automatic Trance Music Generation and Automatic Melodic Variation as Aesthetic Music](https://github.com/bmarv/Summaries-on-AI-topics/blob/master/Paper%20-%20Automatic%20Trance%20Music%20Generation%20and%20Automatic%20Melodic%20Variation%20as%20Aesthetic%20Music.pdf) as well as the coherent [Presentation](https://github.com/bmarv/Summaries-on-AI-topics/blob/master/Presentation%20-%20Automatic%20Trance%20Music%20Generation%20and%20Automatic%20Melodic%20Variation%20as%20Aesthetic%20Music.pdf).\n"}
{"url": "https://github.com/BodoBookhagen/CameraCalibration", "owner": "BodoBookhagen", "repository_name": "CameraCalibration", "date_all_variable_collection": "2023-09-11", "description": "Camera Calibration using OpenCV", "size": 91298, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "dluks", "contributions": 21}, {"contributor": "BodoBookhagen", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 71941}], "readme": "# Camera Calibration using OpenCV\n\nThere exist many resources for Camera Calibration and this has become a standard operating procedure. Here, we use OpenCV to calibrate single or stereo cameras using chessboard or ChArUco boards. We emphasize the importance of high-quality calibration boards that are on flat surfaces and not warped.\n\nAlternative calibration options include importing calibration data produced with the [Calibrator calib.io Software](https://calib.io/products/calib), which relies on a different matrix-optimization approach and other flexible parameters. A python-based conversion code is available that converts output from Calibrator to the OpenCV XML camera matrix format.\n\n**Table of Contents**\n- [Usage](#Usage)\n    - [Examples](#Examples)\n    - [Converting Calib.io JSON calibration files to OpenCV XML format](#convert-json-xml)\n- [Best practices for a good calibration](#best-practices)\n    - [Image capture](#Image-capture)\n    - [Calibration](#Calibration)\n- [Our testing](#Our-testing)\n    - [Different calibration approaches](#Different-calibration-approaches)\n    - [Which distortion coefficients should be estimated during calibration?](#which-coefficents)\n    - [Comparing target type, capture angle, and number of distortion coefficients](#broad-comparison)\n\n## Usage\nThe parameters have been optimized for the cameras that are available at the Geological Remote Sensing lab at the University of Potsdam. These are several Sony alpha-6 (24 MP), Sony alpha-7 (40 MP), and Fuji X-100 (24 MP) all with 55 mm or 85 mm fixed lenses.\n\nThe python code `python/single_camera_calibration_charuco_chess_openCV.py` can be called from the command line. Use `single_camera_calibration_charuco_chess_openCV.py -h` to obtain a short help and description of the parameters.\n\nThe code will read all calibration images from one directory, plots a summary figure showing all photos, performs the camera calibration, and writes the distortion coefficient and intrinsic camera calibration to an OpenCV XML file.\n\n**Example of 49 photos showing a chessboard pattern for camera calibration (Sony alpha-7 55 mm lense):**\n![](examples/camA_chessboard_49images.jpg)\n\n**All detected chessboard intersection - make sure that points are also taken from the corners of the image (Sony alpha-7 55 mm lense):**\n![](examples/camA_chess_23324corners.png)\n\n**Example camera calibration and pixel distortion using intrinsic and distorted parameters (Sony alpha-7 55 mm lense):**\n![](examples/sony_alpha7_55m_CC_chess_comparison_1panel.jpg)\n\n### Examples\nExample call from Ubuntu command line (expecting OpenCV to be installed).\n\n#### Using Sony alpha-6000 and charuco board\n\n```bash\ncamA_initial_CC='cam_A_calib_9parameters_fine_charuco_20Feb2022.xml'\ncharuco_ifiles_camA='sony_stereo_f13_iso1600/charuco/black_a_stereo/DSC*.JPG'\ncamA_charuco_savexml_file='sony_stereo_f13_iso1600/charuco/cam_A_black_calib_9parameters_fine_charuco_25Mar2022.xml'\ncamA_CC_comparison_3panel_png='sony_stereo_f13_iso1600/charuco/CC_comparison_3panel.png'\ncamA_CC_comparison_1panel_png='sony_stereo_f13_iso1600/charuco/CC_comparison_1panel.png'\ncamA_Height=4000\ncamA_Width=6000\nfocal_length_pixels=9000\n\nsingle_camera_calibration_charuco_chess_openCV.py --camA_initial_CC $camA_initial_CC \\\n  --charuco_ifiles_camA $charuco_ifiles_camA \\\n  --camA_charuco_savexml_file $camA_charuco_savexml_file \\\n  --camA_CC_comparison_3panel_png $camA_CC_comparison_3panel_png \\\n  --camA_CC_comparison_1panel_png $camA_CC_comparison_1panel_png \\\n  --camA_Height $camA_Height --camA_Width $camA_Width \\\n  --focal_length_pixels $focal_length_pixels\n```\n\n#### Using Sony alpha-7000 with fixed 55 mm lense and chess board\n\nUsing no initial calibration file and this requires setting the parameters *camA_Height*, *camA_Width*, and\n*focal_length_pixels*.\n\n```bash\nchess_ifiles_camA='near/DSC*.JPG'\ncamA_chess_savexml_file='sony_alpha7_55m_CC_05July2022.xml'\ncamA_chess_75pbest_savexml_file='sony_alpha7_55m_CC_75p_05July2022.xml'\ncamA_CC_comparison_3panel_png='sony_alpha7_55m_CC_chess_comparison_3panel.png'\ncamA_CC_comparison_1panel_png='sony_alpha7_55m_CC_chess_comparison_1panel.png'\ncamA_Height=5304\ncamA_Width=7952\nfocal_length_pixels=12675\n\nsingle_camera_calibration_charuco_chess_openCV.py  \\\n  --chess_ifiles_camA $chess_ifiles_camA \\\n  --camA_chess_savexml_file $camA_chess_savexml_file \\\n  --camA_chess_75pbest_savexml_file $camA_chess_75pbest_savexml_file \\\n  --camA_CC_comparison_3panel_png $camA_CC_comparison_3panel_png \\\n  --camA_CC_comparison_1panel_png $camA_CC_comparison_1panel_png \\\n  --camA_Height $camA_Height --camA_Width $camA_Width \\\n  --focal_length_pixels $focal_length_pixels\n```\n\n#### Using Sony alpha-7000 with fixed 85 mm lense and chess board\n\nUsing no initial calibration file and this requires setting parameters for camera calibration.\n\n```bash\nchess_ifiles_camA='near/DSC*.JPG'\ncamA_chess_savexml_file='sony_alpha7_85m_CC_05July2022.xml'\ncamA_chess_75pbest_savexml_file='sony_alpha7_85m_CC_75p_05July2022.xml'\ncamA_CC_comparison_3panel_png='sony_alpha7_85m_CC_chess_comparison_3panel.png'\ncamA_CC_comparison_1panel_png='sony_alpha7_85m_CC_chess_comparison_1panel.png'\ncamA_Height=5304\ncamA_Width=7952\nfocal_length_pixels=18918\n\nsingle_camera_calibration_charuco_chess_openCV.py  \\\n  --chess_ifiles_camA $chess_ifiles_camA \\\n  --camA_chess_savexml_file $camA_chess_savexml_file \\\n  --camA_chess_75pbest_savexml_file $camA_chess_75pbest_savexml_file \\\n  --camA_CC_comparison_3panel_png $camA_CC_comparison_3panel_png \\\n  --camA_CC_comparison_1panel_png $camA_CC_comparison_1panel_png \\\n  --camA_Height $camA_Height --camA_Width $camA_Width \\\n  --focal_length_pixels $focal_length_pixels\n```\n\n### Converting Calib.io JSON calibration files to OpenCV XML format<a name=\"convert-json-xml\" />\nIf you have an exported JSON calibration file from a calibration done using Calib.io, you convert it using our conversion script. If `json_dir` or `xml_dir` is not supplied, the script will look for JSON files in the current directory and ouput the related XML files in a newly created `xml/` directory.\n\n```bash\npython python/calib-to-opencv.py --json_dir=\"path/to/json\" --xml_dir=\"path/to/output\"\n```\n\nFor help use:\n```bash\npython python/calib-to-opencv.py -h\n```\n\n## Best practices<a name=\"best-practices\" />\n### Image capture\nBefore capturing calibration images it is critical to ensure the camera is configured  and mounted properly, the board is high quality, and the scene is set appropriately to ensure a smooth calibration process.\n\n#### Configuring the camera\n\n##### Exposure settings\nCalibration works best when the camera's internal settings (e.g. f-stop, shutter speed,  ISO) are fixed and constant for the calibration session. The cameras used here were placed into \"Manual\" mode (a feature on the majority of high-quality digital cameras today) and f-stop, shutter speed, and ISO manually set according to the lighting conditions at the time of the sessions.\n\n##### Minimizing blur\nWhen taking the photos it is important to minimize blur, so if it is not possible to use a remote shutter when capturing the images, consider enabling a short self-timer to avoid vibration at the time of capture.\n\nThe Sony cameras used in this study were also equipped with a \"SteadyShot\" feature which was disabled prior to shooting because, when enabled, it results in small adjustments being made to the internal mechanics of the lens to physically eliminate motion blur, but at the cost of slightly altering the lens's internal parameters and resulting in poorer calibration results. It is recommended that any automatic blur-reduction features are disabled.\n\nThe camera should be mounted on a tripod to ensure that its internal and geometric parameters remain constant throughout the session. **This is crucial for a good calibration and handheld photos result in a significantly worse result.**\n\n#### Calibration targets<a name=\"calibration-targets\" />\nWe recommend the use of a high-quality calibration board such as the aluminum composite checkerboard or CharuCo targets made by [Calib.io](https://calib.io/), because any inconsistencies in the target's flatness or pattern will affect the calibration results. Target stiffness is also important as it is recommended to place the board in multiple orientations (often requiring it to be leaned at an angle against another object).\n\nWe found that the checkerboard targets tended to provid better calibration results, but because the entire checkerboard needs to be within the frame at all times it can be somewhat tricky to align it perfectly in the corners (where the most distortion often is found). The CharuCo targets help with this issue as they do not need to be entirely in the frame, but at the cost of *slightly* worse results.\n\n<table><tr>\n    <td> \n      <p align=\"center\" style=\"padding: 10px; text-align: center;\">\n        <img alt=\"Checkerboard\" src=\"img/checker.jpg\" width=\"300\">\n        <br>\n        <em style=\"color: grey\">Calib.io Checkerboard Target</em>\n      </p> \n    </td>\n    <td> \n      <p align=\"center\" style=\"padding: 10px; text-align: center;\">\n        <img alt=\"CharuCo\" src=\"img/charuco.jpg\" width=\"300\">\n        <br>\n        <em style=\"color: grey\">Calib.io CharuCo Target</em>\n      </p> \n    </td>\n</tr></table>\n\n#### Preparing the scene<a name=\"preparing-the-scene\" />\n<table><tr>\n    <td> \n      <p align=\"center\" style=\"padding: 10px; text-align: center;\">\n        <img alt=\"Our camera setup\" src=\"img/setup.jpg\" width=\"300\">\n        <br>\n        <em style=\"color: grey\">A good setup makes things simple. Try to tilt the camera at a slightly more oblique angle to the ground than this, though.</em>\n      </p> \n    </td>\n</tr></table>\n\nIf performing the calibration indoors, a well-lit environment with minimal shadows is key. LED lighting panels are good for this. Place the tripod with the camera in front of the target area and tilt the camera to a slightly oblique orientation to the ground. In fact, we found that calibrations conducted with the camera at an angle to the ground as opposed to looking straight down resulted in lower calibration error. For quick and consistent target placement during the shooting, we found it helped to first place tape along the edge of the camera frame. This can be done by placing the target in one corner of the frame as precisely as possible and then using it as a guide to place the tape. Repeat for the other three corners.\n\n#### Taking the photos\nOnce you have the frame marked out, we recommend taking 20-30 photos with the target covering every part of the frame at least once. Placing the target at oblique angles to the camera is also recommended, and for this we simply leaned the target up against an item in the lab and attempted to capture it in several different areas of the frame. If using the checkerboard, we had best results when placing it as close to the edge and in the corners of the frame as possible. This is simple when tape has been well-placed.\n\nAs mentioned above, we recommend the use of a remote shutter or using a short self-timer to minimize vibration-induced blur in the final shots. \n\n<table><tr>\n    <td> \n      <p align=\"center\" style=\"padding: 10px; text-align: center;\">\n        <img alt=\"Target placed at an oblique angle\" src=\"img/oblique.jpg\" width=\"300\">\n        <br>\n        <em style=\"color: grey\">A checkerboard target placed at an oblique angle</em>\n      </p> \n    </td>\n</tr></table>\n\n### Calibration\nWhen using OpenCV or Calib.io, consider the following rules of thumb:\n- Only 20-30 images are necessary\n- If possible, estimate only for \"k<sub>1</sub>, k<sub>2</sub>, k<sub>3</sub>\", leaving out additional p coefficents.\n- Use between 20 and 30 images.\n\n## Our testing\nTo inform the above recommendations, multiple calibration sessions were conducted with a variety of cameras, targets, image counts, and target-camera orientations. To analyze the success of a calibration, we looked at each calibration's root mean squared reprojection error (RMSE) and distortion plot. To compare two calibrations' distortion plots, we simply took the difference between the two.\n\n### Different calibration approaches\n#### Comparing calibration methods by RMSE\n![RMSE comparison of several calibration variables](img/best-practices-comparison.png)\n<p style=\"text-align: center;\"><em style=\"color: grey; text-align:center;\">Figure 1. To optimize the calibration process, we investigated the performance of estimating for different combinations of distortion coefficients (left), the number of images that should be included in the calibration (center-left), target type (center-right), and camera type (right). Please note that these figures indicate only broad trends from the many tests done and are not indicative of the final recommendations.</em></p>\n\n### Which distortion coefficients should be estimated during calibration?<a name=\"which-coefficents\" />\nWe conducted calibrations comparing different combinations of distortion coefficients, and found that there were diminishing returns (and the possibility of overfitting) when including coefficients beyond \"k<sub>1</sub>, k<sub>2</sub>, k<sub>3</sub>\".\n\n#### Results of solving for different combinations of distortion coefficients\n![Comparison of k1, k2, vs. k1](img/sony_a7_k1k2_k1_comparison.png)\n![Comparison of k1, k2, vs. k1, k2, k3](img/sony_a7_k1k2_k1k2k3_comparison.png)\n![Comparison of k1, k2, vs. k1, k2, k3, p1](img/sony_a7_k1k2_k1k2k3p1_comparison.png)\n![Comparison of k1, k2, vs. k1, k2, p1, p2](img/sony_a7_k1k2_k1k2p1p2_comparison.png)\n![Comparison of k1, k2, vs. k1, k2, k3, p1, p2](img/sony_a7_k1k2_k1k2k3p1p2_comparison.png)\n\n<p style=\"text-align: center;\"><em style=\"color: grey; text-align:center;\">Figure 2. Our results after solving for different combinations of distortion coefficients (using Calib.io). Left column: k<sub>1</sub>, k<sub>2</sub>; middle column: other coefficient combinations; right column: comparison plots.</em></p>\n\nFigure 2 shows that, while the combinations of \"k<sub>1</sub>, k<sub>2</sub>, k<sub>3</sub>, p<sub>1</sub>\", and \"k<sub>1</sub>, k<sub>2</sub>, p<sub>2</sub> result in slightly lower RMSE than \"k<sub>1</sub>, k<sub>2</sub>\", it is not enough to justify estimating for the additional p coefficients. Therefore, our recommendations are to use simply \"k<sub>1</sub>, k<sub>2</sub>, k<sub>3</sub>\", without the need for additional p coefficients.\n\n### Comparing target type, capture angle, and number of distortion coefficients<a name=\"broad-comparison\" />\n\nIn order to inform the magnitude of influence target type, capture angle, and number of distortion coefficients has on reprojection error, we calculated the difference between each calibration and between each distortion plot. This allowed us to then visualize the significance of each aspect of the calibration process (Figures 3-5).\n\n#### Overall effect on RMS RPE\n\n![2p vs. 3p. vs 5p](img/board_angle_p_comparison.png)\n\n<p style=\"text-align: center;\"><em style=\"color: grey; text-align:center;\">Figure 3. RMS RPE differences between CharuCo and checkerboard targets, near-nadir and oblique capture angles, 2-parameter (k1, k2) and 3-parameter (k1, k2, k3), and 2-parameter and 5-parameter (k1, k2, k3, p1, p2) calibrations. All images taken using a Sony A7 camera with a 55mm fixed lens. Numbers in parentheses represent the RMS RPE of the respective treatments.</em></p>\n\n#### Target type\n\n![Checkerboard vs. CharuCuo](img/checkerboard_vs_charuco_oblique.png)\n\n<p style=\"text-align: center;\"><em style=\"color: grey; text-align:center;\">Figure 4. Distortion plot comparison between Checkerboard and CharuCo targets when solving for two parameters (k1, k2), three parameters (k1, k2, k3), and five parameters (k1, k2, k3, p1, p2). All calibrations done with Sony A7 at an oblique angle with a 55mm fixed lens.</em></p>\n\n#### Capture angle\n\n![Nadir vs. Oblique](img/nadir_vs_oblique_checkerboard.png)\n\n<p style=\"text-align: center;\"><em style=\"color: grey; text-align:center;\">Figure 5. Distortion plot comparison between images taken at near-nadir and oblique angles. All calibrations done using five parameters (k1, k2, k3, p1, p2) and a checkerboard target.</em></p>\n\n"}
{"url": "https://github.com/BodoBookhagen/ChanGeom", "owner": "BodoBookhagen", "repository_name": "ChanGeom", "date_all_variable_collection": "2023-09-11", "description": "ChanGeom - Channel Geometry, River Width, and along-stream distance extraction from KML", "size": 85, "stargazers_count": 4, "watchers_count": 4, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 4, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 4, "open_issues": 0, "watchers": 4, "default_branch": "master", "contributors": [{"contributor": "BodoBookhagen", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 89387}, {"language": "MATLAB", "num_chars": 16402}, {"language": "Shell", "num_chars": 548}], "readme": "# ChanGeom\nChanGeom - Channel Geometry, River Width, and along-stream distance extraction from KML files. The KML files can be created in Google Earth (manual clicking along river paths) or by automatic extraction from airphotos or satellite imagery. This is a modified and enhanced version originally described in:\n\nFisher, G.B., Bookhagen, B., Amos, C.B. (2013): Channel planform geometry and slopes from freely available high-spatial resolution imagery and DEM fusion: Implications for channel width scalings, erosion proxies, and fluvial signatures in tectonically active landscapes, Geomorphology, http://dx.doi.org/10.1016/j.geomorph.2013.04.011\n\nPlease cite that manuscript when using these scripts.\n\nContact Bodo Bookhagen (bodo.bookhagen@uni-potsdam.de) for questions and comments pertinent to the code.\n\nThe following major changes have been done to the original code:\n- Full Python 3.6 implementation\n- gdal and ogr workflows to read and write large number of shapefiles and tif files\n- automatic (re-) projection of input files and fully automatized workflows\n- Scipy-based channel extraction (no Matlab required) *_WILL BE UPDATED to allow CUDA and multi-core processing_*\n- merging all channel width shapefiles into one coherent shapefile for each region for easier analysis\n- linking channel width file with topographic information from DEM file (drainage area, flow distance, slope) through Kd trees (no ESRI arcpy or ArcMap necessary). This is a significant speed improvement over arcpy.\n- generating standard output plots through matplotlib to visualize and analyze results\n- Generating a Python-Pandas DataFrame with all data for efficient and fast analysis\n- Saving all data to ASCII and HDF files for further analysis in Python-Pandas or Matlab\n\n\n## Installation\nThe code will run on any operating system. You will need to install a number of packages for python, but these should be standard on any Python 3.X installation (e.g., Anaconda, WinPython): gdal, ogr, numpy, scipy, matplotlib, pandas\n\n## Running the Code\nYou will only need to change/set parameters in the _ChanGeom.ini_ file. These will need to be modifed for each region. See the [ChanGeom.ini](ChanGeom.ini) file for more information. You should create a separate ChanGeom.ini file for each region.\n\n## Example\nWill follow.\n"}
{"url": "https://github.com/BodoBookhagen/DEM-KPP", "owner": "BodoBookhagen", "repository_name": "DEM-KPP", "date_all_variable_collection": "2023-09-11", "description": "Digital Elevation Model (DEM) and KnickZone-Picker (KZP) Analyzer", "size": 126, "stargazers_count": 0, "watchers_count": 0, "language": "Matlab", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "BodoBookhagen", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "MATLAB", "num_chars": 419905}], "readme": "# DEM-KPP\nDigital Elevation Model (DEM) and KnickPointPicker (KPP) processing\n\nCode developed by Al Neely and Bodo Bookhagen 10/12/2015, significantly\nmodified March-May 2016\n\nThe code has been tested with Matlab R2012b, R2014b and R2015b. \nIt requires the Statistical Toolbox, the Topotoolbox, and \nexport_fig (see below). If the Curve Fitting \nToolbox is available, it will be used (_smooth_). If no Curve Fitting \nToolbox is available, _sgolayfilt_ is used (with similar and comparable \nresults).\n\n*Installation*\n\nBefore running the code and taking advantage of all feautres (i.e.,\nhigh-resolution figures and projected shapefile), you will need to\ninstall the additional items:\n\n1. _TopoToolbox_ (https://topotoolbox.wordpress.com/download/). I suggest\nusing the github repository\n(https://github.com/wschwanghart/topotoolbox). For additional\ninformation, see: https://topotoolbox.wordpress.com/.\nThe TopoToolbox requires the Image Processing Toolbox and the Statistics\nToolbox (which are mostly installed in academic environment). \nThe Mapping Toolbox will come in handy, but is not required. The Curve \nFitting Toolbox will be used if available and will produce slightly\ndifferent fitting parameters, e.g. (for 95% confidence Intervals).\nMake sure to add the Topotoolbox to the Matlab PATH.\n\n2. _export_fig_ from Mathworks MATLAB Central:\n(http://www.mathworks.com/matlabcentral/fileexchange/23629-export-fig)\nfor creating the various plots and figures in high-quality PDF format.\nMake sure to add the location of the file export_fig.m to the Matlab PATH.\n\n3. Install _ghostscript_ from\nhttp://www.ghostscript.com/download/gsdnld.html . This is required for \nhigh-res PDF outputs for export_fig.m and highly recommended.\n\n4. _OSGEO4WShell_ or the full GDAL suite (http://www.gdal.org/ or \nhttp://trac.osgeo.org/osgeo4w/). MAC OS X users should install the GDAL \ncomplete framwork from http://www.kyngchaos.com/software/frameworks. \nThis will allow to generate shapefiles from  \ntables that are created during the processing and will allow to\npolygonize raster (TIF) files. GDAL is freely available for all operating\nsystems, and we have tested this on Ubuntu 12.04\n(sudo apt-get install gdal), Windows 7 and 8.1 \n(http://trac.osgeo.org/osgeo4w/), and\nMac OS X (http://www.kyngchaos.com/software/frameworks). This script will\nrun well, if you use the default gdal installation options. Otherwise,\nyou may have to change the directory locations in the parameter file.\nWe rely on: _ogr2ogr_, _gdalsrsinfo_, _gdal_dem_,\n_gdal_polygonize_.\n\n5. Install the _KnickPointPicker_ (KPP) code and subdirectories and add\nthe KPP directory to the Matlab PATH.\n\n\nThis Matlab code takes MAT file written by\n_KPP_topometrics_v1.m_ and calculates knickpoints and\nadditional attributes from _chi-plot_ analysis. It will write several\nshapefiles and csv files that can be read into any GIS software.\n\nYou will have to run _knickpoints_preprocessing_v1.m_ at least once before\nrunning this script.\n\nParameters for this script can be adjusted/changed in\n_knickpoints_parameters_X.m_.\n\nThis file will output the following four shapefiles:\n\n  1: <filename>_kp_bases.shp (knickpoint bases for all tributaries)\n  \n  2: <filename>_kp_lips.shp (knickpoint lips for all tributaries)\n  \n  3: <filename>_kp_bases_trunk.shp (knickpoint bases for trunk stream)\n  \n  4: <filename>_kp_lips_trunk.shp (knickpoint lips for trunk stream)\n\n\nThe code developes a database/csv file/shapefile for the bottom and top\npoints of all knickzones. Each database has the following attributes with\ntheir respective attribute name in brackets [].\n\nKnickpoint Database information [shapefile attribute]\n\n  1: knickpoint # [1kp_id]\n  \n  2: stream id # [2stream_id]\n  \n  3: tributary id # [3trib_id]\n  \n  4: slope of stream, bfl slope: elev/chi [4sl_str]\n  \n  5: chi coordinate [5chi]\n  \n  6: elevation (m) [6elev_m]\n  \n  7: knickpoint magnitude, detrended elevation drop (m) [7kp_magnt]\n  \n  8: Knickpoint Relief, height of knickpoint (not detrended (m)) [8kp_Rel]\n  \n  9: easting (meters utm) [9Easting_m]\n  \n  10: northing (meters utm) [10North_m]\n  \n  11: upstream drainage area (m2) [11DA_m2]\n\n  12: dist upstream (m) [12kp_DFM]\n\n  13: knickpoint slope (elev drop/distance upstream) [13kp_slp]\n\n  14: elevation drop (detrended elevation drop/distance upstream, m) [14kp_slp_d]\n\n  15: knickpoint slope (detrended elevation drop/chi) [15kp_slp_dt/c]\n\n  16: knickpoint length (distance usptream, m) [16kp_len_m]\n\n  17: sgolay smoothing window size (grid cells) [17sgol_smv]\n\n  18: knickpoint lumping search window size (grid cells) [18kp_lm_ws]\n\n  19: minimum knickkpoint size pre-lumping [19kp_pr_lu]\n\n  20: minimum knickpoint size post-lumping (final minimum knickpoitn size) [20kp_pt_lu]\n\n  21: minimum steepness anomaly [21kp_stp_a]\n\n  22: minimum stream size for analysis (cells) [22strea_sz]\n\n#In order to process a DEM and identify Knickpoints, follow these steps:\n(1) Load DEM file and other data from preprocessing\nKPP_processing_1load_v1\n\n(2) Iterate through all basin tributaries and extract knickpoints\nKPP_processing_2kpp_tribs\n\n(3) Iterate through all trunk streams and pull out knickpoints\nKPP_processing_3kpp_trunks\n\n(4) Generate figures for each basin\nKPP_processing_4kpp_mkfigs\n"}
{"url": "https://github.com/BodoBookhagen/GMT-NWArg-TOPO-NDVI-PRECIP-COHERENCE", "owner": "BodoBookhagen", "repository_name": "GMT-NWArg-TOPO-NDVI-PRECIP-COHERENCE", "date_all_variable_collection": "2023-09-11", "description": "Using GMT to create maps of the central Andes in NW Argentina showing topography, vegetation cover, rainfall and S1 coherence", "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "BodoBookhagen", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/BodoBookhagen/GMT-plot-windvectors-SAM", "owner": "BodoBookhagen", "repository_name": "GMT-plot-windvectors-SAM", "date_all_variable_collection": "2023-09-11", "description": "Plot wind vectors (u and v components) with GMT for South America", "size": 34598, "stargazers_count": 0, "watchers_count": 0, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "BodoBookhagen", "contributions": 14}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 8003}], "readme": "# GMT-plot-windvectors-SAM\nPlot wind vectors (u and v components) with GMT for South America.\n\nFor a more detailed description, see blog entry at [GMT-plot-windvectors](https://bodobookhagen.github.io/posts/2019/01/GMT-plot-windvectors/). \n\nExample output images are (explained on blog entry):\n\n![ECMWF-EI-WND_1999_2013_DJF_200hpa_SAM_graytopo.png](https://github.com/BodoBookhagen/GMT-plot-windvectors-SAM/raw/master/output_maps/ECMWF-EI-WND_1999_2013_DJF_200hpa_SAM_graytopo.png)\n\n![ECMWF-EI-WND_1999_2013_DJF_200hpa_SAM_relieftopo.png](https://github.com/BodoBookhagen/GMT-plot-windvectors-SAM/raw/master/output_maps/ECMWF-EI-WND_1999_2013_DJF_200_SAM_relieftopo.png)\n\n![ECMWF-EI-WND_1999_2013_DJF_200hpa_SAM_windvelocity.png](https://github.com/BodoBookhagen/GMT-plot-windvectors-SAM/raw/master/output_maps/ECMWF-EI-WND_1999_2013_DJF_200hpa_SAM_windvelocity.png)\n\n\n\n"}
{"url": "https://github.com/BodoBookhagen/GMT-SAM-EQ-NDVI-PRECIP", "owner": "BodoBookhagen", "repository_name": "GMT-SAM-EQ-NDVI-PRECIP", "date_all_variable_collection": "2023-09-11", "description": "GMT scripts and data for plotting topography,  earthquake distribution, rainfall and NDVI vegetation cover for SAM.", "size": 47337, "stargazers_count": 1, "watchers_count": 1, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "BodoBookhagen", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 30484}], "readme": "# GMT-SAM-EQ-GPS-NDVI-PRECIP\nGMT scripts for plotting topography, earthquake, GPS vectors, vegetation cover and precipitation for the Central Andes.\n"}
{"url": "https://github.com/BodoBookhagen/ICESat-2_SVDA", "owner": "BodoBookhagen", "repository_name": "ICESat-2_SVDA", "date_all_variable_collection": "2023-09-11", "description": "The Sparse Vegetation Detection Algorithm (SVDA) for ICESat-2 data", "size": 408703, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "GNU General Public License v2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 1, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "BodoBookhagen", "contributions": 11}, {"contributor": "tasmi", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 64804139}, {"language": "Python", "num_chars": 26344}], "readme": "# ICESat-2 SVDA\nThis repository contains the python codes and Jupyter Notebooks for the \"Sparse Vegetation Detection Algorithm\" (SVDA) to process ICESat-2 ATL03 data.\n\nWhen using the codes from this github environment, please cite:\nAtmani, F., Bookhagen, B., and Smith, T.: **Measuring vegetation heights and their seasonal changes in the western Namibian savanna using spaceborne lidars**\n\nDetailed concept and theoretical background information are described in the journal article \"Measuring vegetation heights and their seasonal changes in the western Namibian savanna using spaceborne lidars\"\n\n## Jupyter Notebooks\nWe provide a set of Jupyter Notebooks that will guide through the processing steps.\n\n![](figs/JupyterNotebook_CanopyHeight_teaser.png)\n\n### Installation of a dedicated conda environment\nIn order to run the codes and follow the steps in the Jupyter Notebooks, you will need to have installed several additional packages. This can be done through [miniconda](https://docs.conda.io/en/latest/miniconda.html) or [Anaconda](https://www.anaconda.com/).\n\nHere is a code-snippet to install the required packages into an conda environment called `icesat2`:\n\n```\nconda create -y -n icesat2 -c conda-forge ipython numpy python \\\n  ipython matplotlib h5py pandas scipy pyproj pip fiona shapely \\\n  jupyter ipywidgets gdal tqdm scikit-learn weightedstats \\\n  geopandas cartopy plotly\nconda activate icesat2\nconda install -y -c conda-forge pytables laspy requests\n```\n\nSome of these modules are not required for running the code (for example, `cartopy` and `plotly`), but they are useful when interactively exploring the data.\n\n\nYou can also add this conda environment to be recognized by Jupyter Notebooks:\n```\npython -m ipykernel install --user --name=icesat2\n```\n\n### Additional packages for ICESat-2\n**These are not required to run the SVDA classification code, but are helpful when working with ICESat-2 data.**\n\nIn addition, you may want to install the python tools for obtaining and working with elevation data from the NASA ICESat-2 mission from github. This relies on MPI/OPENMPI and you may need to make sure to install the correct version of the compilers within conda. Alternatively, you can install the packages to the system. The following snippet works on an Ubuntu 18.04 and 20.04, but should be easily transferable to other systems.\n\n\n```\ncd ~\nconda activate icesat2\npip install pyGEDI\nconda install -y mpi4py\nconda install -c -y conda-forge openmpi-mpicc\nconda install -c -y conda-forge c-compiler compilers cxx-compiler\ngit clone https://github.com/tsutterley/read-ICESat-2.git\ncd read-ICESat-2\nexport OMPI_MCA_opal_cuda_support=true\npython setup.py build\npython setup.py install\ncd ~\n```\n\n### More additional packages\nIf you plan to use Google Earth Engine, you will need to install their API:\n```\nconda activate icesat2\nconda install -c conda-forge earthengine-api geemap\n```\n\n*Note that these are generally very large.*\n\n\nNow you should be ready to run the various Jupyter Notebooks and steps.\n"}
{"url": "https://github.com/BodoBookhagen/isce_processing", "owner": "BodoBookhagen", "repository_name": "isce_processing", "date_all_variable_collection": "2023-09-11", "description": "Installation, guides, and scripts for processing radar scenes with ISCE", "size": 85, "stargazers_count": 14, "watchers_count": 14, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 4, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 4, "open_issues": 0, "watchers": 14, "default_branch": "master", "contributors": [{"contributor": "BodoBookhagen", "contributions": 26}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 139872}], "readme": "# Processing directory with Radar data\n\n## Sentinel-1\n[prepare_Sentinel1.py](prepare_Sentinel1.py) is a simple script that call topsApp.py (ISCE), gdal and various other commands to process a directory containing SAR data. An output PDF/png will be created showing all interferograms and a baseline plot will be generated. All parameter and config files for GIAnT processing will be prepared. The snytax contains several options:\n<> are required input, -- indicates optional input\n```\nprepare_Sentinel1.py <indir> <baseline> --dem --dem_res --roi --box --label --proc_steps --geocode_reprocess --do_not_delete --generate_utm_geotif --orbit_dir --aux_dir --swath --generate_png\n```\n\nwith the following explanation:\n- _indir_\t\tdirectory to be processed (e.g., /raid/InSAR/Sentinel1A/NWArg)\n- _baseline_\t\tperpendicular baseline threshold in m\n- --dem\t\t\tDEM to be used for processing (e.g., --dem /raid/InSAR/TerraSAR-X/Pocitos/SRTM1/demLat_S23_S26_Lon_W069_W066_f2.dem.wgs84.xml)\n- --roi\t\t\tregion of interest bounding box with S, N, W, E coordinates (include \" \", e.g., - --roi \"[-24,-24.75,-67.25,-66.75]\")\n- --box\t\t\tbounding box with S, N, W, E coordinates (include \" \", e.g., --box \"[-24,-24.75,-67.25,-66.75]\")\n- --label\t\t\ttext string indicating label of current area (e.g., --label \"salta_lower_qdt\")\n- --proc_steps\t\tindicating level of processing (e.g., --proc_steps 0 (default) processes all band combinations that are below baseline threshold, --proc_steps 1 is only baseline generation, --proc_steps 2 will generate baselines and only one (first) ifg with full extent, --proc_steps 3 will generate ifgs using the first (oldest) as master with every other scene and then only adjacent pairs, --proc_steps -1 only generates xml control files and does no processing)\n- --dem_res\t\t\tDEM resolution: default is 30 (m) for SRTM-X (use 10 m here for the TanDEM-X). This is only used when converting TIF files to UTM coordinates.\n- --geocode_reprocess\tReprocessing unwrapping with a new geocode bounding box. If geocode bounding box has changed and new geocoding is necessary, set this to 1 (e.g., --geocode_reprocess 1)\n- --do_not_delete\t\tDelete .raw*, rangeOffset.*, resampImage.*, simamp.* after succesfull interferogram formation. Default = 0 to save space. Set this to 1 to keep all files (e.g., --do_not_delete 1)\n- --generate_utm_geotif\tGenerate geotifs for each interferogram pair. Generates geotif and automatically projects to appropriate UTM Zone X WGS84 coordinate system for all geocoded files. Default = 0 (no tif files are generated). Set this to 1 to generate geotifs (e.g., --generate_utm_geotif 1)\n- --orbit_dir\t\tOrbit directory for Sentinel-1 orbits (e.g., --orbit_dir /raid/InSAR/orbits/S1/precise)\n- --aux_dir\t\tInstrument and calibration auxiliary directory for Sentinel-1 (e.g., - --aux_dir /raid/InSAR/orbits/S1/aux_ins)\n- --swath\t\t\tSwath of Sentinel1 data (1 to 3, e.g., --swath \"[1,2,3]\" (default) or --swath \"[2,3]\" for only swaths 2 and 3)\n- --generate_png\t\tGenerate PNGs with mdx for each interferogram pair. Generates merged views with unwrapped topophase, phase, correlation, amplitude. Default = 0 (no PNG files are generated). Set this to 1 to generate png (e.g., --generate_png 1). You will need to install imagemick or similar packages to use this option\n\n## Example 1: Typical Sentinel-1 processing example\nCopy S1*_IW_SLC_*.zip files for one location (either ascending or descending, but not mixed) to a directory and generate a first interferogram to get extent of image and first impression. Also download the SRTM1 DEM using dem.py:\n```\nstart_isce\ndem.py -a stitch -b 33 35 -121 -119 -c -s 1 -k -m xml -r\n```\nYou may consider upsampling the DEM (if necessary) or using a custom DEM:\n```\nupsampleDem.py -i demLat_N33_N35_Lon_W121_W119.dem.wgs84 -o demLat_N33_N35_Lon_W121_W119_f2.dem.wgs84 -f 2\n```\n\nCall prepare_Sentinel1.py and generate a first interferogram: \n```\npython2 isce_processing/prepare_Sentinel1.py /raid/InSAR/California/SCI/test 500 \\\n--label \"S1_SCI_SRTM1_30m\" \\\n--dem \"/raid/InSAR/California/SCI/SRTM1/demLat_N33_N35_Lon_W121_W119.dem.wgs84\" \\\n--dem_res 30 \\\n--proc_steps 2 \\\n--generate_png 1\n```\n\nUse QGIS or mdx.py to view the output in the merged directory. Identify the region of interest.\n\n\n## Example 2: Processing a subset of an IW Sentinel-1 swath\nAfter identifying area of interest, generate a list of interferograms with the first (oldest) images as master and all consecutive images as slave, followed by interferograms for the next pairs (Date2-Date3, Date3-Date4, Date4-Date5, etc). This is --proces_steps 3. Useful, for example, for damage proxy mapping or coherence analysis. This example will generate compiled PNGs of unwrapped phase, connected components, interferometric phase for each date pair and also a merged PDF containing all generated interferograms.\n\nImportantly, this example creates GeoTIFF files in GEOGRAPHIC-WGS84 coordinates and in their respective UTM projection in the merged directory.\n\n```\npython2 isce_processing/prepare_Sentinel1.py /raid/InSAR/California/SCI/test 500 \\\n--label \"S1_SCI_SRTM1_30m\" \\\n--dem \"/raid/InSAR/California/SCI/SRTM1/demLat_N33_N35_Lon_W121_W119.dem.wgs84\" \\\n--dem_res 30 \\\n--proc_steps 3 \\\n--generate_png 1 \\\n--roi \"[34,34.5,-120,-119.2]\" \\\n--box \"[33.917,34.112,-119.943,-119.479]\" \\\n--swath \"[2]\" \\\n--do_not_delete 1 \\\n--generate_utm_geotif 1 \\\n--generate_png 1\n```\n\n\n## Example 3: Processing a subset of an IW Sentinel-1 swath\nIn this example, the area of interest and area that will be geocoded is between two swaths. These will be automatically merged, clipped and geocoded\n\n```\npython2 /home/bodo/Dropbox/soft/ISCE/isce_processing/prepare_Sentinel1.py /raid/InSAR/NWArg/S1/Pocitos 500 \\\n--dem /raid/InSAR/NWArg/SRTM1/demLat_S28_S22_Lon_W070_W062.dem.wgs84 \\\n--dem_res 30 \\\n--label \"S1_Pocitos_SRTM1_30m\" \\\n--proc_steps 1 \\\n--roi \"[-25.25, -23, -68, -66]\" \\\n--box \"[-25, -23.55, -67.84, -66.30]\" \\\n--swath \"[2,3]\" \\\n--do_not_delete 1 \\\n--generate_utm_geotif 1 \\\n--generate_png 1\n```\n\n\n## Example 4: Generating xml control files with no processing\nGenerate only xml control files through --proc_steps -1. This will allow manual exploration of data and files.\n\n```\npython2 isce_processing/prepare_Sentinel1.py /raid/InSAR/California/SCI/test 500 \\\n--label \"S1_SCI_SRTM1_30m\" \\\n--dem \"/raid/InSAR/California/SCI/SRTM1/demLat_N33_N35_Lon_W121_W119.dem.wgs84\" \\\n--proc_steps -1 \\\n--roi \"[34,34.5,-120,-119.2]\" \\\n--box \"[33.917,34.112,-119.943,-119.479]\" \\\n--swath \"[2]\" \\\n```\n"}
{"url": "https://github.com/BodoBookhagen/isce_setup", "owner": "BodoBookhagen", "repository_name": "isce_setup", "date_all_variable_collection": "2023-09-11", "description": "Installation and setup of ISCE and GIAnT", "size": 30, "stargazers_count": 1, "watchers_count": 1, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "BodoBookhagen", "contributions": 24}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# isce_setup\nThese guides and scripts only work when you have installed the full ISCE suite (see here http://earthdef.caltech.edu/).\n\nThe installation scripts describe how to setup the python environments for ISCE and GIAnT on servers that already have ISCE installed.\n\n\n## Setup ISCE\nClone the repository into isce_setup.\nStart with [install_isce201704_ubuntu1604_for_users.md](install_isce201704_ubuntu1604_for_users.md) and follow instructions\n\n## Setup GIAnT\nYou will need to setup ISCE first.\n\nStart with [install_giant_ubuntu1604_for_users.md](install_giant_ubuntu1604_for_users.md) and follow instructions\n\n"}
{"url": "https://github.com/BodoBookhagen/Lidar_PC_interpolation", "owner": "BodoBookhagen", "repository_name": "Lidar_PC_interpolation", "date_all_variable_collection": "2023-09-11", "description": "Lidar Point-Cloud interpolation using computational efficient tools", "size": 111640, "stargazers_count": 4, "watchers_count": 4, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 4, "default_branch": "master", "contributors": [{"contributor": "BodoBookhagen", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 52064}], "readme": "# Lidar_PC_interpolation\nThis repository describes in detail how to interpolate lidar points to a gridded surface using various interpolation methods implemented in GDAL using [gdal_grid](https://gdal.org/gdal_grid.html) and [GMT](http://gmt.soest.hawaii.edu/).\n\nSee the [PDF](https://github.com/BodoBookhagen/Lidar_PC_interpolation/raw/master/SCI_Pozo_interpolation_GMT_GDAL.pdf) for more information and a detailed description. \n\nThe folder [gmt5_scripts](https://github.com/BodoBookhagen/Lidar_PC_interpolation/tree/master/gmt5_map_scripts) contains a folder with GMT5 scripts to generate maps and different maps.\n\n"}
{"url": "https://github.com/BodoBookhagen/PC_dem_statistics", "owner": "BodoBookhagen", "repository_name": "PC_dem_statistics", "date_all_variable_collection": "2023-09-11", "description": "PointCloud (PC) DEM statistics", "size": 31, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "BodoBookhagen", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 68931}, {"language": "Shell", "num_chars": 2011}], "readme": "# Deriving optimal DEM resolution from point clouds\nThis code accompanies the manuscript Smith et al. [LINK & CITATION]. This specific code uses lidar point clouds as input data to derive the optimal DEM size. The code loads an LAS file, creates a equi-distance grid and calculated elevation, slope, and point-cloud scatter for each grid cell. The grid cell size varies and allows to estimate optimal conditions for slope and aspect calculations. \n\n## Installation\nThis is a Python 3.x code that will run on any OS, which supports the packages. It runs and has been tested on Linux (Ubuntu/Debian), Windows 10, and Mac OS X. You will need several packages for python to run this code. These are standard packages and are included in many distributionss. If you use [conda](https://conda.io/docs/index.html), you can install the required packages (currently we are using Python 3.6 or 3.7):\n```\nconda create -y -n py3 python scipy pandas numpy matplotlib scikit-image gdal ipython spyder h5py\n```\n\nYou can active this environment with `source activate py3`.\n\nYou don't need ipython or spyder to run this code and you can remove these repositories in the command line above, but they usually come in handy. Also, if you plan to store and process large PC datasets, it may come in handy storing the processed data in compressed HDF5 or H5 files. However, for some installations, the above installed h5py does not contain the gzip compression (or any compression). And you may have to update the installation with \n```\nsource activate py3\nconda install -y -c conda-forge h5py\n```\n\n\nInstall a fast and simple LAS/LAZ reader/writer. You can do similar steps through lastools, but this interface is fairly simple to use:\n```\nsource activate py3\npip install laspy\n```\nIf you have issues with pip, see: https://stackoverflow.com/questions/47955397/pip3-error-namespacepath-object-has-no-attribute-sor\n\n\nNOT WORKING YET (lastools will kill gdal): In order to read and write zipped LAS files (LAZ) files, install lastools. These will come in handy. Note that if you have installed pdal, you usually don't need this:\n```\nsource activate py3\nconda install -y -c conda-forge lastools\n```\n\nIf you plan to use some commands/pipelines from pdal, install the following. We usually use this for point-cloud pre-processing, filtering, and classification:\n```\nsource activate py3\nconda install -c mathieu pdal \n```\n\n\nThis code uses [pykdtree](https://github.com/storpipfugl/pykdtree). There are other KDTree implementations, for example [scipy.spatial.cKDTree](https://docs.scipy.org/doc/scipy-0.19.1/reference/generated/scipy.spatial.cKDTree.html). But pykdtree is faster (but doesn't allow you to save the results such as cKDTree). Because we aim at very large point clouds, the pyKDTree algorithm is significantly faster for generating and querying the KDtree and will increase processing speed (we have run tests with 1e6 to 1e9 points). To install pyKDTree:\n```\nsource activate py3\nconda install -y -c conda-forge pykdtree\n\n```\n\nLast, install the repository into your favorite github directory, for example to ~/github:\n```\ncd ~\ngit clone https://github.com/UP-RS-ESP/PC_DEM_stats\n\n```\nYou are now ready to run the code from the command line (see below).\n\n## First steps and running the code\nThe python code `pc_dem_statistics.py` loads a LAS pointcloud and overlays an equi-distance grid (e.g., 1 to 10 m). For each grid cell, the most central point (x, y, z coordinates) is chosen and is used to store field attributes. The code calculates the mean elevation and performs a least-square plane fitting for slope estimation. The slope is used to detrend the elevation data and store the natural scatter (dz) for that grid cell. We argue that the scattering of points around the mean is an indicator for how precise the elevation has been determined.\n\nYou should pre-process your point clouds. For example, you want your point cloud to only contain points that are used for estimating bare-earth ground. This usually requires classifying the pointcloud into ground points and other classes (e.g., buildings, vegetation). There are different ways to do this (e.g., lastools, pdal, and others). Again, the python code `pc_dem_statistics.py` requires bare-earth points only.\n\nThe code requires the following input parameters:\n- --inlas <filename.las>\n- --raster_m_range \"<gridcell_m_start gridcell_m_stop gridcell_m_stepsize>\"     (for example, --raster_m_range \"1 10 1\" will use 1m grid-cell sizes up to 10m in 1m steps)\n- --shapefile_clip <filename.shp>       It is useful to have a polygon shapefile outlining the area of interest to remove potential border effects that may appear through interpolation (Note: <filename.shp> will need to be in the same projection as the las file)\n- --epsg_code <EPSG-CODE>       This is used for writing Geotiff files. In order to generate geotifs with proper projection information, provide the EPSG code (e.g., --epsg_code 26911)\n\nAn example run for the example dataset provided in the [example](example) directory is:\n```\npython -W ignore ~/github/PC_DEM_stats/pc_dem_statistics.py \\\n    --inlas Pozo_USGS_UTM11_NAD83_all_color_cl2.las \\\n    --raster_m_range \"1 10 1\" \\\n    --nr_of_cores 20 \\\n    --shapefile_clip /raid-cachi/bodo/Dropbox/California/SCI/Pozo/shapefiles/Pozo_DTM_noveg_UTM11_NAD83_cat1_b50m.shp \\\n    --epsg_code 26911 2>&1 | tee Pozo_USGS_UTM11_NAD83_all_color_cl2_cat1_pc_dem_groud_slope_statistics_1_10_1.log\n```\n\npython -W ignore /raid-cachi/bodo/Dropbox/soft/github/PC_dem_statistics/PC_DEM_statistics.py --inlas Pozo_USGS_UTM11_NAD83_all_color_cl2.las     --raster_m_range \"1 10 1\"     --shapefile_clip /raid-cachi/bodo/Dropbox/California/SCI/SCI_Pozo_100m_buffer_catchment_UTM11N_NAD83.shp     --epsg_code 26911 --nr_of_cores 20 2>&1 | tee Pozo_USGS_UTM11_NAD83_all_color_cl2_pc_dem_groud_slope_statistics_1_10_1.log\n"}
{"url": "https://github.com/BodoBookhagen/PC_geomorph_roughness", "owner": "BodoBookhagen", "repository_name": "PC_geomorph_roughness", "date_all_variable_collection": "2023-09-11", "description": "PointCloud (PC) statistics and roughness calculation for geomorphologic analysis", "size": 500050, "stargazers_count": 2, "watchers_count": 2, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 5, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 5, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "BodoBookhagen", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 191665}, {"language": "Shell", "num_chars": 111400}], "readme": "# Point Cloud (PC) Geomorphologic roughness and topographic detrending\n*This algorithm for this code is describe in:\nBingham, N., Bookhagen, B., Johnson, K., and Chadwick, O. (in review): Use of lidar point cloud data to assess human-induced erosion and loss of vegetation cover on contrasting lithologies*\n\nWhen using the code, please cite the above paper.\n\n# Point Cloud (PC) Geomorphologic roughness and topographic detrending\nDetrending Point Cloud (PC) data with slope and calculating topographic roughness and curvature from PCs.\n\nThe code reads in a ground-classified PC from a LAS/LAZ file and calculates several geomorphology-relevant metrics on the PC. Input files can be from a lidar or a Structure-from-Motion (SfM) PC, but should be ground classified (for descriptions on how to ground-classify your data, see the [PDF manual](docs/PC_geomorph_roughness_manual.pdf)). \nThe algorithm allows defining a radius which is used to fit a linear plane through the point cloud to detrend the data (i.e., normalize the point cloud with mean elevation of 0). These data are used to calculate deviations from the mean (roughness) and identify rills, arroyos, incised canyons, and other forms of erosion processes. By varying the radius over which the plane is fitted, several scales of the landscape can be analyzed (similar to varying radii of topographic relief).  The algorithm choses seed points from the PC with a user-defined spacing (for example 1m) and calculated statistics for each seed point with that given radius. \n\nOutput includes a set of shapefile and geotiffs that show statistics of the PC within the given radius. Also, CSV and H5 files are created that contain lists of seed point location and statistical results for further analysis in Python or Matlab.\n\nThe code is parallized using `multiprocessing` and uses by default all available cores. This significantly speeds up statistic calculation of the point coud. For large point clouds, a significant amount of RAM is required or you will need to split your point cloud into smaller tiles.\n\n\nThe code performs several additional steps that are described in detail in a [PDF manual](docs/PC_geomorph_manual.pdf). In summary, these are:\n1. Finding seed points with a given spacing, usually 1m to 5m.\n\n2. For each seed point and its neighborhood (for 1m spacing of seed points points within a radius of 0.5m  are used), statistics are calculated from the PC (and all points). These include, for example slope, curvature, variability of height (Z) values (for a full list and detailed description see the manual). The parameters also allow detrending the points within the seed-point radius by its slope and derive surface-roughness parameters.\n\n3. The code allows to subsample a point cloud either by a max. number of neighborhood points (e.g., k=5) or by defining a fraction of points to use to create a point cloud with approximately similar point-cloud density based on probabilities. This step of point-cloud homogenization can also be performed by other approaches (see for example [PDAL filters](https://pdal.io/stages/filters.html). The subsampled point cloud is written as a new LAS file.\n\n4. The code interpolates the seed points to a grid and writes the output as a geotiff. In addition, a point cloud generates a LAS file of all seed points with the relevant metric.\n\n5. If GMT is installed (and that opion is chosen), a set of output maps is generated for initial visualization. \n\n\n# Installation\nThis is a Python 3.x code that will run on any OS, which supports the packages. It runs and has been tested on Linux (Ubuntu/Debian), Windows 10, and Mac OS X. We are using [conda/miniconda](https://conda.io/docs/) to install the required packages, which can be [downloaded here](https://conda.io/miniconda.html). Follow [these instruction](https://conda.io/docs/user-guide/install/index.html) to get miniconda installed.\n\nYou will need several packages for python to run this code. These are standard packages and are included in all distributions. We create an environment called `PC_py3` (PointCloud-python3) in the following way (currently we are using Python 3.6, but  3.7 should work equally well):\n\n```\nconda config --prepend channels conda-forge/label/dev\nconda config --prepend channels conda-forge\nconda create -y -n PC_py3 python=3.6 pip scipy pandas numpy matplotlib \\\n    scikit-image gdal pdal xarray packaging ipython multiprocess \\\n    h5py lastools pykdtree spyder gmt=5*\n```\n\nYou can active this environment on the command line with `source activate PC_py3`.\n\nYou don't need ipython or spyder to run this code and you can remove these repositories in the command line above, but they usually come in handy. Also, we are installing GMT5 for visualization purposes. If you don't plan to generate maps and/or use GMT, you can safely remove `gmt=5*` from the line above.\n\nNext, Install a fast and simple LAS/LAZ reader/writer. You can do similar steps through `lastools`, but this interface is fairly simple to use. *Please note thas laspy currently does not support writing LAZ files*:\n```\nsource activate PC_py3\npip install laspy\n```\nIf you have issues with pip, see: [here](https://stackoverflow.com/questions/47955397/pip3-error-namespacepath-object-has-no-attribute-sor).\n\nThis code uses [pykdtree](https://github.com/storpipfugl/pykdtree). There are other KDTree implementations, for example [scipy.spatial.cKDTree](https://docs.scipy.org/doc/scipy-0.19.1/reference/generated/scipy.spatial.cKDTree.html). But pykdtree is faster (but doesn't allow you to save the results such as cKDTree). Because we aim at very large point clouds, the pyKDTree algorithm is significantly faster for generating and querying the KDtree and will increase processing speed (we have run tests with 1e6 to 1e9 points).\n\nLast, install the repository into your favorite github directory, for example ~/github:\n```\ncd ~/github\ngit clone https://github.com/UP-RS-ESP/PC_geomorph_roughness\n\n```\nYou are now ready to run the code from the command line (see below).\n\n\n# Command line parameters\nThe code can be run from the command line and you can invoke a list of parameters and help with:\n```\npython pc_geomorph_roughness.py -h\n\nusage: pc_geomorph_roughness.py [-h] --inlas INLAS [--raster_m RASTER_M]\n                                [--raster_m_range RASTER_M_RANGE]\n                                [--subsample_1m_pc_k SUBSAMPLE_1M_PC_K]\n                                [--subsample_1m_pc_p SUBSAMPLE_1M_PC_P]\n                                [--redo_subsample_1m_pc_p REDO_SUBSAMPLE_1M_PC_P]\n                                [--k_nr_of_neighbors K_NR_OF_NEIGHBORS]\n                                [--dem_fname DEM_FNAME]\n                                [--shapefile_clip SHAPEFILE_CLIP]\n                                [--epsg_code EPSG_CODE]\n                                [--create_geotiff CREATE_GEOTIFF]\n                                [--create_shapefiles CREATE_SHAPEFILES]\n                                [--create_gmt CREATE_GMT]\n                                [--create_las CREATE_LAS]\n                                [--mean_z_only MEAN_Z_ONLY]\n                                [--nr_of_cores NR_OF_CORES]\n                                [--max_nr_of_neighbors_kdtree MAX_NR_OF_NEIGHBORS_KDTREE]\n                                [--pt_lower_threshold PT_LOWER_THRESHOLD]\n                                [--create_gmt_maps CREATE_GMT_MAPS]\n                                [--gmt_title GMT_TITLE]\n                                [--gmt_basename GMT_BASENAME]\n\nPointCloud (PC) processing for DEM statistics. Deriving gridded ground data\n(elevation and slope) using centroid coordinates. B. Bookhagen\n(bodo.bookhagen@uni-potsdam.de), V0.2 Dec 2018.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --inlas INLAS         LAS/LAZ file with point-cloud data. Ideally, this file\n                        contains only ground points (class == 2)\n  --raster_m RASTER_M   Raster spacing for subsampling seed points on LAS/LAZ\n                        PC. Usually 0.5 to 10 m, default = 1. Seed points are\n                        selected from half that distances\n  --raster_m_range RASTER_M_RANGE\n                        Raster spacing for subsampling seed points on LAS/LAZ\n                        PC. Uses a list of ranges with spacing, e.g.,\n                        --raster_m_range \"1 10 1\" will create raster files\n                        with spatial resolutions of 1 to 10 m in 1 m steps.\n  --subsample_1m_pc_k SUBSAMPLE_1M_PC_K\n                        Number of points in 0.5m radius that are randomly\n                        subsampled from the full point cloud. This is useful\n                        if point-cloud density greatly varies, because\n                        statistics calculated for seed points with different\n                        point numbers may be biased. If subsample_pc_k > 0\n                        then the point cloud will be homogenized by selecting\n                        k=n neighbors for each 1-m seed point. For example, if\n                        subsample_pc_k 10, then each 1-mseed point will have\n                        only 10 neighbors.\n  --subsample_1m_pc_p SUBSAMPLE_1M_PC_P\n                        Factor to subsample point cloud by based on\n                        probability. If subsample_1m_pc_p 0.8, a pointcloud\n                        with 80% of the input points is generated and sampling\n                        of point cloud is based on probability. That is, seed\n                        points with a high number of neighbors is sampled less\n                        often, than a seed point with fewer neighbors. Will\n                        use original points, but creates a reduced point\n                        cloud. Calculates probability for 1-m seed-point\n                        spacing.\n  --redo_subsample_1m_pc_p REDO_SUBSAMPLE_1M_PC_P\n                        Flag to redo random subsampling based on probability.\n                        By default, an existing file with a probability is\n                        loaded, if you set \"redo_subsample_1m_pc_p true\", the\n                        random subsampling based on probability will be rerun\n                        and stored in a separate file.\n  --k_nr_of_neighbors K_NR_OF_NEIGHBORS\n                        Number of neighbors for dynamic density estimation\n                        (k_nr_of_neighbors = 10 by default, change to lower\n                        number for lower-density point clouds).\n  --dem_fname DEM_FNAME\n                        Filename of DEM to extract point spacing. Used to\n                        identify seed-point coordinates. Useful if a DEM\n                        exists and one wants to create point-cloud statistics\n                        aligned to the DEM grid.\n  --shapefile_clip SHAPEFILE_CLIP\n                        Name of shapefile to be used to clip interpolated\n                        surfaces. Give full pathname. This is likely the\n                        shapefile you have previously generated to subset/clip\n                        the point-cloud data.\n  --epsg_code EPSG_CODE\n                        EPSG code (integer) to define projection information.\n                        This should be the same EPSG code as the input data\n                        (no re-projection included yet) and can be taken from\n                        LAS/LAZ input file. Add this to ensure that output\n                        shapefile and GeoTIFFs are properly geocoded.\n  --create_geotiff CREATE_GEOTIFF\n                        Create interpolated geotif files from PC data (default\n                        no: --create_geotiff 0, set to --create_geotiff 1 to\n                        generate geotiff files). Note that creating geotiff\n                        files may increase processing time.\n  --create_shapefiles CREATE_SHAPEFILES\n                        Create point shapefiles in UTM (see --epsg_code) and\n                        Geographic-DD projection. These contain all attributes\n                        calculated during the processing (default no:\n                        --create_shapefiles 0, set to --create_shapefiles 1 to\n                        generate shapefiles).\n  --create_gmt CREATE_GMT\n                        Create gmt point or vector files for plotting with GMT\n                        shapefiles in UTM (see --epsg_code) and Geographic-DD\n                        projection. These contain all attributes calculated\n                        during the processing (default no: --create_gmt 0, set\n                        to --create_gmt 1 to generate GMT files).\n  --create_las CREATE_LAS\n                        Create LAS point file from seed points (currently no\n                        writing of LAZ files supported). The color shows mean\n                        elevation of the seed points. These contain all\n                        attributes calculated during the processing (default\n                        no: --create_las 0, set to --create_las 1 to generate\n                        LAS files).\n  --mean_z_only MEAN_Z_ONLY\n                        Calculate mean elevation for grid cell size and no\n                        other parameters.\n  --nr_of_cores NR_OF_CORES\n                        Max. number of cores to use for multi-core processing.\n                        Default is to use all cores (0), set to --nr_of_cores\n                        6 to use 6 cores. For some memory-intensive\n                        applications, it may be useful to reduce the number of\n                        cores.\n  --max_nr_of_neighbors_kdtree MAX_NR_OF_NEIGHBORS_KDTREE\n                        Setting the max. number of neighbors for KDTree\n                        search. This can remain at 100 points for airborne\n                        lidar data. You may want to consider increasing this\n                        when using terrestrial lidar data or SfM data.\n  --pt_lower_threshold PT_LOWER_THRESHOLD\n                        Lower point threshold for performing plane fitting and\n                        slope normalization. If there are less than\n                        pt_lower_threshold in the seed-point neighborhood, a\n                        point fitting is not performed and values are set to\n                        NaN.\n  --create_gmt_maps CREATE_GMT_MAPS\n                        BASH File with GMT commands for plotting maps. Full\n                        path and filename is required. Will need to be fine\n                        tuned (see example).\n  --gmt_title GMT_TITLE\n                        GMT title to appear in output map.\n  --gmt_basename GMT_BASENAME\n                        GMT basename for filename. \"gmt_basename\" with the\n                        following endings are generated: \"_DEM\", \"_DEM\", .\n```\n\n# Examples\n\nThe first command-line example is using the simplest form, without pointcloud subsampling or homogenization. \n0. We change directory into the example01 directory: `cd example01`;\n1. We generate raster files from a LAZ file `--inlas Blanca_in_Pozo_USGS_UTM11_NAD83_all_color_cl2_SC12.laz` ;\n2. starting at 1m grid spacing and going up to 10m in 1m steps `--raster_m_range \"1 10 1\"`;\n3. We also define a shapefile `--shapefile_clip ~/github/PC_geomorph_roughness/example01/SC12.shp` (it's considered good practice to use the full path to the file - it makes creating maps with GMT easier) to clip the interpolated point cloud with;\n4. define the UTM zone and EPSG code `--epsg_code 26911`;\n5. use all available cores `--nr_of_cores 0`;\n6. create geotiff output files `--create_geotiff 1`;\n7. create GMT point files `--create_gmt 1` ; \n8. no shapefiles `--create_shapefiles 0`; \n9. and write an output LAS file `--create_las 1`. \n\nThese commands put together:\n\n```\npython -W ignore ~/github/PC_geomorph_roughness/pc_geomorph_roughness.py \\\n    --inlas Blanca_in_Pozo_USGS_UTM11_NAD83_all_color_cl2_SC12.laz \\\n    --raster_m_range \"1 10 1\" \\\n    --shapefile_clip ~/github/PC_geomorph_roughness/example01/SC12.shp \\\n    --epsg_code 26911 --nr_of_cores 0 --create_geotiff 1 --create_gmt 1  \\\n    --create_shapefiles 0 --create_las 1 \\\n    2>&1 | tee Blanca_in_Pozo_USGS_UTM11_NAD83_all_color_cl2_SC12_pcgr_1_10_1.log\n```\n\nNext, we subsample the point cloud to have a maximum of 5 neighborhood points by adding the option `--subsample_1m_pc_k 5`. Note that we also change the name of the log file.\n```\npython -W ignore ~/github/PC_geomorph_roughness/pc_geomorph_roughness.py \\\n    --inlas Blanca_in_Pozo_USGS_UTM11_NAD83_all_color_cl2_SC12.laz \\\n    --raster_m_range \"1 10 1\" \\\n    --shapefile_clip ~/github/PC_geomorph_roughness/example01/SC12.shp \\\n    --epsg_code 26911 --nr_of_cores 0 --create_geotiff 1 --create_gmt 1  \\\n    --create_shapefiles 0 --create_las 1 \\\n    --subsample_1m_pc_k 5 \\\n    2>&1 | tee Blanca_in_Pozo_USGS_UTM11_NAD83_all_color_cl2_SC12_pcgr_subsample_k5_1_10_1.log\n```\n\nAlternatively, we can sample the original point cloud down to 80% (p=0.8) to generate a more homogenous point cloud with similar point-cloud density by adding the option `--subsample_1m_pc_p 0.5`:\n```\npython -W ignore ~/github/PC_geomorph_roughness/pc_geomorph_roughness.py \\\n    --inlas Blanca_in_Pozo_USGS_UTM11_NAD83_all_color_cl2_SC12.laz \\\n    --raster_m_range \"1 10 1\" \\\n    --shapefile_clip ~/github/PC_geomorph_roughness/example01/SC12.shp \\\n    --epsg_code 26911 --nr_of_cores 0 --create_geotiff 1 --create_gmt 1 \\\n    --create_shapefiles 0 --create_las 1 \\\n    --subsample_1m_pc_p 0.8 \\\n    2>&1 | tee Pozo_USGS_UTM11_NAD83_all_color_cl2_cat1_pc_geomorph_roughness_subsample_p05_1_10_1.log\n``` \n\nIf you would like to generate GMT figures with some outputs, edit the bash GMT shell file `example01_create_map_view_of_PC_geomorph_output_gmt.sh` and define the proper variables on the command line. Here, we set:\n1. `--create_gmt_maps ~/github/PC_geomorph_roughness/example01/example01_create_map_view_of_PC_geomorph_output_gmt.sh` to the name of the bash file (edit this file first!); \n2. Set the title to contain catchment name and subsampling probability `--gmt_title \"Blanca in Pozo (p=0.8)\"`;\n3. Set the prefix of all filenames that are generated in the `maps` subdirectory `--gmt_basename \"Pozo_Blanca_cl2_p08\"`\n\n```\npython -W ignore ~/Dropbox/soft/github/PC_geomorph_roughness/pc_geomorph_roughness.py \\\n    --inlas Blanca_in_Pozo_USGS_UTM11_NAD83_all_color_cl2_SC12.laz \\\n    --raster_m_range \"1 10 1\" \\\n    --shapefile_clip ~/github/PC_geomorph_roughness/example01/SC12.shp \\\n    --epsg_code 26911 --nr_of_cores 0 --create_geotiff 1 --create_gmt 1  \\\n    --create_shapefiles 0 --create_las 1 \\\n    --subsample_1m_pc_p 0.8 \\\n    --create_gmt_maps ~/github/PC_geomorph_roughness/example01/example01_create_map_view_of_PC_geomorph_output_gmt.sh \\\n    --gmt_title \"Blanca in Pozo (p=0.8)\" \\\n    --gmt_basename \"Pozo_Blanca_cl2_p08\" \\\n    2>&1 | tee Blanca_in_Pozo_USGS_UTM11_NAD83_all_color_cl2_SC1_pcgr_subsample_p08_1_10_1.log\n'''\n"}
{"url": "https://github.com/BodoBookhagen/PointCloud-to-GMT", "owner": "BodoBookhagen", "repository_name": "PointCloud-to-GMT", "date_all_variable_collection": "2023-09-11", "description": "Plot a SfM or Lidar PointCloud (PC) with GMT 6", "size": 14, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "BodoBookhagen", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/BodoBookhagen/PointCloud_to_GMT_maps", "owner": "BodoBookhagen", "repository_name": "PointCloud_to_GMT_maps", "date_all_variable_collection": "2023-09-11", "description": "From Point Clouds (PC) to GMT maps", "size": 73111, "stargazers_count": 0, "watchers_count": 0, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "BodoBookhagen", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 8407}, {"language": "Python", "num_chars": 606}], "readme": "# PointCloud_to_GMT_maps\n\nThis document-in-manual-style roughly outlines the steps necessary to take a point cloud, classify it, and display it as a map with GMT: [PDF](docs/From_PC_to_GMT_Maps.pdf). Visualization with GMT includes 2.5D perspective views with points and meshes, but also 2D maps. Emphasis is put on open-source software (with the exception of LAStools that requires a license for full functionality). The following steps are described:\n\n1. Preprocess and classify point-cloud data\n    * including preprocessing of SfM pointclouds that are usually noisier than lidar pointclouds\n2. Classifying a point cloud to generate Digital Surface Model (DSM) or Digital Terrain Model (DTM)\n    * classification and DEM generation with [LAStools](https://rapidlasso.com/lastools/) and [pdal](https://pdal.io/)\n3. Converting the LAZ files to properly organized shapefiles or GMT files \n    * attribute tables are converted\n4. Generating map and perspective views from the gridded lidar data using GMT\n5. Generating perspective views from point-cloud data\n\nAs an example dataset, we use a SfM point cloud of the University of Potsdam campus Golm collected on May-04-2018 with an [ebee Classic drone](https://www.sensefly.com/drone/ebee-mapping-drone/) using the [S.O.D.A.](https://www.sensefly.com/camera/sensefly-s-o-d-a/) camera. The Structure-from-Motion (SfM) processing was performed in [Agisoft Photoscan](http://www.agisoft.com/). Note: Agisoft will be renamed to Agisoft Metashape by the end of 2018. Flights and SfM processing was performed by Simon Riedl ([sriedl@uni-potsdam.de](sriedl@uni-potsdam.de)).\n"}
{"url": "https://github.com/BodoBookhagen/QuantitativeGeomorphology_IITGn", "owner": "BodoBookhagen", "repository_name": "QuantitativeGeomorphology_IITGn", "date_all_variable_collection": "2023-09-11", "description": "Workshop on Quantitative Geomorphology at IIT Gandhinagar (February 2020)", "size": 288803, "stargazers_count": 10, "watchers_count": 10, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 5, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 5, "open_issues": 0, "watchers": 10, "default_branch": "master", "contributors": [{"contributor": "BodoBookhagen", "contributions": 38}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 6209818}, {"language": "Python", "num_chars": 56798}, {"language": "MATLAB", "num_chars": 31546}, {"language": "TeX", "num_chars": 904}], "readme": "# Workshop on Quantitative Geomorphology\n### Quantitative Geomorphology Workshop at IIT Gandhinagar in February 2020, organized by Prof. Vikrant Jain\n\n![Participants of the workshop](docs/Group_photo.jpg)\n\nThe workshop consists of several lectures and lab exercises. On this github page, some of the exercises pertinent to Digital Elevation Model (DEM) analysis, Landscape Evolution Model (LEM) Exercises, and PointCloud (PC) analysis are included. Additional reference material is included as well.\nPlease see [QGeomorph_Workshop_Required_Software.pdf](docs/QGeomorph_Workshop_Required_Software.pdf)\n\n*Monday, 17.02.2020*\n- Introduction to [Digital Elevation Model](lectures/Lecture1_DEM_lr.pdf) analysis\n- Introduction to [Tectonic Geomorphology](lectures/Lecture2_TectonicGeomorphology_lr.pdf)\n- Exercises with Python using synthetic and real-world DEMs:\n  - Creating a Gaussian Hill and performing analytical and numerical slope calculations ([Python](DEM/GaussianHill/gaussian_hill.py), [Jupyter-Notebook](DEM/GaussianHill/Gaussian%20Hill%20and%20DEM%20analysis.ipynb), [PDF](DEM/GaussianHill/Gaussian%20Hill%20and%20DEM%20analysis.pdf))\n  - Performing FlowDirection and FlowAccumulation calculation on a Gaussian Hill ([Python](DEM/GaussianHill/gaussian_hill_richdem.py), [Jupyter-Notebook](DEM/GaussianHill/Gaussian%20Hill%20-%20FlowDirection%20and%20FlowAccumulation.ipynb), [PDF](DEM/GaussianHill/Gaussian%20Hill%20-%20FlowDirection%20and%20FlowAccumulation.pdf))\n  - Hypsometry and Slope Distributions of Earth and Mars ([Jupyter Notebook](DEM/Earth_Mars/Earth%20and%20Mars%20Hypsometry.ipynb), [PDF](DEM/Earth_Mars/Earth%20and%20Mars%20Hypsometry.pdf))\n\n*Tuesday, 18.02.2020*\n- Introduction to [Landscape Evolution Modeling (LEM)](lectures/Lecture3_LandscapeEvolutionModels_lr.pdf) using [landlab](https://landlab.readthedocs.io/en/master/)\n- Some simple modeling exercises:\n  - Fault-scarp modeling using linear diffusion [Python](LEM/landlab_faultscarp_lineardiffusion.py)\n  - Uplift of a block for plateau and escarpment modeling (diffusion only: [Python](LEM/landlab_block_uplift.py) and fluvial erosion: [Python](LEM/landlab_block_uplift_FSE.py))\n  - Setting up a growing anticline with spatially varying uplift rates [Python](LEM/landlab_growing_anticline.py)\n  - Linear Diffusion and fluvial erosion of a Gaussian Hill ([Python](LEM/landlab_GaussianHill.py), [Jupyter Notebook](LEM/LEM%20-%20Gaussian%20Hill.ipynb), [PDF](LEM/LEM%20-%20Gaussian%20Hill.pdf))\n  - Forward modeling of a real landscape - loading a DEM for the Baspa Valley (NW Himalaya) and model diffusional and fluvial erosion processes ([Python](LEM/landlab_Baspa_from_DEM.py), [Jupyter Notebook](LEM/Baspa%20-%20Landlab%20Modeling%20from%20a%20DEM.ipynb), [PDF](LEM/Baspa%20-%20Landlab%20Modeling%20from%20a%20DEM.pdf)\n\n*Wednesday, 19.02.2020*\n- Introduction to [Lidar and Point Cloud (PC) analysis](lectures/L4_Lidar_lr.pdf)\n- Using a Terrestrial Lidar scanner to generate your own point Cloud outside\n- PC analysis, visualization and classification using open-source tools\n- Ground classification and gridding of PC data to generate high-resolution DTMs:\n  - Using PDAL to ground-classify PCs and generate DTMs for the University of Potsdam Campus Golm ([PDF](PointClouds/PC_pdal_for_UP_CampusGolm.pdf)) and the Santa Cruz Island, California ([PDF](PointClouds/PC_pdal_for_SCI_from_USGS_Lidar.pdf))\n\n*Thursday, 19.02.2020*\n- Introduction of Matlab [TopoToolbox](https://topotoolbox.wordpress.com/)\n- Using TopoToolbox to constrain topometrics, steepness indices and chi values. The DEMs are contained in the *Matlab-Topotools* folder:\n  - 1 m Lidar DEM for Santa Cruz Island ([Matlab Code](Matlab-Topotools/topotools_first_steps_SCI.m))\n  - 30m SRTM1 DEM for the Tons-Yamuna Catchments in the NW Himalaya ([Matlab Code](Matlab-Topotools/Himalaya_topotools.m))\n\n*Friday, 19.02.2020*\n- Examples and Exercises from the Baspa Valley in the Himalaya:\n  - Short compilation of radar- and optical-based near global DEMs [PDF](Matlab-Topotools/DEM_data_compilation.pdf)\n  - DEM Analysis using a SRTM1 30m ([Matlab Code](Matlab-Topotools/Baspa_steepness_indices.m) and [PDF](Matlab-Topotools/Baspa_steepness_indices.pdf)) and ALOS PALSAR 12.5m ([Matlab Code](Matlab-Topotools/Baspa_steepness_indices_ALOS12m.m) and [PDF](Matlab-Topotools/Baspa_steepness_indices_ALOS12m.pdf)) data\n  - Using landlab to model the topography of the Baspa catchment ([Python](LEM/landlab_Baspa_from_DEM.py), [Jupyter Notebook](LEM/Baspa%20-%20Landlab%20Modeling%20from%20a%20DEM.ipynb), [PDF](LEM/Baspa%20-%20Landlab%20Modeling%20from%20a%20DEM.pdf))\n"}
{"url": "https://github.com/Bostame/Bayesian-inference", "owner": "Bostame", "repository_name": "Bayesian-inference", "date_all_variable_collection": "2023-09-11", "description": null, "size": 52838, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "Bostame", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 1012302}], "readme": "# Bayesian-inference\n\nSolutions of the exercises of the course Baysian inference \n"}
{"url": "https://github.com/Bostame/Behavioral-Authentication-with-Machine-Learning", "owner": "Bostame", "repository_name": "Behavioral-Authentication-with-Machine-Learning", "date_all_variable_collection": "2023-09-11", "description": null, "size": 25578, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "dev", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 116584}], "readme": "## BAWML\n\nBehavioral Authentication with Machine Learning\n\n#### Requirements\n1. Need to install [conda](https://www.anaconda.com/distribution/)\n2. Recommended IDE is PyCharm\n\n#### Install Package\n\nRun the following commands to install all packages:\n\n`conda env create -f environment.yml`\n\nRun the following commands to update package:\n\n`conda env update -f environment.yml`\n\n#### Run Configurations\n\nIn order to run the project we need to go through the following steps:\n1. Firstly, we need to set some value for `data_path.yaml`\n      - `raw_data:` : This is the raw path folder where all persons raw data \n      (input data) should exists.\n      - `output_path` : Specify a directory where all data will be saved. e.g \n      series,spectrogram's,training\n      - `test_name` : Any arbitrary name which will be used to create sub directory.\n      - `train_test_split` : It's a boolean value If we set it true then TFRecord \n      will generate based on 70/30 split otherwise not.\n      \n2. Then we need to `/prep/data_prep/run raw_data_processing_main.py` file to \ngenerate all necessary pre-processing data.\n\n3. Then we need to configure our `experiment.yml` file under experiments \ndirectory. Here we need to specify some path:\n    - `NAME` : Give any arbitrary name where logs will be saved\n    - `CHECKPOINT_DIR` : Give a path where it can save checkpoint\n    - `DATA_DIR` : Give the full path of the three channel spectrogram \n    data directory.\n\n    There are some default values for some other parameters like Image width,height,\n    Normalization,optimizer etc. if we want we can modify those variable too. \n    \n4. Run the `training.py`. Currently, this file reads from `experiment_3.yml` \nfile configurations. But if you want to use some other experiments then\nneed to change the `main` function of `training.py` accordingly.  \n\n#### Code Committing\n\nPlease try to use commit message according to this [convention](https://gist.github.com/brianclements/841ea7bffdb01346392c)."}
{"url": "https://github.com/Bostame/capture-market-price-of-Binance", "owner": "Bostame", "repository_name": "capture-market-price-of-Binance", "date_all_variable_collection": "2023-09-11", "description": null, "size": 6016, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "sony720", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 4225}], "readme": "# task-js\nsimple node js code to capture market price of different symbols from Binance and update it after each 10 sec\nprice_update_1.js ==> gives updated price of symbols after each 10 second. I have used binance api to call the price and name\nprice_update_2.js ==> gives updated price of symbols(historical data) after each 10 second. I have tried to used cctx package to call binance api and the price and name\n"}
{"url": "https://github.com/Bostame/Dog-Breed-Classifier", "owner": "Bostame", "repository_name": "Dog-Breed-Classifier", "date_all_variable_collection": "2023-09-11", "description": null, "size": 99, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "Bostame", "contributions": 16}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 754508}, {"language": "Python", "num_chars": 2432}], "readme": "# Dog-Breed-Classifier\n\n**Overview**\n\nThe aim of the project is to identify a breed of dog if a photo is given as input. If the photo contains a human face (or alien face), then the application will return the breed of dog that most resembles this person.\n\nIn this project I have used Convolutional Neural Networks (CNNs)! A pipeline is built to process real-world, user-supplied images. Given an image of a dog, the algorithm will identify an estimate of the canine\u2019s breed. If supplied an image of a human, the code will identify the resembling dog breed.\n\n\n**Objective**\n\nBuilding a model to classify between 133 different breeds of dogs and identify them\n\n**The Road Ahead**\n\nI break the notebook into separate steps to make the steps clear. The following is the steps that I followed during the project building time.\n\n1. Import Datasets\n2. Detect Humans\n3. Detect Dogs\n4. Create a CNN to Classify Dog Breeds (from Scratch)\n5. Use a CNN to Classify Dog Breeds (using Transfer Learning)\n6. Create a CNN to Classify Dog Breeds (using Transfer Learning)\n7. Write your Algorithm\n8. Test Your Algorithm\n"}
{"url": "https://github.com/Bostame/Natural-Scenes-Classification", "owner": "Bostame", "repository_name": "Natural-Scenes-Classification", "date_all_variable_collection": "2023-09-11", "description": null, "size": 2510, "stargazers_count": 2, "watchers_count": 2, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "Bostame", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 3550021}], "readme": "# Image_classification"}
{"url": "https://github.com/Bostame/Predicting-Insurance-Purchases", "owner": "Bostame", "repository_name": "Predicting-Insurance-Purchases", "date_all_variable_collection": "2023-09-11", "description": null, "size": 675, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "Bostame", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 1070678}]}
{"url": "https://github.com/Bostame/python-to-connect-binance-api", "owner": "Bostame", "repository_name": "python-to-connect-binance-api", "date_all_variable_collection": "2023-09-11", "description": null, "size": 8135, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "sony720", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 6193807}, {"language": "C", "num_chars": 295278}, {"language": "Cython", "num_chars": 68425}, {"language": "Shell", "num_chars": 3700}], "readme": "# connect with binance api\nA python script to connect with binance api and show price list of different symbols and update it after each 10 second\n"}
{"url": "https://github.com/Bostame/shareMaster", "owner": "Bostame", "repository_name": "shareMaster", "date_all_variable_collection": "2023-09-11", "description": null, "size": 4, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "Bostame", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 2894}]}
{"url": "https://github.com/Bostame/Wild-Fire-Prediction", "owner": "Bostame", "repository_name": "Wild-Fire-Prediction", "date_all_variable_collection": "2023-09-11", "description": null, "size": 386, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "Bostame", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 573117}], "readme": "# fire-prediction\n\nThe administration of the nature park Montesinho in north-east Portugal wants to predict wild fires based on wheather data of the Fire-Wheather-Index (FWI). The aim is to recognize the affected area and consequently the intensity of the imminent wild fire as early as possible in order to be able to adequatly assess the danger caused by the fire. \n"}
{"url": "https://github.com/boundter/Advent-of-Code-2021", "owner": "boundter", "repository_name": "Advent-of-Code-2021", "date_all_variable_collection": "2023-09-11", "description": null, "size": 83, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "boundter", "contributions": 24}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 60576}], "readme": "# Advent of Code 2021\n\nSolutions to problems from [Advent of Code 2021](https://adventofcode.com/2021).\n\n## Setup\n\nRequires python 3.8 and poetry.\n\n```bash\npoetry install\n```\n\n## Running the problems\n\n### Tests\n\n```bash\npoetry run pytest\n```\n\n### Problems\n\nThe first number indicates the day and the second number indicates the first or second problem of the day. Available solutions can be found in the `pyproject.toml`.\n```\npoetry run day_01_1\n```"}
{"url": "https://github.com/boundter/DAAFi", "owner": "boundter", "repository_name": "DAAFi", "date_all_variable_collection": "2023-09-11", "description": "Data Analysis and Administration for Finances", "size": 47, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "boundter", "contributions": 41}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 15280}, {"language": "HTML", "num_chars": 2335}, {"language": "Dockerfile", "num_chars": 638}], "readme": "# DAAFi - Data Analysis and Administration for Finances\n\nThis program will handle the administration of finances with extended data analysis using machine learning.\n\n## Getting Started\n\nGetting started is, at least for now, not automated\n\n### Docker - recommended\n\nCreate a container from the Dockerfile. It exposes the port 5000 of the container. The program can than be run with the following command (assuming the container is called daafi)\n\n`docker run --rm -d -p 5000:5000 daafi`\n\nThe interface is then accessible in the browser under localhost:5000.\n\n**For now the database is not saved and properly initialized.**\n\n#### Dev Mode\n\nTo prepare the system, a new group has to be added. In the container the daafi user has the uid 5555 and the daafi grouo the gid 5555. To allow the program to write to the database, the whole project should be owned by the group with the gid 5555. This means adding the group\n\n`sudo groupadd -g 5555 daafi`,\n\nadding the user to the group\n\n`sudo usermod -a -G daafi $(whoami)`\n\nand change the ownership of the project\n\n`chgrp -R daafi DAAFi`.\n\nThe dev mode of flask can be accessed by running\n\n`docker run --rm -p 5000:5000 -e 'FLASK_ENV=development' -v $APPLOCATION:/app daafi`,\n\nwhere $APPLOCATION is the directory containing the app. Afterwards the database needs to be initialized by running\n\n`flask init_db`\n\nin the container.\n"}
{"url": "https://github.com/boundter/dotfiles", "owner": "boundter", "repository_name": "dotfiles", "date_all_variable_collection": "2023-09-11", "description": null, "size": 72, "stargazers_count": 0, "watchers_count": 0, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "boundter", "contributions": 88}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 9709}, {"language": "Lua", "num_chars": 9296}, {"language": "Vim Script", "num_chars": 3584}]}
{"url": "https://github.com/boundter/geclass", "owner": "boundter", "repository_name": "geclass", "date_all_variable_collection": "2023-09-11", "description": "Administrative Interface for the G(erman)EClass at the University of Potsdam", "size": 3441, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "boundter", "contributions": 159}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 142942}, {"language": "HTML", "num_chars": 6535}, {"language": "Shell", "num_chars": 3389}, {"language": "CSS", "num_chars": 2393}, {"language": "Dockerfile", "num_chars": 1417}], "readme": "# geclass\n\nThis is the administrative interface for the GEclass at the univeristy of Potsdam. It is written in Python using Flask.\n\nTo run this I would recommend the following [Docker](https://hub.docker.com/r/tiangolo/uwsgi-nginx-flask/). A Dockerfile containg\na test configuration is included.\n"}
{"url": "https://github.com/boundter/ising", "owner": "boundter", "repository_name": "ising", "date_all_variable_collection": "2023-09-11", "description": "Simulation of an Ising system for the Computational Physics Course @ University of Potsdam", "size": 92256, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "boundter", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 326689}, {"language": "TeX", "num_chars": 20300}, {"language": "C++", "num_chars": 15094}, {"language": "Python", "num_chars": 8808}, {"language": "Makefile", "num_chars": 980}], "readme": "# Ising\n\nSimulation of the [Ising model](https://en.wikipedia.org/wiki/Ising_model).\n\n## Used tools\n- C++\n- Python (for plots)\n  - numpy\n  - matplotlib\n"}
{"url": "https://github.com/boundter/kuramoto-sivashinsky", "owner": "boundter", "repository_name": "kuramoto-sivashinsky", "date_all_variable_collection": "2023-09-11", "description": "Simulation of the Kuramoto-Sivashinsky equation for the Computational Physics Course @ University of Potsdam", "size": 2814, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 15127}, {"language": "C++", "num_chars": 13376}, {"language": "Python", "num_chars": 9988}, {"language": "Makefile", "num_chars": 2163}]}
{"url": "https://github.com/boundter/nonlinear_systems", "owner": "boundter", "repository_name": "nonlinear_systems", "date_all_variable_collection": "2023-09-11", "description": "Framework for solving ODEs", "size": 234, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "boundter", "contributions": 212}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 209086}, {"language": "CMake", "num_chars": 3724}], "readme": "# Nonlinear Systems\n\nNonlinear Systems contains a generic interface for integrating ordinary differential equations (ODEs). This reduces the repetitive work of integrating such systems.\n\n## Used tools\n- C++\n- CMake to build, install and test\n- Doxygen for documentation\n- Boost\n  - odeint for integration of the ODEs\n  - program_options for adding command line arguments\n  - test for executing the unit-tests\n- [NLopt](https://github.com/stevengj/nlopt) (may become voluntary in the future)\n\n## Whats In There?\n\nnonlinear_systems is a framework to increase the readability of numerical integration of ODEs. A nice side effect is the reduction of bugs. The most important part is the ```GenericSystem``` in ```<nonlinear_systems/systems/generic_system.hpp>```. This class acts as a wrapper around the ODE and keeps track of the current state of the system. It takes the ODE as a type, where the ```operator()``` of the ODE calculates the ODE for given ```x``` and ```t```. The interaction with the system is then handled by ```GenericSystem```.\n\nThere are simple methods to get the current time or state, as well as more complicated ones to calculate the period for a given poincare surface. For a system of multiple units, there is also the posibility to calculate the mean field. The observation during the integration are handled by [observers for odeint](https://www.boost.org/doc/libs/1_66_0/libs/numeric/odeint/doc/html/boost_numeric_odeint/getting_started/short_example.html). Some generic ones are included in ```nonlinear_systems/observers```. For more complicated systems, where different methods are needed, there is the possibility to inherit from ```GenericSystem```.\n\nA similar framework for networks of ODEs is also available in ```GenericNetwork```. The functions are similar and allow a conversion between thinking in terms of 2d-vectors, as well as a flattened representation.\n\nFinally there are some ODEs prepacked, like the Kuramoto-model or the harmonic oscillator. Everything mentioned is unit tested, although the coverage is not quite 100%.\n\n## Getting Started\nThis is a header-only library, so there is no need to install anything. It is a wrapper around the odeint-boost package\n\n### Prerequisites\n- boost (at least version 1.61, this is the oldest version it was tested with)\n- for installation: cmake (lowest tested version is 3.0)\n- for documentations: doxygen\n- NLopt (at least version 2.5)\n\n### Installing (optional)\n\nClone the repository:\n```\ngit clone https://github.com/boundter/nonlinear_systems\n```\nFor the installation change into the source directory and do:\n```\ncmake . && make install\n```\n\nTo use the library in a program it has to be build with cmake. It can then be found like any other package.\n```\nfind_package(nonliear_systems REQUIRED)\n```\nTo link the library just use\n```\ntarget_link_libraries(target nonlinear_systems)\n```\nWhen including it like this, the ```Boost_INCLUDE_DIRS``` and ```NLOPT_INCLUDE_DIRS``` has to be set and included. An example CMakeLists could look like this\n```\ncmake_minimum_required(VERSION 3.0)\nproject(TEST_APP CXX)\n\nfind_package(nonlinear_systems REQUIRED)\nfind_package(Boost)\ninclude_directories(${Boost_INCLUDE_DIRS})\n\nfind_package(NLopt 2.5.0)\ninclude_directories(${NLOPT_INCLUDE_DIRS})\n\nadd_executable(test_app test_app.cpp)\ntarget_link_libraries(test_app nonlinear_systems)\n```\n\n\n#### Testing\n\nThe tests are integrated into cmake and can be build by setting the variable `NL_BUILD_TESTS` to `ON`:\n```\ncmake -DNL_BUILD_TESTS=ON . && make && make test\n```\n\n### Documentation\n\nThe documentation can be generated with doxygen.\n```\ncd docs && doxygen\n```\n\nThe html-doc can then be found in ``` html/index.html ```.\n\n## Example\nSay you want to integrate the harmonic oscillator and calculate the position.\n```\n#include <iostream>\n#include <vector>\n#include <nonlinear_systems/systems/generic_system.hpp>\n#include <nonlinear_systems/observers/position_observer.hpp>\n\nnamespace nl = nonlinear_systems;\n\ntypedef  std::vector<double> state_type;\n\nclass HarmonicOscillatorODE {\n  public:\n    double _omega;\n\n    HarmonicOscillatorODE(void* params) {\n      _omega = reinterpret_cast<double*>(params)[0];\n    }\n\n    void operator()(const state_type& x, state_type& dx, double t) {\n      dx[0] = x[1];\n      dx[1] = -_omega*_omega*x[0];\n    }\n};\n\nint main() {\n  double omega[] = {1.};  // define the frequency\n  auto HarmonicOsc = nl::GenericSystem<HarmonicOscillatorODE>(1, 2, omega);\n  state_type initial = {0., 1.};\n  HarmonicOsc.SetPosition(initial);  // set the initial condition\n  std::vector<state_type> x; std::vector<double> t;  // container for the pos.\n  double dt = 0.1; int n_steps = 10;\n  HarmonicOsc.Integrate(dt, n_steps, nl::PositionObserver<state_type>(x, t));\n  for (size_t i = 0; i < x.size(); ++i) {\n    std::cout << t[i] << \": (\" <<\n      x[i][0] << \", \" << x[i][1] << \")\" << std::endl;\n  }\n}\n```\nThe output of this program is\n```\n0: (0, 1)\n0.1: (0.0998333, 0.995004)\n0.2: (0.198669, 0.980067)\n0.3: (0.29552, 0.955337)\n0.4: (0.389418, 0.921061)\n0.5: (0.479425, 0.877583)\n0.6: (0.564642, 0.825336)\n0.7: (0.644217, 0.764843)\n0.8: (0.717356, 0.696707)\n0.9: (0.783326, 0.621611)\n1: (0.84147, 0.540303)\n```\n"}
{"url": "https://github.com/boundter/poster_simulated_annealing", "owner": "boundter", "repository_name": "poster_simulated_annealing", "date_all_variable_collection": "2023-09-11", "description": "Poster for the lab-course @ University of Potsdam", "size": 1395, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "boundter", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 7560}, {"language": "Python", "num_chars": 5752}], "readme": "# Poster Simulated Annealing\n\nPoster about simulated annealing with german cities.\n\nThe poster can be found in ```tex/main.pdf```. The results of the whole simulation in ```doc/main.pdf```.\n"}
{"url": "https://github.com/boundter/sam", "owner": "boundter", "repository_name": "sam", "date_all_variable_collection": "2023-09-11", "description": "S(ystem) A(nalysis) M(odule)", "size": 322, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "boundter", "contributions": 73}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 782765}, {"language": "CMake", "num_chars": 2937}], "readme": "# sam\nThe **s**ystem **a**nalysis **m**odule is a collection of tools to integrate ordinary differential equations (ODEs) and to\nanalyze the resulting time series data.\n\n# Planned features\n- generic wrapper for system of coupled differential equations and networks of these\n- some generic observers for the systems\n- command line argument parser\n- Fourier transformation\n- Kernel estimation\n"}
{"url": "https://github.com/boundter/scripts", "owner": "boundter", "repository_name": "scripts", "date_all_variable_collection": "2023-09-11", "description": "Short and handy scripts", "size": 8, "stargazers_count": 0, "watchers_count": 0, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "boundter", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 17704}, {"language": "Python", "num_chars": 2628}]}
{"url": "https://github.com/boundter/simulate_schroedinger", "owner": "boundter", "repository_name": "simulate_schroedinger", "date_all_variable_collection": "2023-09-11", "description": "Simulation of the one-dimensional Schr\u00f6dinger-equation for the Computational Physics Course @ University of Potsdam", "size": 3401, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "boundter", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 29772}, {"language": "TeX", "num_chars": 12421}], "readme": "# Simulate Schroedinger\n\nThis is a script to calculate the Eigenvalues and Eigenfunctions of the Schr\u00f6dinger-Equation.\n\n## Used Tools\n- Python\n  - numpy\n  - matplotlib\n  - scipy for integration and curve fitting\n  \n## Getting Started\n\nThe file ```code/main.py``` is outdated, ```code/main2.py``` should be used. It changes the style of programming from fruntional to object-oriented. The plot should be called from the main-directory.\n\nAll necessary classes are contained in ```code/wave.py```. The script ```code/main2.py``` then creates all the plots.\n\n## Classes\n\n```SchroedingerWave``` - Typical solution of the Schr\u00f6dinger Equation with methods to integrate over the wave and plot\n```StationarySchroedinger``` - Child of ```SchroedingerWave``` to integrate the stationary solution with Runge-Kutta of 4th order\n```GeneralSchroedinger``` - Child of ```SchroedingerWave``` to integrate the time-dependent Schr\u00f6dinger eequation with the Crank-Nicolson scheme\n\n"}
{"url": "https://github.com/boundter/T8", "owner": "boundter", "repository_name": "T8", "date_all_variable_collection": "2023-09-11", "description": "Rework of the instruction to the Brownian motion experiment @ University of Potsdam", "size": 1347, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "boundter", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 473731}, {"language": "TeX", "num_chars": 52798}, {"language": "HTML", "num_chars": 1501}, {"language": "Python", "num_chars": 751}, {"language": "CSS", "num_chars": 531}], "readme": "# T8\n\nThis is a rework of an experiment for the introductory lab at the University of\nPotsdam. It consists of the manual in LaTeX, including some figures in Python,\nand a simulation in JavaScript. A given number of particles under the influence\nof Brownian motion are animated and their displacement is compared to a normal\ndistribution.\n\n## Used Tools\n- LaTeX\n- Python\n  - numpy to generate random numbers\n  - matplotlib for the plotting of the figures in the manual\n- JavaScript\n  - Charts.js for the dynamic plotting in the simulation\n  \n## Applet\n\nThe JS-Applet can be opened by opening ```simulations/index.html``` in a modern browser. \n\nThere are three parameters that can be changed. The number of particles, the duration and the number of collisions per second.\nChanging the number of collisions is equivalent to increasing the duration. It is measured in 30 collissions per second.\n"}
{"url": "https://github.com/boundter/toolbox", "owner": "boundter", "repository_name": "toolbox", "date_all_variable_collection": "2023-09-11", "description": "A collection of useful tools", "size": 147, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "boundter", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 511979}, {"language": "CMake", "num_chars": 2266}]}
{"url": "https://github.com/bptlab/active-chor-js", "owner": "bptlab", "repository_name": "active-chor-js", "date_all_variable_collection": "2023-09-11", "description": "Extension of chor-js for blockchain-based active choreographies", "size": 46, "stargazers_count": 3, "watchers_count": 3, "language": "JavaScript", "has_issues": true, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 5, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 5, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "yT0n1", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 23816}]}
{"url": "https://github.com/bptlab/argos", "owner": "bptlab", "repository_name": "argos", "date_all_variable_collection": "2023-09-11", "description": "Documentation for the Argos project.", "size": 19799, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "friedow", "contributions": 3}, {"contributor": "tommartensen", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 18991}]}
{"url": "https://github.com/bptlab/argos-backend", "owner": "bptlab", "repository_name": "argos-backend", "date_all_variable_collection": "2023-09-11", "description": "This is the repository for the argos backend server. The server controls and serves product, event type and event data for an event dashboard. It requires an Event Processing Platform, eg. Unicorn", "size": 19475, "stargazers_count": 5, "watchers_count": 5, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 5, "default_branch": "master", "contributors": [{"contributor": "tommartensen", "contributions": 146}, {"contributor": "friedow", "contributions": 19}, {"contributor": "MaximilianV", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 494546}, {"language": "HTML", "num_chars": 276679}, {"language": "Shell", "num_chars": 908}], "readme": "[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://raw.githubusercontent.com/bptlab/argos-backend/master/LICENSE)\n[![GitHub release](https://img.shields.io/badge/release-2.1.1-blue.svg)](https://github.com/bptlab/argos-backend/releases/latest)\n\n[![Quality Gate - Dev](https://bpt-lab.org/sonarqube/api/badges/gate?key=de.hpi.bpt:argos-backend:dev \"Developer branch\")](https://bpt-lab.org/sonarqube/overview?id=de.hpi.bpt%3Aargos-backend)\n[![Build Status](https://travis-ci.org/bptlab/argos-backend.svg?branch=master)](https://travis-ci.org/bptlab/argos-backend \"Default branch\")\n[![Coverage Status](https://coveralls.io/repos/github/bptlab/argos-backend/badge.svg?branch=master)](https://coveralls.io/github/bptlab/argos-backend?branch=master)\n\n# Argos Backend\n\n## Prerequisites\n* MySQL/MariaDB database\n* Java 8 (tested with jdk_1.8.0_31 and above)\n* Maven 3 (tested with Maven 3.2.5 and above)\n* git\n* Docker\n\n## Local installation\n1. Clone the git repo at [https://github.com/bptlab/argos-backend.git](https://github.com/bptlab/argos-backend.git).\n1. Copy and rename the template property file in ```src/main/resources``` to ```argos-backend.properties``` and change the values as required in your environment.\n1. Execute the command ```mvn install``` (```mvn clean install``` if you want to delete your old jar file, ```mvn\ninstall -DskipTests``` if you want to skip the tests). This will compile the project into a jar file in the target\nfolder.  \n1. execute `java -jar target\\argos-backend.jar`\n1. If asked, allow app to pass firewall\n\n## Recommended development environment\n* IntelliJ IDE\n    * SonarLint-Plugin (to use the project specific Lint rules)\n    * Configured database connection in IntelliJ\n* Database and other applications server\n    * Tool by Johannes Schneider (Hannes01071995) -- very lightweight, but Windows only\n    * Xampp -- for beginners\n    * Docker (see below)\n\n\n## Build Process\nWe integrated [Travis CI](http://travis-ci.org/bptlab) as a continuous integration tool. It builds the project\nafter every commit, sends a sonarLint diagnose to the Sonarqube server at the chair and executes all tests.\n\n\n## Deployment Process\nPlease see the [Installation Guide](https://github.com/bptlab/wiki-resources/wiki/Argos-deployment) for explanations.\n\n## Troubleshooting\n1. Can't access the database although MySQL/MariaDB server is running on the correct port and server?\n    * Make sure that your user has all the rights that he needs for the intended operation.\n\n1. Server doesn't start?\n\t* Make sure the database is running and accessible from your machine.\n\n1. Can't reach your server via HTTP?\n\t* Make sure the sure is running.\n\t* Make sure that the used port is exposed on your firewall.\n"}
{"url": "https://github.com/bptlab/argos-frontend", "owner": "bptlab", "repository_name": "argos-frontend", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1579, "stargazers_count": 5, "watchers_count": 5, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 5, "default_branch": "master", "contributors": [{"contributor": "julianweise", "contributions": 459}, {"contributor": "friedow", "contributions": 408}, {"contributor": "tommartensen", "contributions": 257}, {"contributor": "MaximilianV", "contributions": 217}, {"contributor": "Munin33", "contributions": 25}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 174419}, {"language": "CSS", "num_chars": 4270}, {"language": "Shell", "num_chars": 376}, {"language": "HTML", "num_chars": 351}], "readme": "# Argos frontend\n\n[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://raw.githubusercontent.com/bptlab/argos-frontend/master/LICENSE)\n[![GitHub release](https://img.shields.io/badge/release-2.1.1-blue.svg)](https://github.com/bptlab/argos-frontend/releases/latest)\n\n[![Quality Gate developer branch](https://bpt-lab.org/sonarqube/api/badges/gate?key=de.hpi.bpt:argos-frontend:developer \"Developer Branch\")](https://bpt-lab.org/sonarqube/overview?id=de.hpi.bpt%3Aargos-frontend)\n[![Build Status](https://travis-ci.org/bptlab/argos-frontend.svg?branch=master)](https://travis-ci.org/bptlab/argos-frontend \"Default branch\")\n\n## Requirements\n- node & npm\n\n## Configuration\nTo configure argos-frontend simply access ```src/config/argosConfig.js```\n\n## Development\n### Quick Start\n- ```git clone git@github.com:bptlab/argos-frontend.git && cd argos-frontend```\n- ```npm install```\n- ```npm start```\n- The server is now running at [localhost:3000](http://localhost:3000)\n\n### Development Environment\n1. Set the intendation inside the IDE of your choice to:\n\t- tabs, smart tabs\n\t- tab size 4\n\t- indent 4, continuation indent 4\n\n## Conventions\n### Git\n#### Feature branch naming\nBranches are named in this style: BP_[JIN]_[DWU]\n* JIN = Jira issue number\n* DWU = Story description with underscores\n\n\n### Code Structure\n#### Break component initialisations\nIf initialising a component with more than two parameters, insert a linebreak after the components name and each parameter. \n\nRight\n```\n<EventTable\n\theader={this.state.activeEventType.attributes}\n\tevents={this.state.activeEvents}\n\tfilter={this.state.filter} />\n```\nWrong\n```\n<EventTable header={this.state.activeEventType.attributes} events={this.state.activeEvents} filter={this.state.filter} />\n```\n\n## Constructor method\nConstructor methods should be structured in this way:\n1. Call the parent constructor.\n2. Initialize the components state.\n3. Execute initialisation functions.\n4. Bind ```this``` to functions.\n\n\n## Testing\nArgos frontend uses ReactTestUtils and Jest to test its components. You can run tests by calling ```npm test``` in your cli. \n\n## Deployment \nPlease see the [Installation Guide](https://github.com/bptlab/wiki-resources/wiki/Argos-deployment) for explanations."}
{"url": "https://github.com/bptlab/ark_automate", "owner": "bptlab", "repository_name": "ark_automate", "date_all_variable_collection": "2023-09-11", "description": "An open source RPA tool which uses BPMN to create bots.", "size": 41133, "stargazers_count": 15, "watchers_count": 15, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 7, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 72, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 7, "open_issues": 72, "watchers": 15, "default_branch": "DEV", "contributors": [{"contributor": "SanJSp", "contributions": 328}, {"contributor": "WolfgangDaniel", "contributions": 259}, {"contributor": "kej-jay", "contributions": 146}, {"contributor": "lukashueller", "contributions": 98}, {"contributor": "MaximilianV", "contributions": 6}, {"contributor": "dependabot[bot]", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["bpmn", "robotframework", "robotic-process-automation", "rpa", "rpaframework"], "languages": [{"language": "JavaScript", "num_chars": 293330}, {"language": "CSS", "num_chars": 3185}, {"language": "HTML", "num_chars": 664}], "readme": "# Ark Automate\n\n[![GitHub stars](https://img.shields.io/github/stars/bptlab/ark_automate)](https://github.com/bptlab/ark_automate)\n[![GitHub open issues](https://img.shields.io/github/issues/bptlab/ark_automate)](https://github.com/bptlab/ark_automate/issues)\n[![GitHub open pull requests](https://img.shields.io/github/issues-closed/bptlab/ark_automate)](https://github.com/bptlab/ark_automate/issues)\n[![GitHub open pull requests](https://img.shields.io/github/issues-pr/bptlab/ark_automate)](https://github.com/bptlab/ark_automate/issues)\n[![heroku](https://heroku-badge.herokuapp.com/?app=ark-automate&root=App.js)](https://heroku-badge.herokuapp.com/App.js)\n\nArk-Automate is a platform that allows office users and software developers to automate business or everyday processes by simply sketching the steps of their process. By using simple flowcharts or powerful BPMN in their process outlines, users can create small software solutions using RPA that finish their tasks much faster and more reliably.\n\n## Quick Links\n\n[Wiki](https://github.com/bptlab/ark_automate/wiki) | \n[Tutorial](https://github.com/bptlab/ark_automate/wiki/tutorial) | \n[Screencast](https://www.youtube.com/watch?v=EIbrYbvtknI)\n\n## Installation using Docker\n\nThe easiest way to run a local instance of Ark is using the provided Docker images.\n\n1. Make sure you have Docker installed and running.\n1. Download the latest [docker-compose file](https://raw.githubusercontent.com/bptlab/ark_automate/docker-deployment/docker-compose.yml).\n1. In your console, navigate to the directory of the downloaded file and run `docker-compose up`. You can add a `-d` to run Ark in the background.\n1. [Install](https://github.com/bptlab/ark_automate_local#setup) and run the local client.\n1. Navigate to http://localhost:3000/ to access the front-end and to start modeling RPA bots!\n1. Do you already know our [tutorial](https://github.com/bptlab/ark_automate/wiki/tutorial)? It will guide you through the creation of your first RPA bot using Ark Automate!\n\n> **What is the local client for?**\n> \n> Ark Automate consists of two main components:\n> The software responsible for managing bots, divided in a web-based front-end for modeling and starting bots, as well as a back-end.\n> The lightweight local client however runs on your computer in the background and listens for new RPA jobs to execute.\n> \n> You can skip the step for installing the local client, however, you will then not be able to run bots.\n\n## Product Demo\n\n[![Watch the video](https://i.imgur.com/Q9UTQSY.png)](https://www.youtube.com/watch?v=EIbrYbvtknI)\n\n---\n\n## Local Setup for Development\n\nIf you want to contribute to Ark, you can set up a local development environment as follows.\nPlease install:\n\n1. [Node.js](https://nodejs.org/en/) (at least v10.19) using the [installer](https://nodejs.org/en/download/)\n2. [npm](https://www.npmjs.com/get-npm) (at least v6.14) which is normally installed with Node.js\n3. [nodemon](https://www.npmjs.com/package/nodemon)(at least v2) using `npm install nodemon -g`\n\nThen to complete the repository setup:\n\n1. Clone this repository using `git clone https://github.com/bptlab/ark_automate.git`\n2. Change into the repository folder using `cd ark_automate`\n3. Install all dependencies by running `npm install` in the server and frontend directory. You can easily do this by running ` cd server/ && npm install && cd .. && cd frontend/ && npm install && cd ..` in the projects root directory\n\n### Set up Heroku\n\nFor this step, an invitation to our Heroku project is necessary. Please create yourself a Heroku account, which you link to your Github profile. Then write a short mail to our team [mailing list](mailto:bpmw2020@gmail.com) to be added to the project.\n\n1. Run in the server directory `npm install -g heroku`\n2. Login to Heroku by running `heroku login` and than login to your heroku account\n3. Create a new .env file in the server directory\n4. Add the MongoDb URI to your .env file by running the following command in the server directory `heroku config:get MONGODB_URI -s -a ark-automate >> .env`\n\n### Setup development tools\n\nTools being used in this project are [EsLint](https://eslint.org/) and [Prettier](https://prettier.io/). For information on how to configure them see our [coding standards](https://github.com/bptlab/ark_automate/wiki/Coding-standards#tools)\n\n### Run application\n\nBefore running, please always make sure to have the most recent module versions installed using `npm install` in the server, as well as the frontend directory.\nTo run a development preview of the app, navigate to the server directory and run `npm run local` to start the API server, navigate into the frontend folder and run `npm start` again to also start the frontend.\nNow check http://localhost:3000/ to have a look at the app.\n\nTo run the local client, follow the steps in the [Readme of the local client](https://github.com/bptlab/ark_automate_local#readme).\n\n## Contribute\n\nContribution and feedback are encouraged and always welcome. For more information about how to contribute, the project structure, as well as additional contribution information, see our [Contribution Guidelines](.github/CONTRIBUTING.md). By participating in this project, you agree to abide by its [Code of Conduct](.github/CODE_OF_CONDUCT.md) at all times.\n\n## Contributors\n\nThe main contributors to the project are the four members of the [2020/21 Bachelor Project](https://hpi.de/fileadmin/user_upload/hpi/dokumente/studiendokumente/bachelor/bachelorprojekte/2020_21/FG_Weske_RPA_meets_BPM.pdf) of Professor Weske's [BPT Chair](https://bpt.hpi.uni-potsdam.de) at the [Hasso Plattner Institute](https://hpi.de):\n\n- [Lukas H\u00fcller](https://github.com/lukashueller)\n- [Kay Erik Jen\u00df](https://github.com/kej-jay)\n- [Sandro Speh](https://github.com/SanJSp)\n- [Daniel Woelki](https://github.com/WolfgangDaniel)\n\nThese four participants will push the project forward as part of their bachelor's degree until the summer of 2021.  \nAt the same time our commitment to open source means that we are enabling -in fact encouraging- all interested parties to contribute and become part of its developer community. Regarding Open Source, this project underlays a MIT license which you can find [here](https://github.com/bptlab/ark_automate/blob/main/LICENSE.md)\n\n## Project documentation\n\nOur [architecture](https://github.com/bptlab/ark_automate/wiki/Architecture-in-2021), as well as our current [vision of the project](https://github.com/bptlab/ark_automate/wiki/Vision-for-2021) can be found in our [wiki](https://github.com/bptlab/ark_automate/wiki).\nPlease also see the [code documentation](https://bptlab.github.io/ark_automate/) on its own website including examples.\n"}
{"url": "https://github.com/bptlab/ark_automate_local", "owner": "bptlab", "repository_name": "ark_automate_local", "date_all_variable_collection": "2023-09-11", "description": "Execute robots build with ark_automate locally", "size": 199, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 1, "default_branch": "DEV", "contributors": [{"contributor": "WolfgangDaniel", "contributions": 34}, {"contributor": "SanJSp", "contributions": 16}, {"contributor": "lukashueller", "contributions": 5}, {"contributor": "kej-jay", "contributions": 2}, {"contributor": "MaximilianV", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 6693}, {"language": "Python", "num_chars": 4003}, {"language": "RobotFramework", "num_chars": 771}], "readme": "# Local Client of Ark Automate\n\nThis script allows the local execution of robots that were built in the [Ark Automate Web Application](https://github.com/bptlab/ark_automate). \n\n## Setup\n\nWhile calls from [robotframeworks standard libraries](http://robotframework.org/robotframework/#standard-libraries) work on Windows and MacOS, calls from the [rpaframework](https://rpaframework.org/#libraries) like `Excel.Application.Open Application` only work on Windows.  \nBecause of missing security permissions we are currently not able to provide this version of the local client for MacOS. We recommend running it in a virtual machine instead.  \nBecause of these factors, the local client for now is only supported to run on Windows.\n\nTo run the client first make sure of the following:\n\n1. [node](https://nodejs.org/en/download/) (at least v10) is installed\n2. [robotframework](https://robotframework.org/robotframework/latest/RobotFrameworkUserGuide.html#installation-instructions) is setup correctly, including the [path](https://robotframework.org/robotframework/latest/RobotFrameworkUserGuide.html#configuring-path) variables!\n3. [rpaframework](https://rpaframework.org/index.html#installation)  (at least v9.6) is installed\n\nTo test this, try to execute a self written robot on your local machine using the cmd/bash/shell, for example `robot ./path/to/myRobot.robot`.\n\nThen you can proceed to:\n1. Clone this repository `git clone https://github.com/bptlab/ark_automate_local.git`\n2. Change into the new directory `cd ark_automate_local`\n3. Execute `npm install -g`\n4. Start the script in the current directory by running `ark` \n\n## About the local client\nThe local client is the companion to the web application Ark-Automate. It registers on to a userId and awaits new robotJobs from this user to execute. As soon as it receives a new job via the socket.io connection, it executes the robot and sends live logs to the backend of Ark-Automate. The userId is set when running the local client for the first time or via the `config.json`.\n\nA special feature is the `LiveLogsListener.py` which is an implementation of the [Listener Interface](http://robotframework.org/robotframework/latest/RobotFrameworkUserGuide.html#listener-interface) provided by Robot Framwork. It reacts to the individual test cases run by executing the robot. A test case can be translated to one instruction element of the ssot. For each test case, information on the execution is written into the `robotLogs.json` which is observed by the local client. Each change will result in sending the entire `robotLogs.json` via the socketConnection to the backend, where it is further processed.\n\n![Screenshot of local client in console](https://i.imgur.com/XYIvl5f.png)\n\n"}
{"url": "https://github.com/bptlab/awesome-master-thesis", "owner": "bptlab", "repository_name": "awesome-master-thesis", "date_all_variable_collection": "2023-09-11", "description": "A curated list of awesome master thesis related things", "size": 3188, "stargazers_count": 12, "watchers_count": 12, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 2, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 2, "watchers": 12, "default_branch": "master", "contributors": [{"contributor": "friedow", "contributions": 4}, {"contributor": "MaximilianV", "contributions": 3}, {"contributor": "j-beyer", "contributions": 2}, {"contributor": "christianwarmuth", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 90787}], "readme": "# awesome-master-thesis\n\nA curated list of awesome master thesis related things\n\n## How to Write a Master Thesis\n\n![Master Thesis Process](./process/master-thesis-process.svg)\n\n## Fonts\n\n- http://www.khirevich.com/latex/font/\n\n## Latex Editors\n\n- [Overleaf](https://www.overleaf.com/) - Cloud-based LaTeX editor. Note: Use the XeLaTeX compiler instead of LaTeX or pdfLaTeX compilers\n\n## Other Editors\n\n- [Auratikum](https://app.auratikum.com) - Cloud-based editor for creating and structuring notes\n\n## Reference Management Tools\n\n- [Citavi](https://www.citavi.com/de) - Comprehensive desktop application for reference management (Windows only. [Free for UP Students](https://www.uni-potsdam.de/de/zim/angebote-loesungen/software-campuslizenzen/campuslizenz-citavi.html))\n- [CrossRef](https://search.crossref.org/) - Online Reference Search Engine\n- [JabRef](https://www.jabref.org/) - Desktop application for bibliography reference management (Windows, Mac, JAR-version)\n\n## Spell Checking Tools\n\n- [Grammarly](https://grammarly.com)\n\n## Translation Tools\n\n- [DeepL](https://www.deepl.com/translator)\n"}
{"url": "https://github.com/bptlab/blockchain-choreography", "owner": "bptlab", "repository_name": "blockchain-choreography", "date_all_variable_collection": "2023-09-11", "description": "Tamper proof collaborative modelling of choreograpy models based on distributed ledger technology.", "size": 433, "stargazers_count": 2, "watchers_count": 2, "language": "TypeScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 7, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 7, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "friedow", "contributions": 92}, {"contributor": "MaximilianV", "contributions": 45}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["blockchain", "choreograpy-models", "collaborative-modelling", "dapp", "distributed-ledger-technology", "ethereum", "react", "tamper-proof", "typescript"], "languages": [{"language": "TypeScript", "num_chars": 43777}, {"language": "CSS", "num_chars": 3744}, {"language": "JavaScript", "num_chars": 1480}, {"language": "HTML", "num_chars": 306}], "readme": "# Negotiating Choreography Models Based on Distributed Ledger Technologies\n\nBlockchain Technology in BPM, Winter Term 2018/2019, Hasso Plattner Institute Potsdam\n\n## Installation\n\n1. (optional) Install a private Blockchain like (Ganache)[https://truffleframework.com/ganache]\n1. Install truffle: \n    \n    `npm install -g truffle`.\n1. Change the `truffle.js` or `truffle-config.json (windows)` according to your ethereum provider.\n1. Deploy the requiered smart contracts: \n\n    ```\n    npm run sol\n    ```\n1. Install dapp dependencies: `npm install`.\n1. Deploy the dapp: `npm start`.\n\n\n## Terminology\n\n**Modeler** - A person who works with the choreography model. He/She can be a proposer, as well as a reviewer, but not both at the same time.\n\n**Proposer** - The person suggesting a new change to the model.\n\n**Reviewer** - A person who has to review a change and approve or reject it.\n\n**Verfifier** - A person whose approval is required for the list of reviewers of a particular change.\n"}
{"url": "https://github.com/bptlab/blockchain-deferred-choice", "owner": "bptlab", "repository_name": "blockchain-deferred-choice", "date_all_variable_collection": "2023-09-11", "description": null, "size": 2155, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": false, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "jan-ladleif", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 33873}, {"language": "Solidity", "num_chars": 25099}, {"language": "Shell", "num_chars": 254}], "readme": "> Which Event Happened First? Deferred Choice on Blockchain Using Oracles\n\n*This repository is part of a research paper and should be viewed in that context.*\n\n# Blockchain Deferred Choice\n\nAn implementation and evaluation of the deferred choice workflow pattern on Ethereum, using various oracle architectures and designs to implement events contingent on external data variables.\n\n## Repository Structure\nThe repository is structured as follows:\n\n- `results`: Results of the simulations as used in the paper\n- `scripts`: Helper scripts to start `geth`\n- `solidity`: Solidity smart contracts\n- `src`: Off-chain components and Node.js framework\n  - `/keys`: Private keys of all pre-funded accounts in the genesis block\n  - `/providers`: Off-chain oracle provider code\n  - `/simulation`: Simulation logic\n\n## Running the Simulations\n\n### Installation\nTo run the simulations, you will need to have the following packages installed:\n\n- [Node.js](https://nodejs.org/en/download/), tested with version `v12.18.3` and npm `6.14.6`\n- [Go Ethereum](https://geth.ethereum.org/downloads/) (`geth`), tested with version `1.9.21-stable`\n\nEverything else is then installed via npm:\n\n```bash\nnpm install\n```\n\n### Starting `geth`\nThe simulations require certain accounts to be pre-funded.\nA custom genesis block and a helpful cleanup/startup script are located in the `scripts` folder:\n\n```bash\ncd scripts\n./geth.sh\n```\n\n### Simulations\nThere are two simulations:\n\n- `npm run correctness`: Starts the correctness simulation\n- `npm run cost`: Starts the cost simulation\n\nBoth simulations will output information to the console and a CSV file.\n\nAdditionally, the CSV output of the cost simulation can be translated to custom LaTeX code for inclusion in a paper using the `heatmap` script.\n"}
{"url": "https://github.com/bptlab/bookshelf-docs", "owner": "bptlab", "repository_name": "bookshelf-docs", "date_all_variable_collection": "2023-09-11", "description": null, "size": 11199, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "julianweise", "contributions": 11}, {"contributor": "tommartensen", "contributions": 7}, {"contributor": "friedow", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["bpmn", "case-management", "docs"], "languages": [{"language": "JavaScript", "num_chars": 1735}], "readme": "# Documentation store for the BP Bookshelf\n```\n|\n|- images (tBPM workshop)\n|- input (lecture notes and talks)\n```\n"}
{"url": "https://github.com/bptlab/bookshelf-frontend", "owner": "bptlab", "repository_name": "bookshelf-frontend", "date_all_variable_collection": "2023-09-11", "description": null, "size": 214, "stargazers_count": 0, "watchers_count": 0, "language": "TypeScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "friedow", "contributions": 83}, {"contributor": "tommartensen", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TypeScript", "num_chars": 27387}, {"language": "Vue", "num_chars": 24695}, {"language": "HTML", "num_chars": 675}, {"language": "JavaScript", "num_chars": 58}], "readme": "# Bookshelf Frontend\n\n## Setup\n1. ```npm install```\n2. Copy the template ```src/config-template.json``` to ```src/config.json``` and add your configuration.\n\n## Start\n1. ```npm start```\n2. Server is running on http://localhost:8000.\n"}
{"url": "https://github.com/bptlab/bpi-challenge-2020", "owner": "bptlab", "repository_name": "bpi-challenge-2020", "date_all_variable_collection": "2023-09-11", "description": "The purpose of this repository is to maintain code and text produced to analyze this year's BPI Challenge.", "size": 8799, "stargazers_count": 4, "watchers_count": 4, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 4, "default_branch": "master", "contributors": [{"contributor": "MaximilianV", "contributions": 1}, {"contributor": "sim-o-n", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 4823410}, {"language": "Python", "num_chars": 6022}], "readme": "# BPI Challenge 2020\n\nThe purpose of this repository is to maintain code and text produced to analyze this year's BPI Challenge: https://icpmconference.org/2020/bpi-challenge/\n\n## Repository Contents\n * Cleaned versions of the event logs (see the [data folder](data/cleaned_logs))\n * A [class diagram](data-model/Classdiagram.png) showing attributes and relations of the logs\n * [Jupyter Notebooks](notebook) we used for analyzing the logs. [Below](#notebooks) you will find a brief overview of the included notebooks and their purposes.\n\n\n### Notebooks \ud83d\udcd3\n> \u2139\ufe0f *Please note that you need to have [PM4Py](https://pm4py.fit.fraunhofer.de/install) installed in order to be able to execute the notebooks by yourself. However, the notebooks contained in this repository already include the respective results, just click on any notebook name in the table below.*\n\n| Topic           | Notebook                   | Description |\n|-----------------|----------------------------|-------------|\n| **General**      | [Log Coverage](notebook/Log%20Coverage.ipynb)               | *Analyze the sparseness of case and event attributes.*            |\n|                 | [Permit Log](notebook/Permit%20Log%20-%20Multiple%20Declarations.ipynb) / [Merge Logs](notebook/Merge%20Logs.ipynb)    | *Analyze relations between Permit log, International Declarations log, and Prepaid Travel Cost log.*            |\n|                 | [Statistical Insights](notebook/Statistical%20Insights.ipynb)       | *Provide high-level insights into the distribution of selected attributes across the event logs.*            |\n|                 |                            |             |\n| **Performance** | [Bottleneck Analysis](notebook/Bottleneck%20Analysis.ipynb)        | *Identify and analyze systemic constraints of the process.* |\n|                 | [Dotted Chart Analysis](notebook/Dotted%20Chart%20Analysis.ipynb)      | *Application of dotted charts to uncover batch-processing.*            |\n|                 | [Root Cause Analysis](notebook/Root%20Cause%20Analysis.ipynb)        | *Identify and explain root causes for temporal anomalies in the event logs.* |\n|                 |                            |             |\n| **Operation**   | [Clusters_ID](notebook/Clusters_ID.ipynb) / [Clusters_PTC](notebook/Clusters_PTC.ipynb) | *Analyze potential differences between projects and organizations for international declarations and prepaid travel costs.*            |\n|                 | [Declarations Analysis](notebook/Declarations%20Analysis.ipynb)      |  *Analyzes the number of (re)submissions in the international and domestic declarations logs.*           |\n|                 | [Rejection Rate](notebook/Rejection%20rate.ipynb)             | *Analyze the number of rejected declarations in each step of the process.* |\n|                 | [Travel Times](notebook/TravelTimes.ipynb)               | *Analyzes the trips and expenses recorded in the Permit log.*            |\n|                 |                            |             |\n| **Compliance**  | [Double Payments](notebook/Double%20Payments.ipynb)            | *Investigate potential double payments and their financial impact.* |\n|                 |                            |             |\n\n"}
{"url": "https://github.com/bptlab/bpic19", "owner": "bptlab", "repository_name": "bpic19", "date_all_variable_collection": "2023-09-11", "description": null, "size": 24, "stargazers_count": 4, "watchers_count": 4, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 3, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 3, "open_issues": 0, "watchers": 4, "default_branch": "master", "contributors": [{"contributor": "sim-o-n", "contributions": 17}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 25310}], "readme": "# Business Process Intelligence Challenge 19 - Rule Checker\nThis Python package can be used to specify and check control-flow based business rules for event logs.\n\n## Existing Scripts\nThe directory `scripts/` contains ready-to-run scripts, to check predefined rules for different item-types, as described in the report.\n\n## Examples\n\n### Import XES log\nFollow the steps below, to import an XES event log:\n````\nform util import import_xes_log\n\npath_to_log = './event_log.xes')\nlog = import_xes_log(path_to_log)\n````\nBeside the activity names, only certain, BPIC19 specific case attributes, will be imported.\n\n### Define and Check Rules\nFollow the steps below, to define and check business rules.\n````\nfrom conformance_checking.rule_base import Rule_Checker\nfrom pprint import pprint\n\nrc = Rule_Checker()\nres = rc.check_response(log, 'Vendor creates invoice', 'Record Invoice Receipt')\npprint(res)\n````\nThe `check_precedence()` function takes a path value as additional argument in order to export the `case ID` and other case attributes of violated cases. \n\n"}
{"url": "https://github.com/bptlab/bpm2019ws-fcm-compliance", "owner": "bptlab", "repository_name": "bpm2019ws-fcm-compliance", "date_all_variable_collection": "2023-09-11", "description": "Checking Compliance in Data-Driven Case Management", "size": 1447, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": false, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "adi64", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Checking Compliance in Data-Driven Case Management\n\nCase management approaches address the special requirements of knowledge workers.\nIn fragment-based case management (fCM), small structured parts are modelled and loosely coupled through data dependencies, which can be freely combined at run-time. \nWhen executing business processes, organizations must adhere to regulations, to laws, to company guidelines etc.\nBusiness process compliance comprises methods to verify designed and executed business processes against certain rules.\nWhile design-time compliance checking works well for structured process models, flexible knowledge-intensive processes have been rarely considered despite increasing interest in academia and industry.\n\nIn this paper, we present (i) formal execution semantics of fCM models using Petri nets.\nWe also cover concurrently running fragment instances and case termination.\nWe (ii) apply model checking to investigate the compliance with temporal logic rules; finally, we (iii) provide an implementation based on the open-source case modeler Gryphon and the free model checker LoLA.\n\n## Screencast\n\n<video src=\"bpm2019ws-fcm-compliance.webm\" controls preload>\n<a href=\"bpm2019ws-fcm-compliance.webm\">Click here</a> to download the screencast.\n</video>\n\n## How to run it yourself\n\nThe compliance-enabled fCM system consists of three components:\n\n* [Gryphon](https://github.com/bptlab/gryphon), a web-based fCM modeller. Use the **compliance** branch.\n* [Chimera](https://github.com/bptlab/chimera), an execution engine for fCM. Use the **compliance** branch.\n* [LoLA webservice](https://github.com/bptlab/lola-webservice), a web service wrapper for LoLA.\n\nIdeally, the components are used together via [Docker Compose](https://docs.docker.com/compose/):\n\n* Clone the three repositories locally to a new folder.\n* Check out Gryphon's **compliance** branch.\n* Check out Chimera's **compliance** branch.\n* Build the Gryphon image: `docker build -t bptlab/gryphon:dev gryphon/`\n* Build the Chimera image: `cd chimera && make build_docker && cd ..`\n* Download the LoLA webservice image: `docker-compose -f lola-webservice/docker-compose.yml pull`\n* Start all three components: `docker-compose -f chimera/docker-compose.yml -f gryphon/docker-compose.yml -f lola-webservice/docker-compose.yml up -d gryphon database lola-webservice chimera`\n* Navigate to `http://localhost:3000` to access Gryphon.\n* Stop all three components: `docker-compose -f chimera/docker-compose.yml -f gryphon/docker-compose.yml -f lola-webservice/docker-compose.yml down --remove-orphans`\n\nIn order to check compliance, the case model must be deployed to Chimera.\n\n## The example case model\n\nThe example [Emergency case model](Emergency.json) can be downloaded and imported into Gryphon."}
{"url": "https://github.com/bptlab/bpstruct", "owner": "bptlab", "repository_name": "bpstruct", "date_all_variable_collection": "2023-09-11", "description": "Archived code from old google code project", "size": 9745, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "m0r13", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 595435}, {"language": "Batchfile", "num_chars": 5867}, {"language": "Python", "num_chars": 3681}, {"language": "HTML", "num_chars": 1827}]}
{"url": "https://github.com/bptlab/bpt-docker-zoo", "owner": "bptlab", "repository_name": "bpt-docker-zoo", "date_all_variable_collection": "2023-09-11", "description": "Docker-compose file to easily deploy bpt lab applications Gryphon, Unicorn and Chimera", "size": 13, "stargazers_count": 1, "watchers_count": 1, "language": "Smarty", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "m0r13", "contributions": 9}, {"contributor": "tommartensen", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Smarty", "num_chars": 886}], "readme": "# BPT Docker Zoo - Easily deploy BPT applications all at once #\n\n## Requirements ##\n\n* Docker\n* Docker Compose (version 3 at least)\n\n## Configuration ##\n\n* You can change the port where the whole system is reachable (default: 8080) in the `docker-compose.yml` file: Look at the proxy service and its specified port. Change the line `8080:80` to `port:80`.\n* You can change the location where the whole system is reachable (default: `/`) in the `host.env` file: Look at the environment variable `DEPLOY_PATH`. Also, you can change the names of deployed Chimera, Unicorn and Gryphon.\n* Even though the MySQL-server is not reachable to outside by default, you might want to change root password in the `docker-compose.yml` file (`MYSQL_ROOT_PASSWORD=...`). You also have to change the password for accessing Chimera und Unicorn (`CHIMERA_DB_PASSWORD=...` and `UNICORN_DB_PASSWORD=...`).\n\n## Deployment ##\n\nRun:\n\n```\ndocker-compose up -d\n```\n\nServices are then reachable as (port and locations may vary depending on configuration):\n\n* http://localhost:8080/gryphon/\n* http://localhost:8080/unicorn/\n* http://localhost:8080/chimera/\n"}
{"url": "https://github.com/bptlab/bpt-iot-website", "owner": "bptlab", "repository_name": "bpt-iot-website", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1631, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "m0r13", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 12176}]}
{"url": "https://github.com/bptlab/bpt-resource-management", "owner": "bptlab", "repository_name": "bpt-resource-management", "date_all_variable_collection": "2023-09-11", "description": "Automatically exported from code.google.com/p/bpt-resource-management", "size": 19123, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": false, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ben31414", "contributions": 80}, {"contributor": "twonggg", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 4394494}, {"language": "CSS", "num_chars": 793076}, {"language": "Java", "num_chars": 250026}]}
{"url": "https://github.com/bptlab/caz", "owner": "bptlab", "repository_name": "caz", "date_all_variable_collection": "2023-09-11", "description": "Generic adapter to handle communication between Unicorn and Third Party APIs", "size": 61, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "mlichtblau", "contributions": 27}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": true, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 22597}, {"language": "Dockerfile", "num_chars": 101}], "readme": "# CAZ\n> Generic adapter to subscribe to handle communication between Unicorn and Third Party APIs\n\n<!-- [![NPM Version][npm-image]][npm-url]\n[![Build Status][travis-image]][travis-url]\n[![Downloads Stats][npm-downloads]][npm-url] -->\n\nChimera uses events to communicate with third party APIs. In order to make it as easy as possible to establish the connection, CAZ provides a generic, easy to configure, framework.\n\n![](documentation/caz_workflow.png)\n\n## Installation\n\n```sh\ngit clone https://github.com/bptlab/caz.git\ncd caz\nnpm install             # Install dependencies\nnpm install -g nodemon  # To restart server on filechange for local development\nnpm run start           # Start server\n```\n\n> Note, that in order to work with UNICORN, CAZ must know the UNICORN URL and its own URL. \nYou can set the URLs using the environment variables `UNICORN_BASE_URL` and `CAZ_BASE_URL`.\nSee [Development Section](#development-setup) for an example.\n\n## Usage\n\nThe CAZ already provides a simple way to subscribe to Unicorn events.\n\n### Subscribe to events\n\nIn order to receive messages it is necessary to first subscribe to all events that are of interest.\nPlease overwrite the `SUBSCRIPTIONS` constant in `app.js` with an array that contains an object for each subscription.\n\n*An example of a subscription:*\n\n```javascript\nconst SUBSCRIPTIONS = [{\n  event: 'DCParcel',\n  attributes: ['*'],\n  filters: { 'DO_state': 'delivered' },\n  route: '/sis/delivery-reported'\n}];\n```\n\nCAZ handles registering and also deleting unnecessary subscriptions in Unicorn automatically.\n\n### Handle Notifications\n\nOnce an event is generated in Unicorn that matches one or multiple subscriptions CAZ is called with a POST request on the specified route.\nThe request body contains a JSON object matching the event type that is registered in Unicorn.\nThe CAZ can now convert the data to a format that is accepted by third party APIs and subsequently call the third party API with the correct data.\n\n*An example of a notification handler:*\n\n```javascript\nrouter.post('/delivery-reported', function (req, res, next) {   // Add route defined by subscription\n  const { sscc, receiverID } = req.body;                        // Pick only necessary event information\n  const eventXml = epcisEvents.receiving2(sscc, receiverID);    // Convert JSON to XML expected by third party API\n  epcisEvents.send(eventXml);                                   // Call third party API with correct data\n  next();\n}, helpers.sendSuccessfullUnicornResponse);                     // Send success response to Unicorn\n```\n\n## SMile\n\nAlthough the generic architecture of the CAZ can be used for all sorts of projects involving Unicorn as the event engine, this implementation is developed for the Smile Project. \nMore details, e.g. the process description can be found in the [Wiki of the Smile Project](https://github.com/bptlab/smile/wiki).\nThe CAZ acts as an adapter between UNICORN and three external API providers, namely: **Pickshare**, **SIS** and **TMS**.\nFor the communication from the process engine to the external partner the CAZ subscribes to events of interest, converts the data and calls the third party API.\nOn the other hand the CAZ offers REST routes for the partners that publish events.\n\n### Pickshare\n\n#### SMile \u27a1 Pickshare\n\n1. `parcel-registered`\n1. `time-slot-offer-created`\n1. `delivery-reported`\n\nSMile informs Pickshare when a new parcel is registered, when an offer is created and after the successful delivery.\n\n#### Pickshare \u27a1 SMile\n\n1. `receiver-preferences-received`\n1. `arrived-at-depot`\n1. `offer-confirmed`\n\nPickshare informs SMile about the receivers address and time slot preferences, the arrival at the microdepot and the confirmation of an offer. \n\n### SIS\n\n#### SMile \u27a1 SIS\n\n1. `arrived-at-depot`\n1. `pickup-reported`\n1. `delivery-reported`\n\nSMile informs SIS when the parcel arrived at the depot, when the deliverer picks up the parcel at the depot and when the parcel is delivered to the receiver.\n\n#### SIS \u27a1 SMile\n\n1. `parcels`\n\nSIS informs SMile about new parcels added by the sender\n\n### TMS\n\n#### TMS \u27a1 SMile\n\n1. `pick-up-reported` \n1. `delivery-reported`\n\nTMS informs SMile when the deliverer picks up a parcel at the microdepot and when the parcel is delivered to the receiver\n\n## Development setup\n\nTo start local development it's enough to run\n\n```sh\nnpm run start # or\nnodemon       # restarts server on filechange\n# If you are running the bpt-docker-zoo you can run this command to hook up the CAZ\nUNICORN_BASE_URL=http://localhost/smile/unicorn CAZ_BASE_URL=http://host.docker.internal:3000 nodemon\n```\n\n## Release History\n\n> Currently no released Version\n\n* 0.0.1\n    * Work in progress\n\n## Meta\n\nMarius Lichtblau \u2013 [@lichtblau](https://twitter.com/lichtblau) \u2013 marius@lichtblau.io\n\n[Github](https://github.com/mlichtblau)\n\n## Contributing\n\n1. Fork it (<https://github.com/bptlab/caz/fork>)\n2. Create your feature branch (`git checkout -b feature/fooBar`)\n3. Commit your changes (`git commit -am 'Add some fooBar'`)\n4. Push to the branch (`git push origin feature/fooBar`)\n5. Create a new Pull Request\n\n<!-- Markdown link & img dfn's -->\n[npm-image]: https://img.shields.io/npm/v/datadog-metrics.svg?style=flat-square\n[npm-url]: https://npmjs.org/package/datadog-metrics\n[npm-downloads]: https://img.shields.io/npm/dm/datadog-metrics.svg?style=flat-square\n[travis-image]: https://img.shields.io/travis/dbader/node-datadog-metrics/master.svg?style=flat-square\n[travis-url]: https://travis-ci.org/dbader/node-datadog-metrics\n[wiki]: https://github.com/yourname/yourproject/wiki\n"}
{"url": "https://github.com/bptlab/cepta", "owner": "bptlab", "repository_name": "cepta", "date_all_variable_collection": "2023-09-11", "description": "CEPTA - Complex Event Processing Transportation Analysis", "size": 17235, "stargazers_count": 12, "watchers_count": 12, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 29, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 29, "watchers": 12, "default_branch": "master", "contributors": [{"contributor": "skydivin4ng3l", "contributions": 194}, {"contributor": "leopetter", "contributions": 136}, {"contributor": "ma-ro", "contributions": 136}, {"contributor": "romnn", "contributions": 70}, {"contributor": "Quacck", "contributions": 41}, {"contributor": "Jostafarr", "contributions": 20}, {"contributor": "grittaweisheit", "contributions": 15}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["cep", "flink", "kafka", "monitoring", "real-time", "transportation"], "languages": [{"language": "Java", "num_chars": 302204}, {"language": "Go", "num_chars": 219911}, {"language": "Vue", "num_chars": 167376}, {"language": "Starlark", "num_chars": 164338}, {"language": "TypeScript", "num_chars": 28299}, {"language": "JavaScript", "num_chars": 15061}, {"language": "Shell", "num_chars": 13797}, {"language": "HTML", "num_chars": 9818}, {"language": "Python", "num_chars": 3103}, {"language": "Dockerfile", "num_chars": 1460}], "readme": "<p align=\"center\">\n  <img style=\"display:inline-block\" width=\"400px\" src=\"https://user-images.githubusercontent.com/19370911/80150874-706f2e80-85b9-11ea-92e8-2a4bf79c0314.png\">\n</p>\n\nCEPTA - Complex Event Processing Transportation Analysis\n\n[![Build Status](https://travis-ci.com/bptlab/cepta.svg?branch=master)](https://travis-ci.com/bptlab/cepta)\n![GitHub](https://img.shields.io/github/license/bptlab/cepta)\n[![Release](https://img.shields.io/github/release/bptlab/cepta)](https://github.com/bptlab/cepta/releases/latest)\n\nThe open-source *CEPTA* project aims to examine the applicability of\nmodern (complex) event processing \ntechniques in the context of intermodal transportation.\nThe project is under active development and will regularly \npush updates to the [demo instance](https://bpt-lab.org/cepta).\n\nFor more information, see [bptlab.github.io/cepta/](https://bptlab.github.io/cepta/).\n\n![Screenshot](web/images/screenshot-light.png)\n\n#### Building\nTo build all executables of the entire project:\n```bash\nbazel build //:cepta\n```\nTo build only a specific module or executable:\n```bash\nbazel build //auxiliary/producers/replayer  # Example\n```\n\n#### Running\nTo run a specific executable:\n```bash\nbazel run //auxiliary/producers/replayer -- --port 8080  # Example\n```\nTo run mutiple specific executables (prevents locking) use run.sh instead of bazel run:\n```bash\n./run.sh //auxiliary/producers/replayer -- --port 8080  # Example\n```\n\n\n\n#### Testing\n```bash\nbazel test :all\nbazel test //core:core-tests  # Only test core\n``` \n\n#### Deployment\nThe project uses `docker` and `docker-compose` for deployment.\nFor instructions see `docs/deployment/dev.md` or `docs/deployment/prod.md` respectively.\n\nSummary: \nTo run the latest production version, run \n```bash\nCEPTA_VERSION=\"v0.5.0\" docker-compose -f deployment/prod/docker-compose.yml up\n```\n\nTo build and run the latest development version, run \n```bash\nBUILD=1 ./deployment/dev/devenv.sh up\n```\n\nTo run specific containers (single or multiple) run:\n```bash\n./deployment/dev/devenv.sh up args...\n```\n\nThe containers that can be used as args can be found in /deployment/dev/compose for example: envoy\n\nHave you never build the docker images before than run following instead:\n```\nBUILD=1 ./deployment/dev/devenv.sh up args...\n```\n\n#### Deployment on Mac\nSeeing an error like this while starting the docker container:  \n`standard_init_linux.go:211: exec user process caused \"exec format error\"`\n\nMacOs needs a slight configuration to the build stage. The docker images that are build with bazel have to be build for linux to run in the docker environment. Therefore you have to build the images like this: \n\n```\nbazel run //osiris/usermgmt:build-image --platforms=@io_bazel_rules_go//go/toolchain:linux_amd64\n```\n"}
{"url": "https://github.com/bptlab/chimera", "owner": "bptlab", "repository_name": "chimera", "date_all_variable_collection": "2023-09-11", "description": "Chimera: Execution Engine for Case Management", "size": 99166, "stargazers_count": 12, "watchers_count": 12, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 55, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 55, "watchers": 12, "default_branch": "master", "contributors": [{"contributor": "jaSunny", "contributions": 912}, {"contributor": "Killerameise", "contributions": 556}, {"contributor": "shaarmann", "contributions": 280}, {"contributor": "j-beyer", "contributions": 273}, {"contributor": "svenihde", "contributions": 189}, {"contributor": "pkuhn", "contributions": 183}, {"contributor": "westphal-jan", "contributions": 124}, {"contributor": "marhew", "contributions": 122}, {"contributor": "Tobias314", "contributions": 83}, {"contributor": "tommartensen", "contributions": 36}, {"contributor": "jnslk", "contributions": 36}, {"contributor": "heikobeck", "contributions": 23}, {"contributor": "m0r13", "contributions": 22}, {"contributor": "danijar", "contributions": 14}, {"contributor": "Siddeshkanth", "contributions": 5}, {"contributor": "SiddeshkanthLogonathan", "contributions": 3}, {"contributor": "friedow", "contributions": 1}, {"contributor": "julianweise", "contributions": 1}, {"contributor": "bptbot", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 5149807}, {"language": "HTML", "num_chars": 4490452}, {"language": "TSQL", "num_chars": 3469084}, {"language": "Java", "num_chars": 852966}, {"language": "CSS", "num_chars": 121417}, {"language": "TeX", "num_chars": 48998}, {"language": "Smarty", "num_chars": 2707}, {"language": "GAP", "num_chars": 870}, {"language": "Makefile", "num_chars": 694}, {"language": "Shell", "num_chars": 374}, {"language": "Dockerfile", "num_chars": 272}], "readme": "\n# Welcome to Chimera\nChimera is an engine for executing fragment-based case models, an approach that allows for modelling flexible business processes.\nIt is developed and maintained by the [Business Process Technology (BPT) group](http://bpt.hpi.uni-potsdam.de/) at the Hasso Plattner Institute (HPI).\n\nChimera is **not a modeling tool** for case models! Creation and deployment of case models is handled by the [Gryphon case modeler](https://github.com/bptlab/gryphon) also available at GitHub.\n\n#### Features of Chimera\n* Execution of [BPMN2](http://www.omg.org/spec/BPMN/2.0/) models based on data dependencies\n* Integration to external events via the Complex Event Processing engine Unicorn\n* Usage of external APIs via webservice tasks\n\n## Getting started\nThe easiest way to try out Chimera is using the publicly available instance at ~https://bpt-lab.org/chimera-demo~, which contains several exemplary case models demonstrating the features of Chimera. Please refer to the [user guide](https://bptlab.github.io/chimera) on how to start and enact cases.\n\nThe following instructions will get the Chimera case engine up and running on your local machine.\n\n### Pre-requisites\nThe following software is necessary to build and run Chimera:\n\n   * `Java 8 JDK` available from [Oracle](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html). Make sure that the environment variable `JAVA_HOME` points to your JDK folder (e.g. like [this](http://www.wikihow.com/Set-Java-Home)).\n   * `Apache Tomcat 7` or newer, available [here](https://tomcat.apache.org/download-70.cgi).\n   * `MySQL 5.7 Server`, available [here](https://dev.mysql.com/downloads/mysql/5.7.html#downloads). For your convenience, you can download the [installer](https://dev.mysql.com/get/Downloads/MySQLInstaller/mysql-installer-web-community-5.7.23.0.msi) (direct link) and install MySQL Server, MySQL Notifier, MySQL Workbench, and Connector/J. \n   * `git`, available [here](https://git-scm.com/downloads), to access the code repositories.\n   * `Apache Maven 3`, available [here](http://maven.apache.org/install.html).\n\n### Installation\n\n   1. Checkout out the source code from [github](http://github.com/bptlab/chimera). From the command line you can run `git clone https://github.com/bptlab/chimera.git` to download the repository to your machine.\n   1. Start your MySQL server and create a database, either using the MySQL Workbench or from the command line: `mysql -u USER_NAME -p PASSWORD -e \"create schema SCHEMA_NAME` where `SCHEMA_NAME` should be something like 'chimeradb'.\n   1. Similarily, create a second database to be used for running test cases and name it something like 'chimeradb_test'.\n   1. Build the source code using Maven: `mvn install -Ddb.user=USER_NAME -Ddb.password=PASSWORD -Ddb.schema=SCHEMA_NAME -Ddb.test.schema=TEST_SCHEMA_NAME -DskipTests` Replace *USER_NAME*, *PASSWORD*, *SCHEMA_NAME*, and *TEST_SCHEMA_NAME* with the values from the previous steps.\n   1. Check whether the configuration file `config.properties` was copied to the main directory and whether the variables (`mysql.username`, `mysql.password` etc.) have been replaced correctly.\n   1. Deploy the created war file `target/Chimera.war` to Tomcat by copying it to the webapps folder in your Tomcat installation.\n      * Alternatively, use `mvn tomcat7:deploy -DskipTests` from the command line to automatically deploy the war file. Note however, that you need to configure your Tomcat credentials as described in [this article](http://www.mkyong.com/maven/how-to-deploy-maven-based-war-file-to-tomcat/).\n   1. Start your Tomcat application server and visit http://localhost:8080/Chimera in your browser, replacing the default port 8080 with the one you configured in Tomcat. You should now be able to see the Chimera frontend.\n\n## Creating & Deploying Case Models\nNow that you have the Chimera case engine running, you probably want to execute some case models. \nTo create case models and deploy them into Chimera you will need the [Gryphon Case Modeler](https://github.com/bptlab/gryphon).\n\n## Executing Cases\nTo manually start a new case select the case model from the left menu and click on the green `Start Instance` button.\nThis will open the case view. Enabled activities are displayed on the right; you can begin an activity by clicking on its name.\nIf the activity has a data pre-condition you will need to select a data object on which it operates.\n\nRunning activities are displayed in the middle. You can terminate them by clicking on the checkmark symbol. \nThis will open a modal dialog, which allows to terminate the activity and set state and values of a potential output data object.\n\n**For further information check the [Chimera user guide](https://bptlab.github.io/chimera).**\n\n## Deployment\nChimera offers two main deployment options: 1) using a Java Servlet container like Apache Tomcat, 2) using a [Docker](https://www.docker.com/) image.\n\n### Deploying to a Servlet container\nThis was already described in the installation section. \nIf you deploy the war file to a remote server, you need to make sure, that a MySQL server is running with the configured database schema.\n> :warning: Deployment was only tested with Apache Tomcat\n\n### Deploying Docker image\nUse the `Dockerfile` in the main directory of the project repository to create a docker image.\nTo start the image in a container follow the [instructions in the wiki](https://github.com/bptlab/chimera/wiki/ChimeraConfig#deployment-with-docker).\n\nUp to date docker images of the Chimera case engine are also hosted on our [dockerhub](https://hub.docker.com/r/bptlab/chimera/).\nYou can pull these images with `docker pull bptlab/chimera`.\n\n**TODO**: connect with MySQL container\n\n### Developing & Deploying with Docker/Compose\nTo simplify the local development workflow, you can make use of the `Makefile`. \n**Todo**: mention requirements for this approach.\n\n* Maven build: `make build`\n* Local tomcat release: `make release_local` (requires Tomcat and Unix)\n* Docker build + deploy: `make docker` (update docker tag in `docker-compose.yml` beforehand!)\n\n## Contributing\nYou want to help us? Great :+1:\n\nPlease check out [Contributing.md](CONTRIBUTING.md) for information how you can contribute to the Chimera project, including templates for bug reports, feature suggestions, and pull requests. For in-depth information about the architecture and the individual components of Chimera, the [developer documentation in the wiki](https://github.com/bptlab/chimera/wiki/DevDoc) is the best starting point.\n\n## License \nThe Chimera case engine is provided under the MIT free and open source software license - see [LICENSE.md](LICENSE.md) for details.\n"}
{"url": "https://github.com/bptlab/chimera-webservice-mock", "owner": "bptlab", "repository_name": "chimera-webservice-mock", "date_all_variable_collection": "2023-09-11", "description": "Mocked Service to test Chimera Webservice Activitites", "size": 12, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "tommartensen", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# chimera-webservice-mock\nMocked Service to test Chimera Webservice Activitites\n"}
{"url": "https://github.com/bptlab/chor-checker", "owner": "bptlab", "repository_name": "chor-checker", "date_all_variable_collection": "2023-09-11", "description": "TLAplus based model checking framework for choreographies", "size": 2290, "stargazers_count": 1, "watchers_count": 1, "language": "TypeScript", "has_issues": true, "has_projects": false, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 5, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 5, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "jan-ladleif", "contributions": 4}, {"contributor": "dependabot[bot]", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TypeScript", "num_chars": 21318}, {"language": "TLA", "num_chars": 11513}, {"language": "Dockerfile", "num_chars": 301}], "readme": "```\ndocker build -t chor-checker .\nwinpty docker run --rm -p 3000:3000 --name chor-checker -it chor-checker\n```"}
{"url": "https://github.com/bptlab/chor-checker-frontend", "owner": "bptlab", "repository_name": "chor-checker-frontend", "date_all_variable_collection": "2023-09-11", "description": "Frontend for the choreography model checking framework", "size": 354, "stargazers_count": 2, "watchers_count": 2, "language": "JavaScript", "has_issues": true, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "yT0n1", "contributions": 9}, {"contributor": "jan-ladleif", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 14245}, {"language": "CSS", "num_chars": 4319}, {"language": "HTML", "num_chars": 2490}, {"language": "Dockerfile", "num_chars": 430}], "readme": "Frontend to use for the `chor-checker` framework.\n\n```shell\nnpm install\nnpm run build\nnpm run dev\n```\n\n## License\n\nMIT\n"}
{"url": "https://github.com/bptlab/chor-js", "owner": "bptlab", "repository_name": "chor-js", "date_all_variable_collection": "2023-09-11", "description": "An editor for BPMN 2.0 choreography diagrams based on bpmn-js", "size": 4886, "stargazers_count": 138, "watchers_count": 138, "language": "JavaScript", "has_issues": true, "has_projects": false, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 24, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 4, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 24, "open_issues": 4, "watchers": 138, "default_branch": "master", "contributors": [{"contributor": "jan-ladleif", "contributions": 43}, {"contributor": "yT0n1", "contributions": 36}, {"contributor": "friedow", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 258306}, {"language": "CSS", "num_chars": 8318}, {"language": "HTML", "num_chars": 1957}], "readme": "# chor-js\n\n[![Build Status](https://travis-ci.com/bptlab/chor-js.svg?branch=master)](https://travis-ci.com/bptlab/chor-js)\n\n### ***[:rocket: Try it live! :rocket:](https://bpt-lab.org/chor-js-demo/)***\n\nView and edit [BPMN 2.0](https://www.omg.org/spec/BPMN/2.0.2/) choreography diagrams in the browser.\nBased on [bpmn-js](https://github.com/bpmn-io/bpmn-js/).\n\n[![chor-js screencast](./docs/screencast.gif \"chor-js in action\")](https://github.com/bptlab/chor-js-demo)\n\n:boom: Supports most of the elements in the choreography diagram standard  \n:boom: Imports/exports standard-compliant BPMN2 XML  \n:boom: Provides features specifically designed for choreography modeling\n\nCheck out our [demo application](https://github.com/bptlab/chor-js-demo) for an example web application using chor-js, adding additional features like a model validator and properties panel.\n\n## Research\n\nIf you use chor-js in an academic setting, please cite our demo paper:\n\n> Jan Ladleif, Anton von Weltzien, Mathias Weske: _chor-js: A Modeling Framework for BPMN 2.0 Choreography Diagrams._ ER Forum/Posters/Demos (2019)\n> [[PDF]](http://ceur-ws.org/Vol-2469/ERDemo02.pdf)\n> [[Bibtex]](https://dblp.org/rec/bibtex/conf/er/LadleifWW19)\n\n## Installation\n\n### a) Pre-Packaged\n\nJust include the pre-packaged code in your webpage:\n\n```html\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/chor-js@latest/dist/assets/chor-js.css\">\n<script src=\"https://cdn.jsdelivr.net/npm/chor-js@latest/dist/chor-js-modeler.min.js\"></script>\n<!-- ... or 'viewer' or 'navigated-viewer'! -->\n```\n\nYou can find a sample webpage [here](./docs/prepackaged.html).\n\n### b) NPM\n\nInstall the package via `npm install chor-js` and import chor-js in your application:\n\n```javascript\nimport ChorJS from 'chor-js/lib/Modeler';\n// ... or 'Viewer' or 'NavigatedViewer'!\n```\n\nYou can include the bundled style files from `dist/assets/chor-js.css` or bundle the assets folder on your own.\n\nFor a more elaborate example of how to use the package, see [our demo](https://github.com/bptlab/chor-js-demo).\nA development setup is described there as well.\n\n## Usage\n\nCreate a chor-js instance and link it to a canvas:\n\n```javascript\nconst xml; // your BPMN2 choreography XML\n\n// Setup modeler\nconst modeler = new ChorJS({\n  container: '#canvas',\n  keyboard: {\n    bindTo: document\n  }\n});\n\n// Load model (optionally with a specific diagram ID)\nawait modeler.importXML(xml, '_choreo1');\n```\n\n## Further Documentation\n\nAs the library is based on [bpmn-js](https://github.com/bpmn-io/bpmn-js/), a lot of the instructions and techniques described there also work for chor-js.\n\n## License\n\nLicensed under the [MIT license](https://github.com/bptlab/chor-js/blob/master/LICENSE).\n"}
{"url": "https://github.com/bptlab/chor-js-demo", "owner": "bptlab", "repository_name": "chor-js-demo", "date_all_variable_collection": "2023-09-11", "description": "A demo showcasing the chor-js BPMN 2.0 choreography diagram modeler.", "size": 282, "stargazers_count": 22, "watchers_count": 22, "language": "JavaScript", "has_issues": true, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 9, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 9, "open_issues": 1, "watchers": 22, "default_branch": "master", "contributors": [{"contributor": "yT0n1", "contributions": 16}, {"contributor": "jan-ladleif", "contributions": 6}, {"contributor": "florian-papsdorf", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 26839}, {"language": "Less", "num_chars": 5051}, {"language": "CSS", "num_chars": 1996}, {"language": "HTML", "num_chars": 1812}, {"language": "Dockerfile", "num_chars": 360}], "readme": "# chor-js-demo\n\n__[:rocket: Live Version :rocket:](https://bpt-lab.org/chor-js-demo/)__\n\nA simple demo application showing the usage of the _npm package_ of [`chor-js`](https://github.com/bptlab/chor-js) to view and edit BPMN 2.0 choreography diagrams in the browser.\n\nThe demo also adds some features such as diagram upload and download, and a [validator](./app/lib/validator).\n\n> For an example on how to use the pre-packaged version of chor-js, please refer to the [README there](https://github.com/bptlab/chor-js).\n\n## Local Usage\n\n### Node\n\nYou can install and run the demo locally using Node.js.\n\n#### Run Only\n\n```shell\nnpm install\nnpm run dev\n```\n\nYou can also build it using `npm run build`.\n\nThe demo is then served to `http://localhost:9013`.\nWe use [Parcel](https://parceljs.org) as a build tool.\nThus, unless you set up the project as a development environment (see below), chor-js will not be transpiled and polyfilled, which should be no problem for modern browsers.\n\n#### Development Environment\n\nIf you want to use the demo while developing [chor-js](https://github.com/bptlab/chor-js), you can link the two repositories:\n\n```shell\ngit clone https://github.com/bptlab/chor-js.git\ncd chor-js\nnpm install\nnpm link\n\ncd ..\ngit clone https://github.com/bptlab/chor-js-demo.git\ncd chor-js-demo\nnpm install\nnpm link chor-js\nnpm run dev\n```\n\n### Docker\n\nWe also provide a `Dockerfile` to use with Docker.\n\n```shell\ndocker build . -t chor-js-demo\ndocker run --rm -p 9013:9013 --name chor-js-demo -it chor-js-demo\n```\n\nThe demo is then served to `http://localhost:9013` as a production build using the latest version of chor-js (see Dockerfile).\n\n## License\n\nMIT\n"}
{"url": "https://github.com/bptlab/conceptual-bot-backend", "owner": "bptlab", "repository_name": "conceptual-bot-backend", "date_all_variable_collection": "2023-09-11", "description": null, "size": 57, "stargazers_count": 0, "watchers_count": 0, "language": "TypeScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "MaximilianV", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TypeScript", "num_chars": 47842}], "readme": "conceptual-bot-backend\n"}
{"url": "https://github.com/bptlab/Context-Aware-Change-Pattern-Detection", "owner": "bptlab", "repository_name": "Context-Aware-Change-Pattern-Detection", "date_all_variable_collection": "2023-09-11", "description": null, "size": 4745, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "jcremerius", "contributions": 26}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 71932}], "readme": "# Context-Aware Change Pattern Detection in Event Attributes of Recurring Activities: Implementation and Evaluation\n\n## Introduction\nThis repository provides the implementation and further evaluation details of the paper entitled <b>Context-Aware Change Pattern Detection in Event Attributes of Recurring Activities</b>. The implementation includes four jupyter notebooks and a modified [pm4py implementation](https://github.com/bptlab/Context-Aware-Change-Pattern-Detection/blob/main/pm4py.zip). The jupyter notebooks enumerated from 1 to 3 represent the approach of the paper, starting with the [detection and transformation of recurring events](https://github.com/bptlab/Context-Aware-Change-Pattern-Detection/blob/main/1_Repetitive_Activity_Detection_Context_Identification.ipynb). Then, the [change pattern detection](https://github.com/bptlab/Context-Aware-Change-Pattern-Detection/blob/main/2_Applying_Change_Detection.ipynb) is applied in the second jupyter notebook. The third jupyter notebook includes the [UI](https://github.com/bptlab/Context-Aware-Change-Pattern-Detection/blob/main/3_UI.ipynb) to interact with the identified change patterns and to illustrate them in a process model. The modified pm4py package is only required, if one wants to visualize change patterns in the process model.\n\n## Datasets\n\n### Sepsis\n\nThe Sepsis dataset provides an event log representing the hospital treatment process of patients having [sepsis](https://data.4tu.nl/articles/dataset/Sepsis_Cases_-_Event_Log/12707639). \nIt includes laboratory measurements as recurring activities, where the result of the measurement is stored as an event attribute. The event log includes 1,050 cases with 15,214 events representing 16 activities.\n\n### MIMIC-IV\n\nMIMIC-IV is a relational database including hospital processes of different patients, with procedures performed, medications given, laboratory values taken, image analysis conducted, and more. Its purpose is to support research in healthcare and is therefore publicly available (https://mimic-iv.mit.edu/). \n\nThe event log extracted from MIMIC-IV incorporates common activities in an intensive care unit for acute kidney failure patients, including different forms of ventilation and dialysis. Additionally, laboratory measurements are recorded, including nine measurements conducted at one activity ``Measurement'', which are important for monitoring the disease progression, such as creatinine and urea nitrogen. It contains 3,528 hospital process instances with 26,370 events representing nine different treatment activities.\n\nThe event log from MIMIC-IV cannot be shared directly due to a required data use agreement. Thus, we provide an event log generation script in the already mentioned GitHub repository.\n\n## Reproducing Sepsis and MIMIC results\nTo reproduce the results of the Sepsis event log, the scripts are ready to be executed, as the Sepsis event log is already available in the [Logs](https://github.com/bptlab/Context-Aware-Change-Pattern-Detection/tree/main/Logs) folder. The [outputs](https://github.com/bptlab/Context-Aware-Change-Pattern-Detection/tree/main/Outputs) of the preprocessing steps, including the transformed event log and the detected change patterns, are also already available for Sepsis, so one can immediately execute the [UI](https://github.com/bptlab/Context-Aware-Change-Pattern-Detection/blob/main/3_UI.ipynb) jupyter notebook if desired. \n\nTo reproduce the MIMIC results, one needs access to the [MIMIC-IV](https://mimic.mit.edu/iv/) database, which requires CITI training. Usually, that does not take much more than a day and access is granted within a week. If access is granted, the event log can be retrieved. We implemented an [event log generation tool](https://github.com/bptlab/mimic-log-extraction/tree/main) for MIMIC-IV, which allows to provide a config file as an input, which results in an ready-to-use event log. Use the [config file](https://github.com/bptlab/Context-Aware-Change-Pattern-Detection/blob/main/MIMIC_LOG_CONFIG.yml) in this repository to retrieve an event log by executing the following command: ```python extract_log.py --config MIMIC_Config.yml```. Some post-processing is required, which is conducted in [this jupyter notebook](https://github.com/bptlab/Context-Aware-Change-Pattern-Detection/blob/main/0_MIMIC-IV_Generation.ipynb). After that, the other jupyter notebooks can be executed with the MIMIC event log.\n\nThe implementation is not limited to the above mentioned event logs and can be used with all event logs. It should be noted, that the event logs require recurring activities to make sense for further analysis. It is only required, that the event logs are provided as a .csv file and that the mandatory attributes case id, activity, and timestamp are renamed in the [first jupyter notebook](https://github.com/bptlab/Context-Aware-Change-Pattern-Detection/blob/main/1_Repetitive_Activity_Detection_Context_Identification.ipynb) accordingly. \n\n## Detailed Evaluation Results\n\nAs mentioned in the paper, the following presents detailed results regarding the detection of recurring activities and change pattern results for the MIMIC event log. First, the results of the vectors dfr/dpr representing the directly follows and directly preceding ratios for all activities in MIMIC and Sepsis are shown. The repetition score is then the sum of one row, which are also illustrated below. The matrices are supposed to be read row-wise. For example, the \"Measurement\" activity in Tab. 1 is followed by \"START Invasive Ventilation\" in 84.5% of the occurences of \"START Invasive Ventilation\". Tab. 1 and Tab. 2 show, that the \"Measurement\" is mostly conducted before the START and after the END of a treatment activity. Tab. 3 and Tab. 4 show the respective results for Sepsis. In Sepsis, \"CRP\" and \"Leucocytes\" are almost never following \"Release A\", but precede it relatively often.\n\n\n|![alt text](https://github.com/bptlab/Context-Aware-Change-Pattern-Detection/blob/main/Evaluation/dfr_MIMIC.PNG?raw=true)|\n|:--:| \n| *Tab. 1 Directly-Follows ratios for activities in MIMIC* |\n\n|![alt text](https://github.com/bptlab/Context-Aware-Change-Pattern-Detection/blob/main/Evaluation/dpr_MIMIC.PNG?raw=true)|\n|:--:| \n| *Tab. 2 Directly-Precedes ratios for activities in MIMIC* |\n\n![alt text](https://github.com/bptlab/Context-Aware-Change-Pattern-Detection/blob/main/Evaluation/dfr_Sepsis.PNG?raw=true)\n|:--:| \n| *Tab. 3 Directly-Follows ratios for activities in Sepsis* |\n\n![alt text](https://github.com/bptlab/Context-Aware-Change-Pattern-Detection/blob/main/Evaluation/dpr_Sepsis.PNG?raw=true)\n|:--:| \n| *Tab. 4 Directly-Precedes ratios for activities in Sepsis* |\n\nTab. 5 and Tab. 6 show the repetition scores, which are the average scores of the rows in the matrices.\n\n![alt text](https://github.com/bptlab/Context-Aware-Change-Pattern-Detection/blob/main/Evaluation/rep_score_MIMIC.PNG?raw=true)|![alt text](https://github.com/bptlab/Context-Aware-Change-Pattern-Detection/blob/main/Evaluation/rep_score_Sepsis.PNG?raw=true)\n:-------------------------:|:-------------------------:\n *Tab. 5 Repetition scores for all activities in MIMIC* | *Tab. 6 Repetition scores for all activities in Sepsis* \n \n ### Sepsis Process Models\n\nWe now compare the results of the transformed event logs to the results of the original event logs. With the identified recurring activities and contexts of interest, the methods of change pattern detection can be applied. Without considering their context, the resulting change patterns can be analysed only in relations from the activities to themselves. This is illustrated in Fig. 1 for the Sepsis event log, where the discovered process model is enhanced with change patterns of event attribute values CRP and Leucocytes, respectively. \n\n![alt text](https://github.com/bptlab/Context-Aware-Change-Pattern-Detection/blob/main/Evaluation/Sepsis_Original_Enhanced_BOLD.PNG?raw=true)\n|:--:| \n| *Fig. 1 Enhanced process model with change patterns detected on the raw Sepsis event log* |\n\nThe dotted lines illustrate change patterns when the activities are performed multiple times, where the blue colour illustrates a decrease of the values of CRP and Leucocytes. Please note, that we speak of activities, e.g. \"CRP\", when quoted and of event attributes, such as CRP, when written without quotes. As the event attributes are not related to other activities, only the relation from the recurring activities to themselves can be considered. The number of statistically significant p < 0.05 results for the original Sepsis event log is only one, which is the relation from \"Leucocytes\" to \"Leucocytes\". We also observe small effect sizes (0.13 for Leucocytes and 0.03 for CRP (not statistically significant!)), expressing that there is only a small indication of value decreases. \n\n![alt text](https://github.com/bptlab/Context-Aware-Change-Pattern-Detection/blob/main/Evaluation/Sepsis_New_Enhanced_BOLD.PNG?raw=true)\n|:--:| \n| *Fig. 2 Enhanced process model with change patterns detected on the transformed Sepsis event log* |\n\nFig.2 presents the discovered process model for the transformed Sepsis event log. It includes the transformed measurement activities describing their context, such as \"CRP AFTER ER Sepsis Triage\" and \"Leucocytes BEFORE Release A\". With that, multiple activities include the event attribute representing the respective measurement (Leucocytes/CRP) now. It can be observed, that, dependent on where the measurements are conducted, the change patterns differ. For example, looking at the CRP measurements, CRP has a tendency to increase from \"CRP AFTER ER Sepsis Triage\" to \"CRP Admission NC\" and then drastically decreases from \"CRP AFTER Admission NC\" to \"CRP BEFORE Release A\" for almost all patients with an effect size of $-0.97$.\n \n \n ### MIMIC Process Models\n\nThe following figures show detailed results of the change pattern detection in MIMIC. Fig. 1 and Fig. 2 show a process model enhanced with change patterns. Fig. 1 illustrates a process model without the detection and transformation of recurring activities and Fig. 2 shows then the process model based on the transformed event log. It can be seen, that the \"Measurement\" activity is highly recurring and acts as a central point in the process, which is also represented as high values in dfr/dpr. Thus, the insights of process discovery are very limited. This is the case for the change pattern detection as well, where a decrease of Anion Gap was idnetified with a very low test statistic of -0.13, meaning that there is a very small indication of a value change only. \n\n\n![alt text](https://github.com/bptlab/Context-Aware-Change-Pattern-Detection/blob/main/Evaluation/MIMIC_PM_RAW.png?raw=true)\n|:--:| \n| *Fig. 1 Enhanced process model with change patterns detected on the raw MIMIC event log* |\n\nFig. 2 illustrates an enhanced process model with a few change patterns identified based on the transformed event log. As for Sepsis, more change patterns with increased effect sizes could be detected. Especially the measurements associated to the \"Dialysis\" activities have high effect sizes (0.78-0.88), where Blood Urea Nitrogene (BUN) decreases after dialysis and increases again, before \"Dialysis\" is conducted again [1]. This looping pattern could not be identified before. Additionally, a significant increase of systolic blood pressure could be identified after the beginning of dialysis until end of invasive ventilation, which is a sign of intradialytic hypertension [2]. Furthermore, the process mostly starts with measurements before Invasive Ventilation is conducted. It can also be seen, that \"Invasive Ventilation\" is conducted until the end of treatment and \"Dialysis\" is repeated multiple times during treatment. Thus, the structure of the process model improved as well and more insights regarding changing patterns could be derived. \n\n![alt text](https://github.com/bptlab/Context-Aware-Change-Pattern-Detection/blob/main/Evaluation/MIMIC_PM.png?raw=true)\n|:--:| \n| *Fig. 2 Enhanced process model with change patterns detected on the transformed MIMIC event log* |\n\nFig. 3 shows another view of the change detection cube, which allows to see two-dimensional slices of the it. On the X-axes, three event attributes, and on the Y-axes, seven selected eventually follows relations are shown. There are some more, as seen in the list above, which can be explored with the [UI](https://github.com/bptlab/Context-Aware-Change-Pattern-Detection/blob/main/3_UI.ipynb) jupyter notebook. Some of the illustrated change patterns in the process model can be seen here again and some more. The values in the cells represent the respective test statistic RBC. \n\n![alt text](https://github.com/bptlab/Context-Aware-Change-Pattern-Detection/blob/main/Evaluation/matrix_MIMIC.PNG?raw=true)\n|:--:| \n| *Fig. 3 Change Pattern Matrix of selected event attributes and relations independent of a trace variant* |\n\n\n\n[1] Schiffl, H.: Discontinuation of renal replacement therapy in critically ill patients\nwith severe acute kidney injury: predictive factors of renal function recovery. Int\nUrol Nephrol 50(10), 1845\u20131851 (Oct 2018)\n\n[2] Inrig JK. Intradialytic hypertension: a less-recognized cardiovascular complication of hemodialysis. Am J Kidney Dis. 2010 Mar;55(3):580-9. doi: 10.1053/j.ajkd.2009.08.013. Epub 2009 Oct 22. PMID: 19853337; PMCID: PMC2830363.\n"}
{"url": "https://github.com/bptlab/correlation-analysis", "owner": "bptlab", "repository_name": "correlation-analysis", "date_all_variable_collection": "2023-09-11", "description": "Code for the master thesis \"Deriving Decisive Case Characteristics in Process Performance Analysis\" by Jonas Beyer", "size": 549, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "j-beyer", "contributions": 118}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 280490}, {"language": "FreeMarker", "num_chars": 8622}, {"language": "Kotlin", "num_chars": 1507}], "readme": "# Deriving Decisive Case Characteristics in Process Performance Analysis\n\nAs described in the thesis, the implementation is split into two parts:\n\n- [Log transformation](log-transformer/README.md)\n- [Correlation analysis](correlation-analysis/README.md)\n\nDetails can be found in the corresponding `README` files.\n\nBoth applications are implemented using Java 11."}
{"url": "https://github.com/bptlab/data-based-process-variant-analysis", "owner": "bptlab", "repository_name": "data-based-process-variant-analysis", "date_all_variable_collection": "2023-09-11", "description": null, "size": 930, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "hndrkp", "contributions": 2}, {"contributor": "jcremerius", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 97671}, {"language": "Python", "num_chars": 68928}, {"language": "TypeScript", "num_chars": 24299}, {"language": "JavaScript", "num_chars": 2121}, {"language": "Batchfile", "num_chars": 760}, {"language": "Makefile", "num_chars": 634}], "readme": "# Data-based Process Variant Analysis\n\nThis repository contains the python implementation of the Data-based Process Variant Analysis paper.\n\n## Setup\n\nTo run the tool, you need to install a custom version of [ipyevents](https://github.com/mwcraig/ipyevents) (which is located in this repository as well).\n\nInstall the python requirements of this tool, like Jupyter Labs, PM4Py first. Then install the custom ipyevents package locally by \n\n```bash\n$ cd custom-ipyevents\n$ pip install -e .\n$ jupyter nbextension install --py --symlink --sys-prefix ipyevents\n$ jupyter nbextension enable --py --sys-prefix ipyevents\n$ npm install\n$ npm run build\n$ jupyter labextension install\n```\n\n## Usage\n\nTo reproduce the findings of the paper, you can download the MIMIC-IV dataset on your own and generate an event log to feed into the tool. For doing so, you can use the Juypter notebook located in `notebooks/DBPVA_Event_Log_Generation.ipynb`.\n\nWith the generated event logs, or your own event logs, you can then use the `VariantComparator`.\n\nThe most simple way to use the tool is by only using the `VisualVariantComparator`. In `notebooks/Showcase.ipynb`there are some examples on how to use the package for variant comparison. \n\nTo launch the tool, the following steps are required:\n\n1. Read your event log\n2. Split the event log by an arbitrary criterion\n3. Initialize the Variant Comparator by \n```python\nvariant_comparator = VariantComparator(split_log_1, split_log_2, full_event_log, 'Name Split 1', 'Name Split 2')\nvariant_comparator.prepare()\n```\n4. Start the VisualVariantComparator by\n```python\nvisual_variant_comparator = VisualVariantComparator(variant_comparator)\nvisual_variant_comparator.show()\n```\n\nIf you only need specific parts of the variant comparator, have a look in the `vadbp/variant_comparator.py` file."}
{"url": "https://github.com/bptlab/ds2020-data-driven-case-management-compliance", "owner": "bptlab", "repository_name": "ds2020-data-driven-case-management-compliance", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1461, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": false, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "adi64", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Checking Compliance in Data-Driven Case Management\n\nCase management approaches address the special requirements of knowledge workers.\nIn fragment-based case management (fCM), small structured parts are modelled and loosely coupled through data dependencies, which can be freely combined at run-time. \nWhen executing business processes, organizations must adhere to regulations, to laws, to company guidelines etc.\nBusiness process compliance comprises methods to verify designed and executed business processes against certain rules.\nWhile design-time compliance checking works well for structured process models, flexible knowledge-intensive processes have been rarely considered despite increasing interest in academia and industry.\n\nIn this paper, we present (i) formal execution semantics of fCM models using Petri nets.\nWe also cover concurrently running fragment instances and case termination.\nWe (ii) apply model checking to investigate the compliance with temporal logic rules; finally, we (iii) provide an implementation based on the open-source case modeler Gryphon and the free model checker LoLA.\n\n## Screencast\n\n<video src=\"bpm2019ws-fcm-compliance.webm\" controls preload>\n<a href=\"bpm2019ws-fcm-compliance.webm\">Click here</a> to download the screencast.\n</video>\n\n## How to run it yourself\n\nThe compliance-enabled fCM system consists of three components:\n\n* [Gryphon](https://github.com/bptlab/gryphon), a web-based fCM modeller. Use the **compliance** branch.\n* [Chimera](https://github.com/bptlab/chimera), an execution engine for fCM. Use the **compliance** branch.\n* [LoLA webservice](https://github.com/bptlab/lola-webservice), a web service wrapper for LoLA.\n\nIdeally, the components are used together via [Docker Compose](https://docs.docker.com/compose/):\n\n* Clone the three repositories locally to a new folder.\n* Check out Gryphon's **compliance** branch.\n* Check out Chimera's **compliance** branch.\n* Build the Gryphon image: `docker build -t bptlab/gryphon:dev gryphon/`\n* Build the Chimera image: `cd chimera && make build_docker && cd ..`\n* Download the LoLA webservice image: `docker-compose -f lola-webservice/docker-compose.yml pull`\n* Start all three components: `docker-compose -f chimera/docker-compose.yml -f gryphon/docker-compose.yml -f lola-webservice/docker-compose.yml up -d gryphon database lola-webservice chimera`\n* Navigate to `http://localhost:3000` to access Gryphon.\n* Stop all three components: `docker-compose -f chimera/docker-compose.yml -f gryphon/docker-compose.yml -f lola-webservice/docker-compose.yml down --remove-orphans`\n\nIn order to check compliance, the case model must be deployed to Chimera.\n\n## The example case model\n\nThe example [Emergency case model](Emergency.json) can be downloaded and imported into Gryphon.\n\n## The CAT example model\nBelow find the first version of the computer-aided translation example. In the paper is an version adapted to meet the compliance requirements.\n![Download the CAT model](./figures/cat_v1.svg)"}
{"url": "https://github.com/bptlab/fCM-Collection", "owner": "bptlab", "repository_name": "fCM-Collection", "date_all_variable_collection": "2023-09-11", "description": "A collection of fCM models", "size": 153, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# fCM: Collected Examples\n\nFragment-based case management (fCM) is an academic case management approach.\nIn fCM, a business process is split into fragments that can be flexibly instantiated and combined at run-time.\nHowever, during execution, the process must not violate data constraints.\nAn fCM model consists of four parts:\n- An eponymous set of process fragments (acyclic control-flow graphs)\n- A domain model (a class diagram structuring the process data)\n- A state transition system for each data class (describing the object behavior)\n- A termination condition specifying the goal\n\nThis repository includes a collection of fCM examples of different domains.\n\n## Tools\n\nThe models can be opened and edited with common tools for BPMN and UML modeling, such as\n- Signavior (process fragments)\n- Camunda Modeler (process fragments, *may break the definition of data inputs and outputs*)\n- Papyrus (domain model and state transition tiagrams)\n- Any text editor (termination condition)\n\n## Models\n- [Job Application Process](application/)\n  - [Fragments](application/fragments.bpmn)\n- [Computer Aided Translation](computeraidedtranslation/)\n  - [Fragments](computeraidedtranslation/fragments.bpmn)\n- [Conference Submission and Reviewing](conference/)\n  - [Fragments](conference/fragments.bpmn)\n- [Diagnosing Diabetes and Initial Treatment](diabetes/)\n  - [Fragments](diabetes/fragments.bpmn)\n- [Enrollment in Study Program](enrollment/)\n  - [Fragments](enrollment/fragments.bpmn)\n- [Fixed Price Request](fixedpricerequest/)\n  - [Fragments](fixedpricerequest/fragments.bpmn)\n- [Insurance Claim Handling](insurance/)\n  - [Fragments](insurance/fragments.bpmn)\n- [Mammography](mammography/)\n  - [Fragments](mammography/fragments.bpmn)\n- [Deutsche Presse Agentur](press/)\n  - [Fragments](press/fragments.bpmn)\n- [Seminar Organization](seminarorganization/)\n  - [Fragments](seminarorganization/fragments.bpmn)\n- [Criminal Justice](criminaljustice/)\n  - [Fragments](criminaljustice/fragments.bpmn)"}
{"url": "https://github.com/bptlab/fCM-design-support", "owner": "bptlab", "repository_name": "fCM-design-support", "date_all_variable_collection": "2023-09-11", "description": "Modeling Tool with Design-Time Support for Fragment-Based Case Management", "size": 2083, "stargazers_count": 7, "watchers_count": 7, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 21, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 21, "watchers": 7, "default_branch": "main", "contributors": [{"contributor": "LeonBein", "contributions": 182}, {"contributor": "ma-ro", "contributions": 71}, {"contributor": "MaximilianKoenig", "contributions": 51}, {"contributor": "florian-papsdorf", "contributions": 4}, {"contributor": "dependabot[bot]", "contributions": 2}, {"contributor": "marc-rosenau", "contributions": 1}, {"contributor": "carlaterboven", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 356128}, {"language": "Less", "num_chars": 27550}, {"language": "HTML", "num_chars": 9384}, {"language": "Dockerfile", "num_chars": 177}], "readme": "# fCM-js\n*Modeling Tool with Design-Time Support for Fragment-Based Case Management.*\n### ***[:rocket: Try it live! :rocket:](https://bpt-lab.org/fcm-js/)***\n\n\nfcm-js is a modeling tool for fragment-based case management. It aims at supporting users at design time by providing a joint, visual user interface for all artifacts and by integrating automated guideline checking based on fCM guidelines. \n\nThe catalog of fCM guidelines is also available in this repository in [the wiki](../../wiki).\n\n## User Guide\n### Installation\nNode needs to be installed for the modeler to run.\n\nTo install the modeler, clone this repository on your machine. To start, navigate to the installation folder and enter the following into your command line:\n```shell\nnpm install\nnpm run build\nnpm run serve\n```\n\nThe modeler is then served to `http://localhost:9024`.\n\nWhen developing, the following can be run to automatically re-bundle on changes:\n```shell\nnpm run dev\n```\n\n### Usage\nThere are a [demo video](https://www.youtube.com/watch?v=bIDZUYBNms0) and a [use case tutorial](/.docs/Tutorial.md) to showcase how to use fcm-js.\n\n## Developer Guide\n### Structure Overview\nThe repository is structured as follows: \n* [/app](app) contains the actual application files.\n    * For changes of the overall UI: The web page `.js` and `.html` files can be found in its root, and most general style files under [/styles](app/styles).\n    * The actual logic is then contained in the [/lib](app/lib) folder\n        * [/datamodelmodeler](app/lib/datamodelmodeler), [/fragmentmodeler](app/lib/fragmentmodeler), [/goalstatemodeler](app/lib/goalstatemodeler), and [/olcmodeler](app/lib/olcmodeler) include the resources of the respective modelers. These build heavily on [diagram-js](https://github.com/bpmn-io/diagram-js), [bpmn-js](https://github.com/bpmn-io/bpmn-js), and [object diagram modeler](https://github.com/timKraeuter/object-diagram-modeler/tree/master/modeler), please refer to the documentations of those three to understand how they work. Common modules between the modelers can be found in [/common](app/lib/common), however, duplication might still exist.\n        * [/mediator](app/lib/mediator) includes the central component that controls the communication between and access to the single modelers. For each modeler, this [Mediator](app/lib/mediator/Mediator.js) contains one so called \"hook\", which wraps and allows access  to the respective modeler.\n        * [/guidelines](app/lib/guidelines) includes all relevant code for guidelines. The list of guidelines is defined in [Guidelines.js](app/lib/guidelines/Guidelines.js).\n* [/resources](resources) contains auxiliary example and default files.\n\n### Guideline Interface\nThe guidelines are integrated via a unified interface. They can be found in [app/lib/guidelines](app/lib/guidelines). Here the actual guidelines are implemented in [Guidelines.js](app/lib/guidelines/Guidelines.js) while the checking component is located in [Checker.js](app/lib/guidelines/Checker.js). Every guideline consists of the following components:\n\n- `title`: The title of the guideline which shortly summarizes what the guideline is about.\n- `id`: The id of the guideline which must be a unique identifier.\n- `getViolations(mediator) {}`: A function which returns an array of elements. The mediator parameter allows access to the respective modelers via its hooks (see above).\n- `severity`: Can be one of the following: Errors | Warnings | Information and indicates the color the element is highlighted in.\n- `link`: A link to the guideline in the [guideline catalog](https://github.com/bptlab/fCM-design-support/wiki/Guidelines). \n\nFor every returned element in the getViolations() function the follwing must be returned:\n- `element`: The .businessobject of the element the violation should be displayed on.\n- `message`: The error message which is displayed in the error table and the hints.\n- `quickFixes[]`: An array of potential quickfixes for the violation.\n    -   `label`: The message which is displayed on the quickfix button.\n    -   `action`: The actual action which is performed when the button is clicked.\n\nA new guideline can therefore be implemented by adding the code in the described format in the `export default` array in the [Guidelines.js](app/lib/guidelines/Guidelines.js) file. \n\n## License\n\n[MIT](LICENSE)\n\nContains parts of [bpmn-io](https://github.com/bpmn-io) released under the [bpmn.io license](http://bpmn.io/license), and [diagram-js](https://github.com/bpmn-io/diagram-js) and [object diagram modeler](https://github.com/timKraeuter/object-diagram-modeler/tree/master/modeler) released under the MIT license.\n"}
{"url": "https://github.com/bptlab/fCM-Engine", "owner": "bptlab", "repository_name": "fCM-Engine", "date_all_variable_collection": "2023-09-11", "description": "An Execution Engine for fragment-based Case Management (fCM) based on Access/CPN", "size": 67404, "stargazers_count": 1, "watchers_count": 1, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "AnjoSs", "contributions": 6}, {"contributor": "shaarmann", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 19629}, {"language": "CSS", "num_chars": 130}]}
{"url": "https://github.com/bptlab/fCM-query-generator", "owner": "bptlab", "repository_name": "fCM-query-generator", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1548, "stargazers_count": 1, "watchers_count": 1, "language": "Vue", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "AnjoSs", "contributions": 82}, {"contributor": "shaarmann", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Vue", "num_chars": 46239}, {"language": "JavaScript", "num_chars": 15663}, {"language": "HTML", "num_chars": 832}], "readme": "# Tell Me How - Assisting Knowledge Workers in Reaching Their Objectives\n\nThis repository provides the proof of concept implementation for different publications.\n\n- To see the state of work for the publication \"Modeling Objectives of Knowledge Workers\" (DEC2H Workshop at BPM Conference 2021), visit the [dedicated branch](https://github.com/bptlab/fCM-query-generator/tree/DEC2H2021).\n- To see the state of work for the publication \"Decision Support for Kowledge-Intensive Processes\" (ZEUS Workshop 2022), visit [this branch](https://github.com/bptlab/fCM-query-generator/tree/ZEUS_2022).\n\nKnowledge workers can be assisted in reaching their objectives by allowing them to plan future actions based on those objectives. For this planning, knowledge workers must be able to\n\ni) specify objectives\n\nii) search the state space of the process to find paths that satisfy these objectives\n\niii) get a recommenation for a sequence of actions to achieve those\n\nThe fCM-query-generator aims to enable the first requirement: specifying objectives.\nThe second requirement&mdash;analyzing the state space of the model&mdash;is possible by utilizing the [fcm2cpn](https://github.com/bptlab/fcm2cpn) compiler. It takes an fCM model as input and generates a colored Petri net (CPN) formalization of it. This formalization can then be executed and analyzed with [CPN Tools](http://cpntools.org). Using CPN Tools, the state space can be searched for plans satisfying objectives. Therefore, queries created by the fCM-query-generator are used.\nThird, recommending sequences of actions is only possible to a limited extend with this implementation: Every next state needs to be investigated to recommend a direct next action. Recommending paths requires further work.\n\nA [Screencast](https://youtu.be/4gswHraTg_A) is available on youtube.\n\nThe interplay of the mentioned components works as follows:\n\n<img width=\"462\" alt=\"image\" src=\"https://user-images.githubusercontent.com/32839252/118828351-7cf9af80-b8bd-11eb-800b-d25412d1f2c5.png\">\n\n## fCM-query-generator\n\nThe fCM-query-generator i) allows to specify objectives and ii) compiles a state space query that can be used in CPN Tools.\n\nIt provides an interface to specify existential and universal state conditions, as well as multiplicity constraints for data objects, the condition whether certain activities are enabled, and the concatenation of those.\nThe input objective is then compiled into a state space query, which can be used in CPN Tools.\nAn examlpe will be elaborated below.\n\n## Content of the Repository\n\nThis repository is a [Vue.js application](https://vuejs.org). It uses the material design framework [Vuetify](https://vuetifyjs.com/). The interface is provided in `src/components`\n\nThe compiler of the input to state space queries can be found in `src/compiler/compiler.js`.\n\nThree examples can be found in the `example`-folder. One describes a claim handling process in an insurance company. The second describes the reviewing process for an academic conference. A third describes the hospital admission of a patient and the activities performed by medical experts. For the conference example, a simple and a more complex variation are provided.\n\nTo evaluate the performance of the generated state space queries, some measurements are provided in the `experiments` folder.\n\n## Project setup\n\nThe project can be used with the latest version of [npm](https://www.npmjs.com).\n\nFirst, navigate to the project folder. To install all dependencies, run:\n\n```\nnpm install\n```\n\nTo run the project, run:\n\n```\nnpm run serve\n```\n\nThe application should then be available at `http://localhost:8080`.\n\n## Usage\n\nIn the following, let us consider the fragments of the simple case model as provided in `example/conference/simple`:\n\n<img width=\"678\" alt=\"image\" src=\"https://user-images.githubusercontent.com/32839252/118828489-9bf84180-b8bd-11eb-8734-ba20f3e05c7f.png\">\n\nTo use the fCM-query-generator, run the project.\n\nIt is now possible to upload an fCM-model, e.g. the provided `example/conference/simple/conference.bpmn`. All data objects and activities are parsed and made available for specifying objectives.\n\n<img width=\"975\" alt=\"image\" src=\"https://user-images.githubusercontent.com/32839252/118852024-a96bf680-b8d2-11eb-8471-a5b25c7cd4fd.png\">\n\n### Modeling Objectives\n\nTo create a new objective, click `Create New` in the section `Your Objectives`. In the input form, the knowledge worker can specify their objective by choosing desired existental and universal conditions for a data object and state, as well as lower and upper bounds. They can also choose desired enabled activities, and concatenate all with the logic operators AND, OR, and NOT.\n\n<img width=\"985\" alt=\"Screenshot 2021-05-14 at 20 55 06\" src=\"https://user-images.githubusercontent.com/32839252/118824077-d4961c00-b8b9-11eb-8bfa-c3edc77d090f.png\">\n\n### Modeling Path Cost Functions\n\nTo create a new objective, click `Create New` in the section `Your Path Cost Functions`. In the form, users can specify a cost function for any path in the model's state space. It can make statements about the path length, activities that are executed on a path, and data objects that are created on a path. Therefore, it is possible to specify four things. First, the path length can be considered not at all, with the length of the path, or with the squared lenght of the path. Second, it can be specified, if the path length costs should be multiplied or added with the rest of the path costs. Third, for every activity, a cost can be assigned. And fourth, a cost for each newly created data object of each class can be defined.\n\n![Screenshot 2022-05-05 at 14 26 30](https://user-images.githubusercontent.com/32839252/166922801-9fb6fa78-89f6-4edf-8523-7ad4474d3ae1.png)\n\n### Configuring State Space Queries\n\nTo specify a state space query, two techniques are available. A user can create a query to derive filter-based recommendations, or score-based recommendations.\n\nA filter-based recommendation query requires a name, one objective, and the current state of execution as input.\n\n![Screenshot 2022-05-05 at 14 35 41](https://user-images.githubusercontent.com/32839252/166924451-0e5c6798-f22b-4869-b18f-d38ef183d81e.png)\n\nA score-based recommendation query requires a name, a set of objectives, a path cost function, and the current state of execution as input. For each selected objective, a weight need to be assigned and to be selected if it is required to satisfy the objective.\n\n![Screenshot 2022-05-05 at 14 35 56](https://user-images.githubusercontent.com/32839252/166924866-dede3398-b279-471e-97f8-83cce27461bc.png)\n\nFor the specified input, the according state space query is automatically compiled. It can be copied and used for the analysis in [CPN Tools](http://cpntools.org).\n\n### Using State Space Queries\n\nThe CPN-representation of the examplary fCM can be found in `example/claim/simple/conference.cpn`. To use it, run the latest version of CPN Tools, which can be downloaded [here](http://cpntools.org/category/downloads/).\n\nThe state space query is an ASK-CTL formula. More information can be found [here](http://cpntools.org/wp-content/uploads/2018/01/askctlmanual.pdf).\n\n![image](https://user-images.githubusercontent.com/32839252/118830701-6eac9300-b8bf-11eb-94d3-d7a2cac66cf2.png)\n\nTo execute it, first, the models state space must be generated. To do so, select the generate state space option in the state space tool and click into the net. Due to the size of the state space, this might take several minutes.\n\n<img width=\"100\" alt=\"image\" src=\"https://user-images.githubusercontent.com/32839252/110791549-a4574f00-8272-11eb-85d3-052434bb50f3.png\">\n\nAlso, the strongly connected components graph has to be computed. Choose the option in the state space tool and click on the net.\n\n<img width=\"100\" alt=\"image\" src=\"https://user-images.githubusercontent.com/32839252/110791587-ade0b700-8272-11eb-9e28-e3cd15c1f053.png\">\n\nNext, the ASK-CTL compiler must be loaded. Choose the ML compiler in the simulation tool and compile the expression `use (ogpath^\"ASKCTL/ASKCTLloader.sml\")` by clicking on it.\n\n<img width=\"200\" alt=\"image\" src=\"https://user-images.githubusercontent.com/32839252/110791704-cf41a300-8272-11eb-9fa5-9099d3dd19d7.png\">\n\nNow, any ASK-CTL formula can be executed by choosing the ML compiler and clicking on it. To execute the state space query, copy it into a separate text field in the net. In the exemplary CPN, the previously created state space query is already given.\n\nInsert picture!\n\nThe query returns a boolean indicating whether or not an execution state can be reached that satisfies the objective. For all possible successor states, it can be investigated which can lead to a satisfying state and which can't. This information assists knowledge workers, what activities to execute.\n\nTo investigate the state space and the successor states of the current state, the state space can be visualized by using the state space tool.\n\n<img width=\"100\" alt=\"image\" src=\"https://user-images.githubusercontent.com/32839252/110791660-bfc25a00-8272-11eb-97ff-29239c890b1e.png\">\n\n## License\n\nThis program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\n\nThis program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  \nSee the GNU General Public License for more details You should have received a copy of the GNU General Public License along with this program. If not, see <https://www.gnu.org/licenses/>.\n"}
{"url": "https://github.com/bptlab/fcm2cpn", "owner": "bptlab", "repository_name": "fcm2cpn", "date_all_variable_collection": "2023-09-11", "description": null, "size": 62452, "stargazers_count": 1, "watchers_count": 1, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 3, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 3, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "LeonBein", "contributions": 84}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 113775}], "readme": "# Cross-Case Data Objects in Business Processes: Semantics and Analysis\n\nThis page lists complementary files for the paper \"CPN-Based Semantics for Cross-Case Data in Case management\" accepted for publication at [BPM Forum](https://congreso.us.es/bpm2020/).\nAll files except the binary are available in the [Github repository](https://github.com/bptlab/fcm2cpn).\nThe binary of the prototype can be downloaded [here](https://owncloud.hpi.de/s/EII5PnKSQEpu0PI).\n\n## List of Files\n* **Examples:**\n  * `models/budget_processes.bpmn` contains a BPMN file comprising both the *office supply purchasing*. and *business trip booking* process used in the paper (modeled using Signavio).\n  * `models/budget_processes_corrected.bpmn` contains a BPM file comprising the two example processes with boundary events (modeled using Signavio)\n  * `models/coloredPN.cpn` contains a complete CPN formalization of the `budget_processes.bpmn` ([CPNtools file](https://cpntools.org))\n  * `models/k-soundness.cpn` contains a formalization `budget_processes.bpmn` including extensions for checking *k-soundness* ([CPNtools file](https://cpntools.org)).\n  * `models/k-soundnessCorrected.cpn` contains a corrected version of the process including extensions for checking *k-soundness*\n  * `models/correlation/*.cpn` contains examples for different correlation mechanisms\n* **Translator:**\n  * `src/*` contains the source files for the translator that translates a set of fragments to a CPN\n  * `lib/*.jar` the [Access/CPN](http://cpntools.org/access-cpn/) libraries required for the prototype\n  \n## Prototype\n\n### Usage\n\nIf you use the [binary](https://owncloud.hpi.de/s/EII5PnKSQEpu0PI), you can run the program using the following command.\n````bash\njava -jar bpmn2cpn.jar \n````\nYou are prompted to choose  a single BPMN file containing one or multiple processes.\nThe program will save a CPN file in the current working directory.\nThe CPN has two hierarchy levels: on the top-level all processes and their connections are described, on the low-level a subnet for each activity is detailed.\n\n### Assumptions\n\n* We assume that the input is provided as a single BPMN file (you can, for example use the [Signavio](https://academic.signavio.com))\n* We assume that, if no input- and output-sets are modeled explicitly, all possible combinations are desired\n* We assume that data stores have a label `objectName[state]` or they are assumed to be in state `BLANK`.\n\n### Sources\n\nAll the sources are available in `src/main/*`, note that you have to add the Access/CPN libraries (`lib`) to your classpath in order to run/compile the tool.\n\n### Binary\n\nThe binary `bpmn2cpn.jar` containing all dependencies is available [here](https://owncloud.hpi.de/s/EII5PnKSQEpu0PI).\n\n### Dependencies\n\nPlease note, that the tool has dependencies, and that these dependencies may have different licenses. In the following we list the dependencies\n* Camunda bpmn-model for parsing BPMN files. The dependency is linked via maven.\n* Access/CPN to create CPNtools compatible CPNs. The dependency is linked as a set of external libraries (see `lib/`)\n* Eclipse EMF dependency for using Access/CPN\n\n### Checking k-soundness\n\nThe example CPNs `k-soundness.cpn` and `k-soundnessCorrected.cpn` can be used to verify the k-soundness property.\nTo do so, the user must first load CPN-Tools state space tool, see (http://cpntools.org/2018/01/15/temporal-logic-for-state-spaces/)[http://cpntools.org/2018/01/15/temporal-logic-for-state-spaces/] for more information, and then reevaluate the `FindNodesViolatingKSoundness` function.\n\n### License\n\n*fcm2cpn* is a compiler, translating process fragments to CPNtools compatible Petri nets.\nCopyright (C) 2020  Hasso Plattner Institute gGmbH, University of Potsdam\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or (at your option) any later version.\nThis program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\nSee the GNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see <https://www.gnu.org/licenses/>.\n"}
{"url": "https://github.com/bptlab/fiber2xes", "owner": "bptlab", "repository_name": "fiber2xes", "date_all_variable_collection": "2023-09-11", "description": "This project contains a python utility intended to use EHR data coming from fiber to create .xes event logs.", "size": 4707, "stargazers_count": 2, "watchers_count": 2, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "fyndalf", "contributions": 65}, {"contributor": "arneboockmeyer", "contributions": 65}, {"contributor": "t-lichtenstein", "contributions": 26}, {"contributor": "oclasen", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 181830}, {"language": "Shell", "num_chars": 320}], "readme": "# fiber2xes\n\nThis project contains a python utility intended to use data coming from `fiber` to create `.xes` event logs.\nTo use this tool you need access to the Mount Sinai Data Warehouse.\n\n## Installation\n\nFollow these steps to install `fiber2xes`:\n\n1. Install fiber according to their [installation guide](https://gitlab.hpi.de/fiber/fiber).\n2. Download and install Spark 3.1.2 according to their [installation guide](https://spark.apache.org/downloads.html). [This](https://www.tutorialspoint.com/pyspark/pyspark_environment_setup.htm) website provides a concise overview of how the Spark environment can be set up. Make sure that both the `SPARK_HOME` and `JAVA_HOME` environment variables are correctly set and exported. Should the Spark Version available change, the pyspark version of this package, as well as the one of the docker image, needs to be changed accordingly. \n3. Run the pip installation to install `fiber2xes`:\n\n```bash\npip install git+https://gitlab.hpi.de/pm1920/fiber2xes.git\n```\n\nFor development and testing, all dev dependencies can be installed using\n\n```bash\npip install -e .[dev]\n```\n\nIf you're using `zsh`, escape the square brackets: `pip install -e .\\[dev\\]`\nIn case you encounter version or dependency issues in relation to `fiber`, it is advisable to run\n\n```bash\nsed -i 's/==/>=/' requirements.txt\n```\n\nin the `fiber` directory in order to allow the installation of `fiber2xes` to override the right dependency versions.  \n\n## Example\n\nAfter following all installation steps, `example.py`, a demo file containing a short overview of how fiber2xes can be executed, can be run by calling\n\n```bash\npython3 ./example.py\n```\n\nThis example creates a sample cohort for a MRN-based event log, which will be extracted and saved to the repository's root directory as a file called `./log_<timestamp>_mrn_5.xes` This file can then be used for process mining.\n\n## Interface\n\nThe package offers two methods for the event log creation and filter for trace and event filtering.\nThe following chapters contains more details about these methods.\n\n### Log creation\n\nTo create a log from a fiber cohort, just call the `cohort_to_event_log`-method:\n\n```python\nfrom fiber2xes import cohort_to_event_log\n\ncohort_to_event_log(\n  cohort,\n  trace_type,\n  verbose=False,\n  remove_unlisted=True,\n  remove_duplicates=True,\n  event_filter=None,\n  trace_filter=None,\n  cores=multiprocessing.cpu_count(),\n  window_size=500,\n  abstraction_path=None,\n  abstraction_exact_match=False,\n  abstraction_delimiter=\";\",\n  include_anamnesis_events,\n  duplicate_event_identifier,\n  event_identifier_to_merge,\n  perform_complex_duplicate_detection\n)\n```\n\nParameters:\n\n- **cohort**: The fiber cohort with the patient\n- **trace_type**: The type of a trace (`mrn` or `visit`)\n- **verbose=False**: Flag if the events should contain original non abstracted values (default False)\n- **remove_unlisted=True**: Flag if a trace should only contain listed events (default True)\n- **remove_duplicates=True**: Flag if duplicate events should be removed (default True)\n- **event_filter=None**: A custom filter to filter events (default None)\n- **trace_filter=None**: A custom filter to filter traces (default None)\n- **cores=multiprocessing.cpu_count()**: The number of cores which should be used to process the cohort (default amount of CPUs)\n- **window_size=500**: The number of patients per window (default 500)\n- **abstraction_path=None**: The path to the abstraction file (default None)\n- **abstraction_exact_match=False**: Flag if the abstraction algorithm should only abstract exacted matches (default False)\n- **abstraction_delimiter=\";\"**: The delimiter of the abstraction file (default ;)\n- **include_anamnesis_events=True**: Should anamnesis events be included in the log (default True)\n- **duplicate_event_identifier=\"BACK PAIN\"**: Event identifier to be analysed separately for duplications (default \"BACK PAIN\")\n- **event_identifier_to_merge=\"CHRONIC LOW BACK PAIN\"**: Event identifier to be used for separately identified duplicates (default \"CHRONIC LOW BACK PAIN\")\n- **perform_complex_duplicate_detection=False**: should complex time- and lifecycle-based duplicate detection be performed (default False)\n\n### Log serialisation\n\nThe method `save_event_log_to_file` serialises a created log to a file.\n\n```python\nfrom fiber2xes import save_event_log_to_file\n\nsave_event_log_to_file(log, file_path)\n```\n\nParameters:\n\n- **log**: The log generated by the `cohort_to_event_log` method\n- **file_path**: The file path / name\n\n### Trace and event filtering\n\nWith the trace or event filter its possible to filter the traces or events during the creation process.\nTherefore there are the following conditions:\n\n- [Diagnosis](https://gitlab.hpi.de/pm1920/fiber2xes#diagnosis)\n- [Material](https://gitlab.hpi.de/pm1920/fiber2xes#material)\n- [Procedure](https://gitlab.hpi.de/pm1920/fiber2xes#procedure)\n- [Time](https://gitlab.hpi.de/pm1920/fiber2xes#time)\n- [Generic](https://gitlab.hpi.de/pm1920/fiber2xes#generic)\n\nThese can be combined by [And](https://gitlab.hpi.de/pm1920/fiber2xes#and), [Or](https://gitlab.hpi.de/pm1920/fiber2xes#or) and [Not](https://gitlab.hpi.de/pm1920/fiber2xes#not) operations.\n\n#### Diagnosis\n\nA filter for a specific diagnosis given by the code.\n\n```python\nfrom fiber2xes.filter.condition import Diagnosis\n\nfilter = Diagnosis(diagnosis_code)\n```\n\nParameter:\n\n- **diagnosis_code**: The diagnosis code\n\n#### Material\n\nA filter for a specific material given by the code.\n\n```python\nfrom fiber2xes.filter.condition import Material\n\nfilter = Material(material_code)\n```\n\nParameter:\n\n- **material_code**: The material code\n\n#### Procedure\n\nA filter for a specific procedure given by the code\n\n```python\nfrom fiber2xes.filter.condition import Procedure\n\nfilter = Procedure(procedure_code)\n```\n\nParameter:\n\n- **procedure_code**: The procedure code\n\n#### Time\n\nA filter the traces based on timing conditions (see parameter)\n\n```python\nfrom fiber2xes.filter.condition import Time\n\nfilter = Time(one_event_after=None, one_event_before=None, all_events_after=None, all_events_before=None)\n```\n\nParameters:\n\n- **one_event_after**: The trace is relevant if one event of the trace was after the given date\n- **one_event_before**: The trace is relevant if one event of the trace was before the given date\n- **all_events_after**: The trace is relevant if all events of the are were after the given date\n- **all_events_before**: The trace is relevant if all events of the are were after the given date\n\n#### Generic\n\nA filter the traces or events with the given lambda expression. The lambda expression gets the trace or event as a parameter and it should return true or false. In case of true its a relevant trace or event, otherwise not.\n\n```python\nfrom fiber2xes.filter.condition import Generic\n\nfilter = Generic(lambda_expression)\n```\n\nParameter:\n\n- **lambda_expression**: The lambda expression which will be applied on all traces and events\n\n#### And\n\nAn aggregation of two other filters with a logical _and_ as aggregation function.\n\n```python\nfrom fiber2xes.filter.operator import And\n\nfilter = And(filter1, filter2)\n```\n\nParameter:\n\n- **filter1** and **filter2**: Two other trace or event filters which will be aggregated by a logical *and*.\n\n#### Or\n\nAn aggregation of two other filters with a logical _or_ as aggregation function.\n\n```python\nfrom fiber2xes.filter.operator import Or\n\nfilter = Or(filter1, filter2)\n```\n\nParameter:\n\n- **filter1** and **filter2**: Two other trace or event filters which will be aggregated by a logical *or*.\n\n#### Not\n\nAn inverter of the result of another filter.\n\n```python\nfrom fiber2xes.filter.operator import Not\n\nfilter = Not(filter)\n```\n\nParameter:\n\n- **filter**: The result of the given filter will be negated.\n\n## Spark Configuration\n\nThis pipeline tool utilises spark for transforming large event data sets. For local development, or for using the tool on differently equipped hardware,\nit can be sensible to change memory requirements and other spark configuration options. For this, the `.env` file in the project's root directory can be used\nin order to override the default options passed to the spark calls.\n\n## Contribution\n\nTo contribute please fork this repository and create a merge request.\nAssign one of the developer of this project for a review.\nPlease always add a short introduction of your submission containing a reason for your submission.\n"}
{"url": "https://github.com/bptlab/gryphon", "owner": "bptlab", "repository_name": "gryphon", "date_all_variable_collection": "2023-09-11", "description": "web-based modeler based on bpmn.io for fCM case models (to be executed by https://github.com/bptlab/chimera)", "size": 13996, "stargazers_count": 4, "watchers_count": 4, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 21, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 21, "watchers": 4, "default_branch": "master", "contributors": [{"contributor": "adi64", "contributions": 172}, {"contributor": "marhew", "contributions": 28}, {"contributor": "m0r13", "contributions": 15}, {"contributor": "MaximilianV", "contributions": 15}, {"contributor": "westphal-jan", "contributions": 8}, {"contributor": "j-beyer", "contributions": 8}, {"contributor": "svenihde", "contributions": 8}, {"contributor": "tommartensen", "contributions": 5}, {"contributor": "dependabot[bot]", "contributions": 4}, {"contributor": "friedow", "contributions": 2}, {"contributor": "fyndalf", "contributions": 2}, {"contributor": "MaximilianKoenig", "contributions": 2}, {"contributor": "Siddeshkanth", "contributions": 2}, {"contributor": "marcfreiheit", "contributions": 2}, {"contributor": "mlichtblau", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 740263}, {"language": "JavaScript", "num_chars": 312429}, {"language": "CSS", "num_chars": 71551}, {"language": "Dockerfile", "num_chars": 1078}], "readme": "Getting Started\n===============\n\nLocal Installation (for developers)\n-----------------------------------\n\n### Prerequisites\n\nThe following software is necessary to build and run the editor:\n\n-   Install **Node.js**, available\n    [here](https://nodejs.org/en/download/) (this includes the node\n    package manager `npm`)\n-   Install **node-gyp** by running `npm install -g node-gyp` on the\n    command line, e.g. [cygwin](https://cygwin.com) or Window `cmd`\n    -   Unix/Mac: this may require the **build-essentials** tools, which\n        you can install with `sudo apt-get install build-essential`\n-   Install **browserify** by running `npm install -g browserify`\n-   Install **grunt-cli** by runniing `npm install -g grunt-cli`\n-   Install **mongodb**, available\n    [here](https://www.mongodb.org/downloads).\n    -   add the `bin` directory to your path (default directory is\n        `C:\\Program Files\\MongoDB\\Server\\3.4\\bin`)\n\n### Initial setup\n\n1.  Clone the source code repository from\n    [github](http://github.com/bptlab/gryphon) (e.g. by running\n    `git clone https://github.com/bptlab/gryphon.git` on the command\n    line)\n    -   we recommend to create a folder `zoo` and clone into\n        `zoo/gryphon`\n    -   the following commands assume that you are in the gryphon\n        directory!\n2.  Run `npm install` (in the gryphon directory) to set up all\n    additional dependency packages\n3.  Run `grunt config` (in the gyphon directory) to copy both config\n    examples and to give them the correct names\n4.  Setup MongoDB\n    -   create a data directory, e.g. in `zoo/mongodata`\n    -   start database server by running `mongod --dbpath ../mongodata`\n        on the command line (if your data directory is somewhere else,\n        be sure to adapt the path accordingly)\n    -   start the mongo client by running `mongo` on the command line\n    -   inside the mongo client create a database named gryphondb with\n        the command `use gryphondb`\n        -   if you named your database differently, you need to adapt\n            the database name in `config.js` by editing the property\n            `MONGODB_HOST: 'mongodb://localhost/YOUR_DATABASE_NAME`\n5.  Run `grunt` (in the gyphon directory) to build the UI files and to\n    compile all script sources\n\nStarting Gryphon\n----------------\n\nOnce your environment is set up, you can start the editor as follows\n\n1.  Navigate to the gryphon directory in your command line\n2.  Start the MongoDB server (if it is not already started) by running\n    `mongod --dbpath ../mongodata` on the command line\n3.  Run the express server by calling `node bin/www` on the command line\n4.  You can now access the editor in your browser at\n    <http://localhost:3000/>\n\n### Using Gryphon in Docker\n\nIf you just want to run the editor, instead of modifying it (even though that doesn't really matter,\nyou could also edit it this way, just the building part will take longer), you can run the whole\nthing in a docker container in 3 easy steps:\n\n1.  Install Docker.\n2.  `cd` into the gryphon dir and run `docker build -t bpt/gryphon .`\n3.  Run `docker run -it --rm -p 3000:3000 --name gryphon -v gryphon-mongodb-data:/var/lib/mongodb bpt/gryphon`\n\n\n### Using Gryphon in Docker Compose\nMOST EASY AND CONVENIENT WAY TO RUN GRYPHON\n\n1. Install docker & docker-compose\n1. `docker-compose up`\n\n### Troubleshooting\nIf running npm install fails:\nCheck wether you have installed all build-essentials (Otherwise run: `sudo apt-get install build-essential`)\nRun: `sudo npm install -g node-gyp`\nTry again.\n\nWhen running on Windows, make sure to have the following additional dependencies installed:\n* Python 2.7 (Python >= 3 won't work!)\n* Any version of Visual Studio (use the --msvs_version=20XY switch for Visual Studio 20XY)\n"}
{"url": "https://github.com/bptlab/holistic-process-platform", "owner": "bptlab", "repository_name": "holistic-process-platform", "date_all_variable_collection": "2023-09-11", "description": "A BPMN-based platform that combines BPMS and RPA.", "size": 414, "stargazers_count": 2, "watchers_count": 2, "language": "Vue", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "main", "contributors": [{"contributor": "MaximilianV", "contributions": 24}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Vue", "num_chars": 26971}, {"language": "TypeScript", "num_chars": 10168}, {"language": "HTML", "num_chars": 337}, {"language": "JavaScript", "num_chars": 284}, {"language": "CSS", "num_chars": 93}], "readme": "# holistic-process-platform\nA BPMN-based platform that combines BPMS and RPA.\n\nCurrently, the prototype enables users to model and combine RPA workflows and business processes using the business process model and notation.\nAddressing the process orchestration issue, RPA workflows can not only be linked and invoked from business processes, but individual RPA operations can be embedded directly into processes.\nTo match the different levels of abstraction of business processes (high abstraction) and RPA workflows (low abstraction), the modeler follows a layered approach, capturing the high process view, the individual acitvities, and, if required, also the atomic tasks that consitute an activity.\n\n\n## Background\nCurrently, business process management systems (BPMS) and tools for robotic process automation (RPA) are usually deployed and enacted seperately.\nBut with the increasing number of processes, RPA workflows and thus complexity, especially orchestrating process executions become more difficult.\nConsequently, companies strive to later connnect both softwares, causing additional costs and maintainance effort.\nThe holistic process platform combines BPMS and RPA, thereby avoiding the need for integration at a later stage.\n\n\n## Usage\n\n### Modeling RPA workflows\nRPA workflows solely consist of tasks that represent atomic RPA operations, such as opening an software application or pressing a button.\n\n![RPA_RPA Flow Creation](https://user-images.githubusercontent.com/1167788/173344209-291e1778-347d-49f0-b348-2b0afe0980a8.gif)\n\nEach task and thus RPA operation can be directly configured in the modeler (for the demonstration only a limited set of available RPA operations is used).\n\n<img src=\"https://user-images.githubusercontent.com/1167788/173344949-2feced85-1bb5-4443-b591-fe0f441c88a5.gif\" width=\"700\" />\n\n\n### Modeling Business Processes\nWhile RPA excels at automatic repetitive tasks at a small scope, business processes are used to describe and enact \"end-to-end\" processes, of which RPA could be part of, e.g., an activity of a business process could be automated using RPA.\n\n![RPA_BP Creation](https://user-images.githubusercontent.com/1167788/173344656-f8502ac7-bf5e-4d8c-bb60-a6c6a58514f3.gif)\n\n\n### Navigation\nBusiness processes can be explored by double-clicking non-atomic element, i.e., call activities that reference RPA flows and sub-processes, which will open the respective process definition.\n\n![RPA_BP RPA Navigation](https://user-images.githubusercontent.com/1167788/173345638-f156301d-ab6a-41a7-980c-2d1a330a811e.gif)\n\n\n## Installation\nIf you want to try the modeler yourself, you can easily install and run it:\n\n1. Clone the repository\n2. Run `npm install`\n3. Execute `npm run dev`\n4. Open \"http://localhost:3000/modeler\"\n"}
{"url": "https://github.com/bptlab/lola-webservice", "owner": "bptlab", "repository_name": "lola-webservice", "date_all_variable_collection": "2023-09-11", "description": "A web service wrapper for LoLA 2.0 (Low-Level Analyzer for petri nets)", "size": 5568, "stargazers_count": 0, "watchers_count": 0, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "adi64", "contributions": 46}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 25598}, {"language": "HTML", "num_chars": 3440}, {"language": "Dockerfile", "num_chars": 1873}], "readme": "# LoLA 2 as a service\n\nThis is a Docker context to build an image for a container that exposes LoLA 2.0 as a webservice.\n\n## How to use\n* Build a Docker image: `docker build -t bpt/lola .`\n* Run as Docker container and bind to local port 8080: `docker run --rm -it --name lola -p 8080:80 bpt/lola`\n* Navigate to `localhost:8080`, select a PNML file, select checks and run\n\n## The `lola.php` wrapper script\nThe service wrapper (`lola.php`) will do the following:\n\n* read user input as *PNML*\n* convert to *lola* format using `petri`\n* parse the *.lola* file (soundness checks with LoLA 2.0 require prior knowledge of source and sink place(s))\n* run selected checks\n* display the check results together with a witness path, if there is any\n\n## The provided `Dockerfile`\nWhen building, it will\n\n* base on a php/nginx image\n* install required dependencies\n* patch and build LoLA 1.18 (needed for petri tool)\n* build LoLA 2.0\n* build petri\n"}
{"url": "https://github.com/bptlab/mantichor-corda", "owner": "bptlab", "repository_name": "mantichor-corda", "date_all_variable_collection": "2023-09-11", "description": "Corda R3 adapter for the Mantichor choreography framework ", "size": 129574, "stargazers_count": 5, "watchers_count": 5, "language": "Kotlin", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 6, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 6, "watchers": 5, "default_branch": "master", "contributors": [{"contributor": "Ferandal", "contributions": 38}, {"contributor": "julisa99", "contributions": 14}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Kotlin", "num_chars": 61814}, {"language": "JavaScript", "num_chars": 6024}, {"language": "HTML", "num_chars": 5779}, {"language": "Dockerfile", "num_chars": 778}, {"language": "Shell", "num_chars": 285}], "readme": "## Mantichor Corda Adapter\n\nAdapter for [Mantichor](https://github.com/bptlab/mantichor-frontend/wiki/Architecture) to execute Process Choreographies on the Corda Platform. In the [wiki](https://github.com/bptlab/mantichor-corda/wiki) you can find the detailled architecture and design concept. In this Readme you will find a quick start to build and run the adapter.\n\n- [Repository Structure](#repository-structure)\n- [Deployment](#deployment)\n  * [Starting](#starting)\n  * [Stopping](#stopping)\n  * [Execute tasks](#execute-tasks)\n- [Development](#development)\n  * [Requirements](#requirements)\n  * [IntelliJ Settings](#intellij-settings)\n  * [Build the project](#build-the-project)\n  * [Node.js Server](#nodejs-server)\n  * [Execute tasks in development](#execute-tasks-in-development)\n  \n## Repository Structure\n\n* `adapterServer/` | Node.js server and pre-built jars\n* `cordapp_template/` | intelliJ CorDapp project as template\n* `initGen/` | src for the pre-built jar to calculate the participant list and the right address for task execution\n* `tasksGen/` | src for the pre-built jar to calculate executable tasks based on corda state\n* `bpmnParser/` | src for the pre-built jar for bpmn parsing and project generation\n* `.gitignore` | files ignored by Git\n* `Dockerfile` | Docker configuration\n* `README.md` | Readme about the repository\n* `constants.properties` | Corda configuration\n\n## Deployment\n\nYou can start a **pre-built version** of the adapter using docker. Make sure that the latest versions of [`docker`](https://docs.docker.com/install/) is installed.\n\n### Starting\n\nOpen a terminal window and use `docker pull ferandal/cordaadapter` and then `docker run \u2014rm -p 8080:8080 ferandal/cordaadapter`.\n\n### Stopping\n\nTo stop the server just kill the docker container: `Docker kill (DockerID)`.\n\n### Execute tasks\n\nWith [Postman](https://www.getpostman.com/downloads/) you can then send requests to `localhost:8080` as described in the REST API for mantichor. The implemented interface can be found as Swagger Documentation in [Mantichor's Frontend Repository](https://github.com/bptlab/mantichor-frontend/blob/master/adapter-apidoc.yaml).\n\n\n## Development\n\n### Requirements\n* **Java 8 JVM** - at least version 8u171, but not Java 9 or higher.\n* **IntelliJ IDEA** - supported versions 2017.x, 2018.x and 2019.x (with Kotlin plugin version 1.2.71).\n* **Gradle 4.10** - the gradlew script in the project will download it for you.\n\n### IntelliJ Settings\n1. Open IntelliJ.\n2. Open the folder `bpmnParser\\` as project in IntelliJ.\n3. Make sure that the folder `src\\` is marked as *Sources Root*.\n4. Click `File`, then `Project Structure`. Under `Project SDK:`, set the project SDK by clicking `New...`, clicking `JDK`, and navigating to `C:\\Program Files\\Java\\jdk1.8.0_XXX` on Windows or `Library/Java/JavaVirtualMachines/jdk1.8.XXX` on MacOSX (where XXX is the latest minor version number). Click `Apply` followed by `OK`.\n\n### Build the project\nFor developing the bpmn parser:\n1. Inside of the main() function of the XmlReader.kt you have to set the path to the testing bpmn. The default value is choreo.bpmn as this is used by the adapter server.\n2. Run the `XmlReader.kt`, which will generate a CorDapp project for the BPMN under `mantichor-corda\\cordapp__XXX\\` (XXX = id of the BPMN).\n```diff\n! If you want to run XmlReader.kt for the first time, a popup window will appear, \n! where you simply click on \"Configure Kotlin\" and then select \"Java\".\n```\n3. Open a terminal window in the `cordapp_XXX` directory. \n```diff\n! For Windows: The project is build for the Unix platform. \n! Therefore, you have to open the generated CorDapp as project in IntelliJ. \n! Then delete the folder `.gradle` and the file `gradle-wrapper.properties` \n! under `mantichor-corda\\cordapp__XXX\\gradle\\wrapper`. \n! Then click on `Import changes`.\n```\n4. Run the `build` Gradle task to compile our CorDapp project:  \n        **Unix/Mac OSX:** `./gradlew build`  \n        **Windows:** `gradlew.bat build`  \n5. Run the `deployNodes` Gradle task to build four nodes with our CorDapp already installed on them:  \n        **Unix/Mac OSX:** `./gradlew deployNodes`  \n        **Windows:** `gradlew.bat deployNodes`  \n6. Start the nodes by running the following command:  \n    **Unix/Mac OSX:** workflows-kotlin/build/nodes/runnodes  \n    **Windows:** call workflows-kotlin/build/nodes/runnodes.bat  \n7. Each participant server needs to be started in its own terminal/command prompt, replace **participantID** with the specific participant id, e.g. *participant_a*:  \n    **Unix/Mac OSX:** ./gradlew run**participantID**Server   \n    **Windows:** gradlew.bat run**participantID**Server  \n```diff\n+ Under `mantichor-corda\\bpmnParser\\` you will find the file `deployServer.txt`, \n+ which the `XmlReader.kt` has also generated. There you have a list of the participants.\n```\n\n### Node.js Server\nThe server that implements the defined interface lives inside the `mantichor-corda\\adapterServer\\` folder. The `index.js` file contains the server. You need to have [Node.js](https://nodejs.org/en/download/) installed to run it. The server is completely written with libraries that [Node.js](https://nodejs.org/en/download/) provides. Therefore, additional installations are not required. To run it, open a terminal window and execute `node index.js`.\n\n### Execute tasks in development\nTo test the Server refere to the defined [interface](https://github.com/bptlab/mantichor-frontend/blob/master/adapter-apidoc.yaml) and send the corresponding requests to `http://localhost:8080`. We recomment to use [Postman](https://www.getpostman.com/downloads/) to do that. For testing the projects, that are generated by the bpmn parser, you need to send the request to the corresponding corda node. For excuting a task corda implies a special structure:\n`http://localhost:50005/api/generatedBPMNID/TASKNAME?partyName0=O=FIRSTPARTICIPANTID, L=London, C=GB&partyName1=O=SECONDPARTICIPANTID, L=London, C=GB&...` \nFor example you could run: `http://localhost:50005/api/generatedchoreo/Task?partyName0=O=participant_a, L=London, C=GB&partyName1=O=participant_b, L=London, C=GB`\n\n###### tags: `Corda Adapter` `Corda` `Process Choreography`\n"}
{"url": "https://github.com/bptlab/mantichor-frontend", "owner": "bptlab", "repository_name": "mantichor-frontend", "date_all_variable_collection": "2023-09-11", "description": "Frontend for the Mantichor choreography framework", "size": 251, "stargazers_count": 6, "watchers_count": 6, "language": "Vue", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 11, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 11, "watchers": 6, "default_branch": "master", "contributors": [{"contributor": "friedow", "contributions": 40}, {"contributor": "oliver-adameck", "contributions": 16}, {"contributor": "fyndalf", "contributions": 4}, {"contributor": "t-lichtenstein", "contributions": 4}, {"contributor": "oliveradameck", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Vue", "num_chars": 32042}, {"language": "TypeScript", "num_chars": 13987}, {"language": "HTML", "num_chars": 1090}, {"language": "Less", "num_chars": 225}, {"language": "Dockerfile", "num_chars": 206}, {"language": "Shell", "num_chars": 99}, {"language": "JavaScript", "num_chars": 59}], "readme": "# Mantichor Frontend\n![alt text](https://img.shields.io/travis/com/bptlab/mantichor-frontend.svg \"Travis Build\")\n\nFrontend service for the Mantichor Choreography Execution Engine.\n\n## Deployment\n\n1. Clone the repository\n    ```console\n    foo@bar:~$ git clone https://github.com/bptlab/mantichor-frontend\n    foo@bar:~$ cd mantichor-frontend\n    ```\n2. Deploy the service using docker compose / stack:\n    ```console\n    foo@bar:~$ docker-compose up\n    # OR #\n    foo@bar:~$ docker stack deploy -c docker-compose.yml mantichor\n    ```\n\n\n## Development\n\n1. Make sure you have [NodeJS](https://nodejs.org/) and [npm](https://www.npmjs.com/) installed.\n2. Clone the repository\n  ```\n  git clone https://github.com/bptlab/mantichor-frontend\n  cd mantichor-frontend\n  ```\n3. Install the dependencies\n  ```\n  npm install\n  ```\n4. Start the app\n  ```\n  npm start\n  ```\n5. Server is running on http://localhost:8080.\n\n## Building Docker Images manually\n\n1. Login to your docker account\n  ```\n  docker login\n  ```\n2. Build the image\n  ```\n  docker build -t bptlab/mantichor-frontend:latest .\n  ```\n3. Run the image\n  ```\n  docker run -p 8080:8080 bptlab/mantichor-frontend:latest\n  ```\n\n## License\n\nCopyright (c) 2020\n\nLicensed under the [MIT license](LICENSE).\n"}
{"url": "https://github.com/bptlab/mantichor-share", "owner": "bptlab", "repository_name": "mantichor-share", "date_all_variable_collection": "2023-09-11", "description": null, "size": 11, "stargazers_count": 0, "watchers_count": 0, "language": "TypeScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "friedow", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TypeScript", "num_chars": 3514}, {"language": "Dockerfile", "num_chars": 430}]}
{"url": "https://github.com/bptlab/mantichor-tezos", "owner": "bptlab", "repository_name": "mantichor-tezos", "date_all_variable_collection": "2023-09-11", "description": "Tezos adapter for the Mantichor choreography framework ", "size": 418, "stargazers_count": 4, "watchers_count": 4, "language": "TypeScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 6, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 6, "watchers": 4, "default_branch": "master", "contributors": [{"contributor": "fyndalf", "contributions": 76}, {"contributor": "t-lichtenstein", "contributions": 51}, {"contributor": "friedow", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TypeScript", "num_chars": 53583}, {"language": "Shell", "num_chars": 2166}], "readme": "# Mantichor Tezos\n\nTezos Blockchain Choreography Converter and Backend based on the Tezos Blockchain.\nThe Adapter is listening for the Mantichor Frontend on Port 7320.\n\n## Dependencies\n\nMake sure that the latest versions of [`docker`](https://docs.docker.com/install/) is installed.\n\n## Starting\n\nStart a **pre-built version** of the adapter using `docker run -p 7320:7320 --name mantichor-tezos-adapter -d bptlab/mantichor-tezos-adapter:latest`.\nAlternatively, execute `start.sh` (or the commands described [here](DOCUMENTATION.md#running-the-tezos-adapter)) to **build** and run the local version of the adapter instead of the prebuilt one.\nYou can follow the container output using `docker logs -f mantichor-tezos-adapter`\n\n## Stopping\n\nStop the tool using `docker stop mantichor-tezos-adapter && docker rm mantichor-tezos-adapter` or `stop.sh`.\n\nAfter stopping, use `docker volume rm ...` to remove the volumes belonging to the adapter and to reset the state of the node.\n\nThe tezos node is a single sandbox node for now, not connected to either the tezos `alphanet` nor the `mainnet`.\n\n---\nFor more in-depth information, e.g. on how to change the adapter to use a full alphanet, see this [Documentation](DOCUMENTATION.md).\nThe adapter's implementation details can be found in the adapter's [Readme](tezos-adapter/README.md).\n"}
{"url": "https://github.com/bptlab/MdRPA_Library", "owner": "bptlab", "repository_name": "MdRPA_Library", "date_all_variable_collection": "2023-09-11", "description": null, "size": 25, "stargazers_count": 3, "watchers_count": 3, "language": "RobotFramework", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 3, "default_branch": "main", "contributors": [{"contributor": "AliKazmi123", "contributions": 4}, {"contributor": "xhoelbano", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "RobotFramework", "num_chars": 34180}, {"language": "Python", "num_chars": 4203}], "readme": "## Installation\n\nThe MdRPA Library has been made available on the official Python Package Index (PyPI), making it easy to install and integrate into your projects.\n\nTo install the library, you can use the following command in your terminal or command prompt:\n\n```shell\npip install mdrpaLibrary\n```\n\n\nFor more detailed information and updates, you can visit the PyPI page of the MdRPA Library at:\nhttps://pypi.org/project/mdrpaLibrary/\nFeel free to explore the library's documentation and features to enhance your Robotic Process Automation workflows.\n\n\n## Example Usage\n\nBelow is an example demonstrating how to leverage the capabilities of the MdRPA Library for your automation tasks. This example showcases the automation of a payroll process using the custom functions provided by the library.\n\n```robotframework\n*** Settings ***\nLibrary    mdrpaLibrary.modelDrivenRpa.ModelDrivenRpa\n\n*** Variables ***\n${FIRSTNAME}    John\n${LASTNAME}     Doe\n${EMAIL}        john.doe@example.com\n${MONTH}        January\n${SALARY}       5000\n\n*** Test Cases ***\nAutomate Payroll Process\n\n    ${uiModels}=    Get Ui Models    http://localhost:8000/all-models (Your API END POINT)\n    \n    Set Suite Variable     ${uiModels}\n    \n    Click Button Model    Payroll    payroll_homepage    addButton    ${uiModels}\n\n    Input Field Model     Payroll    add_payroll    firstName    ${uiModels}    ${FIRSTNAME}\n    \n    Input Field Model    Payroll    add_payroll    lastName    ${uiModels}    ${LASTNAME}\n    \n    Input Field Model    Payroll    add_payroll    email    ${uiModels}    ${EMAIL}\n\n    Select From Dropdown Model    Payroll    add_payroll    month    ${uiModels}    ${MONTH}\n    \n    Input Field Model    Payroll    add_payroll    salary    ${uiModels}    ${SALARY}\n    \n    Select Checkbox Model    Payroll    add_payroll    terms    ${uiModels}\n    \n    Click Button Model    Payroll    add_payroll    addButton    ${uiModels}\n    \n    Close Workbook\n```\n\n## Available Custom Functions\n\n\n### 1. Click Button Model\n\nThe `Click Button Model` custom function in the ModelDrivenRpa library allows you to interact with UI elements in a streamlined and efficient manner. This function facilitates the process of clicking a button within a specific UI model or application.\n\n```robot\nClick Button Model    ${modelName}    ${pageName}    ${elementName}    ${allModels}\n```\n###  Parameters\n\n1. ${modelName} (string): The UI model name or application name in which the button is located.\n2. ${pageName} (string): The name of the page or section containing the button element.\n3. ${elementName} (string): The name of the UI button element to be clicked.\n4. ${allModels} (list): A list containing all the UI models present in your database.\n\n\n\n### 2. Input Field Model\n\nThe `Input Field Model` custom function in the ModelDrivenRpa library allows you to efficiently interact with input fields within UI models or applications. This function simplifies the process of entering data into input fields with a specified UI context.\n\n\n```robot\nInput Field Model    ${modelName}    ${pageName}    ${elementName}    ${allModels}    ${inputValue}\n```\n###  Parameters\n\n1. ${modelName} (string): The UI model or application name in which the input field is located.\n2. ${pageName} (string): The name of the page or section containing the input field element.\n3. ${elementName} (string): The name of the input field element to interact with.\n4. ${allModels} (list): A list containing all the UI models present in your database.\n5. ${inputValue} (string): The value to be entered into the input field.\n\n\n### 3. Select From Dropdown Model\n\nThe `Select From Dropdown Model` custom function in the ModelDrivenRpa library empowers you to interact with dropdown elements within UI models or applications. This function simplifies the process of selecting an option from a dropdown menu with a specified UI context.\n\n\n```robot\nSelect From Dropdown Model    ${modelName}    ${pageName}    ${elementName}    ${allModels}    ${selectedOption}\n```\n###  Parameters\n\n1. ${modelName} (string): The UI model or application name in which the dropdown element is located.\n2. ${pageName} (string): The name of the page or section containing the dropdown element.\n3. ${elementName} (string): The name of the dropdown element to interact with.\n4. ${allModels} (list): A list containing all the UI models present in your database.\n5. ${selectedOption} (string): The option to be selected from the dropdown.\n\n### 4. Select Checkbox Model\n\nThe `Select Checkbox Model` custom function in the ModelDrivenRpa library empowers you to interact with checkboxes within UI models or applications. This function simplifies the process of toggling checkbox states with a specified UI context.\n\n\n```robot\nSelect Checkbox Model    ${modelName}    ${pageName}    ${elementName}    ${allModels}\n```\n###  Parameters\n\n1. ${modelName} (string): The UI model or application name in which the checkbox element is located.\n2. ${pageName} (string): The name of the page or section containing the checkbox element.\n3. ${elementName} (string): The name of the checkbox element to interact with.\n4. ${allModels} (list): A list containing all the UI models present in your database.\n\n### 5. Get Ui Models\n\nThe `Get Ui Models` custom function in the ModelDrivenRpa library enables you to retrieve a list of UI models or applications that are available for automation. This function is particularly useful when you need to dynamically access and utilize UI models during your Robotic Process Automation (RPA) tasks.\n\n```robot\n${uiModels}=    Get Ui Models    ${apiEndpoint}\n```\n\n###  Parameters\n\n1. ${apiEndpoint} (string): The endpoint URL of your own API that returns a list of available UI models.\n\n\n## License\nLicensed under the [MIT license](https://github.com/bptlab/MdRPA_Library/blob/main/LICENSE).\n"}
{"url": "https://github.com/bptlab/mimic-log-extraction", "owner": "bptlab", "repository_name": "mimic-log-extraction", "date_all_variable_collection": "2023-09-11", "description": "A CLI tool for extracting event logs out of MIMIC Databases.", "size": 4044, "stargazers_count": 4, "watchers_count": 4, "language": "Python", "has_issues": false, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 4, "default_branch": "main", "contributors": [{"contributor": "fyndalf", "contributions": 88}, {"contributor": "jcremerius", "contributions": 78}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["event-log", "mimic-iv", "process-mining"], "languages": [{"language": "Python", "num_chars": 70109}], "readme": "# mimic-log-extraction\n\n[![Pylint](https://github.com/bptlab/mimic-log-extraction/actions/workflows/pylint.yml/badge.svg)](https://github.com/bptlab/mimic-log-extraction/actions/workflows/pylint.yml) [![Typecheck](https://github.com/bptlab/mimic-log-extraction/actions/workflows/mypy.yml/badge.svg)](https://github.com/bptlab/mimic-log-extraction/actions/workflows/mypy.yml)\n\nA CLI tool for extracting event logs out of MIMIC Databases. This branch is for MIMIC-IV 1.0. If you use MIMIC-IV 2.0 or 2.2, please pull from the respective branch: https://github.com/bptlab/mimic-log-extraction/tree/mimic-2.0 , https://github.com/bptlab/mimic-log-extraction/blob/mimic-2.2/\n\n- requires python 3.8.10 (newer versions might be fine, though)\n- using a python virtual environment seems like a good idea\n\nThe official python documentation provides a [good overview](https://docs.python.org/3/library/venv.html) on how to create virtual environments. We recommend having the environment either in this directory, or one level above.\n\n## usage\n\n```\nusage: extract_log.py [-h] [--db_name DB_NAME] [--db_host DB_HOST] [--db_user DB_USER] [--db_pw DB_PW] [--subject_ids SUBJECT_IDS]\n                      [--hadm_ids HADM_IDS] [--icd ICD] [--icd_version ICD_VERSION] [--icd_sequence_number ICD_SEQUENCE_NUMBER] [--drg DRG]\n                      [--drg_type DRG_TYPE] [--age AGE] [--type TYPE] [--tables TABLES] [--tables_activities TABLES_ACTIVITIES]\n                      [--tables_timestamps TABLES_TIMESTAMPS] [--notion NOTION] [--case_attribute_list CASE_ATTRIBUTE_LIST] [--config CONFIG]\n                      [--save_intermediate] [--ignore_intermediate]\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --db_name DB_NAME     Database Name\n  --db_host DB_HOST     Database Host\n  --db_user DB_USER     Database User\n  --db_pw DB_PW         Database Password\n  --subject_ids SUBJECT_IDS\n                        Subject IDs of cohort\n  --hadm_ids HADM_IDS   Hospital Admission IDs of cohort\n  --icd ICD             ICD code(s) of cohort\n  --icd_codes_intersection Optional argument, if one wants to filter for disease combinations, such that patients have to have an icd code from icd_codes and from icd_codes_intersection\n  --icd_version ICD_VERSION\n                        ICD version\n  --icd_sequence_number ICD_SEQUENCE_NUMBER\n                        Ranking threshold of diagnosis\n  --drg DRG             DRG code(s) of cohort\n  --drg_type DRG_TYPE   DRG type (HCFA, APR)\n  --age AGE             Patient Age of cohort\n  --type TYPE           Event Type\n  --tables TABLES       Low level tables\n  --tables_activities TABLES_ACTIVITIES\n                        Activity Columns for Low level tables\n  --tables_timestamps TABLES_TIMESTAMPS\n                        Timestamp Columns for Low level tables\n  --notion NOTION       Case Notion\n  --case_attribute_list CASE_ATTRIBUTE_LIST\n                        Case Attributes\n  --config CONFIG       Config file for providing all options via file\n  --save_intermediate   Store intermediate extraction results as csv. For debugging purposes.\n  --ignore_intermediate\n                        Explicitly disable storing of intermediate results.\n  --csv_log             Store resulting log as a .csv file instead of as an .xes event log\n```\n\nCall the tool via\n\n```bash\npython3 -m extract_log <...>\n```\n\npassing the required parameters.\n\nIf you installed the tool via cloning this repository, you should instead execute\n\n```bash\npython3 ./extract_log.py <...>\n```\n\n## config file\n\nFor providing parameters via a `.yml` config file, provide the path to that file via the `--config` flag.\nThis will override any setting provided via prompt or input flag, so be careful. Refer to the `example_config.yml` file for how to provide options. The config keys `icd_codes`, `drg_codes`, and `additional_event_attributes` need to be explicitly set to `[]` in order to not be prompted for during extraction. `include_medications` only needs to be set for POE event logs to avoid the prompt. When `case_attributes` is set to `[]`, the respective default attributes are used. If the key is not provided, no case attributes are added. To be prompted for it during execution, `prompt_case_attributes` needs to be set to true.\n\n```yaml\ndb:\n    name: mimic\n    host: 127.0.0.1\n    user: some_db_user\n    pw: some_db_password\nsave_intermediate: True # True, False\ncsv_log: False # True, defaults to False\ncohort:\n    subject_ids: # Omitting does not consider subject_ids\n        - some subject_ids\n        - ...\n    hadm_ids: # Omitting does not consider hadm_ids\n        - some hadm_ids\n        - ...\n    icd_codes: # could also be [] to avoid ICD filtering. Omitting makes the tool prompt for input.\n        - some ICD code\n        - ...\n    icd_codes_intersection: # optional argument, if one wants to filter for disease combinations, such that patients have to have an icd code from icd_codes and from icd_codes_intersection\n        - some ICD code\n        - ...   \n    icd_version: 10 # 9, 10, 0\n    icd_seq_num: 1\n    drg_codes: [] # could also contain keys to filter for DRG codes. Omitting makes the tool prompt for input. \n    drg_ontology: APR # APR, HCFA\n    age: # could also be [] to avoid age range filtering. Omitting makes the tool prompt for input.\n        - 0:25\n        - 50:90\nevent_type: admission # admission, transfer, poe\ninclude_medications: False # False, True. Only needed if POE event_type\ncase_notion: hospital admission # subject, hospital admission\ncase_attributes: [] # could also be None. [] uses default case attributes for case notion.\nprompt_case_attributes: False # False, True. Setting True forces case attributes to be determined if not provided\nlow_level_tables: # only if event type OTHER\n    - pharmacy\n    - labevents\nlow_level_activities:\n    - medication\n    - label\nlow_level_timestamps:\n    - starttime\n    - charttime\nadditional_event_attributes: # Can be set to []. Omitting makes the tool prompt for input\n    - \n        start_column: a\n        end_column: b\n        time_column: c\n        table_to_aggregate: d\n        column_to_aggregate: f\n        aggregation_method: g\n        filter_column: h # can be omitted\n        filter_values:\n            - one\n            - other\n    -\n        start_column: a\n        end_column: b\n        time_column: c\n        table_to_aggregate: d\n        column_to_aggregate: f\n        aggregation_method: g\n        filter_column: h # can be omitted\n```\n\n## installation\n\nSimply run the pip installation command to install the extraction tool:\n\n```bash\npip install git+https://github.com/bptlab/mimic-log-extraction/\n```\n\nAlternatively, clone this repo and execute\n\n```bash\npip install -e .\n```\n\nFor development and testing, all dev dependencies can be installed using\n\n```bash\npip install -e .[dev]\n```\n\nIf you're using `zsh`, escape the square brackets: `pip install -e .\\[dev\\]`\n\n## development\n\nAfter installing all required dev dependencies, make sure to regularly call\n\n```bash\npylint extract_log.py extractor --rcfile .pylintrc\nmypy --config-file mypy.ini .\n```\n\nto ensure linted and typechecked code.\n"}
{"url": "https://github.com/bptlab/model-driven-RPA", "owner": "bptlab", "repository_name": "model-driven-RPA", "date_all_variable_collection": "2023-09-11", "description": "Master Project 2023 | Model-driven RPA Bot Development", "size": 226091, "stargazers_count": 3, "watchers_count": 3, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 49, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 49, "watchers": 3, "default_branch": "main", "contributors": [{"contributor": "WolfgangDaniel", "contributions": 46}, {"contributor": "xhoelbano", "contributions": 17}, {"contributor": "Altanbagana92", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 991424}, {"language": "JavaScript", "num_chars": 116048}, {"language": "SCSS", "num_chars": 55787}, {"language": "CSS", "num_chars": 11795}], "readme": "# MdRPA\n\nIntroduce a UI model as an abstraction layer between the UI and the RPA bots.\n\n## Installation\n\n#### Our recommendation: Robocorp RPA Software Installation Guide\n\nTo build, test, and run your robot, we recommend using Visual Studio Code with the Robocorp Code extension. This integrated development environment (IDE) provides all the necessary tools for creating software robots using human-readable syntax. Make sure you have the following:\n\n- Visual Studio Code installed on your machine. You can download it from the [official website](https://code.visualstudio.com/download).\n- Robocorp Code extension and the Robot Framework Language Server extension. These can be installed from within Visual Studio Code itself.\n\n1.  Download and install Visual Studio Code from the [official website](https://code.visualstudio.com/download). Choose the version compatible with your operating system.\n2.  Launch Visual Studio Code and install the required extensions:\n    - Robocorp Code extension: Open VS Code, go to the Extensions view (Ctrl+Shift+X), and search for \"Robocorp Code.\" Click on the extension and click \"Install.\"\n    - Robot Framework Language Server extension: Similarly, search for \"Robot Framework Language Server\" in the Extensions view and install the extension.\n3.  With the extensions installed, you're ready to start running the robot using Visual Studio Code with the Robocorp Code extension!\n\n#### Prerequisites\n- Python: make sure you have [python](https://www.python.org/downloads/) installed \n- Robot Framework: make sure you have [robot framework](https://robotframework.org/?tab=1#getting-started) installed\n- RPA Framework: make sure you have [rpa framework](https://rpaframework.org/#installation) installed\n- [MdRPA Library](https://github.com/bptlab/MdRPA_Library): in order to execute robot framework bots using the UI Models please execute the following command in you cmd \"pip install mdrpaLibrary\" \n \n**_NOTE:_** To ensure the best experience we recommend using Firefox as your browser while testing or working with this project.\n\n#### Installation Steps\n- In the backend folder run the command \"npm i\"\n- In the frontend folder run the command \"npm i\"\n\nAddition: If you want to try out our given example (payroll robot) please also navigate to the folder \"examples/payrollSystem\" and run the command \"npm i\"\n\n## Usage\n- To start the frontend navigate to the \"Frontend\" folder and execute the command \"npm start\"\n- To start the backend navigate to the \"Backend\" folder and execute the command \"npm run start\"\n\nAddition: If you want to try out our given example (payroll robot) please also navigate to the folder \"examples/payrollSystem\" and run the command \"npm start\"\n\n## Contributing\n\nJust follow the following recommended process:\n\n- Fork it\n- Create your feature branch (`git checkout -b my-new-feature`)\n- Ensure your new code is tested thoroughly\n- Commit your changes (`git commit -am 'Add some feature'`)\n- Push to the branch (`git push origin my-new-feature`)\n- Create new Pull Request\n\n## License\nLicensed under the [MIT license](https://github.com/bptlab/model-driven-RPA/blob/main/LICENSE).\n"}
{"url": "https://github.com/bptlab/odea-light", "owner": "bptlab", "repository_name": "odea-light", "date_all_variable_collection": "2023-09-11", "description": "The purpose of this repository is to\u00a0provide and maintain code to quantify, interpret, and configure ontology-based event abstraction for process mining.", "size": 3163, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "sim-o-n", "contributions": 45}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 30064}], "readme": "# ODEA-Light\n\nThe `ODEA-Light` package provides functionality to quantify, interpret, and configure ontology-based event abstraction for process mining. \n\nStarting from an [XES Event Log](http://www.xes-standard.org/) and a corresponding ontology, `ODEA-Light` enables to explore and assess different abstraction levels.  After the configuration of a new abstraction level, the initial event log can be enhanced by replacing matching events by their abstract representation.\n\n## Installation\n\nTo install `ODEA-Light`, follow the steps below:\n\n```bash\npip install git+https://github.com/bptlab/odea-light.git\n```\n\n### SPARQL Endpoint\n\nAs the goal of this project is to support semantically meaningful event abstractions, based on domain-specific ontologies, this project uses the free and open source Java framework [Apache Jena Fuseki](https://jena.apache.org/index.html) to set up a local SPARQL endpoint.\n\n1. Install Jena Fuseki according to their [installation guide](https://jena.apache.org/documentation/fuseki2/index.html)\n2. Start the server: \n```bash \n./fuseki-server --update --mem /ds\n```\n3. Upload the [`.owl`](https://github.com/bptlab/odea-light/blob/master/data/ic_ontology.owl) file to the endpoint\n\n### Configuration\nThis package uses a central `.env` file to organize basic configurations. Please add a new `.env` file in the `odea` directory that provides the following two things:\n1. The URL to your Fuseki instance and its endpoint, e.g.:\n    `SPARQL_ENDPOINT=SPARQL_ENDPOINT=http://localhost:3030/ds/query`\n2. Specify the prefix of the running example: \n   `SPARQL_PREFIX=http://www.semanticweb.org/bpt/ontologies/2021/5/insurance-company#`\n\n## Examples\nTo showcase the approach the repository contains several demo scripts and one Jupyter Notebook. The later one serves to interactively explore the application of the metrics to define constraints on the abstraction space.\n\n> Please follow the instructions above to install the required package first.\n\n### Scripts\n\n| Metric             | Script                                                        | Description                                                                                              |\n| ------------------ | ------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------- |\n| **Distance**       | [demo_distance.py](demo/scripts/demo_distance.py)             | demonstrate the computation of the two distance metrics for mapping of low-level and high-level concepts |\n| **Granularity**    | [demo_granularity.py](demo/scripts/demo_granularity.py)       | showcases the computation of the granularity of concepts                                                 |\n| **Support**        | [demo_support.py](demo/scripts/demo_support.py)               | example to compute the two support metrics for mappings of low-level and high-level concepts             |\n| **Expressiveness** | [demo_expressiveness.py](demo/scripts/demo_expressiveness.py) | showcases the computation of the expressiveness of concepts                                              |\n\n### Jupyter Notebook\n\nTo experiment with different configurations to define the abstraction space the [Demo Notebook](demo/Constraint%20Demo.ipynb) can be used.\n\n![example process models, before and after abstraction](demo/example_process_models.png)"}
{"url": "https://github.com/bptlab/onto-rpa-frontend", "owner": "bptlab", "repository_name": "onto-rpa-frontend", "date_all_variable_collection": "2023-09-11", "description": null, "size": 173, "stargazers_count": 0, "watchers_count": 0, "language": "Vue", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 1, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "MaximilianV", "contributions": 65}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Vue", "num_chars": 35895}, {"language": "TypeScript", "num_chars": 29420}, {"language": "JavaScript", "num_chars": 532}, {"language": "CSS", "num_chars": 475}, {"language": "HTML", "num_chars": 337}], "readme": "# Vue 3 + Typescript + Vite\n\nThis template should help get you started developing with Vue 3 and Typescript in Vite. The template uses Vue 3 `<script setup>` SFCs, check out the [script setup docs](https://v3.vuejs.org/api/sfc-script-setup.html#sfc-script-setup) to learn more.\n\n## Recommended IDE Setup\n\n- [VSCode](https://code.visualstudio.com/) + [Volar](https://marketplace.visualstudio.com/items?itemName=johnsoncodehk.volar)\n\n## Type Support For `.vue` Imports in TS\n\nSince TypeScript cannot handle type information for `.vue` imports, they are shimmed to be a generic Vue component type by default. In most cases this is fine if you don't really care about component prop types outside of templates. However, if you wish to get actual prop types in `.vue` imports (for example to get props validation when using manual `h(...)` calls), you can enable Volar's `.vue` type support plugin by running `Volar: Switch TS Plugin on/off` from VSCode command palette.\n"}
{"url": "https://github.com/bptlab/onto-rpa-platform", "owner": "bptlab", "repository_name": "onto-rpa-platform", "date_all_variable_collection": "2023-09-11", "description": "A meta repository for the components of the conceptual bot platform", "size": 539, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "MaximilianV", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Conceptual Bot Platform\n_A meta repository for the components of the conceptual bot platform_\n\nThe conceptual bot platform serves as a software system for modeling and analyzing conceptual RPA bots based on the ontology of RPA operations.\nFurthermore, modeled conceptual RPA bots can be linked, i.e. translated, to existing RPA tools, currently [Robot Framework](https://robotframework.org/) and [taskt](http://www.taskt.net/).\n\nDemonstration of the platform (https://youtu.be/Pq5FIS9KtqA):\n\n[![Thumbnail to screencast](https://img.youtube.com/vi/Pq5FIS9KtqA/0.jpg)](https://www.youtube.com/watch?v=Pq5FIS9KtqA)\n\n## Available components\nSo far, the platform consists of a [front end (the modeler)](https://github.com/bptlab/conceptual-bot-modeler), and a [back end](https://github.com/bptlab/conceptual-bot-backend) for storing and linking bots.\n\n### Conceptual RPA Bot Modeler\nThis modeler currently comprises the following functionality:\n- Parsing the ontology of RPA operations\n- Mapping from BPMO concepts to BPMN\n- Modeling conceptual bots using the Business Process Model and Notation using operations from the ontology\n- Support for different types of operations, such as triggers, decisions, and context containers\n- Parsing BPMN models to generic process trees that are sent to the back end for storing\n- Analzying stored bots for included operations and concepts, i.e. searching the bot repository for bots automating certain applications or using specific operations\n\n\n### Conceptual RPA Bot Back End\nThe back end, serving as the bot repository, currently offers the following features:\n- Storing the generic process tree and the visual BPMN representation of RPA bots\n- Linking, i.e., translating, stored bots to either Robot Framework (`.robot`) or taskt files (`.xml`)\n"}
{"url": "https://github.com/bptlab/orion", "owner": "bptlab", "repository_name": "orion", "date_all_variable_collection": "2023-09-11", "description": null, "size": 4406, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "jcremerius", "contributions": 42}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 4713499}, {"language": "HTML", "num_chars": 19926}, {"language": "CSS", "num_chars": 1221}, {"language": "Dockerfile", "num_chars": 493}], "readme": "# Orion: Discovering and Exploring Change Patterns in Dynamic Event Attributes\n\nThis repository provides orion, a tool to discover and explore change patterns in dynamic event attributes. It includes the source code, as well as the docker container, to run the application. Further, two analysis use cases are presented.\n\n## Setup\n\nThe easiest way to setup orion is to use [docker](https://hub.docker.com/r/jcremerius/orion/tags). Just pull the image using the following command:\n```docker pull jcremerius/orion:latest``` and run it by executing ```docker run -p 8000:8000 -d jcremerius/orion:latest```. After that, a docker container is created and shall run. The application can be accessed via a webbrowser under the following address [http://127.0.0.1:8000](http://127.0.0.1:8000).\n\n\n## Alternative Anaconda Setup\n\nAlternatively, it is possible to setup the tool without docker locally using Anaconda. Install [Anaconda](https://anaconda.org/) and run the following command in this folder: ```conda env create --name env --file=environment_packages.yml```. Then, replace the pm4py package in the environment with the pm4py package included in this repository. After that, activate the enviroment by executing ```conda activate env``` and run the django server in the orion folder with: ```python manage.py runserver 0.0.0.0:8000 --insecure```. The application is then accessible via webbrwoser under the following address: [http://127.0.0.1:8000](http://127.0.0.1:8000)\n\n## Tool Usage + Video\nThe tool can be used with any event log, provided as a .csv file. Please be aware, that event logs should include dynamic event attributes. Else, this tool provides no new insights for the given event log. We recommend the Sepsis Event Log, which can be found [here](https://github.com/bptlab/orion/tree/master/Demonstration/Sepsis).\n\n\nA demonstration of the tool on a healthcare dataset, extracted from MIMIC-IV can be viewed via the following link: [https://www.youtube.com/watch?v=CIwaCuSN03s](https://www.youtube.com/watch?v=CIwaCuSN03s). The dataset was also used by us for evaluating the research contributions.\n\nFurther, a demonstration on the Sepsis event log can be found [here](https://github.com/bptlab/orion/tree/master/Demonstration/Sepsis).\n\nPlease be aware, that the server (or the docker container) needs to be restarted, if one wants to upload a new event log. We are working on fixing this issue.\n\n\n## Source Code\nThe application is written within the Django framework, where the project is stored [here](https://github.com/bptlab/orion/tree/master/orion). It utilizes the python package, also called orion, which can be found [here](https://github.com/bptlab/orion/tree/master/orion/orion), which provides all functionalities without the frontend.\n"}
{"url": "https://github.com/bptlab/relationships-between-change-patterns", "owner": "bptlab", "repository_name": "relationships-between-change-patterns", "date_all_variable_collection": "2023-09-11", "description": null, "size": 4349, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "jcremerius", "contributions": 19}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 85694}, {"language": "Python", "num_chars": 55244}], "readme": "# Relationships between Change Patterns in Dynamic Event Attributes\n\n## Introduction\nThis repository provides the implementation and setup for the evaluation of the paper entitled <b>Relationships between Change Patterns in Dynamic Event Attributes</b>. This repository includes three jupyter notebooks. The first incorporates the event log generation of the ICU related event log. The second applies the change pattern detection, as introduced in [1]. The third identifies the relationships and illustrates the results in a UI. For the relationship identification, we provide a python [package](https://github.com/bptlab/relationships-between-change-patterns/tree/main/package). The results in the paper refer only to the Departments event log.\n\n## Event Logs (Departments and ICU) \n\nTo reproduce the results, one needs access to the [MIMIC-IV](https://mimic.mit.edu/iv/) database, which requires CITI training. Usually, that does not take much more than a day and access is granted within a week. If access is granted, the event log can be retrieved. We implemented an [event log generation tool](https://github.com/bptlab/mimic-log-extraction/tree/main) for MIMIC-IV, which allows to provide a config file as an input, which results in an ready-to-use event log. Use the [config file](https://github.com/bptlab/relationships-between-change-patterns/blob/main/MIMIC_LOG_CONFIG.yml) in this repository to retrieve the ICU event log by executing the following command: ```python extract_log.py --config MIMIC_Config.yml```. Some post-processing is required, which is conducted in [this jupyter notebook](https://github.com/bptlab/relationships-between-change-patterns/blob/main/1_ICU_Log_Preparation.ipynb). After that, the other jupyter notebooks can be executed with the ICU event log.\n\nThe hospital department event log can be extracted, as described in [this repository](https://github.com/jcremerius/Change-Detection-in-Dynamic-Event-Attributes).\n\n\n\n## Change Pattern and Relationship Detection\n\nAfter the event logs have been extracted, change patterns and their relationships can be detected. The implementation is not limited to the above-mentioned event logs and can be used with all event logs. It should be noted, that the event logs should include dynamic event attributes to retrieve any results. It is only required, that the event logs are provided as a .csv file and that the mandatory attributes case id, activity, and timestamp are renamed in the [second jupyter notebook](https://github.com/bptlab/relationships-between-change-patterns/blob/main/2_Applying_Change_Detection.ipynb) accordingly. \n\nWhen the change patterns have been detected, execute the [last](https://github.com/bptlab/relationships-between-change-patterns/blob/main/3_UI.ipynb) jupyter notebook. It performs the relationship identification and visualizes the results in an UI.\n\nThe figure below illustrates the developed tool for the approach presented in the paper. It shwos an example analysis of the Departments log presented in the paper. On top, the change pattern matrix can be configured, such that only the desired relations, attributes, and trace variants are presented. In the middle, the change pattern matrix is visualized, showing change analysis cells. If a significant change pattern was detected, the cell is coloured according to a value increase (red) or decrease (blue) with its respective RBC value. Clicking on one cell highlights the respective cell, which is the second cell from the left in the last row in Fig. 1. After clicking on one cell, all relevant relationships are illustrated in the table on the right. The respective cells in relationship with the selected cell are highlightes by a black rectangle. Below the table, one relationship can be plotted, which is the first one in the example. The buttons at the bottom allow to visualize change patterns with their relationships in the process model. The p-threshold determines, if a cell in the matrix is a significant change pattern and is not used for the correlation. \n\n![alt text](https://github.com/bptlab/relationships-between-change-patterns/blob/main/Tool.PNG)\n|:--:| \n| *Fig. 1 Tool demonstration* |\n\n\n[1] Cremerius, J., Weske, M.: Change detection in dynamic event attributes. In: Di Ciccio, C., Dijkman, R., del R \u0301\u0131o Ortega, A., Rinderle-Ma, S. (eds.) Business Process Management Forum. pp. 157\u2013172. Springer International Publishing, Cham (2022)\n"}
{"url": "https://github.com/bptlab/rembrandt", "owner": "bptlab", "repository_name": "rembrandt", "date_all_variable_collection": "2023-09-11", "description": "A resource organization and resource usage optimization platform.", "size": 17, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 2, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "friedow", "contributions": 17}, {"contributor": "MaximilianV", "contributions": 9}, {"contributor": "t-lichtenstein", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1246}, {"language": "Dockerfile", "num_chars": 719}], "readme": "# Rembrandt\n\nA resource organization and resource usage optimization plattform.\n\nPlease visit our [documentation](https://rembrandt.gitbook.io/docs/) for more information.\n"}
{"url": "https://github.com/bptlab/rembrandt-backend", "owner": "bptlab", "repository_name": "rembrandt-backend", "date_all_variable_collection": "2023-09-11", "description": "The back end for the Rembrandt Resource-Management-Platform.", "size": 433, "stargazers_count": 0, "watchers_count": 0, "language": "TypeScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 9, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 9, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "MaximilianV", "contributions": 208}, {"contributor": "friedow", "contributions": 17}, {"contributor": "Munin33", "contributions": 17}, {"contributor": "t-lichtenstein", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TypeScript", "num_chars": 113275}, {"language": "Dockerfile", "num_chars": 452}, {"language": "JavaScript", "num_chars": 382}], "readme": "# Rembrandt Backend\n![alt text](https://img.shields.io/travis/com/bptlab/rembrandt-backend.svg \"Travis Build\") \n\nBackend service for the Rembrandt Resource-Management-Platform.\n\n## Deployment\n\n1. Please follow the deployment instructions under https://github.com/bptlab/rembrandt.\n\n## Development\n\n1. Make sure you have [NodeJS](https://nodejs.org/) and [npm](https://www.npmjs.com/) installed.\n1. Clone the repository\n    ```\n    git clone https://github.com/bptlab/rembrandt-backend\n    cd rembrandt-backend\n    ```\n1. Install the dependencies\n    ```\n    npm install\n    ```\n1. Start the app\n    ```\n    npm start\n    ```\n1. Server is running on http://localhost:3000.\n\n## Building Docker Images manually\n\n1. Login to your docker account\n    ```\n    docker login\n    ```\n1. Build the image\n    ```\n    docker build -t bptlab/rembrandt-backend:latest .\n    ```\n1. Test the image\n    ```\n    docker run -p 3000:3000 bptlab/rembrandt-backend:latest\n    ```\n1. Push the image\n    ```\n    docker push bptlab/rembrandt-backend:latest\n    ```\n\n\n## License\n\nCopyright (c) 2019\n\nLicensed under the [MIT license](LICENSE).\n"}
{"url": "https://github.com/bptlab/rembrandt-frontend", "owner": "bptlab", "repository_name": "rembrandt-frontend", "date_all_variable_collection": "2023-09-11", "description": "The front end for the Rembrandt Resource-Management-Platform.", "size": 320, "stargazers_count": 2, "watchers_count": 2, "language": "Vue", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 7, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 7, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "Munin33", "contributions": 158}, {"contributor": "friedow", "contributions": 156}, {"contributor": "MaximilianV", "contributions": 33}, {"contributor": "t-lichtenstein", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Vue", "num_chars": 121260}, {"language": "TypeScript", "num_chars": 30842}, {"language": "HTML", "num_chars": 860}, {"language": "Less", "num_chars": 325}, {"language": "Dockerfile", "num_chars": 206}, {"language": "JavaScript", "num_chars": 96}], "readme": "# Rembrandt Frontend\n![alt text](https://img.shields.io/travis/com/bptlab/rembrandt-frontend.svg \"Travis Build\")\n\nFrontend service for the Rembrandt Resource-Management-Platform.\n\n## Deployment\n\n1. Please follow the deployment instructions under https://github.com/bptlab/rembrandt.\n\n\n## Development\n\n1. Make sure you have [NodeJS](https://nodejs.org/) and [npm](https://www.npmjs.com/) installed.\n1. Clone the repository\n  ```\n  git clone https://github.com/bptlab/rembrandt-frontend\n  cd rembrandt-frontend\n  ```\n1. Install the dependencies\n  ```\n  npm install\n  ```\n1. Start the app\n  ```\n  npm start\n  ```\n1. Server is running on http://localhost:8080.\n\n## Building Docker Images manually\n\n1. Login to your docker account\n  ```\n  docker login\n  ```\n1. Build the image\n  ```\n  docker build -t bptlab/rembrandt-frontend:latest .\n  ```\n1. Test the image\n  ```\n  docker run -p 8080:8080 bptlab/rembrandt-frontend:latest\n  ```\n1. Push the image\n  ```\n  docker push bptlab/rembrandt-frontend:latest\n  ```\n\n## License\n\nCopyright (c) 2018\n\nLicensed under the [MIT license](LICENSE).\n"}
{"url": "https://github.com/bptlab/rpa-dmn-operation", "owner": "bptlab", "repository_name": "rpa-dmn-operation", "date_all_variable_collection": "2023-09-11", "description": "This repo contains examples how DMN can be integrated in RPA tools.", "size": 63, "stargazers_count": 0, "watchers_count": 0, "language": "C#", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "MaximilianV", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": true, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C#", "num_chars": 91666}], "readme": "# rpa-dmn-operation\nThis repo contains the sources for a DMN activity for the RPA tool UiPath.\nFor creating and evaluating the DMN decisions, an instance of [Camundas open-source engine](https://camunda.com/download/) is required.\n\n## Installation\n\n1. Go to the [releases](https://github.com/bptlab/rpa-dmn-operation/releases) section, and download the `*.nupkg` file from the _assets_.\n1. Copy the package to the [UiPath directory for local packages](https://docs.uipath.com/studio/docs/managing-activities-packages#adding-custom-feeds).\n1. In your UiPath project, [install the package](https://docs.uipath.com/studio/docs/managing-activities-packages#installing-packages). (_All packages_ \u2192 _local_, you can also search for `DMN`)\n1. Now, the new DMN activity should be available for use as any other UiPath activity. You can find it by the name `External Decision Service`.\n\n## Usage\n\nAfter adding a DMN acivity to your workflow, the following elements need to be configured in the _Properties_-Panel:\n\n**Inputs**:\n- **Input Variables**: the list of variables in UiPath that should be passed to the decision service\n- **Input Variables Names**: the list of input names of the decision table in the same logical order as the input variables.\n\n**Options**:\n- **Decision Key**: The identifier of the decision to evaluate. This ID can be found in the Camunda engine after deploying the decision table.\n- **Service Host**: The URL under which the Camunda engine is reachable.\n\n**Output**:\n- **Decision Result**: The name of the UiPath variable, the decision result(s) should be stored in.\n\n> Example: The decision table requires the inputs _Type of Shipment_ and _Destination_. In the RPA bot, those values are stored in the variables _shipmentType_ and _destination_. To provide the correct mapping of UiPath variables and inputs of the decision table the following must be configured:\n> \n> Input Variables = `{shipmentType, destination}`\n> \n> Input Variables Names = `{\"Type of Shipment\", \"destination\"}`\n> \n> By this, the DMN activity knows how to map the variables to the decision table inputs.\n>\n> The decision key looks something like `\"Decision_1hyvppg\"` and the service host, if the engine is deployed locally, might be `\"http://localhost:8080\"`.\n\n\n> :information_source: Please bear in mind that this activity is currently in the prototype stage.\n\n\n"}
{"url": "https://github.com/bptlab/scylla", "owner": "bptlab", "repository_name": "scylla", "date_all_variable_collection": "2023-09-11", "description": "Extensible BPMN process simulator", "size": 69674, "stargazers_count": 14, "watchers_count": 14, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 8, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 30, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 8, "open_issues": 30, "watchers": 14, "default_branch": "main", "contributors": [{"contributor": "LeonBein", "contributions": 258}, {"contributor": "marcfreiheit", "contributions": 22}, {"contributor": "bdaase", "contributions": 20}, {"contributor": "LuisePufahl", "contributions": 3}, {"contributor": "s4pu", "contributions": 1}, {"contributor": "marhew", "contributions": 1}, {"contributor": "t-lichtenstein", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 1154316}], "readme": "# Scylla - An extensible BPMN process simulator [![Build Status](https://github.com/bptlab/scylla/actions/workflows/CI.yml/badge.svg)]([https://travis-ci.org/bptlab/scylla](https://github.com/bptlab/scylla/actions/workflows/CI.yml/))\r\n\r\nScylla is an extensible business process simulator.\r\nSimulations are configured with a file for general information, such as resources, multiple BPMN model files, which allow multi-process simulation with shared resources, and simulation configuration files, which extend the BPMN files with simulation-specific information, e.g., inter-arrival time of instances, task duration.\r\nScylla simulates these inputs using discrete event simulation (DES) and produces information on the simulated process instances, such as an XES event log.\r\n\r\nThe engine can be controlled via a GUI, which also provides an interface for creating the configuration input files, or by command line.\r\nScylla stands out by offering well-defined entry points for extensions based on a plug-in structure, which allows to make it fulfil specific simulation requirements.\r\n\r\n## Quick Start\r\nDownload the [latest release](https://github.com/bptlab/scylla/releases/latest) zipfile and unpack it.\r\nIt is important that the `lib` folder stays in the same directory as the `scylla.jar` file.\r\n\r\nYou can then start Scylla by executing the jarfile, e.g., by calling `java -jar scylla.jar` in the unpacked folder.\r\n\r\nNote that a valid Java installation is needed to run Scylla, we recommend at least Java 11.\r\n\r\n\r\n## Usage\r\nScylla has two main ways of operation, with a graphical user interface and via a command line interface.\r\n\r\n### UI\r\nWhen starting Scylla without any additional parameters, the Scylla GUI opens.\r\n![grafik](https://github.com/bptlab/scylla/assets/28008098/c932693d-2324-42ab-9c7d-a50f32b0d823)\r\n\r\nThe UI is structured as follows:\r\n- The left side shows the simulation inputs. There, configuration and process model files can be loaded and removed. Further new configuration files can be created or existing ones edited. This then opens the respective interfaces as new tabs.\r\n- The right side shows the loaded plugins. It allows to select which plugins are active, and even to (de-)activate single classes.\r\n- The bottom shows the simulation console output and provides the controls to start the simulation and inspect the last simulation outputs.\r\n\r\nNote that to run a simulation, at the following inputs are needed: One global configuration file, at least one bpmn file, simulation configuration files for all processes of the bpmn files. For details on the simulation inputs, please refer to the [wiki](../../wiki).\r\n\r\n### CLI/Headless Mode\r\nScylla can also be run without GUI. This is useful, e.g., when calling it from another program or when running the same Simulation multiple times. Configuration of the simulation then happens with the following program parameters (defined directly in the main class [Scylla.java](src/main/java/de/hpi/bpt/scylla/Scylla.java)):\r\n- `--help` prints information about the command line usage of Scylla\r\n- `--headless` activates the headless mode\r\n- `--config=<path to file>` where `<path to file>` must lead to a global configuration file. This parameter must be present exactly once in headless mode\r\n- `--bpmn=<path to file>` where `<path to file>` must lead to a bpmn process model. This parameter must be present at least once in headless mode, but might be multiple times\r\n- `--sim=<path to file>` where `<path to file>` must lead to a simulation model configuration file. This parameter might be present multiple times, but there must be configurations for each simulated business process\r\n- `--enable-bps-logging` enables logging of the executed process instances. This flag is optional, but recommended to activate\r\n- `--enable-des-logging` enables logging of the descrete event simulation used. The flag is optional, recommended only to use for debugging\r\n- `--output=<path to folder>` sets the output folder to `<path to folder>`. Optional, otherwise a default path will be used\r\n\r\n### Calling from Code\r\nScylla can also be directly called from another Java application. For this, the application has to import Scylla as Maven dependency.\r\nThen, either call the main class `Scylla`'s `main` method, or manually create a new `SimulationManager` and call `run.`\r\n\r\n\r\n## Plugins\r\nOne distinctive feature of Scylla is its plugin system, which allows to easily add functionality for specialized or refined simulation behavior.\r\n\r\n### Loading Plugins\r\nTo load additional plugins, put their respective jarfiles into the `plugins` subfolder of your Scylla folder. You can check whether a plugin has been loaded by starting the Scylla GUI and asserting that it appears in the plugins list.\r\n\r\n### Plugin Development\r\nTo create a new plugin, create a new Maven project for your plugin. Add Scylla as a Maven dependency to that project. Potentially, you first need to install Scylla via Maven.\r\nThen, create your plugin classes. These are all classes that extend one of the entrypoints (see wiki), which in turn implement the `IPluggable` interface. Note that all classes belonging to the same plugin should return the same value in their implementation of `getName`.\r\nTo test your plugin from within your plugin project, you can put the following hack class into your package and execute it:\r\n``` java\r\npublic class Main {\r\n    public static void main(String[] args) throws IOException {\r\n        PluginLoader.getDefaultPluginLoader().loadPackage(Main.class.getPackageName());\r\n        Scylla.main(args);\r\n    }\r\n}\r\n```\r\n\r\nTo 'publish' your plugin, run Maven package to generate a jarfile and put it into the `plugins` subfolder of your scylla folder.\r\nMore information on the plug-in structure and how plug-ins can be developed are given in the [wiki](../../wiki/Plugin-Concept).\r\n\r\n\r\n## Related Projects\r\n- [Scylla-Container](https://github.com/INSM-TUM/Scylla-Container) provides a simple http API and dockerization of Scylla\r\n- [SimuBridge](https://github.com/INSM-TUM/SimuBridge) is an application that bridges between process mining and business process simulation. It uses Scylla as Simulator and provides a generic metamodel and GUI for the construction of business process simulation models, usable in Scylla.\r\n- [scylla-ui](https://github.com/bptlab/scylla-ui) (discontinued) provides a GUI for visualizing Scylla simulation outputs\r\n\r\n## Related Publications\r\n- [Pufahl, L., Wong, T.Y., Weske, M. (2018). **Design of an Extensible BPMN Process Simulator**. In: Teniente, E., Weidlich, M. (eds) Business Process Management Workshops. BPM 2017. Lecture Notes in Business Information Processing, vol 308. Springer, Cham. https://doi.org/10.1007/978-3-319-74030-0_62](https://doi.org/10.1007/978-3-319-74030-0_62)\r\n- [Pufahl, L., & Weske, M. (2017). **Extensible BPMN Process Simulator**. In: Proceedings of the\r\nBPM Demo Track and BPM Dissertation Award](https://ceur-ws.org/Vol-1920/BPM_2017_paper_198.pdf)\r\n\r\n## About\r\nScylla was initially developed in 2017 as part of a Master's Thesis by Tsun Yin Wong at the chair for Business Process Technologies (BPT) at the Hasso Plattner Institute Potsdam. Further development was then done at the BPT chair. Currently, the project is being developed further and maintained in cooperation by the HPI BPT chair and the chair for Information Systems at the Technical University of Munich.\r\n"}
{"url": "https://github.com/bptlab/scylla-ui", "owner": "bptlab", "repository_name": "scylla-ui", "date_all_variable_collection": "2023-09-11", "description": "UI visualizing results of the BPMN process simulator Scylla", "size": 1715, "stargazers_count": 3, "watchers_count": 3, "language": "TypeScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 11, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 11, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "marcfreiheit", "contributions": 143}, {"contributor": "bisbaldi", "contributions": 86}, {"contributor": "angular-cli", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TypeScript", "num_chars": 105756}, {"language": "HTML", "num_chars": 12489}, {"language": "JavaScript", "num_chars": 2516}, {"language": "CSS", "num_chars": 2265}], "readme": "# ScyllaUi \n\n[![Build Status](https://travis-ci.org/bptlab/scylla-ui.svg?branch=master)](https://travis-ci.org/bptlab/scylla-ui)[![Maintainability](https://api.codeclimate.com/v1/badges/0ae17f1eb85a228f53dd/maintainability)](https://codeclimate.com/github/bptlab/scylla-ui/maintainability)[![Test Coverage](https://api.codeclimate.com/v1/badges/0ae17f1eb85a228f53dd/test_coverage)](https://codeclimate.com/github/bptlab/scylla-ui/test_coverage)\n\n## Prerequisites\n\nThis project is developed using Angular CLI. In order to run and this project or develop on your own, you need to setup the following:\n\n* [Angular CLI (^1.5.0)](https://github.com/angular/angular-cli)\n* Optional: [Docker](https://docs.docker.com/install/)\n\n## Table of Contents\n\n* [Setup](https://github.com/bptlab/scylla-ui#setup)\n* [Development server](https://github.com/bptlab/scylla-ui#development-server)\n* [Build](https://github.com/bptlab/scylla-ui#build)\n* [Running unit tests](https://github.com/bptlab/scylla-ui#running-unit-tests)\n* [Docker](https://github.com/bptlab/scylla-ui#docker)\n* [Documentation](https://github.com/bptlab/scylla-ui#documentation)\n* [License](https://github.com/bptlab/scylla-ui#license)\n\n## Setup\n\nAngular is based on [nodejs](https://nodejs.org/en/) and [npm](https://github.com/npm/npm). In order to run the project locally on your machine, you need to install it's dependencies. You can achieve that by running `npm install`.\nAfter execution, you will see a folder called `node_modules` containing all dependencies.\n\n## Development server\n\nRun `ng serve` for a dev server. Navigate to `http://localhost:4200/`. The app will automatically reload if you change any of the source files.\n\n## Build\n\nRun `ng build` to build the project. The build artifacts will be stored in the `dist/` directory. Use the `-prod` flag for a production build.\n\n## Running unit tests\n\nRun `ng test` to execute the unit tests via [Karma](https://karma-runner.github.io).\n\n## Docker\n\nScylla UI is dockerized. Our deployment process is completly based on Docker and Jenkis CI (deploying the image to [our website](https://bpt-lab.org/scylla-ui/)) as well as Travis CI (running the tests and building the image).\n\n### Build the image on your own\n\nYou can build the image by running `docker build -t bptlab/scylla-ui .`. This will build the image based on our [Dockerfile](Dockerfile).\n\n### Pull image from [hub.docker.com](https://hub.docker.com/r/bptlab/scylla-ui/)\n\nAs an alternative, you can pull our image from Docker Hub by running `npm run build:docker` (or `docker pull bptlab/scylla-ui`).\n\n### Running a container\n\nIn order to run the app, we suggest the following command `npm run start:docker` (or `docker run -p \"8080:80\" --rm -d bptlab/scylla-ui`). Navigate to `http://localhost:8080/`.\n\n## Documentation\n\nThe documentation for the Scylla UI is located in this repo's [wiki](https://github.com/bptlab/scylla-ui/wiki).\n\n## License\n\nMIT\n"}
{"url": "https://github.com/bptlab/subscription-point-visualizer", "owner": "bptlab", "repository_name": "subscription-point-visualizer", "date_all_variable_collection": "2023-09-11", "description": "Visualizes subscription points in bpmn choreography diagrams.", "size": 514, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 3, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 3, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "LeonBein", "contributions": 51}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 52370}, {"language": "CSS", "num_chars": 6773}, {"language": "HTML", "num_chars": 2183}], "readme": "# SubscriptionPointVisualizer ![Build](https://github.com/bptlab/subscription-point-visualizer/workflows/Node.js%20CI/badge.svg)\nVisualizes subscription points in bpmn choreography diagrams.\n![Screenshot](https://user-images.githubusercontent.com/28008098/76978904-90b32a00-6937-11ea-8b22-a50307b21fa3.png)\n\n\n## Installation & Usage\nNode needs to be installed for the visualizer to run.\nTo install it, clone this repository on your machine. To start, navigate to the installation folder and enter the following into your command line:\n```shell\nnpm install\nnpm run build\nnpm run serve\n```\n\nThe visualizer is then served to `http://localhost:9024`.\n\nClick on a choreography task to see the subscription points (green) and unsubscription points (red). If the indicator is placed at the border of the whole process, (un-)deployment time (un-)subscription is indicated.\n\n#\n\nThis repository is based on [chor-js](https://github.com/bptlab/chor-js)\n"}
{"url": "https://github.com/bptlab/Unicorn", "owner": "bptlab", "repository_name": "Unicorn", "date_all_variable_collection": "2023-09-11", "description": "Unicorn Event Processing Platform", "size": 23073, "stargazers_count": 9, "watchers_count": 9, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 3, "license": "GNU General Public License v2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 3, "watchers": 9, "default_branch": "master", "contributors": [{"contributor": "MaximilianV", "contributions": 115}, {"contributor": "friedow", "contributions": 22}, {"contributor": "marhew", "contributions": 21}, {"contributor": "jffjhnsn", "contributions": 19}, {"contributor": "tommartensen", "contributions": 18}, {"contributor": "m0r13", "contributions": 13}, {"contributor": "j-beyer", "contributions": 4}, {"contributor": "julianweise", "contributions": 3}, {"contributor": "sankalita", "contributions": 2}, {"contributor": "jan-ladleif", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 2376428}, {"language": "HTML", "num_chars": 122707}, {"language": "JavaScript", "num_chars": 24863}, {"language": "Smarty", "num_chars": 4327}, {"language": "Batchfile", "num_chars": 2791}, {"language": "CSS", "num_chars": 2414}, {"language": "XSLT", "num_chars": 1951}, {"language": "Shell", "num_chars": 640}, {"language": "Dockerfile", "num_chars": 472}], "readme": "# Unicorn\nAn event processing platform build on top of [Esper](http://espertech.com/products/esper.php). It was developed by the [Business Process Technology group](http://bpt.hpi.uni-potsdam.de) at the [Hasso-Plattner-Institut](http://hpi.de) in the course of several student projects.\n\n__More info on [the website](https://bptlab.github.io/Unicorn/).__\n\n## Pre-requisites \nTo build and run Unicorn you need the following software:\n- Maven 3\n- Apache Tomcat 7.x (or some other container)\n- MySQL server 5.6 or above\n\n## Installation\n\n1. clone the repository\n2. create schemas 'eap_development' and 'eap_testing' in your MySQL database\n3. copy the file unicorn_template.properties, rename it to unicorn.properties and configure your database credentials. It needs to stay in the main directory.\n4. build Unicorn by executing ```mvn install -DskipTests```\n\n### Deployment to Tomcat\n\nYou can manually deploy Unicorn by copying the resulting war file in EapWebInterface/target to the webapps folder of your tomcat installation or you can use ```mvn tomcat7:deploy``` in the EapWebInterface folder if you want to use maven for deployment. However, some configuration is necessary for the latter option, see for example [here](http://www.mkyong.com/maven/how-to-deploy-maven-based-war-file-to-tomcat/).\n\n**Unicorn looks for the unicorn.properties in two locations: 1) in the parent folder of user.dir (NOT user.home) and 2) in user.dir/conf. `user.dir` refers to the directory in which tomcat (and hence, Java) is started. This means you need to start tomcat from EapWebInterface. Assuming you are in the main directory of Unicorn, you can do the following.**\n\n    cd EapWebInterface\n    /path/to/your/tomcat/bin/catalina.sh run\n\n**If your tomcat is started as a windows service, you will need to find out what user.dir is in that case. If Unicorn fails to start, check in `/path/to/your/tomcat/logs/catalina.out` for an error message 'unicorn.properties not found'.**\n\n## Getting Started\n\nYou can now start your browser and visit the Unicorn platform running on your tomcat application server, per default it is deployed to http://localhost:8080/Unicorn\n"}
{"url": "https://github.com/bptlab/wiki-resources", "owner": "bptlab", "repository_name": "wiki-resources", "date_all_variable_collection": "2023-09-11", "description": null, "size": 2750, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "friedow", "contributions": 23}, {"contributor": "tommartensen", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 18993}], "readme": "# wiki-resources"}
{"url": "https://github.com/braunfuss/beirut-explosion-insar-yield", "owner": "braunfuss", "repository_name": "beirut-explosion-insar-yield", "date_all_variable_collection": "2023-09-11", "description": null, "size": 31420, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "braunfuss", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 132692}]}
{"url": "https://github.com/braunfuss/BNN-MT", "owner": "braunfuss", "repository_name": "BNN-MT", "date_all_variable_collection": "2023-09-11", "description": "Bayesian Machine learning based full seismic Moment Tensor estimation example for JGR submission \"Estimation of seismic moment tensors using variational inference machine learning\"", "size": 2712, "stargazers_count": 9, "watchers_count": 9, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 5, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 5, "open_issues": 0, "watchers": 9, "default_branch": "master", "contributors": [{"contributor": "braunfuss", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 1657203}, {"language": "Python", "num_chars": 113774}]}
{"url": "https://github.com/braunfuss/branch-unwrapping-gmtsar", "owner": "braunfuss", "repository_name": "branch-unwrapping-gmtsar", "date_all_variable_collection": "2023-09-11", "description": "branch unwrapping for gmtsar outputs in octave with one sided unwrapping convention", "size": 1626, "stargazers_count": 8, "watchers_count": 8, "language": "Matlab", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 4, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 4, "open_issues": 0, "watchers": 8, "default_branch": "master", "contributors": [{"contributor": "braunfuss", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "MATLAB", "num_chars": 46980}], "readme": "\n\nThis script unwrappes GMTSAR outputs with the 2D Goldstein branch cut phase unwrapping algorithm in octave, with one sign direction only so far.\nSo a positive or negative change will be forced.\n\n\nYou will have to use octave v.4.0 (https://www.gnu.org/software/octave/) or better. \nPlease install if not already installed the following octave packages:\n\nimage and netcdf\n\nby using the following commands in octave:\n\n\npkg install -forge image\n\npkg install -forge netcdf\n\n\n\n\n References::\n 1. R. M. Goldstein, H. A. Zebken, and C. L. Werner, \ufffdSatellite radar interferometry:\n    Two-dimensional phase unwrapping,\ufffd Radio Sci., vol. 23, no. 4, pp. 713\ufffd720, 1988.\n 2. D. C. Ghiglia and M. D. Pritt, Two-Dimensional Phase Unwrapping:\n    Theory, Algorithms and Software. New York: Wiley-Interscience, 1998.\n\n Inputs: 1. Correlation threshold, e.g. 0.12\n         2. Area to be unwrapped. A single 1 for the entire scene, e.g. unwrap_branchcut(0.12, 1)\n         Else give the area as e.g. 1000:1500 for x and y directions. \n         e.g. unwrap_branchcut(0.12, 1000:1500, 1000:1500)\n         3. Image input are assumed to be grds from GMTSAR and are converted. [Using a modified version of GRDREAD2 from Kelsey Jordahl]\n                     \n Outputs: Figures: Unwrapped phase image, phase residues, wrapped phase and branch cuts\n          \n\n Redone for use with InSAR (GMTSAR outputs) and octave by Andreas Steinberg, 27.6.2016 \n Unwrapping algorithms by Bruce Spottiswoode on 22 December 2008 (de.mathworks.com/matlabcentral/fileexchange/22504-2d-phase-unwrapping-algorithms)\n\n\n"}
{"url": "https://github.com/braunfuss/eq-distribution-ml", "owner": "braunfuss", "repository_name": "eq-distribution-ml", "date_all_variable_collection": "2023-09-11", "description": "Basic foreshock-aftershock-distribution pattern machine learning with tensorflow", "size": 15, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "braunfuss", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 43900}], "readme": "# eq-distribution-ml\nBasic foreshock-aftershock-distribution pattern machine learning with tensorflow\n\nA very basic example on how the tensorflow playground example can be used to learn foreshock-aftershock patterns. \n\nThe idea is that it downloads catalog data and labels all foreshocks with a different label than aftershocks. The time for each can be specified in the get_events.py file.Placeholder times are given for the Amatrice eq.\nThe position of the shocks are calculated relative to the origin of the mainshock to keep dimensions simple. There is no time parameter right now.\n\nTo execute you have to run run.py, where you can also modify how many neurons and hidden layers should be considered under the class Run() (sorry again for the mess but at this stage a config file would make no sense). A lot of the options are hardcoded there. They are the same options as available on the playground demo.\n\nI recommend that you first test its functionality by setting test = True in run.py. \nThen it will just use a gaussian distributed example(you can also generate other example with dataset.py to match the ones in the playground). \nThe output will be generated in the folder above in the folder outputs, including images of the model and data distributions as on the playground. \n"}
{"url": "https://github.com/braunfuss/laquila_kite_container", "owner": "braunfuss", "repository_name": "laquila_kite_container", "date_all_variable_collection": "2023-09-11", "description": null, "size": 41526, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "braunfuss", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# L'aquila 2009 displacement data as kite container files \nThese are the kite (https://github.com/pyrocko/kite) container files of the co-seismic displacement data from Enivsat for the 2009 L'Aquila earthquake.\nThey are used in the Bayesian earthquake analysis tool (Beat; https://github.com/hvasbath/beat/) software tutorial. \nSubsampling parameter and co-variance estimation parameters used on the displacement data in that tutorial are saved in the respective \nkite container files for ascending and descending tracks.\nUnwrapping was done using minimum-cost-flow algorithm. \n"}
{"url": "https://github.com/braunfuss/Palantiri", "owner": "braunfuss", "repository_name": "Palantiri", "date_all_variable_collection": "2023-09-11", "description": "Seismological Backprojection array tool", "size": 14510, "stargazers_count": 25, "watchers_count": 25, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 6, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 6, "open_issues": 0, "watchers": 25, "default_branch": "master", "contributors": [{"contributor": "braunfuss", "contributions": 355}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 709102}], "readme": "# Palantiri\n\n### A seismological backprojection array tool\n\nGitHub is restricting access to their services based on user nationality and residence. Such restrictions are incompatible with scientific standards in international research communities like seismology. See the statement at https://pyrocko.org/. \n\nAs researchers, we are obligated to retain open access to all. To achieve this, we are now migrating our code repositories away from GitHub to a new safe home. The new home of the Palantiri repository is at https://git.pyrocko.org/asteinbe/Palantiri.\n\nTo ensure a smooth transition, we will keep a version of the code repository at GitHub until 2020-01-01.\n\n\n## Documentation\n\nWIP Documentation: https://braunfuss.github.io/Palantiri/\n\n\n## Citation\n\n\n## License \nGNU General Public License, Version 3, 29 June 2007\n\nCopyright \u00a9 2018 University Potsdam, Potsdam, Germany and  University of Kiel, Kiel, Germany\nPalantiri is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\nPalantiri is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.\nYou should have received a copy of the GNU General Public License along with this program. If not, see <http://www.gnu.org/licenses/>.\n\n## Contact\n* Andreas Steinberg; \n  andreas.steinberg@ifg.uni-kiel.de\n\n* Frank Kr\u00fcger; \n  kruegerf@geo.uni-potsdam.de\n\n\n```\n University of Kiel\n Institute of Geosciences\n Otto-Hahn-Platz 1\n 24118 Kiel, Germany, Germany\n\n```\n\nAvatar Image by By xDisciplExX, https://www.deviantart.com/xdisciplexx/art/Palantir-Stock-PNG-458559037 under Creative Commons Attribution-Noncommercial 3.0 License\n\n"}
{"url": "https://github.com/braunfuss/shake", "owner": "braunfuss", "repository_name": "shake", "date_all_variable_collection": "2023-09-11", "description": null, "size": 224, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "braunfuss", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 299151}]}
{"url": "https://github.com/braunfuss/SHM_scripts", "owner": "braunfuss", "repository_name": "SHM_scripts", "date_all_variable_collection": "2023-09-11", "description": null, "size": 3, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "braunfuss", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 11169}]}
{"url": "https://github.com/braunfuss/silvertine", "owner": "braunfuss", "repository_name": "silvertine", "date_all_variable_collection": "2023-09-11", "description": null, "size": 13974, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "braunfuss", "contributions": 171}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 4064676}, {"language": "Python", "num_chars": 1952410}, {"language": "JavaScript", "num_chars": 30863}, {"language": "HTML", "num_chars": 24563}, {"language": "CSS", "num_chars": 9907}, {"language": "Shell", "num_chars": 210}], "readme": "# silvertine\n\n\n\n## Documentation and installation\n\n\n\n## Community and support\n\n\n\n## Citation\n\n\n\n## License\n\nGNU General Public License, Version 3, 29 June 2007\n\nsilvertine is free software: you can redistribute it and/or modify it under the\nterms of the GNU General Public License as published by the Free Software\nFoundation, either version 3 of the License, or (at your option) any later\nversion. silvertine is distributed in the hope that it will be useful, but WITHOUT\nANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\nFOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.\nYou should have received a copy of the GNU General Public License along with\nthis program. If not, see <http://www.gnu.org/licenses/>.\n\n## Contact\n* Andreas Steinberg - andreas.steinberg@bgr.de\n\n\n```\nBundesanstalt f\u00fcr Geowissenschaften und Rohstoffe (BGR)\nB4.3 - Seismologisches Zentralobservatorium, Kernwaffenteststopp\nGeozentrum Hannover Stilleweg 2\n30655 Hannover\n```\n"}
{"url": "https://github.com/braunfuss/thermalintertia", "owner": "braunfuss", "repository_name": "thermalintertia", "date_all_variable_collection": "2023-09-11", "description": "Optimize for real thermal inertia from two differential thermal images", "size": 954, "stargazers_count": 1, "watchers_count": 1, "language": "Matlab", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "braunfuss", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "MATLAB", "num_chars": 41298}], "readme": "# thermalintertia\n\nShort matlab scripts (optimrtiraw.m) for optimizing for thermal inertia and estimate parameters density, heat capcity and conductivity, assuming a two layer model. Data input are at least two thermal images.\n\nThe same exisits for soil moisture in:\noptimrtisoilmoisture.m\n\nData and results are subsampled using a Quadtree (interactive with mouse input).\n\nFor questions please contact: andreas.steinberg@ifg.uni-kiel.de\n\nquadtree fct is from J\u0301onsson, S., Zebker, H.A., Segall, P. & Amelung, F., 2002. Fault slip distri bution of the 1999 Mw7.2 Hector Mine earthquake, California, estimated from satellite radar and GPS measurements, Bull. seism. Soc. Am., 92(4)\n\n\n\n"}
{"url": "https://github.com/braunfuss/weathertop", "owner": "braunfuss", "repository_name": "weathertop", "date_all_variable_collection": "2023-09-11", "description": "Prior information extraction from near-field surface displacement data", "size": 121, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "braunfuss", "contributions": 42}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 114997}], "readme": "Download LiCSAR data example:\n\nweathertop_clients http://gws-access.ceda.ac.uk/public/nceo_geohazards/LiCSAR_products/6/006D_05509_131313/interferograms/20171107_20171201/20171107_20171201.geo.unw.tif .\n\n"}
{"url": "https://github.com/brechtknecht/.dotfiles", "owner": "brechtknecht", "repository_name": ".dotfiles", "date_all_variable_collection": "2023-09-11", "description": "My Personal dotfiles", "size": 2, "stargazers_count": 0, "watchers_count": 0, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "brechtknecht", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 4191}]}
{"url": "https://github.com/brechtknecht/advent-of-code", "owner": "brechtknecht", "repository_name": "advent-of-code", "date_all_variable_collection": "2023-09-11", "description": null, "size": 313, "stargazers_count": 2, "watchers_count": 2, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "main", "contributors": [{"contributor": "brechtknecht", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 6556}]}
{"url": "https://github.com/brechtknecht/Blender-Three-Vue.js-Template", "owner": "brechtknecht", "repository_name": "Blender-Three-Vue.js-Template", "date_all_variable_collection": "2023-09-11", "description": null, "size": 3675, "stargazers_count": 1, "watchers_count": 1, "language": "Vue", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 27, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 27, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "brechtknecht", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Vue", "num_chars": 6920}, {"language": "JavaScript", "num_chars": 820}, {"language": "HTML", "num_chars": 555}], "readme": "# tree-test\n\n## Project setup\n```\nnpm install\n```\n\n### Compiles and hot-reloads for development\n```\nnpm run serve\n```\n\n### Compiles and minifies for production\n```\nnpm run build\n```\n\n### Run your tests\n```\nnpm run test\n```\n\n### Lints and fixes files\n```\nnpm run lint\n```\n"}
{"url": "https://github.com/brechtknecht/FabmobilMap", "owner": "brechtknecht", "repository_name": "FabmobilMap", "date_all_variable_collection": "2023-09-11", "description": "Created with CodeSandbox", "size": 167, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "brechtknecht", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# t\n\n## Project setup\n```\nyarn install\n```\n\n### Compiles and hot-reloads for development\n```\nyarn serve\n```\n\n### Compiles and minifies for production\n```\nyarn build\n```\n\n### Lints and fixes files\n```\nyarn lint\n```\n\n### Customize configuration\nSee [Configuration Reference](https://cli.vuejs.org/config/).\n"}
{"url": "https://github.com/brechtknecht/FHP-Applaus", "owner": "brechtknecht", "repository_name": "FHP-Applaus", "date_all_variable_collection": "2023-09-11", "description": "Website of the final theses of the graduates of the University of Applied Sciences Potsdam in the department of design.", "size": 2533331, "stargazers_count": 0, "watchers_count": 0, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "gustavneustadt", "contributions": 97}, {"contributor": "brechtknecht", "contributions": 48}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["design", "landingpage"], "languages": [{"language": "PHP", "num_chars": 1770823}, {"language": "CSS", "num_chars": 360146}, {"language": "HTML", "num_chars": 316190}, {"language": "Vue", "num_chars": 315881}, {"language": "JavaScript", "num_chars": 278674}, {"language": "Logos", "num_chars": 831}, {"language": "Shell", "num_chars": 555}], "readme": "# Applaus 2018 Dokumentation\n\nDas hier ist das offizielle Applaus Repository. Das hier ist total toll!\n\n"}
{"url": "https://github.com/brechtknecht/FHP-Kursplaner", "owner": "brechtknecht", "repository_name": "FHP-Kursplaner", "date_all_variable_collection": "2023-09-11", "description": "The official class-planner for the design department \ud83d\ude80 \u2014 University of Applied Sciences Potsdam (FHP)", "size": 31667, "stargazers_count": 1, "watchers_count": 1, "language": "Vue", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 34, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 34, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "brechtknecht", "contributions": 278}, {"contributor": "dependabot[bot]", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["vue", "vuejs"], "languages": [{"language": "Vue", "num_chars": 98753}, {"language": "JavaScript", "num_chars": 66118}, {"language": "HTML", "num_chars": 56413}, {"language": "SCSS", "num_chars": 23137}], "readme": "# FHP-Kursplaner\n[![Netlify Status](https://api.netlify.com/api/v1/badges/134b5c6b-70c5-4c31-a02f-8f99eb0a7f16/deploy-status)](https://app.netlify.com/sites/practical-wescoff-36d273/deploys)\n# How to get started?\n\nDuring development you have to switch to the `develop` branch!\n\n### Start the Nuxt.js Application\n\n``` bash\n# install dependencies\n$ npm install\n\n### Compiles and hot-reloads for development\n```\nnpm run serve\n```\n\n### Compiles and minifies for production\n```\nnpm run build\n```\n\n### Run your tests\n```\nnpm run test\n```\n"}
{"url": "https://github.com/brechtknecht/FHP-Speiseplan-Telegram-Bot", "owner": "brechtknecht", "repository_name": "FHP-Speiseplan-Telegram-Bot", "date_all_variable_collection": "2023-09-11", "description": "A Telegram Bot for the Mensa Kiepenheueralle of the University of Applied Sciences Potsdam. \ud83e\uddc1", "size": 14875, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 7, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 7, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "brechtknecht", "contributions": 36}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 11450}], "readme": "# FHP Speiseplan Bot\n\nEin Telegram Bot f\u00fcr die Mensa Kiepenheueralle der Fachhochschule Potsdam.\n\n[FH;P Speiseplan Bot](https://t.me/FHPSpeiseplanBot)\n\n### Installing\nInstalliert dieses Respoitory, indem ihr es herunterladet, entpackt und dann mit npm alle dependencies installiert.\n\n```\nnpm install\n```\n\n## Bot deployment auf eurer local Machine\nUm den Bot auf eurer local Machine zum Laufen zu bringen ben\u00f6tigt ihr lediglich einen Bot Token f\u00fcr euren Bot vom [BotFather](https://telegram.me/BotFather).\nDer Bot l\u00e4sst sich dann mit eurem Token starten.\n\n```\nBOT_TOKEN='$BOT_TOKEN' npm start\n```\n\n## Bot deployment auf einem Server\n\nZum jetzigen Zeitpunkt l\u00e4uft der Bot auf dem [ZEIT.co Deployment Service](https://www.zeit.co). Ihr k\u00f6nnt diesen Bot modifizieren und selbst auf dem Server hosten. Zum Starten ben\u00f6tigt ihr folgenden command.\n\n```\nnow -e BOT_TOKEN='$BOT_TOKEN'\n```\n\nMei\u00dftens schaltet sich die Zeit App nach einiger Zeit wieder ab. Um eine kontinuierliche runtime zu gew\u00e4hrleisten m\u00fcsst ihr euren App Status setzen. Den $NOW_BOT_DOMAIN findet ihr auf eurem [ZEIT.co Dashboard](https://zeit.co/dashboard/instances).\n\n```\nnow scale $NOW_BOT_DOMAIN 1\n```\n\nPlease read [CONTRIBUTING.md](https://gist.github.com/PurpleBooth/b24679402957c63ec426) for details on our code of conduct, and the process for submitting pull requests to us.\n"}
{"url": "https://github.com/brechtknecht/Figjam-Device-Frames-Widget", "owner": "brechtknecht", "repository_name": "Figjam-Device-Frames-Widget", "date_all_variable_collection": "2023-09-11", "description": null, "size": 429, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "brechtknecht", "contributions": 26}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 528035}, {"language": "TypeScript", "num_chars": 33939}, {"language": "CSS", "num_chars": 34}], "readme": "# Device Frames\n\n## Development guide\n\n*This widget is built with [Create Figma Plugin](https://yuanqing.github.io/create-figma-plugin/).*\n\n### Pre-requisites\n\n- [Node.js](https://nodejs.org) \u2013 v14\n- [Figma desktop app](https://figma.com/downloads/)\n\n### Build the widget\n\nTo build the widget:\n\n```\n$ npm run build\n```\n\nThis will generate a [`manifest.json`](https://figma.com/widget-docs/manifest/) file and a `build/` directory containing the JavaScript bundle(s) for the widget.\n\nTo watch for code changes and rebuild the widget automatically:\n\n```\n$ npm run watch\n```\n\n### Install the widget\n\n1. In the Figma desktop app, open a FigJam document.\n2. Search for and run `Import widget from manifest\u2026` via the Quick Actions search bar.\n3. Select the `manifest.json` file that was generated by the `build` script.\n\n### Debugging\n\nUse `console.log` statements to inspect values in your code.\n\nTo open the developer console, search for and run `Open Console` via the Quick Actions search bar.\n\n## See also\n\n- [Create Figma Plugin docs](https://yuanqing.github.io/create-figma-plugin/)\n- [Storybook](https://yuanqing.github.io/create-figma-plugin/ui/)\n- [`yuanqing/awesome-create-figma-plugin`](https://github.com/yuanqing/awesome-create-figma-plugin#readme)\n- [`yuanqing/figma-plugins`](https://github.com/yuanqing/figma-plugins#readme)\n\nOfficial docs and code samples from Figma:\n\n- [FigJam widget API docs](https://figma.com/widget-docs/)\n- [`figma/widget-samples`](https://github.com/figma/widget-samples#readme)\n# DeviceFrames-Widget-Figjam-\n"}
{"url": "https://github.com/brechtknecht/holytrinity", "owner": "brechtknecht", "repository_name": "holytrinity", "date_all_variable_collection": "2023-09-11", "description": null, "size": 64333, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "gh-pages", "contributors": [{"contributor": "brechtknecht", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/brechtknecht/influut.js", "owner": "brechtknecht", "repository_name": "influut.js", "date_all_variable_collection": "2023-09-11", "description": "Inluut is an JavaScript Library wich adds cool color Transition effects to your Pages.", "size": 2718, "stargazers_count": 0, "watchers_count": 0, "language": "CSS", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 2, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "brechtknecht", "contributions": 24}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "CSS", "num_chars": 9459}, {"language": "HTML", "num_chars": 5480}, {"language": "JavaScript", "num_chars": 5300}], "readme": "**Welcome to Influut.js!**\n\nThis is the demopage of Influut.js. A Javascript Framework by @brechtknecht. It gives you the easy ability to add cool color transition effects to your websites or projects.\n\n*How to install Influut.js*\nYou just add Influut.js above your body-closing tag and you're ready to go. There are two possible ways. I recommend you the remote implementation, so you'll keep up to date. Influut.js requires the newest Version of jQuery.\n        <script src=\"https://cdn.rawgit.com/brechtknecht/influut.js/master/js/index.js\u201c></script>\nAlternatively you can download Influut.js from the repository and import it by yourself.\n        <script src=\"js/influut.js\u201c></script>\n        \nHow to use Influut.js\n\nJust add the inf class to your divs to trigger Influut. Then add one Influut class for the color transition method. After that add your color as hex and you're done! \n<div class=\u201einf incoming #2d2d2d\u201c></div>\n\nInfluut Classes\n- incoming     \n- middle     *IN DEVELOPMENT*\n- outcoming  *IN DEVELOPMENT*\n\nSupport or Contact\nHaving trouble with Influut.js? Message me on my GitHub page or add an issue</a> to the issue section of Influut.js"}
{"url": "https://github.com/brechtknecht/komet", "owner": "brechtknecht", "repository_name": "komet", "date_all_variable_collection": "2023-09-11", "description": null, "size": 67764, "stargazers_count": 0, "watchers_count": 0, "language": "CSS", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "CSS", "num_chars": 129993}, {"language": "JavaScript", "num_chars": 35484}, {"language": "HTML", "num_chars": 9758}, {"language": "Ruby", "num_chars": 377}], "readme": "![Electron tutorial app](http://www.christianengvall.se/wp-content/uploads/2017/08/Electron-tutorial-app-github.png \"Electron tutorial app\")\n# Electron tutorial app\nAn electron application for tutorials\n\n## Installation\nThis post contains [installation instructions](https://www.christianengvall.se/install-electron-tutorial-app/ \"Install electron tutorial app\")\n\n## Tutorials\n\n| # | Topic | Description |\n|---|:------|-------------|\n| 01 | [Hello world tutorial](http://www.christianengvall.se/electron-hello-world/) | Get electron running on your computer|\n| 02 | [Testing electron app on Ubuntu](http://www.christianengvall.se/testing-electron-app-on-ubuntu-linux/) | Set up a VirtualBox virtual machine running Ubuntu and share app |\n| 03 | [Electron app navigation](http://www.christianengvall.se/electron-app-navigation/) | Add a left menu and make it load new sections |\n| 04 | [Electron frameless window](http://www.christianengvall.se/electron-frameless-window/) | A frameless window is a window that has no chrome, the parts of the window, like toolbars, that are not a part of the web page |\n| 05 | [Electron white screen app startup](http://www.christianengvall.se/electron-white-screen-app-startup/) | This post will cover how to fix the electron white screen app startup |\n| 06 | [Electron app icons](http://www.christianengvall.se/electron-app-icons/) | Adding icons to the app |\n| 07 | [Electron packager tutorial](http://www.christianengvall.se/electron-packager-tutorial/) | Creating packages for mac, windows and linux |\n| 08 | [Electron menu](http://www.christianengvall.se/electron-menu/) | Adding a main menu to your Electron app |\n| 09 | [Electron localization](http://www.christianengvall.se/electron-localization/) | Translating an Electron app |\n| 10 | [Main process and Renderer process in Electron](http://www.christianengvall.se/main-and-renderer-process-in-electron/) | A simple explanation |\n| 11 | [IPCMain and IPCRenderer](http://www.christianengvall.se/ipcmain-and-ipcrenderer/) | Communicating between main and renderer process |\n| 12 | [Electron asar](http://www.christianengvall.se/electron-asar/) | Packaging the app with asar |\n| 13 | [DMG Installer](http://www.christianengvall.se/dmg-installer-electron-app/) | Creating a DMG-installer for macOS |\n| 14 | [Windows installer](http://www.christianengvall.se/electron-windows-installer/) | Creating a windows installer with electron-winstaller |\n"}
{"url": "https://github.com/brechtknecht/Minutemen", "owner": "brechtknecht", "repository_name": "Minutemen", "date_all_variable_collection": "2023-09-11", "description": "A Flutter testapp", "size": 71, "stargazers_count": 0, "watchers_count": 0, "language": "Dart", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "brechtknecht", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Dart", "num_chars": 16992}, {"language": "Ruby", "num_chars": 3437}, {"language": "Objective-C", "num_chars": 503}, {"language": "Swift", "num_chars": 494}, {"language": "Kotlin", "num_chars": 413}], "readme": "# minutemen\n\nA new Flutter project.\n\n## Getting Started\n\nThis project is a starting point for a Flutter application.\n\nA few resources to get you started if this is your first Flutter project:\n\n- [Lab: Write your first Flutter app](https://flutter.dev/docs/get-started/codelab)\n- [Cookbook: Useful Flutter samples](https://flutter.dev/docs/cookbook)\n\nFor help getting started with Flutter, view our\n[online documentation](https://flutter.dev/docs), which offers tutorials,\nsamples, guidance on mobile development, and a full API reference.\n"}
{"url": "https://github.com/brechtknecht/purple-fox-tokens", "owner": "brechtknecht", "repository_name": "purple-fox-tokens", "date_all_variable_collection": "2023-09-11", "description": null, "size": 41, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "brechtknecht", "contributions": 13}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "### Design Tokens"}
{"url": "https://github.com/brechtknecht/python-pdf-rotate-n-print", "owner": "brechtknecht", "repository_name": "python-pdf-rotate-n-print", "date_all_variable_collection": "2023-09-11", "description": "A tiny python script, that will take single pages and rotates every odd page and exports everything on one sheet", "size": 6009, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "brechtknecht", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 982}], "readme": "# Python PDF Rotate'n'Print\nA tiny python script, that will take single pages and rotates every odd page and exports everything on one sheet\n\n`python setup.py`\n\nPlease Note that this script is tested on Mac Native Python (ver. 2.7)\n"}
{"url": "https://github.com/brechtknecht/Radeberger-Wichtel", "owner": "brechtknecht", "repository_name": "Radeberger-Wichtel", "date_all_variable_collection": "2023-09-11", "description": null, "size": 52423, "stargazers_count": 0, "watchers_count": 0, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "brechtknecht", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 518386}, {"language": "HTML", "num_chars": 407282}, {"language": "JavaScript", "num_chars": 121887}, {"language": "CSS", "num_chars": 44522}, {"language": "ApacheConf", "num_chars": 969}]}
{"url": "https://github.com/brechtknecht/REST-API-Passphrase-Authentication", "owner": "brechtknecht", "repository_name": "REST-API-Passphrase-Authentication", "date_all_variable_collection": "2023-09-11", "description": "This small API can generate Passphrases for Users to authenticate and get/update data from a JSON database via secure JWT webtokens.", "size": 29, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "brechtknecht", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 3555}], "readme": "# REST-API-Passphrase-Authentication\nThis small API can generate Passphrases for Users to authenticate and get/update data from a JSON database.\n"}
{"url": "https://github.com/brechtknecht/sollteicheinbiertrinkenApp", "owner": "brechtknecht", "repository_name": "sollteicheinbiertrinkenApp", "date_all_variable_collection": "2023-09-11", "description": null, "size": 10166, "stargazers_count": 0, "watchers_count": 0, "language": "Objective-C", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "brechtknecht", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Objective-C", "num_chars": 18169}, {"language": "Swift", "num_chars": 1830}]}
{"url": "https://github.com/brechtknecht/starter-kit-webpack-babel-liveserver", "owner": "brechtknecht", "repository_name": "starter-kit-webpack-babel-liveserver", "date_all_variable_collection": "2023-09-11", "description": "A starter Kit wich features ES6 with Babel and Webpack powered by an automaitc refreshing dev-server", "size": 9073, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 3026}, {"language": "HTML", "num_chars": 180}]}
{"url": "https://github.com/brechtknecht/SwiftUI-Tasker-Database-Demo", "owner": "brechtknecht", "repository_name": "SwiftUI-Tasker-Database-Demo", "date_all_variable_collection": "2023-09-11", "description": "Demo Application for Realm Databases for a class called \u00bbNeue Softwaregestaltung+\u00ab at Fachhochschule Potsdam", "size": 24, "stargazers_count": 2, "watchers_count": 2, "language": "Swift", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "main", "contributors": [{"contributor": "brechtknecht", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Swift", "num_chars": 7595}]}
{"url": "https://github.com/brechtknecht/SwiftUI.Cru", "owner": "brechtknecht", "repository_name": "SwiftUI.Cru", "date_all_variable_collection": "2023-09-11", "description": "A prototype for a digital planning tool for musicians. Built with SwiftUI.", "size": 10378, "stargazers_count": 1, "watchers_count": 1, "language": "Swift", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 7, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 7, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "brechtknecht", "contributions": 145}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Swift", "num_chars": 221478}]}
{"url": "https://github.com/brechtknecht/throw.sketchplugin", "owner": "brechtknecht", "repository_name": "throw.sketchplugin", "date_all_variable_collection": "2023-09-11", "description": "An open-souce alternative to confetti.sketchplugin \u2604\ufe0f", "size": 453, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 14, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 14, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "brechtknecht", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 8178}, {"language": "CSS", "num_chars": 1853}, {"language": "HTML", "num_chars": 1652}], "readme": "# confetti-boy\n\n## Installation\n\n- [Download](../../releases/latest/download/confetti-boy.sketchplugin.zip) the latest release of the plugin\n- Un-zip\n- Double-click on confetti-boy.sketchplugin\n\n## Development Guide\n\n_This plugin was created using `skpm`. For a detailed explanation on how things work, checkout the [skpm Readme](https://github.com/skpm/skpm/blob/master/README.md)._\n\n### Usage\n\nInstall the dependencies\n\n```bash\nnpm install\n```\n\nOnce the installation is done, you can run some commands inside the project folder:\n\n```bash\nnpm run build\n```\n\nTo watch for changes:\n\n```bash\nnpm run watch\n```\n\n### Custom Configuration\n\n#### Babel\n\nTo customize Babel, you have two options:\n\n- You may create a [`.babelrc`](https://babeljs.io/docs/usage/babelrc) file in your project's root directory. Any settings you define here will overwrite matching config-keys within skpm preset. For example, if you pass a \"presets\" object, it will replace & reset all Babel presets that skpm defaults to.\n\n- If you'd like to modify or add to the existing Babel config, you must use a `webpack.skpm.config.js` file. Visit the [Webpack](#webpack) section for more info.\n\n#### Webpack\n\nTo customize webpack create `webpack.skpm.config.js` file which exports function that will change webpack's config.\n\n```js\n/**\n * Function that mutates original webpack config.\n * Supports asynchronous changes when promise is returned.\n *\n * @param {object} config - original webpack config.\n * @param {object} entry - entry property from webpack config\n * @param {boolean} entry.isPluginCommand - whether the config is for a plugin command or a resource\n **/\nmodule.exports = function(config, entry) {\n  /** you can change config here **/\n};\n```\n\nTo use the polyfills or the mocks for certain Node.js globals and modules use the `node` property.\n\nVisit [the official documention](https://webpack.js.org/configuration/node/) for available options.\n\n```js\nif(entry.isPluginCommand ){\n  config.node = {\n    setImmediate: false\n  }\n} else {\n  config.node = false;\n}\n```\n\n### Debugging\n\nTo view the output of your `console.log`, you have a few different options:\n\n- Use the [`sketch-dev-tools`](https://github.com/skpm/sketch-dev-tools)\n- Open `Console.app` and look for the sketch logs\n- Look at the `~/Library/Logs/com.bohemiancoding.sketch3/Plugin Output.log` file\n\nSkpm provides a convenient way to do the latter:\n\n```bash\nskpm log\n```\n\nThe `-f` option causes `skpm log` to not stop when the end of logs is reached, but rather to wait for additional data to be appended to the input\n\n### Publishing your plugin\n\n```bash\nskpm publish <bump>\n```\n\n(where `bump` can be `patch`, `minor` or `major`)\n\n`skpm publish` will create a new release on your GitHub repository and create an appcast file in order for Sketch users to be notified of the update.\n\nYou will need to specify a `repository` in the `package.json`:\n\n```diff\n...\n+ \"repository\" : {\n+   \"type\": \"git\",\n+   \"url\": \"git+https://github.com/ORG/NAME.git\"\n+  }\n...\n```\n"}
{"url": "https://github.com/brechtknecht/umbrella", "owner": "brechtknecht", "repository_name": "umbrella", "date_all_variable_collection": "2023-09-11", "description": "Weather app wich recommends you the perfect clothing", "size": 5499, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "brechtknecht", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 156364}, {"language": "HTML", "num_chars": 30570}, {"language": "CSS", "num_chars": 24510}, {"language": "Java", "num_chars": 19961}, {"language": "Objective-C", "num_chars": 17105}, {"language": "C++", "num_chars": 5727}, {"language": "Batchfile", "num_chars": 3033}, {"language": "C#", "num_chars": 1116}], "readme": "# umbrella\nWeather app wich recommends you the perfect clothing\n"}
{"url": "https://github.com/brechtknecht/Waste-the-Planet-Survey", "owner": "brechtknecht", "repository_name": "Waste-the-Planet-Survey", "date_all_variable_collection": "2023-09-11", "description": "Eine Interaktive Informationsvisualisierung zum Thema \u00bbM\u00fcll & M\u00fcll im Meer\u00ab. Aus dem Kurs \u00bbStorytelling with Data\u00ab an der Fachhochschule Potsdam", "size": 12328, "stargazers_count": 0, "watchers_count": 0, "language": "Vue", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "brechtknecht", "contributions": 32}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Vue", "num_chars": 376487}, {"language": "JavaScript", "num_chars": 8891}, {"language": "HTML", "num_chars": 571}], "readme": "# Waste the planet survey\n\n## Project setup\n```\nnpm install\n```\n\n### Compiles and hot-reloads for development\n```\nnpm run serve\n```\n\n### Compiles and minifies for production\n```\nnpm run build\n```\n\n### Run your tests\n```\nnpm run test\n```\n\n### Lints and fixes files\n```\nnpm run lint\n```\n"}
{"url": "https://github.com/briemadu/codraw-icr-v1", "owner": "briemadu", "repository_name": "codraw-icr-v1", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1368, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "briemadu", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 2047319}, {"language": "Python", "num_chars": 164281}, {"language": "Shell", "num_chars": 925}], "readme": "# Instruction Clarification Requests in the CoDraw Dataset\n\nThis is the code repository accompanying the following publication:\n\n- Instruction Clarification Requests in Multimodal Collaborative Dialogue Games: Tasks, and an Analysis of the CoDraw Dataset. (Madureira, B. & Schlangen, D., EACL 2023).\n\nWe implement neural network baseline models to indentify when an iCR should be made and when it has been made in the CoDraw dialogue game.\n\n\n## Description\n\nThe directories are:\n\n- ```checkpoints/```: contains the trained model checkpoints at the best validation epoch.\n- ```codrawmodels/```: contains one script from the CoDraw authors with minor adaptations to make it work in our setting.\n- ```data/```: is where all downloaded data should live, and it also contains the scripts to preprocess the data and generate the incremental images and the embeddings.\n- ```env/```: contains the files to reconstruct the conda environment (see below).\n- ```icr/```: code of our implementation.\n- ```notebooks/```: juypter notebooks used for corpus analysis, trivial baselines and evaluation.\n- ```outputs/```: the generated outputs of the experiments.\n\n\n## Dependencies\n\nThe directory ```env/``` contains the files that can be used to recreate the conda environment. Running\n\n```bash\nsh create_env.sh\n```\n\nshould create it by calling the same installations one by one as we did. In case is does not work, this directory also contain the .yml files and a spec file auto-generated by comet.ml.\n\n\n## Data\n\nCheck data/README.md for the details on how to download the necessary datasets. Our annotation is available at OSF: [https://osf.io/gcjhz/](https://osf.io/gcjhz/). You can download it manually or clone via the [osfclient](https://github.com/osfclient/osfclient).\n\n\n## Replicating the results\n\nAfter setting up the data directory, you can replicate the results by regenerating the pretrained embeddings and then calling the ```experiments``` script. ```search.py``` was used for hyperparameter search.\n\n```bash\nconda activate codraw_pl\nsh setup.sh\nsh experiments.sh\n```\n\n## General usage\n\n```main.py``` can be used to run other experiments. It accepts different hyperparameters via the CLI. Check the arguments in ```icr/config.py``` for details.\n\n```bash\npython3 main.py\n```\n\n## Testing\n\nTo run unit tests, run:\n\n```bash\npython3 -m unittest discover -v\n```\n\n\n## Credits\n\nWe thank Philipp Sadler for generating the step-by-step CoDraw scenes. The code under data/IncrementalCoDrawImages is his work.\n\nWe thank the developers of all the open libraries we use (Pytorch, Pytorch Lightning, h5py, comet.ml, torchmetrics, pandas, matplotlib, scikit-learn, scipy, seaborn, sentence-transformers, wordcloud).\n\nThis work is based on the CoDraw dataset and AbstractScenes (see Data section above).\n\n## License\n\nOur source code is licensed under the MIT License.\n\n\n## Citation\n\nIf you use our work, please cite:\n\n```\n@inproceedings{madureira-schlangen-2023-instruction,\n    title = \"Instruction Clarification Requests in Multimodal Collaborative Dialogue Games: Tasks, and an Analysis of the {C}o{D}raw Dataset\",\n    author = \"Madureira, Brielen  and\n      Schlangen, David\",\n    booktitle = \"Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics\",\n    month = may,\n    year = \"2023\",\n    address = \"Dubrovnik, Croatia\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2023.eacl-main.169\",\n    pages = \"2303--2319\",\n}\n```\n"}
{"url": "https://github.com/briemadu/evalNLP", "owner": "briemadu", "repository_name": "evalNLP", "date_all_variable_collection": "2023-09-11", "description": "University of Potsdam", "size": 24, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "briemadu", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 2236}, {"language": "SCSS", "num_chars": 478}], "readme": "Webpage of the seminar: Evaluation of NLP Systems\n\nB.Sc. Computational Linguistics / Linguistics\n\nWinter Semester 20/21, Aufbaumodule (Methoden der Computerlinguistik)\n"}
{"url": "https://github.com/briemadu/evalNLP-22", "owner": "briemadu", "repository_name": "evalNLP-22", "date_all_variable_collection": "2023-09-11", "description": null, "size": 29, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "briemadu", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 2251}, {"language": "SCSS", "num_chars": 478}], "readme": "Webpage of the seminar: Evaluation of NLP Systems\n\nB.Sc. Computational Linguistics / Linguistics\n\nWinter Semester 22/23, Aufbaumodule (Methoden der Computerlinguistik)\n"}
{"url": "https://github.com/briemadu/inc-bidirectional", "owner": "briemadu", "repository_name": "inc-bidirectional", "date_all_variable_collection": "2023-09-11", "description": null, "size": 44, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "briemadu", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 94907}], "readme": "# README #\n\nCode used for running experiments in the research paper:\n\nMADUREIRA, Brielen & SCHLANGEN, David. Incremental Processing in the Age of Non-Incremental Encoders: An Empirical Assessment of Bidirectional Models for Incremental NLU. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing.\n\nCheck the pdf in this repository.\n\n# Warnings\n- [May 5, 2022] The Edit Overhead metric with delay is being incorrectly computed in the code. We will update a correction soon.\n- [Aug 26, 2022] It has been fixed in the code. The numbers change minimally. A revision will come soon, but the conclusions remain unchanged.\n- Known bug: the model's weight initialization seems to be overwriting the pretrained GloVe embeddings.\n\n### What is this repository for? ###\n\nWe can use this code to train a neural encoder and use it either for sequence tagging or sequence classification with 10 task/dataset combinations. After training, it retrieves the incrementality evaluation metrics in the test set. Two special configurations may be added: truncated training (we sample a length to use only a prefix of each sentence during training) and prophecies (we use GPT-2 language model to generate 'prophecies' for each prefix of the sequence, and feed this hypothetical continuation to the encoder during the estimation of incrementality metrics).\n\n\n### How do I get set up? ###\n\n## Set up\n\nSpecific Python installations:\n\n* [PyTorch](https://pytorch.org/) (v. 1.3.1)\n* [pytorch-crf](https://pypi.org/project/pytorch-crf/) (v. 0.7.2) to add a CRF layer on top of our neural network\n* [seqeval](https://pypi.org/project/seqeval/) (v. 0.0.12) to estimate F1 score in BIO labeling scheme\n* [transformers](https://github.com/huggingface/transformers) (v. 2.5.1) to generate prophecies and use BERT model\n* [nltk](https://www.nltk.org/) (v. 3.4.5) for tokenization of generated prophecies\n* [comet_ml](https://www.comet.ml/docs/quick-start/) if you want to log information of your experiment (optional)\n\nIf you want to use comet_ml, first include your api_key, project name and workspace on line 76 in main.py.\n\nDownload GloVe pre-trained embeddings [here](http://nlp.stanford.edu/data/glove.6B.zip) and unzip it in the main folder (replacing the currently empty glove.6B folder here).\n\n\n# Download data\n\n* [CoNLL 2000](https://www.clips.uantwerpen.be/conll2000/chunking/)\n* [OntoNotes 5.0](https://catalog.ldc.upenn.edu/LDC2013T19)\n* [ATIS](https://www.aclweb.org/anthology/H90-1021.pdf)\n* [SNIPS](https://github.com/sonos/nlu-benchmark)\n* [Pros/Cons](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html#datasets)\n* [Positive/Negative](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences)\n\nFor ATIS and SNIPS, we use the preprocessed data made available by [E et al. (2019)](https://github.com/ZephyrChenzf/SF-ID-Network-For-NLU).\n\nPreprocessing is needed to put them in the following format:\n\n* Sequence tagging:\n> token \\t label \\n token \\t label \\n\nwith an extra \\n between sequences.\n\n* Sequence classification:\n> <LABEL>: atis_airfare \\n token \\n token \\n\nwith an extra \\n between sequences.\n\nSee examples in the data directory.\n\n# Prepare data\n\nAs it is, the code can run experiments on:\n\n* Sequence tagging\n    * chunk, CoNLL 2000 (chunk)\n    * named entity recognition, OntoNotes5.0, WSJ part (ner_nw_wsj)\n    * pos tagging, OntoNotes5.0, WSJ part (pos_nw_wsj)\n    * semantic role labeling, OntoNotes5.0, WSJ part (srl_nw_wsj)\n    * slot filling, ATIS or SNIPS (atis_slot, snips_slot)\n* Sequence classification\n    * Sentiment (proscons or sent_negpos)\n    * intent , ATIS or SNIPS (atis_intent, snips_intent)\n\nIf you have a new file, include the name in lines 65-69 in main.py, to specify whether it is a tagging or classification task and which evaluation function should the system use during training.\n\nData has to be split into three files (data/train/train.<task>, data/valid/valid.<task> and data/test/test.<task>), where <task> is one of the names in parenthesis above. All of them must follow the format above.\n\n## How to run tests\n\n> python3.py main.py\n\nUse `--help` to check all possible arguments.\n>  --task TASK           type of task: snips_slot snips_intent, atis_slot, atis_intent, chunk, proscons, srl_nw_wsj, pos_nw_wsj, ner_nw_wsj, sent_negpos\n\n>  --only_training       train model only, no incrementality evaluation\n\n>  --comet_track         log data to comet.ml\n\n>  --truncated_training  sample truncated inputs during training\n\n>  --device DEVICE       choose a specific device\n\n>  --outliers OUTLIERS   len above which sentences are ignored\n\n>  --model MODEL         type of LSTM: vanilla_lstm, vanilla_bilstm, lstm_crf, bilstm_crf, bert-base-{cased, uncased}\n\n>  --dim_emb DIM_EMB     dimenstion of word embeddings\n\n>  --dim_hid DIM_HID     dimension of hidden layer\n\n>  --nlayers NLAYERS     number of lstm layers\n\n>  --epochs EPOCHS       training iterations over dataset\n\n>  --batch_size BATCH_SIZE batch size\n\n>  --lr LR               initial learning rate\n\n>  --clip CLIP           size of gradient for clipping, 0 for no clipping\n\n>  --dropout DROPOUT     dropout probability\n\n>  --no_glove            do not use GloVe embeddings\n\n>  --freeze              do not update GloVe embeddings during training\n\n### Citing this paper ###\n\n```\n@inproceedings{madureira-schlangen-2020-incremental,\n    title = \"Incremental Processing in the Age of Non-Incremental Encoders: An Empirical Assessment of Bidirectional Models for Incremental {NLU}\",\n    author = \"Madureira, Brielen  and\n      Schlangen, David\",\n    booktitle = \"Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)\",\n    month = nov,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2020.emnlp-main.26\",\n    doi = \"10.18653/v1/2020.emnlp-main.26\",\n    pages = \"357--374\",\n}   \n```\n"}
{"url": "https://github.com/briemadu/inc-eval-revisions", "owner": "briemadu", "repository_name": "inc-eval-revisions", "date_all_variable_collection": "2023-09-11", "description": "Framework for evaluation of edits and revisions in incremental sequence labelling.", "size": 1293, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "briemadu", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 1866271}, {"language": "Python", "num_chars": 91379}, {"language": "Shell", "num_chars": 242}], "readme": "# A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling\n\nCode to accompany the manuscript: The Road to Quality is Paved with Good \nRevisions: A Detailed Evaluation Methodology for Revision Policies in \nIncremental Sequence Labelling (Brielen Madureira, Patrick Kahardipraja and \nDavid Schlangen, SIGdial 2023).\n\n## Files\n\n- ```setup.sh```: A bash script that create the conda environment and the needed empty directories.\n- ```inceval/aux.py```: Defines the symbol used to fill the unused upper part \nof the incremental charts, which are represented as numpy arrays. Defines enum\nvariables for the silver and gold standard.\n- ```inceval/edit.py```: Classes that represent edits.\n- ```inceval/revision.py```: Classes that represent revisions.\n- ```incoutputs.py```: Class to represent an incremental chart. Contains all\nthe main metrics on sequence level.\n- ```incdataset.py```: Class to represent a dataset of incremental charts.\nContains all the main metrics on dataset level.\n- ```example.ipynb```: A Notebook with a demonstration of how to use the framework.\n- ```analysis-tapir.ipynb```: The notebook used to generate results in the paper.\n- ```characterisation.ipynb```: A notebook with more examples for each category.\n\n## Set Up\n\nCreate the conda environment. Either run ```sh setup.sh``` for the exact steps \nof create via conda using ```conda env create -f environment.yml```. \n```sh setup.sh``` also creates one directory for the preprocessed data and one \nfor the output figures. Put the incremental outputs into ```preprocessed/```.\n\n## Replicating results\n\nThe plots and table in the paper have been generated using \n```analysis-tapir.ipynb```.\n\n## Evaluating other models\nThe scripts in ```inceval``` implement all the metrics and characteristics \ndescribed in the paper. See ```example.ipynb```` for a short demonstration of \nthe main functionalities.\n\n### Structures\n\nThe class ```IncOutputs``` represents the incremental chart of a sequence. It\ncan be used to compute metrics on sequence level, whereas ```IncData``` gets\na dictionary of ```IncOutputs``` and computed metrics on dataset level.\n\nWhen ```IncOutputs``` is initialised, the used can define whether to use the\nreal 'true' labels or the final labels as gold standard (GOLD and SILVER enum\narguments, respectively). For models that perform revisions via recomputations,\nthe sequence of recomputation steps can also be passed as an argument, so that\nadditional metrics can be computed. It builds and makes accessible various\nattributes: \n\n- ```chart```: a lower triangular matrix containing all the output prefixes\n- ```edits```: a lower triangular matrix containing 1 when an edit occurred\n- ```edit_qualities```: a lower triangular matrix containing all the charactesised\n- ```revision_qualities```: a sequence containing all the characterised revisions\n\n\nThey rely on the following objects:\n\n- ```EditQualities```: a dataclass representing all the attributes of an edit.\n- ```EditQualityChart```: a class representing the whole sequence of edits.\n```self.chart``` contains a lower triangular matrix, filled with Nones or with\nan ```EditQualities``` object in cells that represent edited labels.\n- ```Revisionualities```: a dataclass representing all the attributes of a\nrevision.\n\n\n### Usage\n\n1. Build the incremental chart of a sequence represented with the \n```IncOutputs``` class. You can feed the full chart at once or incrementaly,\none prefix at a time.\n\n2. Compute metrics on sequence level. Use the methods in ```IncOutputs```.\n\n3. Compute metrics on dataset level. Create a dictionary that maps sequence\nIDs to its IncOutputs object. This can be used ot initialise ```IncData```,\nwhich allows dataset level metrics to be computed.\n\nThe notebook ```example.ipynb``` has a demonstration.\n\n## Design decisions\n\n- the first write is counted as occurring always upon a correct (empty) prefix\n- the revision metrics are ```np.nan``` when no revision/addition occurred\n- the recomputation metrics are ```np.nan``` when no recomputation is passed \nas an argument\n\n## Testing\n\n```bash\npython -m unittest discover .\n```\n\n## TODOs\n\n- implement corretion time score and correction time per token\n- write unittests for a few extra methods not used in the paper and for incdata\n\n## License\n\nThis code is licensed under the MIT License (see the ```LICENSE``` file).\n\n## Citation\n\nTBA\n"}
{"url": "https://github.com/briemadu/mathLM", "owner": "briemadu", "repository_name": "mathLM", "date_all_variable_collection": "2023-09-11", "description": null, "size": 28, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "briemadu", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 2223}, {"language": "SCSS", "num_chars": 478}], "readme": "Webpage of the seminar: Mathematical Foundations of Language Modeling\n\nB.Sc. Computational Linguistics / Linguistics\n\nWinter Semester 21/22, Aufbaumodule (Methoden der Computerlinguistik)\n"}
{"url": "https://github.com/briemadu/rl4nlp", "owner": "briemadu", "repository_name": "rl4nlp", "date_all_variable_collection": "2023-09-11", "description": "Universit\u00e4t Potsdam", "size": 227, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "briemadu", "contributions": 119}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 2231}, {"language": "CSS", "num_chars": 478}], "readme": "Webpage of the seminar: Reinforcement Learning for Natural Language Processing\n\nM.Sc. Cognitive Systems \n\nSummer semester 2020, Advanced Module\n"}
{"url": "https://github.com/briemadu/science-and-research", "owner": "briemadu", "repository_name": "science-and-research", "date_all_variable_collection": "2023-09-11", "description": null, "size": 32, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "briemadu", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 2301}, {"language": "SCSS", "num_chars": 478}], "readme": "Webpage of the seminar: Doing Science and Conducting Research\n\nM.Sc. Cognitive Systems\n\nSummer semester 2021, Advanced Module\n"}
{"url": "https://github.com/briemadu/scorekeeping", "owner": "briemadu", "repository_name": "scorekeeping", "date_all_variable_collection": "2023-09-11", "description": null, "size": 2532, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "briemadu", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 4409578}, {"language": "Python", "num_chars": 242807}, {"language": "Shell", "num_chars": 8047}], "readme": "# README\n\nThis is the accompanying repository of the following publication:\n\nMadureira & Schlangen (2022). Can Visual Dialogue Models do Scorekeeping? \nExploring how Dialogue Representations Incrementally Encode Shared Knowledge. \nShort paper presented at ACL 2022 in Dublin, Ireland.\n\n## Erratum ##\n\nThe axis labels are swapped in Table 3 (and the corresponding figures in the Jupyter notebook).\n\n\n## What is this repository for?\n\nThe paper proposes an evaluation method to assess how visual dialogue models \nkeep track of information about an image that is private/shared at a given \nturn. It implements a probing classifier based on a neural network whose \ninput is a proposition embedding and a dialogue state representations and the \noutput is a probability over classes (private or shared, believed to be true \nor false by the answerer).\n\n## Details of each directory\n\nThe set up involves three main steps, each depending on one of the three\nsubdirectories here:\n\n1. ```generating_propositions/```: turn VisDial QA pairs into propositions and\nget their embeddings.\n2. ```retrieving_dialogue_representations/```: extract the dialogue state \nrepresentations of the original visual dialogue encoders.\n3. ```main_task/```: run experiments with the probing classifier.\n\n## How do I get set up?\n\nDue to the different dependencies we used different Python environments for\neach part. You can re-create the environments with conda using the ```yml````\nfiles: \n\n- ```python_envs/environmentcoref.yml```: to replace pronouns on VisDial.\n- ```python_envs/environment.yml```: to generate propositions.\n- ```python_envs/main_task_environment.ym```: to get proposition embeddings \nand run the main experiments.\n\nTo retrieve dialogue representations, follow the instructions on the original\nrepository to build the environment.\n\n## How do I replicate the results on the paper?\n\n1. Follow the instructions on ```retrieving_dialogue_representations```.\n2. Follow the instruction on ```generating_propositions```.\n3. Follow the instructions on ```main_task```.\n\n\nThis version of the code was used for the final version submitted on\nMarch 30, after fixing a problem with the extraction of the \ndialogue representations. \n\n## Citation\n\nIf you use this work, please cite: \n\n```\n@inproceedings{madureira-schlangen-2022-visual,\n    title = \"Can Visual Dialogue Models Do Scorekeeping? Exploring How Dialogue Representations Incrementally Encode Shared Knowledge\",\n    author = \"Madureira, Brielen  and\n      Schlangen, David\",\n    booktitle = \"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)\",\n    month = may,\n    year = \"2022\",\n    address = \"Dublin, Ireland\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2022.acl-short.73\",\n    doi = \"10.18653/v1/2022.acl-short.73\",\n    pages = \"651--664\",\n}\n\n```\n\n## License\n\nThis work is licensed mainly under two licences:\n\n- Code deriving from Murahari et al. (2019) is licensed under BSD.\n- Other source code is licensed under MIT.\n\nWe use many Python libraries. See credits on each repository for details.\n"}
{"url": "https://github.com/CaptainUnbrauchbar/asp-assignments", "owner": "CaptainUnbrauchbar", "repository_name": "asp-assignments", "date_all_variable_collection": "2023-09-11", "description": null, "size": 2091, "stargazers_count": 1, "watchers_count": 1, "language": "Prolog", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "CaptainUnbrauchbar", "contributions": 23}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Prolog", "num_chars": 3750}, {"language": "Python", "num_chars": 3345}], "readme": "# ASP-Assignments (Answer Set Programming)\n\nAssignments from Computational Intelligence Course\n\nGet my VSCode Extension to run .lp files directly in the editor: \n\n| [Extension](https://marketplace.visualstudio.com/items?itemName=ffrankreiter.answer-set-programming-language-support) | [Potassco](https://potassco.org/) | [Clingo](https://potassco.org/clingo/) |\n"}
{"url": "https://github.com/CaptainUnbrauchbar/asp-language-support", "owner": "CaptainUnbrauchbar", "repository_name": "asp-language-support", "date_all_variable_collection": "2023-09-11", "description": null, "size": 5912, "stargazers_count": 7, "watchers_count": 7, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 7, "default_branch": "master", "contributors": [{"contributor": "CaptainUnbrauchbar", "contributions": 22}, {"contributor": "richilino", "contributions": 5}, {"contributor": "sjkillen", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 11011}], "readme": "# Answer Set Programming Language Support (for Clingo)\n\n | [Potassco](https://potassco.org/) | [Potassco on Github](https://github.com/potassco) | [Clingo](https://potassco.org/clingo/) | \n\n## Features\n\nThis Extension uses Clingo Answer Set Solver (bundled), developed by Potassco (University of Potsdam).\nWe added multi-file support with v0.4.0!\n\nIf you have any suggestions for a new feature or anything else please E-Mail me: frankreiter@uni-potsdam.de\n\n## Usage\n\nJust right click anywhere on a logic program (.lp) file and select `> Compute all Answer Sets` or `> Compute the first Answer Set`.\nA new Terminal will open with the results!\n\nIf you want to add **additional startup arguments** you can use the `> Compute Answer Sets (config.json)` option.\n\nFirst generate a **sample config.json** file with the `ASPLanguage: Initialize clingo config file in current working directory` command *(Press Ctrl+Shift+P)*. \n\nThis will create a config file with all supported arguments/settings in your current working directory. \nIf you want to use your **own config file**, just change the config file name in the extension settings.\nAdditionally you can use **arguments not directly supported** by the config.json by passing them in the **\"customArgs\" setting** as a String.\n\nYou can also specify **additional files** to interpret in this config using the relative path from the current working directory.\n\nSee the Clingo [Documentation](https://github.com/potassco/guide/releases/download/v2.2.0/guide.pdf) for more details on the config settings!\n\nIf you want to use your own Version of Clingo from PATH with this extension, please enable **\"Use PATH Clingo\"** option in settings!\n\n## Requirements\n\nFor the extension to work properly, please install the Answer Set Programming syntax highlighter by abelcour (abelcour.asp-syntax-highlight)\n\n[Answer Set Syntax Highlighter](https://marketplace.visualstudio.com/items?itemName=abelcour.asp-syntax-highlight)\n\n## Extension Settings\n\nThis extension contributes the following settings:\n\n- `ASPLanguage: Select Operating System`: Select your Operating System, so the currect clingo version is used! (default: Auto)\n- `ASPLanguage: Terminal Mode`: Select if you want a new Terminal after every execution! (default: False)\n- `ASPLanguage: Use PATH Clingo`: Set this option if you would like to use the Clingo version from your PATH instead of the version included! (default: False)\n- `ASPLanguage: Turn Messages Off`: Set this option if you want to turn off all Messages (bottom right)! (default: False)\n- `ASPLanguage: Set Config`: Set a .json file if you want to use a specific config file for clingo (default: empty)\n\n## Extension Features\n\nThis extension contributes the following features:\n\n- `> Compute all Answer Sets`: Get all answer sets for the current logic program file!\n- `> Compute the first Answer Set`: Get the first answer set for the current logic program file!\n- `> Compute Answer Sets (config.json)`: Compute answer sets using the clingo configuration from a config file\n\n## 0.4.0\n\n- Added Multi-File Support! (use with config file)\n- Added Option to use a configuration file for clingo arguments\n- Added VSCode command to create sample config file\n- Optimization\n- Big Thanks to Richard Hegewald ([richilino](https://github.com/richilino)) for contributing the new features and helping optimize the extension code!\n"}
{"url": "https://github.com/CaptainUnbrauchbar/assembly-projects", "owner": "CaptainUnbrauchbar", "repository_name": "assembly-projects", "date_all_variable_collection": "2023-09-11", "description": "32bit MIPS Assembly", "size": 1345, "stargazers_count": 2, "watchers_count": 2, "language": "Assembly", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "CaptainUnbrauchbar", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Assembly", "num_chars": 14776}], "readme": "# Assembler Projects\n\n32bit MIPS Assembly\n\nGet MARS [here](https://courses.missouristate.edu/KenVollmar/mars/download.htm)!\n"}
{"url": "https://github.com/CaptainUnbrauchbar/cellular-automaton", "owner": "CaptainUnbrauchbar", "repository_name": "cellular-automaton", "date_all_variable_collection": "2023-09-11", "description": "Just an experiment", "size": 40, "stargazers_count": 1, "watchers_count": 1, "language": "C", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "CaptainUnbrauchbar", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C", "num_chars": 86107}, {"language": "Julia", "num_chars": 44348}, {"language": "Makefile", "num_chars": 482}], "readme": "# Cellular Automaton\nJust an experiment\n"}
{"url": "https://github.com/CaptainUnbrauchbar/processing-stuff", "owner": "CaptainUnbrauchbar", "repository_name": "processing-stuff", "date_all_variable_collection": "2023-09-11", "description": null, "size": 5, "stargazers_count": 1, "watchers_count": 1, "language": "Processing", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "CaptainUnbrauchbar", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Processing", "num_chars": 4331}, {"language": "Python", "num_chars": 3345}], "readme": "# Processing Stuff\n\nMostly visualizers or small jokes\n"}
{"url": "https://github.com/CaptainUnbrauchbar/programming-assignments", "owner": "CaptainUnbrauchbar", "repository_name": "programming-assignments", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1866, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "CaptainUnbrauchbar", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 57467}, {"language": "Java", "num_chars": 38405}, {"language": "C", "num_chars": 14856}], "readme": "# python-assignments\n\nSome Python stuff for Uni \n"}
{"url": "https://github.com/CaptainUnbrauchbar/python-math", "owner": "CaptainUnbrauchbar", "repository_name": "python-math", "date_all_variable_collection": "2023-09-11", "description": null, "size": 40, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "CaptainUnbrauchbar", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 7074}]}
{"url": "https://github.com/CaptainUnbrauchbar/random-stuff", "owner": "CaptainUnbrauchbar", "repository_name": "random-stuff", "date_all_variable_collection": "2023-09-11", "description": null, "size": 832, "stargazers_count": 1, "watchers_count": 1, "language": "SQF", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "CaptainUnbrauchbar", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "SQF", "num_chars": 130584}, {"language": "Python", "num_chars": 11297}, {"language": "C++", "num_chars": 3381}, {"language": "Batchfile", "num_chars": 199}], "readme": "# Random Stuff\n\nJust some A3 Missions and WoT Calculators\n"}
{"url": "https://github.com/ChrisYanLuc/Fragebogen-Tabelle", "owner": "ChrisYanLuc", "repository_name": "Fragebogen-Tabelle", "date_all_variable_collection": "2023-09-11", "description": "Project for the Physics-Didaktiv Institution of the University of Potsdam", "size": 78, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "ChrisYanLuc", "contributions": 45}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 23421}, {"language": "HTML", "num_chars": 13622}, {"language": "CSS", "num_chars": 5652}, {"language": "SCSS", "num_chars": 42}]}
{"url": "https://github.com/ClemensKubach/bicycle-bell-sed-models", "owner": "ClemensKubach", "repository_name": "bicycle-bell-sed-models", "date_all_variable_collection": "2023-09-11", "description": null, "size": 2008, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": true, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "ClemensKubach", "contributions": 27}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 308064}, {"language": "Python", "num_chars": 28008}], "readme": "# Bicycle Bell Sound Event Detection Models\r\n**Author: Clemens Kubach**\r\n\r\nThis repository is one of three for my bachelor thesis on \"Development of an Embedded System \r\nfor Detecting Acoustic Alert Signals of Cyclists Using Neural Networks\".\r\n\r\nIt contains the architectures of the used neural networks to detect the sound event of cyclists using their bicycle bell. Written in Python 3.9.\r\n\r\nThe other related repositories are:\r\n- [bicycle-bell-sed-pipeline](https://github.com/ClemensKubach/bicycle-bell-sed-pipeline)\r\n- [bicycle-bell-sed-software](https://github.com/ClemensKubach/bicycle-bell-sed-software)\r\n\r\n\r\n## Usage\r\nYou can use this package with:\r\n```\r\npip install git+https://github.com/ClemensKubach/bicycle-bell-sed-models.git\r\n```\r\n\r\nIf this repository is private, use `pip install git+https://{gh_token}@github.com/ClemensKubach/bicycle-bell-sed-models.git`\r\nwhere `{gh_token}` is your personal access token to your github account with the rights to clone private repositories. You must have granted permissions to access this repository from GitHub.\r\n\r\n## Models\r\nThere are 3 model configurations...\r\n\r\n### CRNN\r\nA model based on a CRNN architecture without any pre-training. Inspired by [[1]](#1).\r\n\r\n![CRNN](src/visualizations/crnn.png)\r\n\r\n### YAMNet Base\r\nThe pre-trained YAMNet[[2]](#2)[[3]](#3) base model without any transfer learning. The resulting probability values for the class \"Bicycle bell\" is directly taken out of the results of all 521 classes and the maximum probability from the windows of the wave input file is taken.\r\n\r\n![YAMNet Base](src/visualizations/yamnet_base.png)\r\n\r\n### YAMNet Extended\r\nAn extended pre-trained YAMNet model with transfer learning using embeddings of the base model[[2]](#2)[[3]](#3). A classifier with LSTM and dense layers are followed.\r\n\r\n![YAMNet Extended](src/visualizations/yamnet_lstm_fc.png)\r\n \r\n\r\n## References\r\n<a id=\"1\">[1]</a>\r\n[Lim, H., Park, J., & Han, Y. (2017, November). Rare sound event detection using 1D convolutional recurrent neural networks. In Proceedings of the detection and classification of acoustic scenes and events 2017 workshop (pp. 80-84).](http://dcase.community/documents/challenge2017/technical_reports/DCASE2017_Lim_204.pdf)\r\n\r\n<a id=\"2\">[2]</a>\r\nhttps://tfhub.dev/google/yamnet/1\r\n\r\n<a id=\"3\">[3]</a>\r\nhttps://github.com/tensorflow/models/tree/master/research/audioset/yamnet"}
{"url": "https://github.com/ClemensKubach/bicycle-bell-sed-pipeline", "owner": "ClemensKubach", "repository_name": "bicycle-bell-sed-pipeline", "date_all_variable_collection": "2023-09-11", "description": null, "size": 761, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": true, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "ClemensKubach", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 2701583}], "readme": "# Bicycle Bell Sound Event Detection Pipeline\n**Author: Clemens Kubach**\n\nThis repository is one of three for my bachelor thesis on \"Development of an Embedded System \nfor Detecting Acoustic Alert Signals of Cyclists Using Neural Networks\".\n\nIt contains the ML-pipeline for inspecting and preparing the datasets, training the neural networks and evaluating them on hold-out data for atomatically detecting the sound event of cyclists using their bicycle bell. Written in Python 3.9.\n\nThe other related repositories are:\n- [bicycle-bell-sed-models](https://github.com/ClemensKubach/bicycle-bell-sed-models)\n- [bicycle-bell-sed-software](https://github.com/ClemensKubach/bicycle-bell-sed-software)\n\n\n## Dependencies\nThere are two types of dependencies used for this project:\n- Python package dependencies\n- Data dependencies\n\n### Python Package Dependencies\nThe pip dependencies can be installed via the `requirements.txt`. \nTo train a model, you also have to install the package from the repository [bicycle-bell-sed-models](https://github.com/ClemensKubach/bicycle-bell-sed-models.git). \nYou can install it via:\n```shell\npip install git+https://github.com/ClemensKubach/bicycle-bell-sed-models.git\n```\n\nIf it is private, you need granted permissions to this repo and use a personal access token. \nThen, the following command can be executed:\n```shell\npip install git+https://{gh_token}@github.com/ClemensKubach/bicycle-bell-sed-models.git\n```\nThis is also already in use within the notebook.\n\n\n### Data Dependencies\nThe notebook supports two types of data sources to run its cells:\n- the Google Cloud Storage (GCS) bucket and\n- the exported bucket as Zip file\n\nDuring the development GCS was used and therefore the code is mainly based on it. \nHowever, it should also be feasible without problems or with only a few adjustments locally with the data from the zip backup.\n\nTo access the GCS bucket, you have to use the .json key when asked via the notebook. A key file can be asked from the author. Thus, you have access to request data from this bucket. Alternatively, you can upload the folders in `thesis-bicycle-bell-sed-bucket` of the zip file to your own bucket.\n\nFor using the local bucket from the zip file directly without GCS:\n- unpack the zip file\n- use the folder `thesis-bicycle-bell-sed-bucket` as root folder and set `USE_GCS=False` within the notebook.\n\nUsing GCS for inspecting/reading the results, is recommended. For further development, you can use your own GCS bucket or using the local bucket via the zip.\n\n\n## Usage\n**It was extensively tested with Google Colab with use of Google Cloud Storage bucket. The models were trained on a Colab GPU instance.**\n\nThe jupyter notebook can be inspected without running on any system. \nFor executing the cells, follow the instructions given in the notebook.\n\nIn the most cases, it is not necessary and **not recommended** to simply run **all cells**, because they are generating a lot of data and traffic.\nThis is already done and the prepared files can be found in the Google Cloud Storage bucket or the backup zip file of the bucket.\nI.e., the trained models can also be found in GCS and can be loaded directly within the evaluation chapter.\n"}
{"url": "https://github.com/ClemensKubach/bicycle-bell-sed-software", "owner": "ClemensKubach", "repository_name": "bicycle-bell-sed-software", "date_all_variable_collection": "2023-09-11", "description": null, "size": 22376, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": true, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "ClemensKubach", "contributions": 53}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 101114}, {"language": "PureBasic", "num_chars": 785}], "readme": "# Bicycle Bell Sound Event Detection System\n**Author: Clemens Kubach**\n\nThis repository is one of three for my bachelor thesis on \"Development of an Embedded System \nfor Detecting Acoustic Alert Signals of Cyclists Using Neural Networks\".\n\nIt contains the software as an easy-to-use and customizable CLI for the project. \nOnly this part has to be installed on the target device and can be used and \ndeveloped independently of the other components.\n\nA trained saved model can be selected, which is then converted to an inference format \n(TFLite or TF-TRT), allowing real-time predictions to be made to a single sound event for \nlive-streamed audio via connected sound devices. \n\nThe other related repositories are:\n- [bicycle-bell-sed-models](https://github.com/ClemensKubach/bicycle-bell-sed-models)\n- [bicycle-bell-sed-pipeline](https://github.com/ClemensKubach/bicycle-bell-sed-pipeline)\n\n\n## Getting Started\nThe software is based on the [PortAudio](http://www.portaudio.com/) library for audio I/O. \nTherefore, this must be installed on the system.\nFor more detailed installation instructions on an embedded device like the \n[Jetson Nano](#Jetson-Nano-Setup), see the corresponding chapter.\n\n```shell\napt-get update\napt-get install portaudio19-dev\n\npip install --upgrade pip\npip install bicycle-bell-seds-cli\n\nseds-cli --help\nseds-cli run --tfmodel='!crnn' production\n```\n\nThere are generally 4 main functionalities that are displayed with `seds-cli --help`.\n- `conversion` can convert recordings of a pre-executed run command with appropriate \nparameterization for sound recording to a wave file.\n- `devices` can be used for testing the available devices by doing a sound check.\n- `resources` can be used for find the location of resource files like log-files or recordings.\n- `run` is the main functionality of the software. \nThis command is used to start a sound event detection.\n\n## General Information\nGenerally, two versions of the CLI are installed: `jn-seds-cli` and `seds-cli`. \nThe first one is based on the second one and only contains simplifications and specifications for \nthe execution of the bicycle bell detection on the Jetson Nano. \nWith the right choice of parameters, however, \nboth CLIs can be used on all devices without any problems. \nDetails about the differences can be found via `jn-seds-cli run --help`. In the following, the \n`jn-seds-cli` version will be used for an easier copy-and-paste usage on the Jetson Nano as \ntarget device.\n\nPlease use `--help` for detailed explanations of the individual software \nfunctionalities and parameters. \nWith this you can get help for each level, i.e.: \n`jn-seds-cli --help`, `jn-seds-cli run --help`, `jn-seds-cli run evaluation --help`.\n\n## Usage Examples\nShow the location of the resources' folder:\n```shell\njn-seds-cli resources where\n```\nMake a sound check of the audio devices:\n```shell\njn-seds-cli devices soundcheck\n```\nStart a sound event detection with saving the logs to a file in the resources' folder and \nrecord the first minute of the received audio input stream:\n```shell\njn-seds-cli run --tfmodel='!crnn' production --save_log=True --save_records=True --storage_length=60\n```\nConvert the recorded file of the previous run into a wave file:\n```shell\njn-seds-cli conversion record_to_wav --path_storage_pickle=\"/abs/path/to/seds_cli/res/records/record-xx.pickle\" --target_wav_path=\"./target_filepath/filename.wav\"\n```\n\n### Run Command\nThere are two different modes with the run command: production and evaluation. \nThe production mode is the main mode and receives live the current sound of the environment \nthrough the selected microphone device. \nThe evaluation mode can play a recorded wave file with a corresponding annotation csv file and \ndisplays the ground-truth value as well as the prediction for the live microphone recordings.\n\nMost parameters for the run command are available for both modes. \nMode specific parameters can be found via `--help` for the selected mode. \nThe following flags are used for the production mode, but are available for the evaluation mode too.\n\n**There are three models pre-defined and pre-trained for direct usage for \ndetecting bicycle bell sounds. They can be chosen by using `--tfmodel=\"!model-name\"` without any \nfurther specifications of `saved_model` type or the absolute path to the saved model resource \nin `tfmodel`. Available are `!crnn`, `yamnet_base` and `yamnet_extended`.**\n\n\nSelect the predefined CRNN model via `!crnn`, and run the production mode without displaying \nthe probability value of the predictions. The logs will be saved to a file:\n```shell\njn-seds-cli run --tfmodel='!crnn' production --save_log=True --prob_logging=False\n```\nVia specifying an integer for `input_device`, not `None`, a specific (not default) sound device \ncan be selected. \nUse the extended YAMNet model in a production run and define that the selected (default) \ninput device only has one input channel:\n```shell\njn-seds-cli run --tfmodel='!yamnet_extended' production --channels=1\n```\nUse the base YAMNet model in a production run with a lower threshold as default and activate the\nlogging of the probabilities to see that every prediction from a value of 0.3 will True:\n```shell\njn-seds-cli run --tfmodel='!yamnet_base' production --threshold=0.3 --prob_logging=True\n```\n\nMode specific flag-usage examples...\n\nFor the evaluation mode, use the first option for a random test example or specify an own test:\n```shell\njn-seds-cli run --tfmodel='!crnn' evaluation --save_log=True --silent=False\n# Or\njn-seds-cli run --tfmodel='!crnn' evaluation --save_log=True --wav_file=\"/path/to/wave.wav\" --annotation_file=\"/path/to/annotations.csv\" --silent=False\n```\nFor playback:\n```shell\njn-seds-cli run --tfmodel='!crnn' production --save_log=True --use_output=True\n```\n\n## Advanced Usage\nPlease note that in order to use the gpu, an appropriately compatible TensorFlow build must be \ninstalled and used with `--gpu=True`. \nIn addition, the inference model type must be set to use \nTensorFlow-TenorRT via `--infer_model=tftrt`, depending on the specific machine. \nIn some cases, also TFLite can be used with gpu support.\nUnfortunately, TF-TRT could not yet be tested thoroughly because compatible devices or \nsoftware dependencies were not available.\nFor further information, read `run --help` under the related parameters.\n\nNew trained models can be used via `--tfmodel=\"/path/to/tf-savedmodel-dir savedmodel=crnn`. \nThe best way, is to modify the source code in the file `saved_models.py` and create a new child class of BaseSavedModel or Mono16kWaveInputSavedModel.\nThen create an entry for this class in selectors.py, thus custom preprocessing and postprocessing for the model can be defined.\nAn easier way without modifying code is to use a saved model with the currently support interface of mono 16 kHz waveform input. \nIf so, it can easily be used via `--tfmodel=\"/path/to/tf-savedmodel-dir --saved_model=MONO_16K_IN`.\nPlease note that this feature has not yet been thoroughly tested.\n\n## Jetson Nano Setup\nThe following explanation based on the latest stable version of the JetPack OS (4.6.1) for the \nJetson Nano at the time of writing. \nThe use of the future version JetPack 5.0 is expected to resolve the installation issues with \nTensorflow_io and thus possibly allow support of the GPU and Tensorflow-TRT on the Jetson Nano.\nHowever, without development intentions, the here documented version 4.6.1 of JetPack \nshould be used for now.\n\nMake sure that JetPack 4.6.1 has been installed!\n```shell\napt-get update\napt-get install portaudio19-dev\n\nsudo apt-get update\nsudo apt-get install libhdf5-serial-dev hdf5-tools libhdf5-dev zlib1g-dev zip libjpeg8-dev liblapack-dev libblas-dev gfortran\nsudo apt-get install python3-pip\n\nmkdir ./venv\npython3 -m venv ./venv\nsource venv/bin/activate\n\npip install -U pip testresources setuptools==49.6.0 \npip install -U --no-deps numpy==1.19.4 future==0.18.2 mock==3.0.5 keras_preprocessing==1.1.2 keras_applications==1.0.8 gast==0.4.0 protobuf pybind11 cython pkgconfig\nenv H5PY_SETUP_REQUIRES=0 pip install -U --no-build-isolation h5py==3.1.0\npip install --pre --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v461 'tensorflow>=2'\n\npython -c \"from tensorflow.python.client import device_lib; device_lib.list_local_devices()\"\nPIP_EXTRA_INDEX_URL=https://snapshots.linaro.org/ldcg/python-cache pip install tensorflow_io\npython -c \"from tensorflow.python.client import device_lib; device_lib.list_local_devices()\"\n\npip install bicycle-bell-seds-cli\n\njn-seds-cli --help\njn-seds-cli run --tfmodel='!crnn' production\n```\nIt is expected that after `tensorflow_io` installation no gpu will be detected. \nThis is because this build of `tensorflow_io` brings a specific build of `tensorflow` (2.6) that does not \nsupport gpus'. \nWith JetPack 5.0 and thus higher Python version (>3.6), more recent versions of `tensorflow_io` can \nbe installed directly, for which there are also pre-build wheels for aarch64.\n\nMost of the installation steps for TensorFlow on the Jetson Nano are from \n\"Prerequisites and Dependencies\" [in corresponding the Nvidia Docs](https://docs.nvidia.com/deeplearning/frameworks/install-tf-jetson-platform/index.html).\n\nUsing Docker can save some on setup steps, but can also add some others. \nIf Docker should be used on the Jetson Nano:\n```shell\nsudo docker run -it --rm --runtime nvidia --network host -v /home/jetson:/home/jetson --device /dev/snd nvcr.io/nvidia/l4t-tensorflow:r32.7.1-tf2.7-py3\n```\n\n## Development\nFeel free to report bugs as issues and also contribute to the project. \nPlease contact me for this. \nEspecially the integration of new models and the full and tested integration of TF-TRT are still \noutstanding points of improvement. \nIn addition, the SEDS-CLI will be offered completely separate from the bicycle bell sound event \nin a further step and repository.\n\nUse the following steps to install directly from the GitHub repository and \ndo not forget to call `git lfs pull` before running. \nThis will download the model data.\n```shell\napt-get update\napt-get install portaudio19-dev git git-lfs\n\ngit clone https://github.com/ClemensKubach/bicycle-bell-sed-software.git\ncd bicycle-bell-sed-software\ngit lfs pull\npip install -e .\n```\n\n![system-overview](visualizations/overview.drawio.png \"System Overview\")\n"}
{"url": "https://github.com/ClemensKubach/star-galaxy-segmentation", "owner": "ClemensKubach", "repository_name": "star-galaxy-segmentation", "date_all_variable_collection": "2023-09-11", "description": null, "size": 7776, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "ClemensKubach", "contributions": 91}, {"contributor": "optzGuitar", "contributions": 73}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 2517751}, {"language": "Python", "num_chars": 131685}, {"language": "Shell", "num_chars": 100}], "readme": "# Star and Galaxy Segmentation\n\n## Getting Started\n### Prerequisites\n- Python 3.10\n- `pip install -r requirements.txt`\n- navigate to the project root directory\n- configure PYTHONPATH: `export PYTHONPATH=$PYTHONPATH:$(pwd)`\n\nPrerequisites for training:\n- `python star_analysis/stara_cli.py download`. This can take hours depending on the server load.\n- `python star_analysis/stara_cli.py repair`. This is only necessary, if the internet connection is lost while downloading. The downloaded files are checked for integrity and repaired if necessary.\n- `python star_analysis/stara_cli.py align`. This can take a while but reduces computation time later on.\n\n\n### Usage\nOur deep learning approach can be used via two entrypoints:\n- `python star_analysis/run_script.py` to train and test a model on the SDSS dataset.\n- `python star_analysis/stara_cli.py --help` as a wip command line tool as a collection of useful additional utils like downloading, repairing and aligning data.\n- for just using the trained model, take a look at the visualization notebook, linked below.\n\nWe recommend, if available, to use already downloaded and aligned data for faster processing. \nIf the data is at the correct location and the script run from the correct location, the data should be used automatically. \nAlso included are models that have already been trained. \nThe model `final-models/model-run-UNET-2023-06-30 00:17:11.130331.pt` is the selected final model (purple in the report plots).\nIt is loaded and used in `star_analysis/experiments/visualizations.ipynb` for predictions and visualizations.\n\n## General SDSS Information\n\n### Glossary and Specifications\n- SDSS: Sloan Digital Sky Survey. This is our data source.\n- DR: Data Release. We selected DR17.\n- Rerun: A rerun is a reprocessing of the data. We selected 301.\n- Fields: A field is a region of the sky.\n- Run-camcol-field identifier: A unique identifier for a field. I.e. 3704-3-91.\n- Frame: Corresponding to a single filter (u, g, r, i, z) image of a field.\n- Filter: One of the five filters (u, g, r, i, z) used by SDSS.\n- Object: A star, galaxy, or other astronomical object.\n- FITS: Flexible Image Transport System. A file format used to store astronomical data.\n\n### Data\nWe are using the following data:\n- FITS files for the five filters (u, g, r, i, z) for each field.\n- DR17 rerun 301.\n- Fields.csv: A CSV file containing the run-camcol-field identifiers (rcf-id) for each field.\n- We can download the FITS files via the rcf-ids in Fields.csv.\n- Fields are overlapping by 10%. We should skip one Field between subsets.\n\n#### Alignement between:\n- IRG: i, r, g as jpg. (frame-irg-001000-1-0027.jpg)\n- u: u as FITS. (frame-u-001000-1-0027.fits)\n- z: z from FITS. (frame-z-001000-1-0027.fits)\n- Labels: ?\n\n#### Download\nUse syntax as described in https://www.sdss4.org/dr17/data_access/bulk/ .\n\n\n## SDSS Information\nhttps://www.sdss4.org/dr17/help/glossary/\nhttps://www.sdss4.org/dr14/imaging/imaging_basics/\nhttps://dr12.sdss.org/fields/raDec?ra=143&dec=15\n"}
{"url": "https://github.com/ClemensKubach/vae-art-restoration", "owner": "ClemensKubach", "repository_name": "vae-art-restoration", "date_all_variable_collection": "2023-09-11", "description": null, "size": 28928, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "ClemensKubach", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 38894807}, {"language": "Python", "num_chars": 133060}, {"language": "Dockerfile", "num_chars": 800}], "readme": "# Variational Autoencoder\n**in Disentangled Representation Learning**\n\nClemens Kubach, Joanina Oltersdorff, Lukas Beinlich and Yilei Chen\n\nTutor: Monika\n\n## Available Models\n- Simple Residual VAE (SimpleResVAE)\n- VAE with normalizing flows (NF-VAE)\n- Very Deep VAE (VDVAE)\n- Residual VAE (ResVAE - inspired by VDVAE)\n- Advanced VAE (Adv-VAE)\n- Sequential VAE (SeqVAE)\n- Sequential VDVAE (SeqVDVAE)\n\n## Prerequisites\n- Install git lfs for downloading the saved checkpoints in selected-checkpoints directory\n\n## Getting Started\n1. Clone the repository\n2. Install Python 3.10\n3. Install Dependencies \n   - Run `pip install -r requirements.txt` to install all dependencies \n   - WandB account is optional but recommended\n4. Goto repo root directory\n5. Setup the dataset\n   - Make sure you have the SIAR dataset available in `datafiles/`. \n   - For the time of reviewing, you can download it from [SIAR](https://drive.google.com/file/d/1r5JYUvPSP7j0O6GzjB5mMakD_CURLEJB/view?usp=sharing) and extract it to `datafiles/`.\n   - An example path from the repository root to one image would look like the following: `datafiles/1/1.png`.\n   - See section \"Dataset\" for further notes.\n6. Make packages available to python \n   - Set env `export PYTHONPATH=$PYTHONPATH:$(pwd)`\n7. Run experiments\n   - Under `siar/experiments/` you can find scripts that you can use for doing experiments. \n   - For getting started easily, you can just run `python3 siar/experiments/simple_run_script.py` to train a predefined simple VAE. \n   - You can simply modify the configuration to your needs, like selecting different batch sizes, architectures, etc. \n   - Alternatively, you can also run our other run scripts in the folder for the different model types.\n\n\n## Repository Structure\n\n### Unitorchplate\nThe `unitorchplate` package contains a try of implementing a unified template for Pytorch experiments in the Computer Vision Domain.\nThe idea is to offer a baseline structure and functionality for your deep learning projects as Gradle is offering for software projects.\nEvery run is configurable via config classes/file to increase easy usability and reproducibility.\nIt is based on the framework Pytorch, Lightning and some ideas of mlflow.\n\nWhile offering a standardized implementation for Lightning DataModules and Modules for Models (here named: ModelModules), it is saves time for getting started with a new project but also easily customizable via subclassing.\nThis project is a result of this semester's project and will be further developed in the future.\n\n### Siar\nThe `siar` package implements this template for our specific use case and the SIAR dataset of this project.\nFor the model implementations, we built upon [Pythae](), a library for different autoencoder architectures for reconstructing input images.\n\n## Dataset\nYou can also have the somewhere else, but then you have to change the path in the config in every run.\nTo make it easier, you can also make a softlink in the datafiles folder in the repository root directory to the folder where the dataset is located. \n\nWindows:\n```\nmklink /D \"C:\\<your-path-to-repo>\\cvp2\\datafiles\" \"C:\\<your-path-to-dataset>\\SIAR\"\n```\nUnix:\n```\nln -s <your-path-to-dataset>/SIAR <your-path-to-repo>/cvp2/datafiles\n```\n\n## Development\n\n### Experiment Configs\nIn `siar/experiments/` you can find scripts that you can use for doing experiments.\nJust change the parameters offered in the run config to your needs.\n\n### Adding further models\nYou can orientate yourself on the already implemented models. The following files are relevant:\n\nIn `siar/models/architectures/`\n- Define YourModelName in `your_model_name.py` for defining Encoder, Decoder, Architecture and Config.\nFor an example take a look at `simple_res_vae.py`.\n- ModelTypes in `model_types.py` for registering your new architecture\n- In `siar/experiments/` you can add a new experiment or just change the parameter in an already created run-script.\n\nOptional:\n- Look under `base_architectures` for some base architectures that you can use for your model or create a new one to customize the forward pass between encoder and decoder.\n\nNote: The Pythae models only support reconstruction of the input image (self-reconstruction task).\nThat's why we had to override the forward function of their model classes (see VAE, NF-VAE).\n\n![ML System](./resources/cvp-mlsystem.drawio.png)\n\n## Papers\nThe references can be found in the project report."}
{"url": "https://github.com/crpiceda/dynamictopography", "owner": "crpiceda", "repository_name": "dynamictopography", "date_all_variable_collection": "2023-09-11", "description": "Lab exercise on dynamic topography for Neotectonics and Geodynamics course at University of Potsdam", "size": 460, "stargazers_count": 7, "watchers_count": 7, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 7, "default_branch": "master", "contributors": [{"contributor": "crpiceda", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Calculation of Residual Topography\n## About\nThis Jupyter Notebook is a python implementation of the modified approach by Gvirtzman et al. (2016) to calculate the residual topography in the Middle East region, including North Africa, Arabia, the Afar rift, the Mediterranean basins, Anatolia and the Zagros Mountains.\n\n## Pre-requisites\n1. A python installation (Anaconda). In case of not having anaconda, download it following this link:\nhttps://docs.anaconda.com/anaconda/install/\n2. Clone this repository containing the Jupyter Notebook and the input data files\n\n\n## Extra dependencies\nInstall using command `conda install`\n- cartopy 0.18.0\n\n## Input data\n- *topography.txt*: topography from DEM model ETOPO1 (Amante and Eakins, 2009)\n- *l_sed.txt*: sediment thickness from CRUST1 model (Laske et al., 2013)\n- *rho_sed.txt*: sediment density from CRUST1 model ((Laske et al., 2013)\n- *l_crust.txt*: crustal thickness from CRUST 1 model (Laske et al., 2013)\n\n## References\n- Amante, C. and B.W. Eakins, 2009. ETOPO1 1 Arc-Minute Global Relief Model: Procedures, Data Sources and Analysis. NOAA Technical Memorandum NESDIS NGDC-24. National Geophysical Data Center, NOAA. doi:10.7289/V5C8276M [access date: 6/24/2021]\n- Gvirtzman, Z., Faccenna, C., Becker, T. W., 2016. Isostasy, flexure, and dynamic topography. Tectonophysics, 683, 255\u2013271.\n- Laske, G., Masters., G., Ma, Z. and Pasyanos, M., 2013. Update on CRUST1.0 - A 1-degree Global Model of Earth's Crust, Geophys. Res. Abstracts, 15, Abstract EGU2013-2658\n\n## License\n\n\n<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>.\n"}
{"url": "https://github.com/crpiceda/PythonScripts", "owner": "crpiceda", "repository_name": "PythonScripts", "date_all_variable_collection": "2023-09-11", "description": "Python scripts to plot, manipulate and/or analyze data", "size": 44, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "crpiceda", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 169690}], "readme": "# PythonScripts\nPython scripts to plot, manipulate and/or analyze data  \nversion: python 3\n"}
{"url": "https://github.com/cslm-lab/.github", "owner": "cslm-lab", "repository_name": ".github", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "laura-riedel", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# .github"}
{"url": "https://github.com/cslm-lab/cognitive_skills", "owner": "cslm-lab", "repository_name": "cognitive_skills", "date_all_variable_collection": "2023-09-11", "description": "Experiment 2 from SFB Phase 1", "size": 8796, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "pamfuhrmeister", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 166924}], "readme": "# Cognitive skills and language production\n## Experiment 2 from SFB Phase 1\n\nData and code for cognitive skills/language production paper\n"}
{"url": "https://github.com/cslm-lab/pcibex", "owner": "cslm-lab", "repository_name": "pcibex", "date_all_variable_collection": "2023-09-11", "description": "Python and R scripts to make pre-processing of data collected with Prolific/PCIbex easier", "size": 81563, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "pamfuhrmeister", "contributions": 13}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 7097}, {"language": "R", "num_chars": 1831}], "readme": "# pcibex\nDescription:  \nPython and R scripts to make pre-processing of speech production data collected with Prolific/PCIbex easier\n\nWhy:  \nWhen collecting speech production data through Prolific/PCIbex, there are a lot of files that have to be moved various places, and doing this can be error prone. \nThe goal of this pipeline is to reduce some of the manual labor involved to be more efficient and less error prone.\n\n\nHelp documentation:\n\nusage: \n```\npcibex.py [-h] -i INPUT -o OUTPUT\n\noptional arguments: \n  -h, --help            show this help message and exit\n  -i INPUT, --input INPUT\n                        Please enter the full path of the input directory.\n  -o OUTPUT, --output OUTPUT\n                        Please enter the full path of the output directory.\n```\n                                              \nWhat the pipeline does: \n1. Unzips all zip files in the directory (participant audio files are saved to the server in zip files)\n2. Moves the R script to the input directory and calls it; this cleans up the results file (writes a new file called my_results.csv) and writes a csv file that is a tidy version of the information we ask participants to provide in a questionnaire (tidy.csv)\n3. Renames audio files to include trial number and name of object and converts them to .wav format (they are originally in .webm format); writes a new file called my_results_new_name_file_correspondance.csv; creates a directory for the webm files and moves them all there\n4. Creates a directory for each participant (one directory for each participant number in tidy.csv file) and moves the audio files that correspond to that participant there\n5. Creates a destination directory to move usable data to (unless the directory already exists); prompts user for input for various attribues of the experiment to name this directory\n    - For the current example, we used the experiment number, session number, list, and condition. This can be customized on lines 222-227 of pcibex.py\n6. User checks data for each participant manually. Script prompts the user to say whether the data for each participant is usable\n    - If so, it moves the participant directory with all the audio files to the destination directory that was just created\n    - If not, the directory remains where it is\n\n\nInstructions for using the pipeline:\n\nSetup: \n\nCreate a directory (anywhere on your computer) that includes the following: \n- Participant's audio files saved to server (zip files)\n- Results file generated from PCIbex (can include more participants than you have audio files for); this needs to be named results.csv\n\nCreate a directory (anywhere on your computer) that includes the following files: \n- pcibex.py\n- tidy_pcibex.R\n\nTo run the pipeline:  \n- Open a terminal and navigate to the directory that includes the two files (on a mac this is cd path/to/directory)\n- Type python pcibex.py -i path/to/input/directory -o path/to/output/directory\n  + Input directory is where the zip files and results file are\n  + Output directory is the root directory for where you want to create a new directory for each experiment/session/condition/etc. to move the audio files to\n- Follow prompts\n  \n"}
{"url": "https://github.com/cslm-lab/reliability", "owner": "cslm-lab", "repository_name": "reliability", "date_all_variable_collection": "2023-09-11", "description": "reliability", "size": 1172, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "pamfuhrmeister", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 1135881}], "readme": "# reliability\nReliability\n\nData files and scripts for reliability paper\n"}
{"url": "https://github.com/cslm-lab/reliability_project", "owner": "cslm-lab", "repository_name": "reliability_project", "date_all_variable_collection": "2023-09-11", "description": "reliability_project", "size": 3559, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "pamfuhrmeister", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 1706261}, {"language": "TeX", "num_chars": 108270}, {"language": "R", "num_chars": 4884}], "readme": "# Reliability in picture naming\n\nData files and scripts for reliability paper\n\nDirectory structure: \n\nanalysis_scripts: Rmd files for analyses\n\ndata: all data files for the two experiments\n\npaper: Rmd files for paper\n\nbalance_stimuli: script and files needed to reproduce balanced stimulus lists\n"}
{"url": "https://github.com/ctiedt/bfrs", "owner": "ctiedt", "repository_name": "bfrs", "date_all_variable_collection": "2023-09-11", "description": "A brainfuck/Blub interpreter in Rust", "size": 4, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 6961}]}
{"url": "https://github.com/ctiedt/cranefuck", "owner": "ctiedt", "repository_name": "cranefuck", "date_all_variable_collection": "2023-09-11", "description": null, "size": 14, "stargazers_count": 1, "watchers_count": 1, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "ctiedt", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 11091}, {"language": "Brainfuck", "num_chars": 1420}, {"language": "Python", "num_chars": 482}, {"language": "Shell", "num_chars": 217}, {"language": "PowerShell", "num_chars": 168}, {"language": "HyPhy", "num_chars": 3}, {"language": "Befunge", "num_chars": 2}], "readme": "# A brainfuck compiler using cranelift\n\nThis is a compiler for the brainfuck programming language based on the [cranelift](https://docs.rs/cranelift) framework.\n\n## Examples\n\nThis project includes various examples that should all compile and run (please open an issue if\nany of them doesn't work for you!).\n\nYou can also use the `print_bf.py` file to generate brainfuck code to print a string.\n\n## Linking\n\nThis project only provides the compiler. To get an executable for your platform, you will need\nto link the object file built by the compiler. Scripts are included to link with `ld` on\nLinux and `link.exe` on Windows.\n\n## Building on Windows\n\nTo compile brainfuck code on windows, you will need MSVC build tools and `ucrt.lib`.\nYou can install these via the Visual Studio Installer and will need\nto put the correct path for `ucrt.lib` into the `link.exe` invocation\nin `build.ps1`."}
{"url": "https://github.com/ctiedt/ctiedt", "owner": "ctiedt", "repository_name": "ctiedt", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "ctiedt", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "## Hi, I'm Clemens - I do things with computers\n\n### About Me\n\nI currently study IT-Systems Engineering in the Master's program at [HPI](https://hpi.de).\n\nYou can find out more about me on my website: https://tiedt.dev\n\n### Interests\n\n- Operating Systems\n- Embedded Systems\n- Mobile Development\n\n<!--\n**ctiedt/ctiedt** is a \u2728 _special_ \u2728 repository because its `README.md` (this file) appears on your GitHub profile.\n\nHere are some ideas to get you started:\n\n- \ud83d\udd2d I\u2019m currently working on ...\n- \ud83c\udf31 I\u2019m currently learning ...\n- \ud83d\udc6f I\u2019m looking to collaborate on ...\n- \ud83e\udd14 I\u2019m looking for help with ...\n- \ud83d\udcac Ask me about ...\n- \ud83d\udceb How to reach me: ...\n- \ud83d\ude04 Pronouns: ...\n- \u26a1 Fun fact: ...\n-->\n"}
{"url": "https://github.com/ctiedt/documentor", "owner": "ctiedt", "repository_name": "documentor", "date_all_variable_collection": "2023-09-11", "description": "Einfaches Dokumentationstool, das urspr\u00fcnglich f\u00fcr Rogue Inc. gedacht war. Generiert API-Dokumentationen aus Python-Code.", "size": 2, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 2664}], "readme": "# documentor\nEinfaches Dokumentationstool, das urspr\u00fcnglich f\u00fcr Rogue Inc. gedacht war. Generiert API-Dokumentationen aus Python-Code.\n"}
{"url": "https://github.com/ctiedt/dotfiles", "owner": "ctiedt", "repository_name": "dotfiles", "date_all_variable_collection": "2023-09-11", "description": "My dotfiles for linux", "size": 13, "stargazers_count": 0, "watchers_count": 0, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 350}], "readme": "# dotfiles\n\nThese are my settings for various utilities I use in Linux.\nFeel free to steal anything you like.\nThey work, but they may not be written in the best style.\nIf you want to improve anything, I'm happy to see issues or PRs.\n\n| Util          | File                           | Description                                                 |\n| ------------- | ------------------------------ | ----------------------------------------------------------- |\n| i3            | `.config/i3/config`            | My window manager. For usage on top of KDE Plasma.          |\n| fish          | `.config/fish/config.fish`     | My shell. Mostly to make it look nicer                      |\n| kitty         | `.config/kitty/kitty.conf`     | Terminal emulator. Enable transparency and use a nicer font |\n| neofetch      | `.config/neofetch/config.conf` | Show system stats. Shows my universit's logo                |\n| omf           | `.config/omf/*`                | The fish customisation framework.                           |\n| kde-autostart | `kde-autostart.sh`             | Use `i3` instead of `kwin`                                  |"}
{"url": "https://github.com/ctiedt/dwm", "owner": "ctiedt", "repository_name": "dwm", "date_all_variable_collection": "2023-09-11", "description": "My personal patched dwm", "size": 6194, "stargazers_count": 0, "watchers_count": 0, "language": "C", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "garbeam", "contributions": 541}, {"contributor": "hiltjo", "contributions": 23}, {"contributor": "cls", "contributions": 19}, {"contributor": "anydot", "contributions": 8}, {"contributor": "schachmat", "contributions": 4}, {"contributor": "ericpruitt", "contributions": 2}, {"contributor": "klemensn", "contributions": 2}, {"contributor": "ctiedt", "contributions": 1}, {"contributor": "dcousens", "contributions": 1}, {"contributor": "osandov", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C", "num_chars": 68745}, {"language": "Objective-C", "num_chars": 13422}, {"language": "Roff", "num_chars": 5179}, {"language": "Makefile", "num_chars": 2057}, {"language": "C++", "num_chars": 305}], "readme": "dwm - dynamic window manager\n============================\ndwm is an extremely fast, small, and dynamic window manager for X.\n\n\nRequirements\n------------\nIn order to build dwm you need the Xlib header files.\n\n\nInstallation\n------------\nEdit config.mk to match your local setup (dwm is installed into\nthe /usr/local namespace by default).\n\nAfterwards enter the following command to build and install dwm (if\nnecessary as root):\n\n    make clean install\n\n\nRunning dwm\n-----------\nAdd the following line to your .xinitrc to start dwm using startx:\n\n    exec dwm\n\nIn order to connect dwm to a specific display, make sure that\nthe DISPLAY environment variable is set correctly, e.g.:\n\n    DISPLAY=foo.bar:1 exec dwm\n\n(This will start dwm on display :1 of the host foo.bar.)\n\nIn order to display status info in the bar, you can do something\nlike this in your .xinitrc:\n\n    while xsetroot -name \"`date` `uptime | sed 's/.*,//'`\"\n    do\n    \tsleep 1\n    done &\n    exec dwm\n\n\nConfiguration\n-------------\nThe configuration of dwm is done by creating a custom config.h\nand (re)compiling the source code.\n"}
{"url": "https://github.com/ctiedt/dwmstat-rs", "owner": "ctiedt", "repository_name": "dwmstat-rs", "date_all_variable_collection": "2023-09-11", "description": null, "size": 3, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 1883}]}
{"url": "https://github.com/ctiedt/egui_wasm_editor", "owner": "ctiedt", "repository_name": "egui_wasm_editor", "date_all_variable_collection": "2023-09-11", "description": null, "size": 13, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 5437}], "readme": "# WASM Editor\n\nA simple editor for quickly compiling C to WASM with the ability to also view the WASM text representation."}
{"url": "https://github.com/ctiedt/fibonacci", "owner": "ctiedt", "repository_name": "fibonacci", "date_all_variable_collection": "2023-09-11", "description": null, "size": 5, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 2527}]}
{"url": "https://github.com/ctiedt/flutter_md_slides", "owner": "ctiedt", "repository_name": "flutter_md_slides", "date_all_variable_collection": "2023-09-11", "description": null, "size": 4, "stargazers_count": 0, "watchers_count": 0, "language": "Dart", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Dart", "num_chars": 3424}], "readme": "# flutter_md_slides\n\nA new Flutter package project.\n\n## Getting Started\n\nThis project is a starting point for a Dart\n[package](https://flutter.dev/developing-packages/),\na library module containing code that can be shared easily across\nmultiple Flutter or Dart projects.\n\nFor help getting started with Flutter, view our \n[online documentation](https://flutter.dev/docs), which offers tutorials, \nsamples, guidance on mobile development, and a full API reference.\n"}
{"url": "https://github.com/ctiedt/greenscream", "owner": "ctiedt", "repository_name": "greenscream", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1124, "stargazers_count": 0, "watchers_count": 0, "language": "TypeScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 11, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 11, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "batteredgherkin", "contributions": 2}, {"contributor": "ctiedt", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TypeScript", "num_chars": 12230}, {"language": "JavaScript", "num_chars": 8862}, {"language": "Svelte", "num_chars": 5237}, {"language": "GLSL", "num_chars": 1388}, {"language": "HTML", "num_chars": 1031}, {"language": "CSS", "num_chars": 584}], "readme": "# sapper-template\n\nThe default template for setting up a [Sapper](https://github.com/sveltejs/sapper) project. Can use either Rollup or webpack as bundler.\n\n\n## Getting started\n\n\n### Using `degit`\n\nTo create a new Sapper project based on Rollup locally, run\n\n```bash\nnpx degit \"sveltejs/sapper-template#rollup\" my-app\n```\n\nFor a webpack-based project, instead run\n\n```bash\nnpx degit \"sveltejs/sapper-template#webpack\" my-app\n```\n\n[`degit`](https://github.com/Rich-Harris/degit) is a scaffolding tool that lets you create a directory from a branch in a repository.\n\nReplace `my-app` with the path where you wish to create the project.\n\n\n### Using GitHub templates\n\nAlternatively, you can create the new project as a GitHub repository using GitHub's template feature.\n\nGo to either [sapper-template-rollup](https://github.com/sveltejs/sapper-template-rollup) or [sapper-template-webpack](https://github.com/sveltejs/sapper-template-webpack) and click on \"Use this template\" to create a new project repository initialized by the template.\n\n\n### Running the project\n\nOnce you have created the project, install dependencies and run the project in development mode:\n\n```bash\ncd my-app\nnpm install # or yarn\nnpm run dev\n```\n\nThis will start the development server on [localhost:3000](http://localhost:3000). Open it and click around.\n\nYou now have a fully functional Sapper project! To get started developing, consult [sapper.svelte.dev](https://sapper.svelte.dev).\n\n### Using TypeScript\n\nBy default, the template uses plain JavaScript. If you wish to use TypeScript instead, you need some changes to the project:\n\n * Add `typescript` as well as typings as dependences in `package.json`\n * Configure the bundler to use [`svelte-preprocess`](https://github.com/sveltejs/svelte-preprocess) and transpile the TypeScript code.\n * Add a `tsconfig.json` file\n * Update the project code to TypeScript\n\nThe template comes with a script that will perform these changes for you by running\n\n```bash\nnode scripts/setupTypeScript.js\n```\n\n`@sapper` dependencies are resolved through `src/node_modules/@sapper`, which is created during the build. You therefore need to run or build the project once to avoid warnings about missing dependencies.\n\nThe script does not support webpack at the moment.\n\n## Directory structure\n\nSapper expects to find two directories in the root of your project \u2014  `src` and `static`.\n\n\n### src\n\nThe [src](src) directory contains the entry points for your app \u2014 `client.js`, `server.js` and (optionally) a `service-worker.js` \u2014 along with a `template.html` file and a `routes` directory.\n\n\n#### src/routes\n\nThis is the heart of your Sapper app. There are two kinds of routes \u2014 *pages*, and *server routes*.\n\n**Pages** are Svelte components written in `.svelte` files. When a user first visits the application, they will be served a server-rendered version of the route in question, plus some JavaScript that 'hydrates' the page and initialises a client-side router. From that point forward, navigating to other pages is handled entirely on the client for a fast, app-like feel. (Sapper will preload and cache the code for these subsequent pages, so that navigation is instantaneous.)\n\n**Server routes** are modules written in `.js` files, that export functions corresponding to HTTP methods. Each function receives Express `request` and `response` objects as arguments, plus a `next` function. This is useful for creating a JSON API, for example.\n\nThere are three simple rules for naming the files that define your routes:\n\n* A file called `src/routes/about.svelte` corresponds to the `/about` route. A file called `src/routes/blog/[slug].svelte` corresponds to the `/blog/:slug` route, in which case `params.slug` is available to the route\n* The file `src/routes/index.svelte` (or `src/routes/index.js`) corresponds to the root of your app. `src/routes/about/index.svelte` is treated the same as `src/routes/about.svelte`.\n* Files and directories with a leading underscore do *not* create routes. This allows you to colocate helper modules and components with the routes that depend on them \u2014 for example you could have a file called `src/routes/_helpers/datetime.js` and it would *not* create a `/_helpers/datetime` route.\n\n\n#### src/node_modules/images\n\nImages added to `src/node_modules/images` can be imported into your code using `import 'images/<filename>'`. They will be given a dynamically generated filename containing a hash, allowing for efficient caching and serving the images on a CDN.\n\nSee [`index.svelte`](src/routes/index.svelte) for an example.\n\n\n#### src/node_modules/@sapper\n\nThis directory is managed by Sapper and generated when building. It contains all the code you import from `@sapper` modules.\n\n\n### static\n\nThe [static](static) directory contains static assets that should be served publicly. Files in this directory will be available directly under the root URL, e.g. an `image.jpg` will be available as `/image.jpg`.\n\nThe default [service-worker.js](src/service-worker.js) will preload and cache these files, by retrieving a list of `files` from the generated manifest:\n\n```js\nimport { files } from '@sapper/service-worker';\n```\n\nIf you have static files you do not want to cache, you should exclude them from this list after importing it (and before passing it to `cache.addAll`).\n\nStatic files are served using [sirv](https://github.com/lukeed/sirv).\n\n\n## Bundler configuration\n\nSapper uses Rollup or webpack to provide code-splitting and dynamic imports, as well as compiling your Svelte components. With webpack, it also provides hot module reloading. As long as you don't do anything daft, you can edit the configuration files to add whatever plugins you'd like.\n\n\n## Production mode and deployment\n\nTo start a production version of your app, run `npm run build && npm start`. This will disable live reloading, and activate the appropriate bundler plugins.\n\nYou can deploy your application to any environment that supports Node 10 or above. As an example, to deploy to [Vercel Now](https://vercel.com) when using `sapper export`, run these commands:\n\n```bash\nnpm install -g vercel\nvercel\n```\n\nIf your app can't be exported to a static site, you can use the [vercel-sapper](https://github.com/thgh/vercel-sapper) builder. You can find instructions on how to do so in its [README](https://github.com/thgh/vercel-sapper#basic-usage).\n\n\n## Using external components\n\nWhen using Svelte components installed from npm, such as [@sveltejs/svelte-virtual-list](https://github.com/sveltejs/svelte-virtual-list), Svelte needs the original component source (rather than any precompiled JavaScript that ships with the component). This allows the component to be rendered server-side, and also keeps your client-side app smaller.\n\nBecause of that, it's essential that the bundler doesn't treat the package as an *external dependency*. You can either modify the `external` option under `server` in [rollup.config.js](rollup.config.js) or the `externals` option in [webpack.config.js](webpack.config.js), or simply install the package to `devDependencies` rather than `dependencies`, which will cause it to get bundled (and therefore compiled) with your app:\n\n```bash\nnpm install -D @sveltejs/svelte-virtual-list\n```\n\n\n## Bugs and feedback\n\nSapper is in early development, and may have the odd rough edge here and there. Please be vocal over on the [Sapper issue tracker](https://github.com/sveltejs/sapper/issues).\n"}
{"url": "https://github.com/ctiedt/hpi-mathe2", "owner": "ctiedt", "repository_name": "hpi-mathe2", "date_all_variable_collection": "2023-09-11", "description": "Ein Versuch, das Skript zur Vorlesung 'Mathematik II' am Hasso-Plattner-Institut zug\u00e4nglicher zu machen.", "size": 4, "stargazers_count": 1, "watchers_count": 1, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 8758}], "readme": "# hpi-mathe2\nEin Versuch, das Skript zur Vorlesung 'Mathematik II' am Hasso-Plattner-Institut zug\u00e4nglicher zu machen.\n"}
{"url": "https://github.com/ctiedt/hpi_lv_crawler", "owner": "ctiedt", "repository_name": "hpi_lv_crawler", "date_all_variable_collection": "2023-09-11", "description": null, "size": 2, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "ctiedt", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 4275}]}
{"url": "https://github.com/ctiedt/influx_client", "owner": "ctiedt", "repository_name": "influx_client", "date_all_variable_collection": "2023-09-11", "description": "A Rust library to interact with InfluxDB", "size": 30, "stargazers_count": 3, "watchers_count": 3, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 1, "watchers": 3, "default_branch": "main", "contributors": [{"contributor": "ctiedt", "contributions": 13}, {"contributor": "johanster", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": true, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["database", "influxdb", "influxdb-client", "rust"], "languages": [{"language": "Rust", "num_chars": 16020}], "readme": "# influx_client\n[![crates-badge](https://img.shields.io/crates/v/influx_client?style=for-the-badge)](https://crates.io/crates/influx_client) [![docs-badge](https://img.shields.io/docsrs/influx-client/latest?style=for-the-badge)](https://docs.rs/influx_client)\n\nA Rust library to interact with [InfluxDB](https://www.influxdata.com/) databases.\nIt is still early in development, so expect bugs and missing features.\n\n## Things that work\n\n- Writing data to a bucket\n- Querying data in a certain time range (only relative so far)\n- Using filters in queries\n\n## Examples\n\nWriting to a bucket:\n\n```rust\nuse std::{collections::HashMap, time::SystemTime};\n\nuse influx_client::{\n    Client, InfluxError, Precision, WriteQuery,\n};\n\nfn main() -> Result<(), InfluxError> {\n    let client = Client::from_env(\"http://localhost:8086\").expect(\"INFLUXDB_TOKEN not set\");\n    let mut tags = HashMap::new();\n    tags.insert(\"t1\", \"v1\");\n    tags.insert(\"t2\", \"v2\");\n    let data = WriteQuery {\n        name: \"test\",\n        tags,\n        field_name: \"i\",\n        value: 42,\n        timestamp: Some((SystemTime::now(), Precision::ns)),\n    };\n\n    client.insert(\"home\", \"home\", Precision::ms, data)?;\n}\n\n```\n\nReading from a bucket:\n\n```rust\nuse influx_client::{\n    flux::functions::{NumericFilter, Range, StringFilter},\n    Client, InfluxError, Precision, ReadQuery,\n};\n\nfn main() -> Result<(), InfluxError> {\n    let client = Client::from_env(\"http://localhost:8086\").expect(\"INFLUXDB_TOKEN not set\");\n    \n    let q = ReadQuery::new(\"home\")\n        .range(Range::new(Some((-12, Precision::h)), None))\n        .filter(StringFilter::Eq(\"_measurement\", \"test\"))\n        .filter(NumericFilter::Lt(\"_value\", 99));\n\n    println!(\"{}\", client.get(\"home\", q)?);\n    Ok(())\n}\n\n```"}
{"url": "https://github.com/ctiedt/interruptable_function", "owner": "ctiedt", "repository_name": "interruptable_function", "date_all_variable_collection": "2023-09-11", "description": null, "size": 2, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 2847}]}
{"url": "https://github.com/ctiedt/kanban_flutter", "owner": "ctiedt", "repository_name": "kanban_flutter", "date_all_variable_collection": "2023-09-11", "description": "A simple kanban board built using flutter", "size": 70, "stargazers_count": 0, "watchers_count": 0, "language": "Dart", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Dart", "num_chars": 9964}, {"language": "C++", "num_chars": 5171}, {"language": "Makefile", "num_chars": 4370}, {"language": "Batchfile", "num_chars": 2390}, {"language": "Swift", "num_chars": 404}, {"language": "Kotlin", "num_chars": 340}, {"language": "Objective-C", "num_chars": 37}], "readme": "# kanban_flutter\n\nA new Flutter project.\n\n## Getting Started\n\nThis project is a starting point for a Flutter application.\n\nA few resources to get you started if this is your first Flutter project:\n\n- [Lab: Write your first Flutter app](https://flutter.dev/docs/get-started/codelab)\n- [Cookbook: Useful Flutter samples](https://flutter.dev/docs/cookbook)\n\nFor help getting started with Flutter, view our\n[online documentation](https://flutter.dev/docs), which offers tutorials,\nsamples, guidance on mobile development, and a full API reference.\n"}
{"url": "https://github.com/ctiedt/make-rs", "owner": "ctiedt", "repository_name": "make-rs", "date_all_variable_collection": "2023-09-11", "description": null, "size": 4, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 5162}, {"language": "Makefile", "num_chars": 211}, {"language": "C", "num_chars": 160}], "readme": "# make-rs\n\nA simple subset of `make` implemented in Rust without dependencies.\n\n# Differences to gnu make\n\nThis is really just a small subset of the capabilities of gnu `make`\nand just intended to show that such a thing can be built in Rust without\nexternal dependencies.\n\nMissing features:\n\n- command line flags\n- timestamp checking\n- parallel compilation\n"}
{"url": "https://github.com/ctiedt/mathe-vorkurs", "owner": "ctiedt", "repository_name": "mathe-vorkurs", "date_all_variable_collection": "2023-09-11", "description": "Notizen zum Mathe-Vorkurs am HPI WS2018/19", "size": 454, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 1903416}, {"language": "Python", "num_chars": 6231}, {"language": "CSS", "num_chars": 2418}]}
{"url": "https://github.com/ctiedt/meeting-notifier", "owner": "ctiedt", "repository_name": "meeting-notifier", "date_all_variable_collection": "2023-09-11", "description": null, "size": 6, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 3104}], "readme": "Basically just a super simple proof of concept to run a command if the system detects a process whose name matches a pattern. Windows-specific.\n\n## How to use it\n\n```\nmeeting-notifier <pattern> <command>\n```\n\nYou have to put the command in quotes if it has an argument.\n\nOptionally, you can add a second command that runs when the targeted process exits."}
{"url": "https://github.com/ctiedt/minimal-rust-km", "owner": "ctiedt", "repository_name": "minimal-rust-km", "date_all_variable_collection": "2023-09-11", "description": "A minimal kernel module using Rust", "size": 3, "stargazers_count": 0, "watchers_count": 0, "language": "Makefile", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["kernel-module", "linux-kernel", "rust"], "languages": [{"language": "Makefile", "num_chars": 674}, {"language": "C", "num_chars": 437}, {"language": "Rust", "num_chars": 298}], "readme": "# minimal-rust-km\n\nA simple prototype to show how you can build a linux kernel module using Rust.\n\n## How to build\n\nYou need a working C toolchain, headers for the kernel you are compiling for and a (nightly) Rust toolchain with `cargo-xbuild`.\nTo compile the module, run `make all` from the base directory. Try it out with `make test` or `sudo insmod build/minimod.ko` \n(don't forget to unload the module with `sudo rmmod minimod` afterwards).\n\n## A short overview\n\n### What `module.c` does\n\nThe easiest way to create a kernel module in a language other than C is to write some C code that does all the basic work for initializing\na kernel module (which uses C macros and/or inline functions which are hard to call via FFI) and then calls a Rust function to take over.\nWe also include a C function to be called from Rust as an example of how to additionally use this C file as a sort of library.\n\n### What `lib.rs` does\n\nThis is where most of the code in a real kernel module should go. In our case, we just have a `rust_main` function that calls a C function.\nSince we are in a `#![no_std]` context, we need to define some language items ourselves.\n\n### What's still missing\n\nOne of the biggest missing things is the `print!()` macro. To implement this, you could create a struct that implements \nthe formatting trait and use a static instance of it to define your `print!()` macro using the C `kprintf` function. You\nmight also want to create an allocator using `krealloc` and `kfree` to be able to use heap-allocated data types.\n"}
{"url": "https://github.com/ctiedt/ramfs-loadable-module", "owner": "ctiedt", "repository_name": "ramfs-loadable-module", "date_all_variable_collection": "2023-09-11", "description": "The ramfs file system with comments as a loadable kernel module", "size": 3, "stargazers_count": 0, "watchers_count": 0, "language": "C", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C", "num_chars": 7960}, {"language": "Makefile", "num_chars": 176}], "readme": "ramfs-loadable-module\n=====================\n\nThis is a modification of the ramfs code in the Linux kernel to run as a loadable\nmodule. Additionally, it adds some explanatory comments.\n\n# How to use this module\n\nBuild the module by running `make`.\nLike all kernel modules, you will need to have the appropriate kernel headers installed.\nInsert the module with `sudo insmod ramfs.ko`\nand mount a directory with `sudo mount -t myramfs none /path/to/dir`. Note that ramfs doesn't use an actual block device. \nTo unload the module use `sudo rmmod ramfs.ko`. Keep in mind to unmount any ramfs directories\nbefore unloading."}
{"url": "https://github.com/ctiedt/rasta-rs", "owner": "ctiedt", "repository_name": "rasta-rs", "date_all_variable_collection": "2023-09-11", "description": null, "size": 64, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "ctiedt", "contributions": 15}, {"contributor": "laugengebaeck", "contributions": 4}, {"contributor": "Mese96", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 69527}], "readme": "# rasta-rs\n\nAn implementation of the Rail Safe Transport Application Protocol (RaSTA) in Rust.\nThis implementation only provides very basic functionality, no redundancy and no\nexplicit retransmission (since it is TCP-based)."}
{"url": "https://github.com/ctiedt/rasta-sys", "owner": "ctiedt", "repository_name": "rasta-sys", "date_all_variable_collection": "2023-09-11", "description": null, "size": 11, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 1, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "ctiedt", "contributions": 1}, {"contributor": "laugengebaeck", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 1537}, {"language": "CMake", "num_chars": 1096}], "readme": "# Rust bindings for RaSTA\n\nRaSTA is a network protocol used in the railway sector. \nThere exists an open-source [C implementation](https://github.com/eulynx-live/rasta-protocol).\nThis library provides unsafe Rust bindings to this implementation.\n\nFor an example, see [`scip_localhost.rs`](examples/scip_localhost.rs)"}
{"url": "https://github.com/ctiedt/retry", "owner": "ctiedt", "repository_name": "retry", "date_all_variable_collection": "2023-09-11", "description": null, "size": 4, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 3518}], "readme": "# retry\n\nProof of concept for a Rust [procedural macro](https://doc.rust-lang.org/reference/procedural-macros.html) to rerun a function if it fails. \nSupports functions returning `Result` or `Option`.\n\n## Usage\n\n```rust\n#[retry(3)]\nfn might_fail() -> Result<(), SomeError> {\n    /* ... */\n}\n```\n\nThis example will run up to four attempts of `might_fail`. You lose the information of possible errors.\nInstead, a function with the `#[retry]` macro will return that it has exceeded its number of retries.\n\n## Warning\n\nThis is just a proof of concept. Procedural macros are dangerous and I am no expert, so there are\nprobably a lot of cases in which this crate will generate wrong code. Proceed at your own risk if\nyou use it!"}
{"url": "https://github.com/ctiedt/revpi-tools-rs", "owner": "ctiedt", "repository_name": "revpi-tools-rs", "date_all_variable_collection": "2023-09-11", "description": null, "size": 13, "stargazers_count": 0, "watchers_count": 0, "language": "C", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "ctiedt", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C", "num_chars": 11643}, {"language": "Rust", "num_chars": 5726}], "readme": "# RevPi Tools in Rust\n\nThis repository contains a library `picontrol` and a `pitest` binary to interact with Revolution Pi industrial computers.\nIt is by no means complete or production-ready yet."}
{"url": "https://github.com/ctiedt/rogue-inc", "owner": "ctiedt", "repository_name": "rogue-inc", "date_all_variable_collection": "2023-09-11", "description": "Informatikprojekt Q4 2018 von Felix Bachstein, Clemens Tiedt und Jonas Tresper", "size": 198, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 22}, {"contributor": "DieHeiligeBratpfanne", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 15662}, {"language": "TeX", "num_chars": 2329}], "readme": "# rogue-inc\nInformatikprojekt Q4 2018 von Felix Bachstein, Clemens Tiedt und Jonas Tresper\n"}
{"url": "https://github.com/ctiedt/rsramfs", "owner": "ctiedt", "repository_name": "rsramfs", "date_all_variable_collection": "2023-09-11", "description": "A Rust Port of the ramfs file system", "size": 182, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 2, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 33}, {"contributor": "Tardigrade00", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["kernel", "kernel-module", "linux", "ramfs", "rsramfs", "rust"], "languages": [{"language": "Rust", "num_chars": 1225225}, {"language": "C", "num_chars": 4622}, {"language": "Makefile", "num_chars": 2405}, {"language": "Shell", "num_chars": 1041}, {"language": "C++", "num_chars": 359}], "readme": "# rsramfs\n\nAn implementation of the `ramfs` file system in [Rust](https://rust-lang.org).\n\n## How to build\n\nYou need a working C toolchain, headers for the kernel you are compiling for and a (nightly) Rust toolchain.\nYou also need `rust-src` (install it with `rustup component add rust-src`).\nTo compile the module, run `make all` from the base directory. Try it out with `./test.sh` or `sudo insmod build/rsramfs.ko` and mount some mount point with the device `none` and the file system type `rsramfs`.\n\n## A short overview\n\n### What `inode.c` does\n\nThe easiest way to create a kernel module in a language other than C is to write some C code that does all the basic work for initializing\na kernel module (which uses C macros and/or inline functions which are hard to call via FFI) and then calls a Rust function to take over.\nIt also exports some functions to do with memory allocation and IO.\n\n### What the Rust files do\n\n### `io.rs` and `mem.rs`\n\nThese files contain functions that have to do with memory allocation and IO, such as a definition of Rust's `print!` macro using `kprintf`.\n\n### `bindings.rs`, `c_structs.rs` and `c_fns.rs`\n\nThese files contain bindings to the Linux kernel interface we use and Rust wrappers around them. Most of these wrappers are hand-written.\n\n### `lib.rs`\n\nThis is probably the most interesting module. It contains all of the `rsramfs` operations such as mounting, creating files etc.\n\n\n## Acknowledgements\n\nOur build system is a modified version of the one found in [souvik1997/kernel-roulette](https://github.com/souvik1997/kernel-roulette). \nFor generating kernel bindings, we used the system provided by [fishinabarrel/linux-kernel-module-rust](https://github.com/fishinabarrel/linux-kernel-module-rust).\n\"Basic neccessities\" such as IO and memory management are also taken from or based on these two modules.\nThe functionality of our file system is an almost direct port of the C code from the [Linux kernel](https://github.com/torvalds/linux/tree/master/fs/ramfs)."}
{"url": "https://github.com/ctiedt/service_levels", "owner": "ctiedt", "repository_name": "service_levels", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "ctiedt", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 654}]}
{"url": "https://github.com/ctiedt/sonic-nodes", "owner": "ctiedt", "repository_name": "sonic-nodes", "date_all_variable_collection": "2023-09-11", "description": null, "size": 3, "stargazers_count": 1, "watchers_count": 1, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 4936}], "readme": "# Sonic nodes\n\nHave you ever used Blender shader nodes? They are an excellent way to visualize shader code\nand can be used to learn the concepts without learning all the details of a shader language\nlike GLSL.\n\nThis project aims to provide a similar experience for creating sound.\n\n## Examples\n\nThe project includes two examples so far.\n\n- [Basic example](examples/basic.rs): How to create a simple node graph\n- [Cpal example](examples/cpal.rs): Output sound generated by sonic nodes using [cpal](https://crates.io/crates/cpal)"}
{"url": "https://github.com/ctiedt/steam_crawler", "owner": "ctiedt", "repository_name": "steam_crawler", "date_all_variable_collection": "2023-09-11", "description": null, "size": 29, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "ctiedt", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 9910}], "readme": "# steam_crawler\n\nA crawler to scrape game information from steam.\n\n## Usage\n\nWith number of titles to return:\n\n```sh\ncargo run -- --count 50 400 50\n```\n\nWith maximum runtime (seconds):\n\n```sh\ncargo run -- --time 120 400 50\n```\n\nThe last two numbers are the \"seed\" game IDs, i.e. the games to start from."}
{"url": "https://github.com/ctiedt/studypoints", "owner": "ctiedt", "repository_name": "studypoints", "date_all_variable_collection": "2023-09-11", "description": "An app to help overcome procrastination", "size": 5644, "stargazers_count": 1, "watchers_count": 1, "language": "Dart", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 3, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 3, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 15}, {"contributor": "batteredgherkin", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["android", "flutter", "procrastination"], "languages": [{"language": "Dart", "num_chars": 45034}, {"language": "Objective-C", "num_chars": 753}, {"language": "Java", "num_chars": 366}], "readme": "# StudyPoints\n\n*StudyPoints* is an app that helps you get organized better by letting you track tasks and receiving in-app rewards to customize your own avatar. \n\nProcrastination is a serious issue, don't let anyone tell you otherwise. But we are here to help you overcome it!\n"}
{"url": "https://github.com/ctiedt/swsl", "owner": "ctiedt", "repository_name": "swsl", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "ctiedt", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# The Safe WebAssembly Standard Library\n\n`swsl` is a proposal for a standard library for safety-critical applications that\ncan be used in a WebAssembly context.\n\n## Contents\n\n### Memory management\n\n### IO Channels\n\n### Miscellaneous utils\n"}
{"url": "https://github.com/ctiedt/tangible_soundscape", "owner": "ctiedt", "repository_name": "tangible_soundscape", "date_all_variable_collection": "2023-09-11", "description": null, "size": 84927, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 15654}, {"language": "Makefile", "num_chars": 171}], "readme": "# Tangible Soundscapes - Sonic Thinking 2023\n\nThis project was created as part of the *Sonic Thinking* and *Design Thinking for Digital Engineering* courses\nin the summer term 2023 at HPI.\n\nIt presents a proof of concept for using miniatures equipped with RFID\nchips to dynamically generate ambient soundscapes in tabletop RPGs.\n\nThere is also a [demo video](https://files.tiedt.dev/demo.mp4).\n\n## Instructions\n\nThe RFID readers are MFRC522 modules connected to an STM32F401RE board. Build the image for the board by calling\n`make` in the `stm32_figure_reader` directory and flash `node.bin` to the board.\n\nConnect the board to a PC with a Mini USB cable and run the `tangible_soundscape_player` binary with the board's serial\nport and the file containing the ruleset as arguments.\n\n## Used sounds\n\nThe example sounds distributed here are taken from freesound.org.\n\n- \"Ambience, Night Wildlife, A.wav\" by InspectorJ (www.jshaw.co.uk)\n- \"10347 single bell campanile loop.wav\" by Robinhood76\n- \"Owl.WAV\" by inchadney\n- \"Birds in the wood.wav\" by emilgasi\n- \"1203_hungarian_sheep.wav\" reinsamba\n- \"tree_creak_04.wav\" by Department64\n- \"frogs in a pond\" by eastierp\n- \"Stream Running Into Pond\" by mhtaylor67"}
{"url": "https://github.com/ctiedt/temperature-example", "owner": "ctiedt", "repository_name": "temperature-example", "date_all_variable_collection": "2023-09-11", "description": null, "size": 11, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "MarcelGarus", "contributions": 2}, {"contributor": "ctiedt", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 6751}, {"language": "Makefile", "num_chars": 378}, {"language": "RPC", "num_chars": 103}], "readme": "## Project Setup\n\nInstall the `thumbv7em-none-eabi` target using\n`rustup target install thumbv7em-none-eabi`.\n\nMake sure that you have the `binutils-arm-none-eabi` package installed.\n\n## Building and flashing\n\nBuild the project using `cargo build --release`. Then run `arm-none-eabi-objcopy -O binary target/thumbv7em-none-eabi/release/node node.bin`.\n\nThe `STM32F401RE` board should appear as a USB drive on the PC.\nCopy the `.bin` file onto it.\n"}
{"url": "https://github.com/ctiedt/tome", "owner": "ctiedt", "repository_name": "tome", "date_all_variable_collection": "2023-09-11", "description": null, "size": 2376, "stargazers_count": 2, "watchers_count": 2, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 12347}, {"language": "HTML", "num_chars": 6255}], "readme": "# Tome - A Rusty Wiki\n\nTome is a super simple, Markdown-based wiki. It is easy to setup and run since it doesn't\nuse a database, but just a directory of Markdown files.\n\n## Todos\n\n- [ ] Media Upload\n- [ ] Edit History for articles\n- [ ] Edit Safety (Locking articles during editing)\n- [ ] User Management (unlikely in the near future)"}
{"url": "https://github.com/ctiedt/vcost-prototypes", "owner": "ctiedt", "repository_name": "vcost-prototypes", "date_all_variable_collection": "2023-09-11", "description": null, "size": 114481, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 5731}, {"language": "Rust", "num_chars": 3397}], "readme": "# Video Conference Soundtrack Prototypes\n\nThis repository contains my prototypes and documentation from the Sonic Thinking and Neurodesign Lecture classes\nat Hasso Plattner Institute in the winter term 2021/2022.\n\nMy project evaluated the idea of adding music to video conferences to enhance the empathy between participants.\n\n## Contents\n\n- [Prototype 0](vcost-prototype-0/): My first prototype, generating music on the fly using the `music21` package\n- [Prototype 1](vcost-prototype-1/): My second prototype, using pre-recorded music segments for different moods\n- [Prototype 2](vcost-prototype-2/): The final prototype of this semester, using a multithreaded approach\n  to eliminate gaps between emotion recognition and music playback.\n- [Documentation](documentation/): The presentations from class and bibliography\n\n## Acknowledgements\n\nThe music used in prototype 1 and 2 was kindly provided by [Marcel Garus](https://github.com/MarcelGarus) under a MIT license."}
{"url": "https://github.com/ctiedt/voronoi", "owner": "ctiedt", "repository_name": "voronoi", "date_all_variable_collection": "2023-09-11", "description": "A simple Voronoi implementation in Rust", "size": 7, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 1869}]}
{"url": "https://github.com/ctiedt/vosk-voice-assistant", "owner": "ctiedt", "repository_name": "vosk-voice-assistant", "date_all_variable_collection": "2023-09-11", "description": null, "size": 45386, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 4133}], "readme": "# Vosk-Voice-Assistant\n\nA simple voice assistant to control [HomeAssistant](https://home-assistant.io).\nCurrently supports only German language, but the model can easily be changed."}
{"url": "https://github.com/ctiedt/wrapgen", "owner": "ctiedt", "repository_name": "wrapgen", "date_all_variable_collection": "2023-09-11", "description": null, "size": 23, "stargazers_count": 1, "watchers_count": 1, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "ctiedt", "contributions": 15}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": true, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 15358}], "readme": "# wrapgen\n\n![Crates.io](https://img.shields.io/crates/v/wrapgen) ![Crates.io](https://img.shields.io/crates/d/wrapgen)\n\n`wrapgen` is a tool to automatically generate Rust wrappers around C functions called via FFI.\nIt will wrap pointer returns in an `Option` and `int` returns in a `Result`.\nAs of now, `wrapgen` only works if your functions adhere to the C convention of returning\n0 on a successful run and another value otherwise.\n\n## How to use `wrapgen`\n\nYou can use wrapgen as a standalone binary:\n\n`wrapgen input.rs output.rs`\n\nwhere `input.rs` contains one function declaration per line\n\nor include it in your `build.rs` file:\n\n```rust\nfn main() {\n    WrapGen::new(\"input1.rs\")\n        .add_file(\"input2.rs\")\n        .function(\"fn my_test_fn(arg1: cty::c_int) -> cty::c_int\")\n        .prefix(\"rs_\")\n        .use_core(false)\n        .generate(\"output.rs\");\n}\n```"}
{"url": "https://github.com/dagtann/auditPoster", "owner": "dagtann", "repository_name": "auditPoster", "date_all_variable_collection": "2023-09-11", "description": "Postergrafiken f\u00fcr das DD Beiratsaudit vom 12./13. November 2016", "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 10961}]}
{"url": "https://github.com/dagtann/blog", "owner": "dagtann", "repository_name": "blog", "date_all_variable_collection": "2023-09-11", "description": null, "size": 3765, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "dagtann", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 5359}], "readme": "# blog"}
{"url": "https://github.com/dagtann/boardgames", "owner": "dagtann", "repository_name": "boardgames", "date_all_variable_collection": "2023-09-11", "description": "Analysis of Gabriele Baldassarre's Board Game Dataset", "size": 2, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "dagtann", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 481}]}
{"url": "https://github.com/dagtann/datasciencecoursera", "owner": "dagtann", "repository_name": "datasciencecoursera", "date_all_variable_collection": "2023-09-11", "description": null, "size": 164, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "dagtann", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 26775}], "readme": "This repo holds my notes on the Data Science classes offered\nby John Hopkins University on Coursera."}
{"url": "https://github.com/dagtann/esDigitalCareerDay", "owner": "dagtann", "repository_name": "esDigitalCareerDay", "date_all_variable_collection": "2023-09-11", "description": null, "size": 9525, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "dagtann", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# esDigitalCareerDay\n\nDieses Repository enth\u00e4lt s\u00e4mtliche Materialien, die das Team WP Support im\nRahmen des [Ebner Stolz Digital Career Day 2021](https://www.ebnerstolz.de/de/digital-career-day-368886.html) pr\u00e4sentiert.\nWendet euch bei Nachfragen gerne an dag.tanneberg@ebnerstolz.de!\n\n## Data-Driven Auditing: Digitale Werkzeuge f\u00fcr die Wirtschaftspr\u00fcfung\n\nAusgel\u00f6st durch die Digitalisierung beschleunigt sich das Gesch\u00e4ft ganzer Wirtschaftsbranchen massiv und die entstehenden Zahlenwerke wachsen enorm. Im Zangengriff von Velozit\u00e4t und Quantit\u00e4t braucht die Wirtschaftspr\u00fcfung neue Werkzeuge, um ihren Auftrag effizient und effektiv zu erf\u00fcllen. Das Team WP Support stellt sich dieser Herausforderung. Im Rahmen des Vortrags zeigen wir, wie sich pr\u00fcferisches Wissen mit Data Science und Coding in digitale Werkzeuge f\u00fcr die Wirtschaftspr\u00fcfung \u00fcbersetzt. "}
{"url": "https://github.com/dagtann/hardTimes", "owner": "dagtann", "repository_name": "hardTimes", "date_all_variable_collection": "2023-09-11", "description": "Replication materials for \"Hard Times and Regime Failure. Autocratic Responses to Economic Downturns\"", "size": 69, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "dagtann", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 78958}, {"language": "Stata", "num_chars": 2768}], "readme": "# Hard Times and Regime Failure\n\nThis repository contains all code required to reproduce the results presented in [Dag Tanneberg/Christoph H. Stefes/Wolfang Merkel (2013): Hard Times and Regime Failure. Autocratic Responses to Economic Downturns. In: *Contemporary Politics*, **19**(1), pp. 115-129](http://www.tandfonline.com/doi/abs/10.1080/13569775.2013.773206). The data is available on request only as it includes variables that were licensed from [Databanks International](http://www.cntsdata.com/). Please [email](mailto:dag.tanneberg@wzb.eu) me for further information."}
{"url": "https://github.com/dagtann/hrplanner", "owner": "dagtann", "repository_name": "hrplanner", "date_all_variable_collection": "2023-09-11", "description": "Track staff availability", "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "dagtann", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# hrplanner\nTrack staff availability\n"}
{"url": "https://github.com/dagtann/hrps_conflict", "owner": "dagtann", "repository_name": "hrps_conflict", "date_all_variable_collection": "2023-09-11", "description": "Follow up on Cingranelli's and Filippov's critique of Fariss' & Schnakenberg's HRPS", "size": 2563, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "dagtann", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 140165}]}
{"url": "https://github.com/dagtann/hrps_v1", "owner": "dagtann", "repository_name": "hrps_v1", "date_all_variable_collection": "2023-09-11", "description": "Experimenting with Bayesian IRT modeling based on the Human Rights Protection Scores v1", "size": 100, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "dagtann", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 25196}], "readme": "# hrps_v1\nExperimenting with Bayesian IRT modeling based on the Human Rights Protection Scores v1\n"}
{"url": "https://github.com/dagtann/kk2r", "owner": "dagtann", "repository_name": "kk2r", "date_all_variable_collection": "2023-09-11", "description": "Convert example code in Kohler/Kreuter (2017): Datenanalyse mit STATA. 5th ed. Berlin/Boston: Walter de Gruyter to R.", "size": 1319, "stargazers_count": 0, "watchers_count": 0, "language": "Stata", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "dagtann", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Stata", "num_chars": 83960}, {"language": "R", "num_chars": 3440}]}
{"url": "https://github.com/dagtann/kruschke2", "owner": "dagtann", "repository_name": "kruschke2", "date_all_variable_collection": "2023-09-11", "description": "Exercises and solutions for Kruschke, Doing bayesian data analysis, 2nd edition", "size": 631, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "dagtann", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 744626}, {"language": "Rebol", "num_chars": 5}], "readme": "# kruschke2\nExercises and solutions for Kruschke, Doing bayesian data analysis, 2nd edition\n"}
{"url": "https://github.com/dagtann/learning", "owner": "dagtann", "repository_name": "learning", "date_all_variable_collection": "2023-09-11", "description": "Snippets and exercises from various textbooks on programming, statistical modelling, and simulation", "size": 1278, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "dagtann", "contributions": 52}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 1049091}, {"language": "Python", "num_chars": 621611}, {"language": "R", "num_chars": 34286}], "readme": "# learning\nSnippets and exercises from various textbooks on programming, statistical modelling, and simulation\n"}
{"url": "https://github.com/dagtann/legitdev", "owner": "dagtann", "repository_name": "legitdev", "date_all_variable_collection": "2023-09-11", "description": "Replication package for \"Autokratische Regimelegitimation und soziale Entwicklung\"", "size": 692, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "dagtann", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 197384}, {"language": "HTML", "num_chars": 27099}], "readme": "# legitdev\nReplication package for \"Autokratische Regimelegitimation und soziale Entwicklung\"\n"}
{"url": "https://github.com/dagtann/lpthw", "owner": "dagtann", "repository_name": "lpthw", "date_all_variable_collection": "2023-09-11", "description": "Learning Python", "size": 11, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "dagtann", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 6016}], "readme": "# lpthw\nLearning Python\n\nThis repo follows Zed Shaw (2014): Learn Python the hard way, 3rd ed., Addison-Wesley: Upper Saddle River, NJ.\n"}
{"url": "https://github.com/dagtann/mleMidterm", "owner": "dagtann", "repository_name": "mleMidterm", "date_all_variable_collection": "2023-09-11", "description": "Implement OLS in R", "size": 456, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "dagtann", "contributions": 17}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 16689}, {"language": "TeX", "num_chars": 5896}], "readme": "# MLE Midterm\n\nThese scripts implements OLS in R for my midterm in MLE at Duke \nUniversity."}
{"url": "https://github.com/dagtann/mleTermpaper", "owner": "dagtann", "repository_name": "mleTermpaper", "date_all_variable_collection": "2023-09-11", "description": "Replication project for my MLE class at Duke University", "size": 10168, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "dagtann", "contributions": 43}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 866830}, {"language": "R", "num_chars": 156610}], "readme": "This repo documents my replication of Frantz, Erica & Andrea Kendall-Taylor\n(2014): A dictator's toolkit: Understanding how co-optation affects\nrepression in autocracies, in: Journal of Peace Research, Vol. 51(3), \npp. 332-346. To follow my __replication__ get the data [here](http://jpr.sagepub.com/content/51/3/332/suppl/DC1). To follow my __extension__ of their work you will need the [Civil Liberties Dataset](http://ps.au.dk/en/research/research-projects/dedere/datasets/) and some raw data that Erica Frantz kindly shared with me. I'll post the entire required data on [dataverse.org](http://dataverse.org/) as soon as I got her permission to do so.\n"}
{"url": "https://github.com/dagtann/pcqr", "owner": "dagtann", "repository_name": "pcqr", "date_all_variable_collection": "2023-09-11", "description": "Materials for the two-day workshop \"Introduction to R\" at University of Potsdam, Germany", "size": 7611, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "dagtann", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# pcqr\nMaterials for the two-day workshop \"Introduction to *R*\" at the University of Potsdam, Germany.\n"}
{"url": "https://github.com/dagtann/pecs", "owner": "dagtann", "repository_name": "pecs", "date_all_variable_collection": "2023-09-11", "description": null, "size": 80136, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "dagtann", "contributions": 132}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 162238}, {"language": "TeX", "num_chars": 13006}, {"language": "Stata", "num_chars": 1821}, {"language": "Rich Text Format", "num_chars": 1188}], "readme": "# Readme\n\nThis repository contains all data and code required that were used in a joint\npublication effort by Prof. Dr. Steffen Ganghof, Dr. Sebastian Eppner, and Dr. Dag Tanneberg.\n\n## Folder list\n\n- data ... contains all data used in our analyses\n- manuscript ... contains all manuscript files\n- nbk ... contains development notebooks\n- out ... contains all figures, graphs, and tables generated\n- prestudies ... contains prior, but related projects\n- src ... contains our source code\n"}
{"url": "https://github.com/dagtann/random-data-tables", "owner": "dagtann", "repository_name": "random-data-tables", "date_all_variable_collection": "2023-09-11", "description": "Created with StackBlitz \u26a1\ufe0f", "size": 15, "stargazers_count": 0, "watchers_count": 0, "language": "Svelte", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "dagtann", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Svelte", "num_chars": 1903}, {"language": "CSS", "num_chars": 1310}, {"language": "JavaScript", "num_chars": 762}, {"language": "HTML", "num_chars": 626}], "readme": "# random-data-tables\n\n[Edit on StackBlitz \u26a1\ufe0f](https://stackblitz.com/edit/vitejs-vite-kntkke)"}
{"url": "https://github.com/dagtann/reproducibleResearch", "owner": "dagtann", "repository_name": "reproducibleResearch", "date_all_variable_collection": "2023-09-11", "description": "Draft for Reproducible Workflows in Social Science", "size": 1053, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "krauwe", "contributions": 8}, {"contributor": "dagtann", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 22858}, {"language": "HTML", "num_chars": 15765}], "readme": "# reproducibleResearch\nDraft for Reproducible Workflows in Social Science\n"}
{"url": "https://github.com/dagtann/stabilityAtr", "owner": "dagtann", "repository_name": "stabilityAtr", "date_all_variable_collection": "2023-09-11", "description": "Graphs and algorithms for the research project \"Critical Junctures and the Survival of Dictatorships. Explaining the Stability of Autocratic Regimes\"", "size": 14, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "dagtann", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 12947}], "readme": "This repo contains code required to reproduce some of my contributions to a \ndrafted volume on critical junctures and the stability of dictatorships. \nVisit our [webpage](http://www.wzb.eu/en/research/dynamics-of-political-systems/democracy-and-democratization/critical-junctures).\n"}
{"url": "https://github.com/dagtann/svelte-feedback-app", "owner": "dagtann", "repository_name": "svelte-feedback-app", "date_all_variable_collection": "2023-09-11", "description": null, "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/dagtann/teaching", "owner": "dagtann", "repository_name": "teaching", "date_all_variable_collection": "2023-09-11", "description": "Bits and pieces for teaching", "size": 52105, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "dagtann", "contributions": 165}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 5194079}, {"language": "HTML", "num_chars": 3630302}, {"language": "R", "num_chars": 59434}, {"language": "Rebol", "num_chars": 223}], "readme": "# teaching\nBits and pieces for teaching\n"}
{"url": "https://github.com/dagtann/timeR", "owner": "dagtann", "repository_name": "timeR", "date_all_variable_collection": "2023-09-11", "description": "Time Tracking, done Shiny", "size": 10, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "dagtann", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 668}], "readme": "# timeR\nTime Tracking, done Shiny\n"}
{"url": "https://github.com/dagtann/vizTricks", "owner": "dagtann", "repository_name": "vizTricks", "date_all_variable_collection": "2023-09-11", "description": "This repo holds case studies and tutorials on data visualization using R.", "size": 1769, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "dagtann", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 3485953}, {"language": "R", "num_chars": 1608}], "readme": "# vizTricks\nThis repo holds case studies and tutorials on data visualization using R. It documents my own learning process as much as it provides applied examples for everyone else who might be interested.\n"}
{"url": "https://github.com/dagtann/wimaCareer", "owner": "dagtann", "repository_name": "wimaCareer", "date_all_variable_collection": "2023-09-11", "description": "Case study material that exemplifies our inhouse data science philosophy", "size": 5, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "dagtann", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 2911}]}
{"url": "https://github.com/damariszurell/4D-niche-overlap", "owner": "damariszurell", "repository_name": "4D-niche-overlap", "date_all_variable_collection": "2023-09-11", "description": "Codes for: Zurell D, Gallien L, Graham CH, Zimmermann NE (2018) Do long-distance migratory birds track their niche through seasons? Journal of Biogeography 45: 1459-1468.doi: 10.1111/jbi.13351", "size": 24, "stargazers_count": 4, "watchers_count": 4, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 4, "default_branch": "master", "contributors": [{"contributor": "damariszurell", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 6293}], "readme": "This repo contains the codes extending the niche overlap analyses in the ecospat package to 3D and 4D niches.\n\nReference: Zurell D, Gallien L, Graham CH, Zimmermann NE (2018) Do long-distance migratory birds track their niche through seasons? Journal of Biogeography 45: 1459-1468. doi: 10.1111/jbi.13351\n\n---\n\n\nAim\n\nSeasonal migration by animals is an extensively studied, global phenomenon. Yet, we still lack a general understanding whether migrants track their niche between summer and winter ranges (following fixed environmental conditions throughout the year) and which mechanisms influence this behaviour. Here, we assessed the degree of seasonal niche tracking in Holarctic long\u2010distance migratory birds (n = 717; excluding very rare species) and evaluate the influence of biogeographic (regional and range characteristics) and ecological (trophic) factors on tracking.\nLocation\n\nGlobal.\nTaxon\n\nBirds.\nMethods\n\nWe calculated seasonal niche overlap by means of ordination, and estimated the degree of niche tracking using similarity tests. Niche tracking was evaluated for two different environmental predictor sets: climate and vegetation productivity (reflecting resource selection) versus climate and land cover (reflecting habitat choice). Multivariate phylogenetic regression was used to evaluate effects of biogeographic and ecological traits on niche tracking.\nResults\n\nWe found significant niche tracking in 65\u201395% of species with a higher proportion of species significantly tracking climate and land cover compared to climate and vegetation productivity. Traits explained 12\u201318% of the variance in niche tracking with strong regional differences, a negative effect of migration distance and positive effects of range size on niche tracking. The effects of niche breadth and trophic traits were less pronounced and varied between environmental predictor sets.\nMain conclusions\n\nOur results indicate that at coarse spatial resolution, long\u2010distance migratory species tend to track their niche and select largely similar environments through seasons. Stronger niche tracking of land cover could reflect conservatism in habitat selection across seasons, for example for foraging and roosting. This conservatism towards land cover should be considered when making predictions to future environments. A better understanding of the factors that constrain seasonal range limits will be critical for predicting how migration patterns could respond to future environmental changes.\n"}
{"url": "https://github.com/damariszurell/CLEWS-EDB", "owner": "damariszurell", "repository_name": "CLEWS-EDB", "date_all_variable_collection": "2023-09-11", "description": "Practicals for the CLEWS-Master module Ecosystem Dynamics and Biodiversity", "size": 182034, "stargazers_count": 1, "watchers_count": 1, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "damariszurell", "contributions": 53}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 1044630}, {"language": "CSS", "num_chars": 228927}, {"language": "TeX", "num_chars": 98360}, {"language": "JavaScript", "num_chars": 40450}], "readme": "# CLEWS-EDB\nPracticals for the CLEWS-Master module \"Ecosystem Dynamics and Biodiversity\" at Univ. Potsdam: https://damariszurell.github.io/CLEWS-EDB/\n"}
{"url": "https://github.com/damariszurell/EEC-Macro", "owner": "damariszurell", "repository_name": "EEC-Macro", "date_all_variable_collection": "2023-09-11", "description": "R practicals for the course \"Macroecological analyses\" at Univ. Potsdam", "size": 30903, "stargazers_count": 3, "watchers_count": 3, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 3, "default_branch": "main", "contributors": [{"contributor": "damariszurell", "contributions": 13}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# EEC-Macro\nR practicals for the course \"Macroecological analyses\" at Univ. Potsdam have moved to the website [https://damariszurell.github.io/EEC-MGC/](https://damariszurell.github.io/EEC-MGC/).\n"}
{"url": "https://github.com/damariszurell/EEC-MGC", "owner": "damariszurell", "repository_name": "EEC-MGC", "date_all_variable_collection": "2023-09-11", "description": null, "size": 106530, "stargazers_count": 2, "watchers_count": 2, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "main", "contributors": [{"contributor": "damariszurell", "contributions": 37}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 584380}, {"language": "CSS", "num_chars": 229817}, {"language": "TeX", "num_chars": 67068}, {"language": "JavaScript", "num_chars": 41232}], "readme": "# EEC-MGC\n\nPracticals for Master module \"Macroecology and global change\" at Univ. Potsdam: https://damariszurell.github.io/EEC-MGC/\n"}
{"url": "https://github.com/damariszurell/EEC-QCB", "owner": "damariszurell", "repository_name": "EEC-QCB", "date_all_variable_collection": "2023-09-11", "description": null, "size": 54173, "stargazers_count": 1, "watchers_count": 1, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "damariszurell", "contributions": 34}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 467491}, {"language": "CSS", "num_chars": 187634}, {"language": "TeX", "num_chars": 54020}, {"language": "JavaScript", "num_chars": 39943}], "readme": "# EEC-QCB\n\nhttps://damariszurell.github.io/EEC-QCB/\n\nThe Master module \u201cQuantitative conservation biogeography\u201d is an elective module within the Master programme \u201cEcology, Evolution and Conservation (EEC)\u201d at the University of Potsdam.\n\n**Module coordinator:** Prof. Dr. Damaris Zurell\n**Contributors:** Dr. Guillermo Fandos, Anne-Kathleen Malchow, Dr. Jette Reeg\n\nThis site provides the accompanying R practicals for the module. Topics include:\n\n\n- Occupancy modelling: data preparation, fitting simple occupancy-detection models in unmarked, evaluating occupancy models and making predictions, dynamic occupancy models\n- Spatial explicit population modelling: modelling dispersal and demography, assessing reintroduction success and population viability under global change - based on RangeShiftR\n\n\nPrerequisites for the module are: basic understanding of conservation biogeography (e.g. from accompanying lecture), basic knowledge of statistics, basic knowledge in geographic information systems, basic understanding of R. If you don\u2019t feel comfortable with R yet, you should work through the [R preparatory course](https://damariszurell.github.io/EEC-R-prep/) first.\n"}
{"url": "https://github.com/damariszurell/EEC-R-prep", "owner": "damariszurell", "repository_name": "EEC-R-prep", "date_all_variable_collection": "2023-09-11", "description": null, "size": 14463, "stargazers_count": 1, "watchers_count": 1, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "damariszurell", "contributions": 40}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 238629}, {"language": "CSS", "num_chars": 48145}, {"language": "TeX", "num_chars": 47021}, {"language": "JavaScript", "num_chars": 39943}, {"language": "R", "num_chars": 17691}], "readme": "# EEC-R-prep\n\nPracticals for R preparatory course: https://damariszurell.github.io/EEC-R-prep/\n"}
{"url": "https://github.com/damariszurell/EEC-SDM", "owner": "damariszurell", "repository_name": "EEC-SDM", "date_all_variable_collection": "2023-09-11", "description": "The course **Introduction to species distribution modelling*** is part of the Master module \"Macroecology and global change\" in the Master programme \"Ecology, Evolution and Conservation (EEC)\" at the University of Potsdam. ", "size": 36446, "stargazers_count": 3, "watchers_count": 3, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "damariszurell", "contributions": 17}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# EEC-SDM\nR practicals for the course **Introduction to species distribution modelling** at the University of Potsdam have been moved to the website [https://damariszurell.github.io/EEC-MGC/](https://damariszurell.github.io/EEC-MGC/).\n"}
{"url": "https://github.com/damariszurell/EFForTS-workshop-2023", "owner": "damariszurell", "repository_name": "EFForTS-workshop-2023", "date_all_variable_collection": "2023-09-11", "description": "Upscaling workshop CRC-990 EFForTS G\u00f6ttingen 14-Feb-2023", "size": 11897, "stargazers_count": 6, "watchers_count": 6, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 6, "default_branch": "main", "contributors": [{"contributor": "damariszurell", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 27740}], "readme": "# EFForTS upscaling workshop 2023: Introduction to species distribution models (SDMs)\nUpscaling workshop CRC-990 EFForTS G\u00f6ttingen 14-Feb-2023\n\nTeaching material by Damaris Zurell (Ecology & Macroecology, Univ. Potsdam), damaris@zurell.de, https://damariszurell.github.io\n\nDownload the zip-folder of this repository and unpack it. Open the script \"SDM_RingOuzel.R\" and get started.\n\n## Additional resources for self-study\n\n* Practicals:\n  * Introduction to SDMs: https://damariszurell.github.io/SDM-Intro/ \n  * Teaching resources (Master level) with more details on single SDM steps: https://damariszurell.github.io/EEC-MGC/ \n* Lectures:\n  * International lecture series from experts on ecological niche modelling: all videos available online, see Table 1 in: Peterson et al. (2022) ENM2020: A Free Online Course and Set of Resources on Modeling Species\u2019 Niches and Distributions. Biodiversity Informatics 17: 1-9. https://journals.ku.edu/jbi/article/view/15016\n"}
{"url": "https://github.com/damariszurell/IBM_OptimalForaging", "owner": "damariszurell", "repository_name": "IBM_OptimalForaging", "date_all_variable_collection": "2023-09-11", "description": "C++ source code for the individual-based model of optimal foraging in white storks introduced in Zurell et al. (2015) Oikos. The model predicts the spatial structure and breeding success of white stork populations in heterogeneous landscapes by explicitly simulating foraging behaviour and home range formation of individuals competing for resources. Because resource depletion is modelled explicitly, the model can predict the maximum carrying capacity of white stork breeding populations in different landscapes, and density-dependent breeding success by inducing fixed stork density levels below carrying capacity. Different behavioural options for the optimal foraging routine and the home range optimisation can be made, and the model also allows tracking individual movement paths. Please note that the code is not optimised for custom use. For any questions, please feel free to contact me via email.", "size": 846, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "damariszurell", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 146773}], "readme": "# IBM_OptimalForaging\nC++ source code for the individual-based model of optimal foraging in white storks introduced in Zurell et al. (2015) Oikos. The model predicts the spatial structure and breeding success of white stork populations in heterogeneous landscapes by explicitly simulating foraging behaviour and home range formation of individuals competing for resources. Because resource depletion is modelled explicitly, the model can predict the maximum carrying capacity of white stork breeding populations in different landscapes, and density-dependent breeding success by inducing fixed stork density levels below carrying capacity. Different behavioural options for the optimal foraging routine and the home range optimisation can be made, and the model also allows tracking individual movement paths. Please note that the code is not optimised for custom use. For any questions, please feel free to contact me via email.\n\nThe main file is breeding.cpp. An example landscape file is also included to run the model (lc_33_stat.txt).\nMore detailed description of the IBM submodels can be found in the Online Appendix of the Journal article (oik-01294_appendix.pdf).\n\nReference: Zurell D, Eggers U, Kaatz M, Rotics S, Sapir N, Wikelski M, Nathan R, Jeltsch F (2015). Individual-based modelling of resource competition to predict density-dependent population dynamics: a case study with white storks. Oikos 124: 319-330.\n"}
{"url": "https://github.com/damariszurell/RangeshiftR-tutorial", "owner": "damariszurell", "repository_name": "RangeshiftR-tutorial", "date_all_variable_collection": "2023-09-11", "description": "This tutorial will introduce the main features of the new R package RangeShiftR. Examples follow those provided in the original RangeShifter publication (Bocedi et al. 2014): https://doi.org/10.1111/2041-210X.12162.", "size": 14344, "stargazers_count": 2, "watchers_count": 2, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "damariszurell", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# RangeshiftR-tutorial\nThe RangeshiftR tutorial website moved to https://rangeshifter.github.io/RangeshiftR-tutorials/\n"}
{"url": "https://github.com/damariszurell/Rcodes_MapNovelEnvironments_SDMs", "owner": "damariszurell", "repository_name": "Rcodes_MapNovelEnvironments_SDMs", "date_all_variable_collection": "2023-09-11", "description": "Inflated response curves and environmental overlap masks for species distribution models SDMs (R codes). Here you can download the R codes for inflated SDM response curves and environmental overlap masks introduced in Zurell et al. (2012) DDI. These simple functions facilitate visualisation of multi-dimensional SDM response and of model extrapolations to novel (=unsampled) environments.  Inflated response curves are an extension of conventional partial dependence plots that show the effects of one variable on the response while accounting not only for the average effects of all other variables but also for minimum and maximum (and median and quartile) values. Thus, they are basically an abstracted 2D version of the multidimensional response surfaces. Their advantages are that (1) they are explicit about the shape of the response at different values of all other variables, and (2) make the responses clear if interactions are (implicitly or explicitly) included in SDMs.  Environmental overlap masks compare two datasets (sampled data and prediction data, e.g. climate change scenario or different geographical area) and identify novel environments, meaning both environmental conditions beyond the sampled ranges of the single variables and novel combinations of environmental variables. ", "size": 761, "stargazers_count": 3, "watchers_count": 3, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "damariszurell", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 20950}], "readme": "# Rcodes_MapNovelEnvironments_SDMs\nInflated response curves and environmental overlap masks for species distribution models SDMs (R codes). Here you can download the R codes for inflated SDM response curves and environmental overlap masks introduced in Zurell et al. (2012) DDI. These simple functions facilitate visualisation of multi-dimensional SDM response and of model extrapolations to novel (=unsampled) environments.  Inflated response curves are an extension of conventional partial dependence plots that show the effects of one variable on the response while accounting not only for the average effects of all other variables but also for minimum and maximum (and median and quartile) values. Thus, they are basically an abstracted 2D version of the multidimensional response surfaces. Their advantages are that (1) they are explicit about the shape of the response at different values of all other variables, and (2) make the responses clear if interactions are (implicitly or explicitly) included in SDMs.  Environmental overlap masks compare two datasets (sampled data and prediction data, e.g. climate change scenario or different geographical area) and identify novel environments, meaning both environmental conditions beyond the sampled ranges of the single variables and novel combinations of environmental variables. \n\nR codes are available for the functions (AppendixS1-functions.r) and for an example using simulated data (AppendixS1.r). \n\nMore info on how the R functions inflated.response() and eo.mask() work, can be found in the Online Supplementary material of the published article (DDI_887_sm_AppendixS2-S4.pdf).\n\nReference: Zurell D, Elith J, Schr\u00f6der B (2012). Predicting to new environments: tools for visualising model behaviour and impacts on mapped distributions. Diversity and Distributions 18:628-634. \n"}
{"url": "https://github.com/damariszurell/SDM-Intro", "owner": "damariszurell", "repository_name": "SDM-Intro", "date_all_variable_collection": "2023-09-11", "description": "Introduction to species distribution modelling", "size": 28325, "stargazers_count": 2, "watchers_count": 2, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "damariszurell", "contributions": 19}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 7065704}], "readme": "# SDM-Intro\nCourse materials for an \"Introduction to species distribution modelling\"\n\n"}
{"url": "https://github.com/damariszurell/SSDM-JSDM", "owner": "damariszurell", "repository_name": "SSDM-JSDM", "date_all_variable_collection": "2023-09-11", "description": "Codes for Zurell et al. (2020) Testing species assemblage predictions from stacked and joint species distribution models. Journal of Biogeography 47: 101-113. DOI: 10.1111/jbi.13608.", "size": 34, "stargazers_count": 12, "watchers_count": 12, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 12, "default_branch": "master", "contributors": [{"contributor": "damariszurell", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 39195}], "readme": "# SSDM-JSDM\nThis repository contains all codes to reproduce the results presented in: \n\nZurell et al. (2020) Testing species assemblage predictions from stacked and joint species distribution models. Journal of Biogeography 47: 101-113. DOI: [10.1111/jbi.13608](https://doi.org/10.1111/jbi.13608).\n\nData Availability Statement: The species data were provided by courtesy of the Swiss Ornithological Institute and the Swiss Forest Inventory. The presence\u2013absence data (with geographical coordinates removed) and the environmental predictor data are available on Dryad (https://doi.org/10.5061/dryad.k88v330). \n\n-------------------\n**Abstract**\n\n*Aim*\nPredicting the spatial distribution of species assemblages remains an important challenge in biogeography. Recently, it has been proposed to extend correlative species distribution models (SDMs) by taking into account (a) covariance between species occurrences in so\u2010called joint species distribution models (JSDMs) and (b) ecological assembly rules within the SESAM (spatially explicit species assemblage modelling) framework. Yet, little guidance exists on how these approaches could be combined. We, thus, aim to compare the accuracy of assemblage predictions derived from stacked and from joint SDMs.\n\n*Location*\nSwitzerland.\n\n*Taxon*\nBirds, tree species.\n\n*Methods*\nBased on two monitoring schemes (national forest inventory and Swiss breeding bird atlas), we built SDMs and JSDMs for tree species (at 100 m resolution) and forest birds (at 1 km resolution). We tested accuracy of species assemblage and richness predictions on holdout data using different stacking procedures and ecological assembly rules.\n\n*Results*\nDespite minor differences, results were consistent between birds and tree species. Cross\u2010validated species\u2010level model performance was generally higher in SDMs than JSDMs. Differences in species richness and assemblage predictions were larger between stacking procedures and ecological assembly rules than between stacked SDMs and JSDMs. On average, predictions were slightly better for stacked SDMs compared to JSDMs, probabilistic stacks outperformed binary stacks, and ecological assembly rules yielded best predictions.\n\n*Main conclusions*\nWhen predicting the composition of species assemblages, the choice of stacking procedure and ecological assembly rule seems more decisive than differences in underlying model type (SDM vs. JSDM). JSDMs do not seem to improve community predictions compared to SDMs or improve predictions for rare species. Still, JSDMs may provide additional insights into community assembly and may help deriving hypotheses about prevailing biotic interactions in the system. We provide simple rules of thumb for choosing appropriate modelling pathways. Future studies should test these preliminary guidelines for other taxa and biogeographical realms as well as for other JSDM algorithms.\n\n-------------------\n"}
{"url": "https://github.com/DanieleMaselli/gestalten-in-code", "owner": "DanieleMaselli", "repository_name": "gestalten-in-code", "date_all_variable_collection": "2023-09-11", "description": null, "size": 2399, "stargazers_count": 1, "watchers_count": 1, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "DanieleMaselli", "contributions": 63}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "## Git commands\n\n\n#### from terminal\n```bash\ncd working-directory\ngit add .  \ngit commit -m \"Message Describing the push\"\ngit push\n```\n\n## Gestalten in Code \n\n\n####_analog algorithm_\n\n_Draw round shapes in vertical and horizontal which differ from the diameter.\nCreate lines that merge into different points._\n\n\n\n\n\n\n\n\n\n![01](https://cloud.githubusercontent.com/assets/23034957/19771416/2c6749a4-9c63-11e6-8571-091066470f56.jpg)\n\n![bozze](https://cloud.githubusercontent.com/assets/23034957/19812070/63ff4692-9d34-11e6-8252-78d4d66a9d92.jpg)\n\n\n\n####_elaborate algorithm_\n\n_Draws circles of various sizes throughout the sheet distant each other. Trace straight lines which intersect but do not touch the circles_ \n\n\n![tree](https://cloud.githubusercontent.com/assets/23034957/19840120/91989d8a-9eef-11e6-97c8-a81572c9b18f.png)\n![aaaaaaaa](https://cloud.githubusercontent.com/assets/23034957/19841155/25541b2e-9f06-11e6-99b2-a75c0593d960.png)\n![sdk](https://cloud.githubusercontent.com/assets/23034957/19841133/a8982f30-9f05-11e6-8166-94b046e4fc81.png)\n\n\n\n\n###personal thoughs\n\n_My second attempt for an analogue algorithm was more accurate on the description. Even it was explained very well, most of the people draw something that i never though about it. I didn't wont to create a text that scares the reader or make him think too much for concluding an action. For that reason I found interesting the different visual tension giving from a circle and a line to create some sort of grid. While looking on different drawings, we can recognize that every person gives a different touch and express them self in different way by just using a circle and a line. The problems for creating my expectation for this work, was more on getting the people covering the whole paper with circle and lines, and not just 3 or 4 circles. But I like the results, even I expected to create more some sort of texture maze all over the paper._\n"}
{"url": "https://github.com/DanieleMaselli/Houdini_Python", "owner": "DanieleMaselli", "repository_name": "Houdini_Python", "date_all_variable_collection": "2023-09-11", "description": null, "size": 57, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "DanieleMaselli", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 17291}], "readme": "# Houdini_Python"}
{"url": "https://github.com/DanieleMaselli/Interacting-with-the-canvas-Web-Audio-API", "owner": "DanieleMaselli", "repository_name": "Interacting-with-the-canvas-Web-Audio-API", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1985, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "DanieleMaselli", "contributions": 73}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1146}, {"language": "HTML", "num_chars": 267}], "readme": "# Interacting with the Canvas + Web Audio API\n\n\n#### The Canvas Element: \n\nA canvas is a single DOM element that encapsulates a picture. To create a new canvas, we first need a context. This object provides us a drawing interface. There are currently two supported styles: \"2d\" for two-dimensional graphics and WebGL for three-dimensional graphics:  \n\n\n```Javascript\n\nvar canvas = document.querySelector('#canvas');\nvar context = canvas.getContext('2d');\n```\nThis method is gonna determine the available `width` and `height` of the browser window's content area. \n\n```Javascript\ncanvas.width = window.innerWidth;\ncanvas.height = window.innerHeight;\n\n```\n#### Step 1: mousemove coordinates\n\nTo get the x, y coordinates of our mouse, we first need to create an EventListener on the DOM Element representing the screen (window). An EventListener is a function that will get called whenever an event occurs on a DOM Element. To attach an EventListener we need to call the function `<DOMElement>.addEventListener` with two arguments. The first argument is a string with the name of the `<event>` we want to monitor (in this case 'mousemove'). The second argument is the `handler` function. The handler function `must` take as first argument the event object (representing the event for that unit of time). Within the handler the `eventObject` contains the x, y values that we need. We then store this values in a global object. The handler is fired asynchronously so once the handler is attached we \"forget about it\" and from others part of our code we can reference the global object (updated by the handler).\n```Javascript\nvar mouse = {\n\tx: 0,\n\ty: 0\n};\n\nwindow.addEventListener('mousemove', \n\tfunction(event){\n\t\tmouse.x = event.x;\n\t\tmouse.y = event.y;\n\t \t\n});\n```\n\n#### Step 2: Draw on Canvas \n\nTo draw a circle that interacts with our mouse position, we need to declare a function `drawCircle`. This function is going to have two parameters (x, y), this refers to the coordinate where the circle is going to be drawn on the canvas. Inside the function `body`, which contains the statements that are to be executed, we call the `arc` method on the drawing `context` (canvas) that is used to create circles. But to actually draw the circle, we have to create a function `animate`. Inside the body of animate, we call the `requestAnimationFrame` method. This method tells the browser that an animation is going to be performed, with a number of `callbacks` that is usually 60 calls per second. Inside the `animate` function we call now our previous defined function `drawCircle` and set two arguments of the mouse object `drawCircle(mouse.x, mouse.y)`, this will draw our circle at the position of the mouse cursor. The last step is to declare a `clear` function which invokes the `clearRect` method on the context and erase the canvas every time `animate` is executed.  \n\n\n\n```Javascript\nfunction drawCircle(x, y) {\n        context.beginPath();\n\tcontext.arc(x, y, 50, 0, 2*Math.PI);\n\tcontext.strokeStyle = \"black\";\n\tcontext.stroke();\n}\n\nfunction clear() {\n\tcontext.clearRect(0, 0, canvas.width, canvas.height);\n}\n\nfunction animate() {\n\trequestAnimationFrame(animate);\n\tclear();\n\tdrawCircle(mouse.x, mouse.y);\n}\n\nanimate();\n```\n#### Web Audio API: \n\nThe Web Audio API provides a variety of features that allow developers to select audio sources, add effects to them, generate visualizations, playing sounds and much more.\n\n#### Visualizations with the Web Audio API: \n\nThe canvas element in combination with the Web Audio Api gives us a cool way to generate visual on the browser. To create a visual effect we first need an Analyser Node.\n```Javascript\nvar audioContext = new AudioContext();\nvar analyser = audioContext.createAnalyser();\n```\nOnce the AudioContext.createAnalyser() method creates an AnalyserNode, we can start to extract the data from our audio source.\nBut first, we have to create our audio object to get the actual source. \n```Javascript\nvar audio = new Audio();\naudio.src = 'audio.mp3';\naudio.play();\n```\nOnce we defined our audio variable, we can now connect the Node and the destination. \n```Javascript\nvar source = audioContext.createMediaElementSource(audio);\nsource.connect(analyser);\nanalyser.connect(audioContext.destination);\n```\n#### Merge Web Audio APi and Canvas\n\nOur goal is to create an interaction with the moving circle. In order to do this, we need to declare a variable that is setting up the `buffer`. \n```Javascript\nvar bufferLength = analyser.frequencyBinCount;\n```\nNext we declare the `buffer` variable with our `bufferLength` variable as an argument:\n```Javascript\nvar buffer = new Uint8Array(bufferLength);\n```\nThe `drawCircle` function iterates the buffer and creates a circle from the value `v` of each iteration wich will be the radius of the circle. \n```Javascript\nfunction drawCircle(x, y) {\n\t\n\tfor(var i = 0; i < bufferLength; i++) { \n    \tvar v = buffer[i];\n        context.beginPath();\n        context.arc(x, y, v, 0, v);\n        context.strokeStyle = \"black\";\n\tcontext.stroke();\n\t\n\t} \n}\n```\nLast step is to grap the `analyser.getByteTimeDomainData` method an copy it to our array.\n```Javascript\nfunction animate() {\n\trequestAnimationFrame(animate);\n\tanalyser.getByteTimeDomainData(buffer);\n\tclear();\n\tdrawCircle(mouse.x, mouse.y);\n}\n\nanimate();\n```\n## Useful links\n\n[Web Audio Api](https://developer.mozilla.org/de/docs/Web/API/Web_Audio_API)\n[Web Audio Api - Visual](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Visualizations_with_Web_Audio_API)\n[Javascript](https://eloquentjavascript.net/index.html)\n[JS Canvas](https://developer.mozilla.org/de/docs/Web/Guide/HTML/Canvas_Tutorial)\n\n\n\n\n\n\n\n\n\n\n\n"}
{"url": "https://github.com/DanieleMaselli/Robot__me", "owner": "DanieleMaselli", "repository_name": "Robot__me", "date_all_variable_collection": "2023-09-11", "description": null, "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/danieljanko98/IADL_post-DBS_longitudinal", "owner": "danieljanko98", "repository_name": "IADL_post-DBS_longitudinal", "date_all_variable_collection": "2023-09-11", "description": null, "size": 38, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "danieljanko98", "contributions": 19}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 10512}], "readme": "# IADL_post-DBS_longitudinal\n\n"}
{"url": "https://github.com/danielrm84/DeepLearning_AnimalVocalizations", "owner": "danielrm84", "repository_name": "DeepLearning_AnimalVocalizations", "date_all_variable_collection": "2023-09-11", "description": "This repository includes deep learning models I have developed during my postdoc in Hannover to process mouse lemur vocalizations data. They are in the form of jupyter notebooks. The first model is a binary classification problem intented to remove unwanted noise from the database. The second one is a multiclass supervised classification problem that classifies the data according to predefined categories", "size": 258, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "danielrm84", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 475978}], "readme": "# DeepLearning_AnimalVocalizations\nThis repository includes deep learning models I have developed during my postdoc in Hannover to process mouse lemur vocalizations data. They are in the form of jupyter notebooks. The first model is a binary classification problem intented to remove unwanted noise from the database. The second one is a multiclass supervised classification problem that classifies the data according to predefined categories\n"}
{"url": "https://github.com/danielrm84/Fixed-Zotero-styles", "owner": "danielrm84", "repository_name": "Fixed-Zotero-styles", "date_all_variable_collection": "2023-09-11", "description": "This repository has zotero styles that I have modified to fix some inconsistencies. I have not created the full code, I have just modified specific lines. The original files can be found at https://www.zotero.org/styles", "size": 4, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "danielrm84", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/danielrm84/My-CNC-Remastered-mods", "owner": "danielrm84", "repository_name": "My-CNC-Remastered-mods", "date_all_variable_collection": "2023-09-11", "description": "Here you can find and download the mods I have created for command and conquer remastered. If you would like to use the material for own projects, please give the corresponding credits. Many thanks in advance!", "size": 23231, "stargazers_count": 1, "watchers_count": 1, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "danielrm84", "contributions": 373}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 4520082}, {"language": "C", "num_chars": 98336}], "readme": "# My-CNC-Remastered-mods\n\nAuthor: Daniel Romero Mujalli -- Kerekupai-meru (steam)\n\nHere you can find and download the mods I have created for command and conquer remastered. \n\nIf you would like to use the material for own projects, please give the corresponding credits.\nBe fair. Do not steal the work of others.\nMany thanks in advance!\n\nI have uploaded only those files from the source code that I have modified to create the mods.\nYou will need to download the source code independently.\n\nList of mods:\n- immersive_helis\n- Ra immersive helis\n- TD color mod\n- RA color mod\n- TD Mujalli Mod\n- RA Mujalli Mod (not finished yet!)\n\nsteam link:\nhttps://steamcommunity.com/profiles/76561198039778133/myworkshopfiles/?appid=1213210\n\nIf you would like to use material from any of my mods that are not released yet, let me know \nand I can prepare it for you.\n\nIn case, you are interested in the back-to-work feature for technicians, I strongly\nrecommend to implement it the way it is done for RA Mujalli Mod (not TD Mujalli Mod!).\nIt is way simpler in the former case.\n\nPlease feel free to contact me if you have questions.\nHave fun commander!\n"}
{"url": "https://github.com/danielrm84/Netlogo_Map_Generator", "owner": "danielrm84", "repository_name": "Netlogo_Map_Generator", "date_all_variable_collection": "2023-09-11", "description": "This is a map generator of artificial landscapes for Netlogo. It can be used to create scenarios of fragmented landscapes (habitat suitability maps)", "size": 14, "stargazers_count": 0, "watchers_count": 0, "language": "NetLogo", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "danielrm84", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "NetLogo", "num_chars": 25332}], "readme": "# Netlogo_Map_Generator\n\nAuthor: Daniel Romero-Mujalli\n\nUniversity of Greifswald\nEmail: danielrm84@gmail.com\n\nThis is a map generator of artificial landscapes for Netlogo. It can be used to create scenarios of fragmented landscapes (habitat suitability maps)\n\nThe model offers the possibility to create landscapes based on two neutral landscape models: random and fractal model (With et al 1997).\n\nParameters description\n\nRandom model:\n- p: proportion of suitable habitat\n\nCurrently, the random model supports two habitats distributed randomly according to the uniform distribution\n\nFractal model:\n- Roughness:            This is the parameter H of the mid-point displacement algorithm typically used for the modelling of fragmented \n                        landscapes (With et al. 1997).\n                        The smaller the value, the higher the level of landscape fragmentation\n- Habitat-contagion:    This parameter is used to smooth the landscape\n\n\nAfter the map is generated, one can export it as a png file. \nIf no name for the file is provided, the function writes a map.png file by default.\nAs well, it is possible to import a map, based on the provided filename, to work it further, if necessary \n(e.g., change the color of the patches and prepare the map to import it into another model) \n\nAcknowledgements:\nEspecial thanks to https://github.com/klaytonkowalski and the\nyoutube channel of Mathematics of Computer Graphics and Virtual\nEnvironments for their very useful and valuable material, which\nhelped me in the development of this map generator.\n\nReferences:\nWith, K., Gardner, R., & Turner, M. (1997). Landscape Connectivity and Population Distributions in Heterogeneous Environments. <i>Oikos,</i> <i>78</i>(1), 151-169. doi:10.2307/3545811\n"}
{"url": "https://github.com/danielrm84/PanModel33", "owner": "danielrm84", "repository_name": "PanModel33", "date_all_variable_collection": "2023-09-11", "description": "Hello! this is an eco-evolutionary model that I developed together with my colleagues Sandra Kahl, Sophia Paraskevopoulou, and Remco Folkertsma, as part of my PhD at the University of Potsdam, Germany. It was designed for theory development, communication and learning.", "size": 487, "stargazers_count": 3, "watchers_count": 3, "language": "NetLogo", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "danielrm84", "contributions": 14}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "NetLogo", "num_chars": 124466}], "readme": "# PanModel33\nHello! this is an eco-evolutionary model developed at the University of Potsdam, Germany. It was designed for theory development, communication and learning.\n\nTo install and learn to use the model, please visit the document \"user_manual.pdf\" in this repository.\n\nFor a detailed explanation of model features, check the \"odd_protocol.pdf\"\n\nUpdate:\nOnly the simple version, that uses native netlogo functions only, is available in this repositoty. One can comment out the corresponding lines of code in order to use the r extension as it was implemented for the previous \"full\" model version.\n\n-----------\nDaniel Romero-Mujalli\n"}
{"url": "https://github.com/danielrm84/Romero-Mujalli-et-al.-BMC-Evolutionary-Biology", "owner": "danielrm84", "repository_name": "Romero-Mujalli-et-al.-BMC-Evolutionary-Biology", "date_all_variable_collection": "2023-09-11", "description": "This repository contains the data used for the paper in BMC Evolutionary Journal. For this project we used an extended version of the PanModel33 to simulate the evolution of the mutation rate. The PanModel33 can be found in its own repository (see my github repositories)", "size": 2377, "stargazers_count": 2, "watchers_count": 2, "language": "NetLogo", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "danielrm84", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "NetLogo", "num_chars": 91541}, {"language": "R", "num_chars": 2459}]}
{"url": "https://github.com/danielrm84/Social-Learning-Project-Robotics", "owner": "danielrm84", "repository_name": "Social-Learning-Project-Robotics", "date_all_variable_collection": "2023-09-11", "description": "This repository contains the simulator I created and used for my research on social learning during my Master studies at the Simon Bolivar University in Venezuela. It consists of individual agents or robots navigating the arena and finding the target feeding patch. The movement behavior of each robot is governed by artificial neural networks (AI). The full simulator is programmed in C++ and can be visualized on Netlogo (optional).", "size": 45327, "stargazers_count": 5, "watchers_count": 5, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 5, "default_branch": "master", "contributors": [{"contributor": "danielrm84", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 392314}, {"language": "NetLogo", "num_chars": 73600}, {"language": "C", "num_chars": 67388}, {"language": "Makefile", "num_chars": 790}], "readme": "# Social-Learning-Project-Robotics\nThis repository contains the simulator I created and use for my research on social learning in small populations during my Master studies at the Simon Bolivar University in Venezuela. I programmed the simulator in C++ and can be visualize on Netlogo.\n\n\nPROJECT SOCIAL LEARNING ( ROMERO-MUJALLI ET AL. 2017 JOURNAL OF ETHOLOGY)\n\nURL: https://link.springer.com/article/10.1007%2Fs10164-016-0490-8\n\nCite this article as:\n    Romero-Mujalli, D., Cappelletto, J., Herrera, E.A. et al. J Ethol (2017) \n    35: 61. https://doi.org/10.1007/s10164-016-0490-8\n\nUNIVERSIDAD SIM\u00d3N BOL\u00cdVAR, CARACAS, VENEZUELA\nUNIVERSIDAD CENTRAL DE VENEZUELA, CARACAS, VENEZUELA\n\n\nContact information: \nDaniel Romero-Mujalli email: danielrm84@gmail.com\n\n\n\nTERMS OF USE\nIf you decide to use any material of our work, the code, or part of it, please remember to do the correct citation. Many thanks in advance!\n\nPlease also refer to the license agreement as well.\n\nUPDATED CODE\n\nProject_Social_Learning_V4\n\n*) main_Project_SL/\n\n\tcontain the main function of the project. \n\tRun main_netlogo.cpp to run the model. This will also create a movement file that can be plotted using netlogo.\n\nExperimental scenarios can be set at\n\t/include/headers/treatment/treatment.h\n\n\t- Scenario of Behavior: social learning SL, asocial learning AL, mixed population Mx, genetic evolution GE and Random Search RS (Control)\n\n\n\t- Scenario of Environment: static, abrupt change or gradual change. Also includes Migration, an extra condition to test the feasibility of discovering alternatives (THE CURRENT UPDATED VERSION SUPPORTS ONLY THE STATIC SCENARIO)\n\n\tFor details on parameter values used in the simulation please refer to the methods in\n\tRomero-Mujalli et al. 2017.\n\nAll parameter values can be set at\n\t/include/headers/parameter\n\n\tTo run the project, \n\t\n\t\n\tUBUNTU:\n\t\n\t\n\tcheck /include/headers/miscellaneous/miscellaneous.h: \n\tall the sources (.cpp) should be commented out (//)\n\t\n\t(THE MAKEFILE IN THIS VERSION IS OUTDATED)\n\t\n\n\tWINDOWS:\n\n\t\n\tmake sure that all sources (.cpp) files are uncommented in\n\t\n\t/include/headers/miscellaneous/miscellaneous.h\n\n\t\n\tBuild and compile the main.cpp with the program of your choice\n\t(example, dev c++)\n\n\n**) main_training_V3.cpp\n\n\tthis is the main routine used to train the neural networks (NN). It is possible to train networks of different topology. The networks are then store in output files.\n\n\tto run this file in ubuntu type to terminal: make training\n\tthen: ./training (outdated!)\n\tfor cleaning objects, type: make clean\n\n***) include/\n\n\tthis folder contains all the header files, including clases, functions, sources and a miscellaneous file.\n\n\tI've included documentation on how to use each function and can be found \n\tin the corresponding header file.\n\nfiles (.h) \n        /include/headers/agentFunctions\n\t/include/headers/classes\n\t/include/headers/debug\n\t/include/headers/geneticFunctions\n\t/include/headers/initialization\n\t/include/headers/outputData\n\t/include/headers/parameter\n\t/include/headers/readWeights\n\t/include/headers/runWorld\n\t/include/headers/sensorFunctions\n\t/include/headers/treatment\n\n\n"}
{"url": "https://github.com/danielrm84/tihoCluster", "owner": "danielrm84", "repository_name": "tihoCluster", "date_all_variable_collection": "2023-09-11", "description": "This R package contains the function  (KmeansElbow) used by Langehennig-Peristenidou, Romero-Mujalli et al to automate the categorization of mouse lemur calls (unsupervised cluster analysis)", "size": 1158, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "danielrm84", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 13862}], "readme": "## tihoCluster\nauthor:\tDaniel Romero Mujalli\n\nemail:\tdanielrm84@gmail.com\n\nThis R package contains the function  (KmeansElbow) used by Langehennig-Peristenidou, Romero-Mujalli et al to automate the categorization of mouse lemur calls (unsupervised cluster analysis)\n\n### How to install the package?\n(requires devtools)\n> devtools::install_github(\"danielrm84/tihoCluster\")\n\n### Dependencies:\n-stats\n\n-cluster\n\n-FactoMineR\n\n-factoextra\n\n-rgl\n"}
{"url": "https://github.com/danielrm84/Unsupervised-Clustering", "owner": "danielrm84", "repository_name": "Unsupervised-Clustering", "date_all_variable_collection": "2023-09-11", "description": "This repository contains 1) a custom R function to automatically find the optimal number of clusters based on the k-means model; 2) Material related to an introductory course on clustering using R", "size": 4846, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "danielrm84", "contributions": 16}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 30524}], "readme": "# Unsupervised-Clustering\n\nauthor: Daniel Romero Mujalli\nemail: danielrm84@gmail.com\ninstitute: Tier\u00e4rztliche Hochschule Hannover, DE\n\n\nThis repository contains a custom R function to automatically find the optimal number of clusters based on the k-means model.\n\nIn addition, it has the material used for an introductory course on clustering using R. \nLearning goals:\nBy the end of the course, the student is able to\n\n- import and prepare data in R for clustering analysis\n- use the K-means model and interpret its results\n- apply a DFA to the data and interpret the results\n- plot and visualize data\n"}
{"url": "https://github.com/daqinghou/BEM", "owner": "daqinghou", "repository_name": "BEM", "date_all_variable_collection": "2023-09-11", "description": "Building Energy Modeling (NYSERDA)", "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/daqinghou/lab1", "owner": "daqinghou", "repository_name": "lab1", "date_all_variable_collection": "2023-09-11", "description": null, "size": 87, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alanschay", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 1257}]}
{"url": "https://github.com/DavidLeonhard/github-slideshow", "owner": "DavidLeonhard", "repository_name": "github-slideshow", "date_all_variable_collection": "2023-09-11", "description": "A robot powered training repository :robot:", "size": 3524, "stargazers_count": 0, "watchers_count": 0, "language": "Ruby", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "githubteacher", "contributions": 15}, {"contributor": "hectorsector", "contributions": 9}, {"contributor": "DavidLeonhard", "contributions": 3}, {"contributor": "dependabot[bot]", "contributions": 3}, {"contributor": "brianamarie", "contributions": 2}, {"contributor": "JasonEtco", "contributions": 2}, {"contributor": "snyk-bot", "contributions": 2}, {"contributor": "carolynshin", "contributions": 1}, {"contributor": "crichID", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Ruby", "num_chars": 7559}, {"language": "HTML", "num_chars": 3039}, {"language": "Shell", "num_chars": 2193}], "readme": "# Your GitHub Learning Lab Repository for Introducing GitHub\n\nWelcome to **your** repository for your GitHub Learning Lab course. This repository will be used during the different activities that I will be guiding you through. See a word you don't understand? We've included an emoji \ud83d\udcd6 next to some key terms. Click on it to see its definition.\n\nOh! I haven't introduced myself...\n\nI'm the GitHub Learning Lab bot and I'm here to help guide you in your journey to learn and master the various topics covered in this course. I will be using Issue and Pull Request comments to communicate with you. In fact, I already added an issue for you to check out.\n\n![issue tab](https://lab.github.com/public/images/issue_tab.png)\n\nI'll meet you over there, can't wait to get started!\n\nThis course is using the :sparkles: open source project [reveal.js](https://github.com/hakimel/reveal.js/). In some cases we\u2019ve made changes to the history so it would behave during class, so head to the original project repo to learn more about the cool people behind this project.\n"}
{"url": "https://github.com/davidschlangen/cosine-paris", "owner": "davidschlangen", "repository_name": "cosine-paris", "date_all_variable_collection": "2023-09-11", "description": "Material for the \"Concepts, Composition, and Conversational Coordination\" Lecture Series, Paris 2019", "size": 94787, "stargazers_count": 1, "watchers_count": 1, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "davidschlangen", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "*David Schlangen, September 2019*\n\n# Concepts, Composition, and Conversational Coordination\n\nMaterial for the \"Concepts, Composition, and Conversational Coordination\" Lecture Series, Paris 2019.\n\nThis repository collects the slides (and other material) for my 2019 Paris lectures. References to the cited literature in the slides. [Videos of the lectures](http://www.labex-efl.com/wordpress/2019/11/14/conference-video-david-schlangen-concepts-composition-and-conversational-coordination-semantic-competence-for-situated-interaction/) are now online.\n\nRelated material can be found here:\n\n* [website for 2017 talk in Amsterdam](http://dsg-bielefeld.de/talks/amsterdam-2017/)\n* [website for 2017 talk in Gothenburg](http://dsg-bielefeld.de/talks/gothenburg-2017/)\n\nThe corpus examples can be found in the [\"Semantics with Pictures\"](https://github.com/clp-research/sempix) repository. The code for preprocessing the corpora in the [`clp-vision`](https://github.com/clp-research/clp-vision) repository. It assumes that you have downloaded all the original corpora, which is a lot of stuff and takes a lot of effort. If you want to try out these things, you can get access from me to a JupyterHub installation in an environment where all this data and preprocessing results are available.\n\n\n**Update August 2020:** You can find a slightly more cleaned up version of this in my [semdial 2020 paper](Papers/Schlangen-semdial2020.pdf), of which you can also find here [the slides](Slides/sitdrp_semdial2020.pdf), and even [the recorded talk](Media/semdial2020_talk.mov).\n"}
{"url": "https://github.com/delwarhub/Advanced-Natural-Language-Processing-2022", "owner": "delwarhub", "repository_name": "Advanced-Natural-Language-Processing-2022", "date_all_variable_collection": "2023-09-11", "description": null, "size": 13279, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# ANLP-2023\n\n## Feedback on the paper\nPoints were deducted mostly due to:\n\n- failing to follow the project guidelines\n- missing sections in the paper structure (as per section 6.1 in the project guidelines)\n- incomplete sections (e.g. no examples in the data section, no baseline in the experiments, no error analysis in the results)\n- inadequate task formalization\n- low quality in writing (too many spelling mistakes, leftover comments to self, too many claims without evidence, informal tone)\n- submission of clearly unfinished work\n- When submission guidelines are put forward, please follow them closely. Things like number of pages, citation format, template, figure and table layout, paper structure are very important for - - the reviewers/readers (that's why we created guidelines in the first place).\n\nHere are some further general feedback on the papers. Not everything impacted grades, this is meant as recommendations for writing better papers in general.\n\n## General Comments\n- Use scientific, formal language, with a coherent flow. Proofread your text.\n- Do not submit unfinished work. Plan enough time for projects (and for writing!).\n- Avoid making claims that are only based on your assumptions and perceptions. Everything should be backed up by a citation, by the data/results, or by other forms of concrete evidence or argumentation.\n- Follow citation standards. In NLP literature, the default is: SurnameA and SurnameB (YEAR) if it is a part of the sentence, or (Surname, YEAR) when it is used to reference where the claim comes from. It is not necessary to mention the title of a paper or the first names of the authors in the text.\n- Avoid strange passive constructions. It's totally fine to use 1st person (I or we).\n- Use the right symbol for opening quotation marks in LaTeX.\n- Avoid vertical lines in tables. Also avoid horizontal lines except at the top, bottom, and after the header. Exceptions to this are only when we need to split blocks for some reason. You can check the APA table layout guidelines.\n- Figure size should be appropriate to the document. Figures that are too small or too large are not helpful.\n- Make sure that the font sizes in figures are readable. Figures should be readable for colourblind people, and preferably in grey version too. Ideally, do not rely on colour only to make a distinction (use marker format, line style etc instead or additionally).\n- Include a caption in every figure and table. It should be self-contained.\n- Always refer to every figure and table at least once in the text.\n## Title and abstract\n- Titles should be informative, containing all relevant keywords.\n- Abstracts are a full summary of the work: It must mention the motivation, the research question, the approach, and also the main takeaways.\n## Introduction\n- Should include the motivation/background, the research question, the approach, the contributions.\n- In this project, the SemEval task should be put in evidence and cited.\n- Avoid boilerplate texts that do not add much in content. For example, starting the introduction with \"NLP models have been showing impressive results in the latest year\".\n## Related Work\n- Do not just add short summaries of papers one after the other.\n- This section should tell a story about how the work fits into its context.\n- What are the limitations of existing works? How does the work relate to existing work and tries to overcome the known limitations?\n## Task Formalisation\n- This was the section with most issues. Here, you should formalise the task, in abstract form, using mathematical notation.\n- We had a full session on this and the slides with plenty of examples are available on Moodle (week 7).\n- Just describing what is the data, model etc. is not enough.\n- This also does not relate to describing how the model is trained or evaluated.\n## Data\n- Always add examples and include basic descriptive statistics, as well as any important preprocessing steps.\n- Even if using existing datasets, include the main information that the reader needs to understand the work without having to go to the original publication.\n- Publicly available is not always public domain.\n## Experiments\n- It's always a good idea to add an illustration of the model architecture.\n- The evaluation methods and metrics should be presented before the results section so that, when we get there, we already know what to expect.\n- The implementation should be discussed in a high level overview.\n- Function names, for example, are not necessary here.\n- Other very specific details belong to the code documentation and, if applicable, the appendix.\n## Results\n- Do not use the word \"significant\" when referring to results, unless you have run statistical significance tests.\n- Preferably, disentangle reporting results from interpreting them.\n- The error analysis in NLP should discuss the evaluation taking into account the linguistic aspects of the inputs and outputs, focusing on the cases where the model fails.\n- By default, one table with the main results and a few plots for additional analysis are expected in this section. Reporting numbers sparsely over the text hinders the comparison of results.\n## Conclusion\nThis is a recap on what was done and a wrap-up, summarising the main takeaways and possible further research.\n## Limitations and Ethics\n- Avoid generic text that adds no value.\n- Be clear about what you know that could have been done in other ways and explain why you did not do it.\n- Think critically about the consequences of your work (even if only potential) in reality.\n## References\n- Make sure that the references are complete.\n- Sometimes, the .bib entry has missing information that is important and needs to be added manually.\n- Before citing arXiv papers, first check if they have been published somewhere.\n- Published work must be cited as such, not as preprints.\n"}
{"url": "https://github.com/delwarhub/Android-App-for-Health-Management-System", "owner": "delwarhub", "repository_name": "Android-App-for-Health-Management-System", "date_all_variable_collection": "2023-09-11", "description": "Android App for Health Management System", "size": 4673, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 21}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "## Android App for Health Management System(iCare)\n\n### ACKNOWLEDGEMENT\n\nFirst we express our heartiest thanks and gratefulness to almighty Allah for His divine blessing makes us possible to complete this project successfully.\n\nWe are grateful and wish our profound indebtedness to Nazmun Nessa Moon, Assistant Professor, Department of Computer Science and Engineering, Daffodil International University, Dhaka. Deep Knowledge & keen interest of our supervisor in the field of \u201cAndroid Application Development\u201d influenced us to carry out this project. Her endless patience, scholarly guidance, continual encouragement, constant and energetic supervision, constructive criticism, valuable advice, reading many inferior draft and correcting them at all stage have made it possible to complete this project.\n\nWe would like to express our heartiest gratitude to Dr. Syed Akhter Hossain, Professor and Head, Department of CSE, CIS & CS Daffodil International University for his kind help and support to finish our project and also to other faculty member and the staff of CSE department of Daffodil International University.\n\nWe would like to thank our entire course mate in Daffodil International University, who took part in this discuss while completing the course work.\n\nFinally, we must acknowledge with due respect the constant support and patients of ours parents.\n\n### ABSTRACT\nDue to revolution of internet technology worldwide, the rapid use of mobile application on regarding various subjects increasing day by day. A good mobile application on Health Care is user friendly to save the information of family members of current health condition. This project \u201cAn Android Apps for Advanced Health Management System\u201d is based on this concept of development of a mobile application on caring health by mobile apps. By using this application, it will be very easy to maintain healthcare. Its functionality is very easy and anyone can use it to manage family and personal health. Its functionality is designed according to the basic demands of user. It provides much functionality among them. There are Diet Chart management, Vaccination management, Doctor Management, Medical History management and etc. The intended project \u201cDesign and Development of an Android Application for Advanced Health Management System\u201d is targeted to facilitate users from home and abroad by giving information using mobile.\n"}
{"url": "https://github.com/delwarhub/ANLP-2021", "owner": "delwarhub", "repository_name": "ANLP-2021", "date_all_variable_collection": "2023-09-11", "description": null, "size": 2132, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 290070}], "readme": "# ANLP-2021\n\nThis course will mainly follow the major textbook in our field, Jurafsky & Martin's \"Speech and Language Processing\". The authors are currently preparing the 3rd edition, and while they are doing this, the draft version is freely available. We will use this mostly (denoted by JM3 below). The plan is to cover chapters 2 -- 9 and 12 -- 16.\n\n* Recently, another textbook that aims at a general introduction has come out, Jacob Eisenstein's \"Introduction to Natural Language Processing\". This takes a somewhat more CS / ML-inspired approach, and can be used as further background reading. (The free PDF that you will find online is the pre-final draft missing some corrections; we have a couple of paper copies available in the library.)\n\n* Even more recently, and indicating what an active field this is, yet another textbook has come out, Zhang & Teng's \"Natural Language Processing: A Machine Learning Perspective\". This, as the subtitle indicates, comes at the problems even more clearly from a machine learning-perspective; it can also be used as further background reading. We have a couple of paper copies available in the library as well.\n\n* Finally, if you don't have a background in linguistics, you will be taking the \"Foundations in Linguistics\" class. For reference, there are also two very useful \"linguistic fundamentals\" books (see below), that you can download for free when accessing the links below through the uni network / VPN.\n\n1. Jurafsky & Martin, Speech and Language Processing, 3rd Ed.\n2. Jacob Eisenstein, Introduction to NLP (2018 version)\n3. Yue Zhang & Zhiyang Teng, NLP: A Machine Learning Perspective\n4. Emily Bender, Linguistic Fundamentals for Natural Language Processing: 100 Essentials from Morphology and Syntax\n5. Emily Bender & Alex Lascarides, Linguistic Fundamentals for Natural Language Processing II: 100 Essentials from Semantics and Pragmatics\n"}
{"url": "https://github.com/delwarhub/Bayesian-Statistical-Inference-ML-2", "owner": "delwarhub", "repository_name": "Bayesian-Statistical-Inference-ML-2", "date_all_variable_collection": "2023-09-11", "description": null, "size": 529, "stargazers_count": 0, "watchers_count": 0, "language": "Stan", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Stan", "num_chars": 6175}], "readme": "# Bayesian Statistical Inference ML 2\n### About this course:\n\n We are going to cover the following topics,\n1. Introduction to Stan: a probabilistic programming language\n2. Meta-analysis and measurement models\n3. Model evaluation and model selection\n4. Multinomial processing trees and mixture models\n5. Accumulator models and Drift-diffusion models\n\nThe book An Introduction to Bayesian Data Analysis for Cognitive Science (chapter 10 onwards) by Bruno Nicenboim, Daniel Schad, and Shravan Vasishth.\n\nLecture style: The lectures will consist of an introduction to the topic and some do-in-class exercises. It is important in an advanced Bayesian course to get quick feedback and learn it by doing. You should bring your laptops (with working R and Stan setup).\n\nMathematics lectures: https://www.youtube.com/playlist?list=PL0TWbOjq4HH1Y1-PBA_guwZ482G8kQHHW\n"}
{"url": "https://github.com/delwarhub/Current-Highlights-in-NLP", "owner": "delwarhub", "repository_name": "Current-Highlights-in-NLP", "date_all_variable_collection": "2023-09-11", "description": "A seminar course ", "size": 20957, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Current-Highlights-in-NLP\nSeminar on Current Highlights in NLP \\\nThis seminar covers various recent advancements from the Natural Language Processing field. The goals of the seminar are the following:\n\n* Find out about recent developments in the NLP world\n* Learn to read and understand scientific publications\n* Discuss the outcomes, shortcomings\n* Critically review\n* Come up with the follow up ideas\n* Learn how to write scientific publications\\\n\nRole-playing Paper Reading \\\nEvery week this course will thoroughly read and the selected paper(s) and discuss them. We will follow the role-playing setting inspired by the experience of Jacobson & Raffel.\n"}
{"url": "https://github.com/delwarhub/delwarhub", "owner": "delwarhub", "repository_name": "delwarhub", "date_all_variable_collection": "2023-09-11", "description": "My personal repository.", "size": 26, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "<h1 align=\"center\">Hi \ud83d\udc4b, I'm Md Delwar Hossain</h1>\n<h4 align=\"left\">I'm a student of the Cognitive Systems Master's program at the University of Potsdam, Germany. That means that I'm specialised in Computational Linguistics, Natural Language Processing and Machine Learning. My main expertise lays in Python (Numpy, Pandas, NLTK, Scipy, Sklearn, Pytorch,Matplotlib, ...). \n<br>I worked as a Lecturer Dept. of Computer Science and Engineering at the World University of Bangladesh (WUB) from 17th September 2018 to 17th December 2020. Previously I worked as an ICT Instructor at Community Participation & Development (Project of Save the Children, BD) Dhaka, Bangladesh. Also, I worked as a Trainer of Java and Android Apps Development at Open IT Ltd, Mirpur-10, Dhaka. I completed some professional-certified courses from BASIS, EATL, APPSO, etc.</h4>\n\n<p align=\"left\"> <img src=\"https://komarev.com/ghpvc/?username=delwarhub&label=Profile%20views&color=0e75b6&style=flat\" alt=\"delwarhub\" /> </p>\n\n<p align=\"left\"> <a href=\"https://github.com/ryo-ma/github-profile-trophy\"><img src=\"https://github-profile-trophy.vercel.app/?username=delwarhub\" alt=\"delwarhub\" /></a> </p>\n\n<p align=\"left\"> <a href=\"https://twitter.com/delwar55555\" target=\"blank\"><img src=\"https://img.shields.io/twitter/follow/delwar55555?logo=twitter&style=for-the-badge\" alt=\"delwar55555\" /></a> </p>\n\n- \ud83c\udf31 I\u2019m currently learning **Deep Learning, Machine Learning and NLP**\n\n- \ud83d\udcac Ask me about **Machine Learning || Deep Learning || Natural Language Processing**\n\n- \ud83d\udceb How to reach me **delwar.ieee@gmail.com**\n\n- \ud83d\udcc4 Know about my experiences [https://bit.ly/3A8N4Oi](https://bit.ly/3A8N4Oi)\n\n- Here are two useful tutorials on building research software that you may find useful: The Good Research Code Handbook: https://goodresearch.dev/index.html and Research Software Engineering With Python: https://github-pages.ucl.ac.uk/rsd-engineeringcourse/\n\n<h3 align=\"left\">Connect with me:</h3>\n<p align=\"left\">\n<a href=\"https://twitter.com/delwar55555\" target=\"blank\"><img align=\"center\" src=\"https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/src/images/icons/Social/twitter.svg\" alt=\"delwar55555\" height=\"30\" width=\"40\" /></a>\n<a href=\"https://linkedin.com/in/delwar1971\" target=\"blank\"><img align=\"center\" src=\"https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/src/images/icons/Social/linked-in-alt.svg\" alt=\"delwar1971\" height=\"30\" width=\"40\" /></a>\n<a href=\"https://kaggle.com/mddelwarhossain\" target=\"blank\"><img align=\"center\" src=\"https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/src/images/icons/Social/kaggle.svg\" alt=\"mddelwarhossain\" height=\"30\" width=\"40\" /></a>\n<a href=\"https://fb.com/delwar555\" target=\"blank\"><img align=\"center\" src=\"https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/src/images/icons/Social/facebook.svg\" alt=\"delwar555\" height=\"30\" width=\"40\" /></a>\n</p>\n\n<h3 align=\"left\">Languages and Tools:</h3>\n<p align=\"left\"> <a href=\"https://developer.android.com\" target=\"_blank\"> <img src=\"https://raw.githubusercontent.com/devicons/devicon/master/icons/android/android-original-wordmark.svg\" alt=\"android\" width=\"40\" height=\"40\"/> </a> <a href=\"https://www.arduino.cc/\" target=\"_blank\"> <img src=\"https://cdn.worldvectorlogo.com/logos/arduino-1.svg\" alt=\"arduino\" width=\"40\" height=\"40\"/> </a> <a href=\"https://getbootstrap.com\" target=\"_blank\"> <img src=\"https://raw.githubusercontent.com/devicons/devicon/master/icons/bootstrap/bootstrap-plain-wordmark.svg\" alt=\"bootstrap\" width=\"40\" height=\"40\"/> </a> <a href=\"https://www.cprogramming.com/\" target=\"_blank\"> <img src=\"https://raw.githubusercontent.com/devicons/devicon/master/icons/c/c-original.svg\" alt=\"c\" width=\"40\" height=\"40\"/> </a> <a href=\"https://www.w3schools.com/css/\" target=\"_blank\"> <img src=\"https://raw.githubusercontent.com/devicons/devicon/master/icons/css3/css3-original-wordmark.svg\" alt=\"css3\" width=\"40\" height=\"40\"/> </a> <a href=\"https://www.w3.org/html/\" target=\"_blank\"> <img src=\"https://raw.githubusercontent.com/devicons/devicon/master/icons/html5/html5-original-wordmark.svg\" alt=\"html5\" width=\"40\" height=\"40\"/> </a> <a href=\"https://www.adobe.com/in/products/illustrator.html\" target=\"_blank\"> <img src=\"https://www.vectorlogo.zone/logos/adobe_illustrator/adobe_illustrator-icon.svg\" alt=\"illustrator\" width=\"40\" height=\"40\"/> </a> <a href=\"https://www.java.com\" target=\"_blank\"> <img src=\"https://raw.githubusercontent.com/devicons/devicon/master/icons/java/java-original.svg\" alt=\"java\" width=\"40\" height=\"40\"/> </a> <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript\" target=\"_blank\"> <img src=\"https://raw.githubusercontent.com/devicons/devicon/master/icons/javascript/javascript-original.svg\" alt=\"javascript\" width=\"40\" height=\"40\"/> </a> <a href=\"https://www.linux.org/\" target=\"_blank\"> <img src=\"https://raw.githubusercontent.com/devicons/devicon/master/icons/linux/linux-original.svg\" alt=\"linux\" width=\"40\" height=\"40\"/> </a> <a href=\"https://www.mongodb.com/\" target=\"_blank\"> <img src=\"https://raw.githubusercontent.com/devicons/devicon/master/icons/mongodb/mongodb-original-wordmark.svg\" alt=\"mongodb\" width=\"40\" height=\"40\"/> </a> <a href=\"https://www.mysql.com/\" target=\"_blank\"> <img src=\"https://raw.githubusercontent.com/devicons/devicon/master/icons/mysql/mysql-original-wordmark.svg\" alt=\"mysql\" width=\"40\" height=\"40\"/> </a> <a href=\"https://opencv.org/\" target=\"_blank\"> <img src=\"https://www.vectorlogo.zone/logos/opencv/opencv-icon.svg\" alt=\"opencv\" width=\"40\" height=\"40\"/> </a> <a href=\"https://www.oracle.com/\" target=\"_blank\"> <img src=\"https://raw.githubusercontent.com/devicons/devicon/master/icons/oracle/oracle-original.svg\" alt=\"oracle\" width=\"40\" height=\"40\"/> </a> <a href=\"https://www.photoshop.com/en\" target=\"_blank\"> <img src=\"https://raw.githubusercontent.com/devicons/devicon/master/icons/photoshop/photoshop-line.svg\" alt=\"photoshop\" width=\"40\" height=\"40\"/> </a> <a href=\"https://www.python.org\" target=\"_blank\"> <img src=\"https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg\" alt=\"python\" width=\"40\" height=\"40\"/> </a> <a href=\"https://pytorch.org/\" target=\"_blank\"> <img src=\"https://www.vectorlogo.zone/logos/pytorch/pytorch-icon.svg\" alt=\"pytorch\" width=\"40\" height=\"40\"/> </a> <a href=\"https://scikit-learn.org/\" target=\"_blank\"> <img src=\"https://upload.wikimedia.org/wikipedia/commons/0/05/Scikit_learn_logo_small.svg\" alt=\"scikit_learn\" width=\"40\" height=\"40\"/> </a> <a href=\"https://www.sqlite.org/\" target=\"_blank\"> <img src=\"https://www.vectorlogo.zone/logos/sqlite/sqlite-icon.svg\" alt=\"sqlite\" width=\"40\" height=\"40\"/> </a> <a href=\"https://www.tensorflow.org\" target=\"_blank\"> <img src=\"https://www.vectorlogo.zone/logos/tensorflow/tensorflow-icon.svg\" alt=\"tensorflow\" width=\"40\" height=\"40\"/> </a> <a href=\"https://unity.com/\" target=\"_blank\"> <img src=\"https://www.vectorlogo.zone/logos/unity3d/unity3d-icon.svg\" alt=\"unity\" width=\"40\" height=\"40\"/> </a> </p>\n\n<p><img align=\"left\" src=\"https://github-readme-stats.vercel.app/api/top-langs?username=delwarhub&show_icons=true&locale=en&layout=compact\" alt=\"delwarhub\" /></p>\n\n<p>&nbsp;<img align=\"center\" src=\"https://github-readme-stats.vercel.app/api?username=delwarhub&show_icons=true&locale=en\" alt=\"delwarhub\" /></p>\n\n<p><img align=\"center\" src=\"https://github-readme-streak-stats.herokuapp.com/?user=delwarhub&\" alt=\"delwarhub\" /></p>\n"}
{"url": "https://github.com/delwarhub/Docker-and-Kubernetes-The-Complete-Guide", "owner": "delwarhub", "repository_name": "Docker-and-Kubernetes-The-Complete-Guide", "date_all_variable_collection": "2023-09-11", "description": "Docker and Kubernetes: The Complete Guide", "size": 249, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Docker-and-Kubernetes-The-Complete-Guide\nDocker and Kubernetes: The Complete Guide\n### Diagrams\n\nThe diagrams shown in the course are attached to this lecture note as a zip file.\nVisit diagrams.net (formerly draw.io).\nSelect Open Existing Diagram and use the file explorer to select the diagram file from your computer.\n"}
{"url": "https://github.com/delwarhub/How-to-Perform-Logistic-Regression-in-Python", "owner": "delwarhub", "repository_name": "How-to-Perform-Logistic-Regression-in-Python", "date_all_variable_collection": "2023-09-11", "description": "In this short lesson, I will show you how to perform Logistic Regression in Python. This would be very easy. An you will have all the codes.", "size": 18, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 32390}], "readme": "# How-to-Perform-Logistic-Regression-in-Python\nIn this short lesson, I will show you how to perform Logistic Regression in Python. This would be very easy. An you will have all the codes.\n"}
{"url": "https://github.com/delwarhub/Intelligent-Data-Analysis-Machine-Learning", "owner": "delwarhub", "repository_name": "Intelligent-Data-Analysis-Machine-Learning", "date_all_variable_collection": "2023-09-11", "description": null, "size": 672, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "### Intelligent Data-Analysis Machine Learning-I \n#### (9CP Mandatory Course of M.Sc Cognitive Systems at the University of Potsdam)\n\nThis project is part of the exam Intelligent Data Analysis. Each project assignment is to\nbe resovled by a single student on his/her own. The student is supposed to present the\nsolution as part of the oral exam. The student is required to present a printed version\nof the Python code together with diagrams, tables, etc. that summarize the results. The\nspecific way of how the project is presented is up to the student\u2019s choice.\n#### Problem setting\nA polling institute wants to be able to estimate an individual\u2019s income from his/her personal data (see einkommen.train). To this aim, 30.000 individuals were interviewed concerning the features summarized below. For some of the individuals, not all features are\navailable. Crucially, the income of only 5.000 of the interviewee\u2019s is known.\nYour task is to predict the income group of the remaining 25.000 interviewees and to\nprepare the data such that they can be used for further regression and correlation analyses.\n- Age\n- Employment type (Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov,\nState-gov, Without-pay, Never-worked)\n- Weighting factor to compensate for an interview-dependent selection bias\n- Level of education (Bachelors, Some-college, HS-grad, Prof-school, Assoc-acdm, Assocvoc, 1st-4th, 5th-6th, 7th-8th, 9th, 10th, 11th, 12th, Masters, Doctorate, Preschool)\n- Schooling/training period\n- Marital status (Married-civ-spouse, Divorced, Never-married, Separated, Widowed,\nMarried-spouse-absent, Married-AF-spouse)\n- Employment area (Tech-support, Craft-repair, Other-service, Sales, Exec-managerial,\nProf-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing,\nTransport-moving, Priv-house-serv, Protective-serv, Armed-Forces)\n- Partnership (Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried)\n- Ethnicity (White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black)\n- Gender (Female, Male)\n- Gains on financial assets\n- Losses on financial assets\n- Weekly working time\n- Country of birth (United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba,\nIran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong Kong, Holand-Netherlands)\n1\n- Income (\u2264 50k, > 50k)\n### Exercise\nLoad the data into Python and preprocess it. Choose adequate data transformations,\nnormalizations etc. and decide on how to deal with missing values (marked with \u201c?\u201d).\nConsider which kinds of features the preprocessed data shall contain. Once you have\npreprocessed the data, train a model to predict a person\u2019s income group and apply it to\nthe 25.000 individuals whose income group is unknown. Identify a suitable learning method\nand implement it in Python. Train and evaluate the model. Provide a short documentation\nand motivation of each of your steps.\n"}
{"url": "https://github.com/delwarhub/Introduction-to-Python", "owner": "delwarhub", "repository_name": "Introduction-to-Python", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1232, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 1556162}], "readme": "# Python for Data Science Course \n## Objective of the course:\nThis course is designed for people who want to learn Python to enable their Data Science career. This course provides you with sufficient practice materials to home your Python skillset. \n\n## Overview of the Course\n<li> Introduction to Python </li>\n<li> Understanding Operators\n<li> Variables and Data Types\n<li> Conditional Statements\n<li> Looping Constructs\n<li> Functions\n<li> Data Structure\n<li> Lists\n<li> Dictionaries\n<li> Understanding Standard Libraries in Python\n<li> Reading a CSV File in Python\n<li> Data Frames and basic operations with Data Frames\n<li> Indexing a Data Frame\n<li> Data Manipulation and Visualization\n<li> Regular Expressions\n<li> Cheatsheet for Python\n<li> Evaluate\n"}
{"url": "https://github.com/delwarhub/Language_Task_and_Feature_Attribution_Analysis", "owner": "delwarhub", "repository_name": "Language_Task_and_Feature_Attribution_Analysis", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1214, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 32533}], "readme": "# XAI Project 2\n## Project 2 - Language Task & Feature Attribution Analysis\n\n# Task Data\n\n## TweetTopic: Twitter Topic Classification\nThe TweetTopic repository contains a dataset on Twitter topic classification with 6 labels, including timestamps from September 2019 to August 2021. \\n\nThe below link provide direct access to the task the task dataset.\n- [Hugging Face Dataset](https://huggingface.co/datasets/cardiffnlp/tweet_topic_single)\n\n\n# Training and Testing Setup(Linux SetUp)\n\n1. Clone the repository\n\n```git clone [git clone https URL]```\n\n2. Create a Python virtual environment\n\n```\n# Update and upgrade\nsudo apt update\nsudo apt -y upgrade\n\n# check for python version \"ideal: 3.8.2\"\npython3 -V\n\n# install python3-pip\nsudo apt install -y python3-pip\n\n# install-venv\nsudo apt install -y python3-venv\n\n# Create virtual environment\npython3 -m venv my_env\n\n\n# Activate virtual environment\nsource my_env/bin/activate\n```\n\n3. Install project dependent files\n\n```\npip install requirements.txt\n```\n\n4. Run main.py\n\n```\npython3 main.py\n```\n\n# Project Directory Tree\n\n```\n\u2514\u2500\u2500 Project2/\n    \u251c\u2500\u2500 classification_dataset.py\n    \u251c\u2500\u2500 config.yaml\n    \u251c\u2500\u2500 main.py\n    \u251c\u2500\u2500 models.py\n    \u251c\u2500\u2500 trainer.py\n    \u251c\u2500\u2500 utils.py\n    \u2514\u2500\u2500 requirements.txt\n```\n\n# NOTE\n\n```\nIf there are any dependency issues related to SHAP or LIME not compatible on local environment try using the .ipynb notebook instead. \n```\n\n## Reference\n\n## Tasks\n1.\tPick a dataset of your interest that is based on a language task (POS tagging, text retrieval, news analysis, \u2026)\n2.\tImplement a classification/regression model with the pre-trained transformer architecture (BERT, Distillbert, XLM-BERT, ...)\n3.\tIntegrate with LIME/SHAP\n4.\tPerform feature attribution analysis and create a visualization of results\n5.\tGenerate visualizations with selected examples (3-5 correct and 3-5 failed samples) - think about adding counter-factual examples and show the performance change\n6.\tPresent the overall task & performance, show explainable aspects of the trained model with examples (good & bad predictions)\n\n\n- **Repository Name:** TweetTopic\n- **Version:** COLING main conference 2022\n- **Dataset Labels:** 6\n- **Related Repository:** [cardiffnlp/tweet_topic_multi](https://github.com/cardiffnlp/tweet_topic_multi)\n"}
{"url": "https://github.com/delwarhub/Lightweight_Approach_to_Legal_NER", "owner": "delwarhub", "repository_name": "Lightweight_Approach_to_Legal_NER", "date_all_variable_collection": "2023-09-11", "description": null, "size": 4734, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 84249}], "readme": "# Lightweight approach to Legal NER \nRepository for the final group project as part of the Advanced Natural Language Processing course at Universit\u00e4t Potsdam\nin the winter semester 2022/23.  \nBy Emanuele DeRossi, Md.Delwar Hossain and Jonathan Jordan\n\n## General\nProject based on theoretical aspects and data from https://github.com/Legal-NLP-EkStep/legal_NER .  \nCode is the work of the authors unless specified otherwise here or in code comments.  \nhttps://github.com/huggingface/transformers/blob/v4.27.0/src/transformers/models/roberta/modeling_roberta.py#L1360 used \nas reference for the RoBERTaLegalNER model class in model/roberta_legal_ner.py.  \nThe function collect_named_entities() in evaluation/evaluation.py was inspired by \nhttps://github.com/davidsbatista/NER-Evaluation/blob/master/ner_evaluation/ner_eval.py\n\n## Usage\n### Source dataset acquisition\nRun data/data_util.py to retrieve and unpack the source dataset JSON files. This is required for all further use.\n### Source dataset exploration\nRun preprocessing/exploration.py to examine a few aspects of the source dataset, like dataset instances with a specified \namount of labeled spans, the actual format of an instance in the source dataset JSON files, text lengths of the two \ndifferent judgement and preamble parts, and adjacent labeled spans.\n### Tokenization and token labeling\nRun preprocessing/tokenization.py to assess dataset instances that will be discarded due to containing too many RoBERTa \nBPE tokens, to show the result of preprocessing a single dataset instance and to assess the need for BIO token labels \nvia adjacency of labeled token spans in the preprocessed training dataset.\n### Training dataset preprocessing and storage\nRun preprocessing/last_hidden_states.py to preprocess the training dataset and save it as a HDF5 file to be used for \ntraining. This is necessary for model training using model/linear_heads.py and model/convolution_heads.py.\n### Head model training\nRun model/linear_heads.py to perform a sample training run of a SimpleLinearLNERHead model class instance with dropout.  \nRun model/convolution_heads.py to perform a sample training run of a ConvolutionLNERHeadDeep model class instance.\n### Full model inference\nRun model/roberta_legal_ner.py to use a RobertaLegalNER model class instance with a SimpleLinearLNERHead classifier \nhead model trained without dropout for 70 epochs to infer token labels for an example sentence from the training \ndataset.  \nThis demonstrates the core task the head models are trained for.\n### Evaluation\nRun evaluation/evaluation.py to evaluate a RobertaLegalNER model class instance with a SimpleLinearLNERHead classifier \nhead model trained without dropout for 70 epochs on the development dataset, using the partial/type match criterion."}
{"url": "https://github.com/delwarhub/Linear-Regression-Car-Driving-Risk-Analysis", "owner": "delwarhub", "repository_name": "Linear-Regression-Car-Driving-Risk-Analysis", "date_all_variable_collection": "2023-09-11", "description": "Linear Regression Car Driving Risk Analysis based on car speed", "size": 24, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 53208}], "readme": "# Linear-Regression-Car-Driving-Risk-Analysis\nLinear Regression Car Driving Risk Analysis based on car speed\n"}
{"url": "https://github.com/delwarhub/Linear-Regression-in-Practice-Home-Price-Predict", "owner": "delwarhub", "repository_name": "Linear-Regression-in-Practice-Home-Price-Predict", "date_all_variable_collection": "2023-09-11", "description": "Predict Simple Home prices based on area in square feet. ", "size": 26, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 53497}], "readme": "# Linear-Regression-in-Practice\nPredict Simple Home prices based on area in square feet. \n"}
{"url": "https://github.com/delwarhub/Linear-Regression-Model-for-Advertising-Data", "owner": "delwarhub", "repository_name": "Linear-Regression-Model-for-Advertising-Data", "date_all_variable_collection": "2023-09-11", "description": "Linear Regression Model for Advertising Data", "size": 121, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 122270}], "readme": "# Simple-Linear-Regression\nUnderstanding and building a Simple Linear Regression Model\n\n-------------------------------------------------\nWhen we go about knowing Machine Learning models, one of the first things we generally come across is the Simple Linear Regression. It's the first step into Machine Learning.\n\nThe term regression was first coined in the 19th century to describe a phenomenon, that the heights of descendants of tall ancestors tend to regress (or approach) towards the normal average height. In other words, regression is the tendency to return to moderation (mean). In statistics, the term is defined as a measure of the relation between an output variable and the input variable(s). Hence, the Linear Regression assumes a linear relationship between the former and the latter. \n\nDepending upon the number of input variables, Linear Regression can be classified into two categories:\n1. Simple Linear Regression (Single Input Variable)\n2. Multiple Linear Regression (Multiple Input Variables)\n"}
{"url": "https://github.com/delwarhub/Linear-Regression-with-Multiple-Variable-Car-Risk-Analysis", "owner": "delwarhub", "repository_name": "Linear-Regression-with-Multiple-Variable-Car-Risk-Analysis", "date_all_variable_collection": "2023-09-11", "description": "Linear Regression with Multiple Variable Car Risk Analysis", "size": 3, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 13839}], "readme": "# Linear-Regression-with-Multiple-Variable-Car-Risk-Analysis\nLinear Regression with Multiple Variable Car Risk Analysis\n"}
{"url": "https://github.com/delwarhub/Machine-Learning-Algorithms", "owner": "delwarhub", "repository_name": "Machine-Learning-Algorithms", "date_all_variable_collection": "2023-09-11", "description": null, "size": 248, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 333863}], "readme": "# Machine Learning Algorithms \n## List of Topics\n<li> Matplotlib Graph Example\n<li> Data Distribution\n<li> Machine Learning - Scatter Plot\n<li> Random Data Distributions\n<li> Machine Learning - Linear Regression\n<li> R for Relationship\n<li> Bad Fit Line\n<li> Machine Learning - Polynomial Regression\n<li> R-Squared Values\n<li> Multiple Regression\n<li> Result Explained\n<li> Machine Learning - Train/Test \n<li> Decision Tree\n"}
{"url": "https://github.com/delwarhub/Matplotlib-Example-Linear-and-Polynomial-Regression-Decision-Tree-Train-Test", "owner": "delwarhub", "repository_name": "Matplotlib-Example-Linear-and-Polynomial-Regression-Decision-Tree-Train-Test", "date_all_variable_collection": "2023-09-11", "description": "In this code you will get the following examples:  1.Matplotlib Example 2.Data Distribution 3.Scatter Plot 4.Linear Regression 5.Polynomial Regression 6.Train/Test 7.Decision Tree", "size": 242, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 332824}], "readme": "# Matplotlib-Example-Linear-and-Polynomial-Regression-Decision-Tree-Train-Test\nIn this code you will get the following examples:  1.Matplotlib Example 2.Data Distribution 3.Scatter Plot 4.Linear Regression 5.Polynomial Regression 6.Train/Test 7.Decision Tree\n\nIn this code you will get the following examples: \n1.Matplotlib Example\n2.Data Distribution\n3.Scatter Plot\n4.Linear Regression\n5.Polynomial Regression\n6.Train/Test\n7.Decision Tree\n"}
{"url": "https://github.com/delwarhub/Multimodal_Task_and_Feature_Attribution", "owner": "delwarhub", "repository_name": "Multimodal_Task_and_Feature_Attribution", "date_all_variable_collection": "2023-09-11", "description": null, "size": 24575, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 13960569}, {"language": "Python", "num_chars": 28932}], "readme": "# XAI Project 3\n## Project 3 - Multimodal Task and Feature Attribution\n\n## Task Data: e-SNLI-VE\n\nThe e-SNLI-VE dataset is derived from the well-known SNLI (Stanford Natural Language Inference) dataset and extends it with visual information. It combines textual premises, hypotheses, and corresponding images to enable the investigation of visual entailment, where the goal is to determine if a textual hypothesis can be inferred from a given image and a textual premise. \n\nThe dataset consists of train, dev, and test splits, which can be found in the data folder of this repository. The data is stored in .csv files, and each file contains Flickr30k Image IDs. To access the actual image data, you can download the Flickr30k dataset separately from [Flickr30K](https://www.kaggle.com/hsankesara/flickr-image-dataset).\n\n### Data Format: ###\nThe dataset is available in a structured format, consisting of CSV files. The e-SNLI-VE dataset has the following data format:\n\n- **pairID**: A unique identifier for each pair of image and textual data.\n- **Flickr30kID**: A string or object representing the Flickr30k Image ID associated with the data entry.\n- **hypothesis**: The textual hypothesis or prediction associated with the image.\n- **gold_label**: The gold or ground truth label for the image-text pair.\n- **explanation**: An object or string containing the natural language explanation for the image-text pair.\n\nThe below link provide access to the e-SNLI-VE dataset and corresponding Flick30K images.\n\n- [e-VIL](https://github.com/maximek3/e-ViL/tree/main)\n- [Flickr30K](https://www.kaggle.com/hsankesara/flickr-image-dataset)\n\nThe below link provides access to already downloaded version of the above mention dataset via Google drive.\n\n- [e-SNLI-VE](https://drive.google.com/file/d/105KNRwMRseTtGrYQ0PUVTpvCXSTO5zB0/view?usp=drive_link)\n- [Flick30K](https://drive.google.com/file/d/1-2xugLRKZMsbV-8bQz5IJsE46ex0mt03 /view?usp=sharing)\n\n```\n# Download Fickr30K dataset from the either of above provided links.\nunzip $PATH_TO_DOWNLOADED_FLICKR30K_DATA.zip -d \"./data/\"\n```\n\n## Training & Testing Set-Up  (Linux SetUp)\n\n1. Clone the repository\n\n```\ngit clone [git clone https URL]\n```\n\n2. Create a Python virtual environment\n\n```\n# Update and upgrade\nsudo apt update\nsudo apt -y upgrade\n\n# check for python version\npython3 -V\n\n# install python3-pip\nsudo apt install -y python3-pip\n\n# install-venv\nsudo apt install -y python3-venv\n\n# Create virtual environment\npython3 -m venv my_env\n\n\n# Activate virtual environment\nsource my_env/bin/activate\n```\n\n3. Install project dependent files\n\n```\npip install requirements.txt\n```\n\n4. Run main.py\n\n```\npython3 main.py\n```\n\n## Topic Modeling\n\nThe below link provides access to already trained topic-model w/ 20 topic clusters alongwith other files required to train the model.\n\n- [Topic-Model](https://drive.google.com/file/d/1n4kl5uxml96lJZ5Kb0XrUIhkVmU7mKDI/view?usp=sharing)\n- [Cached-Embeddings](https://drive.google.com/file/d/1--EcUuMvmwsV1L3jEgNhkbelml9ef5R0/view?usp=sharing)\n\n```\nNote: Download the above mentioned files as follows:\n1. Topic-Model => \"./trained_models/topic-model\"\n2. Cached-Embeddings => \"./trained_models/sentence_transformers_all-MiniLM-L6-v2_embeddings.npy\"\n```\n\n### Training Topic-Model\n\n```\n# edit ./config.yaml file\nvim ./config.yaml\n\n# change following attributes\nAPPLY_TOPIC_MODELING: True\nTRAIN_TOPIC_MODEL: True\n\n# train-topic model\npython3 main.py\n```\n\n\n## Multimodal Features Preparation.\n\nTo extract mutimodal text and image features via zero-shot-classification of already defined features\n\n```\n# edit ./config.yaml file\nvim ./config.yaml\n\n# change following attributes \nAPPLY_TEXT_FEATURE_EXTRACTION: True\nAPPLY_IMAGE_FEATURE_EXTRACTION: True\n\nAppropriate feature_type (`topic-oriented` or `emotion-oriented`) can implemented by changing the attributes;\nTEXTUAL_FEATURES_TYPE: feature-type\nIMAGE_FEATURES_TYPE: feature-type\n\nNote: When modeling XGBoost we add additional feature-type `skip` to perform single modality training.\n\n# train-topic model\npython3 main.py\n```\n\n## Training XGBoost Model\n\n```\n# edit ./config.yaml file\nvim ./config.yaml\n\n# change following attributes \nTRAIN_XGBOOST: True\n\nAppropriate feature_type (`topic-oriented`, `emotion-oriented` or `skip`) can implemented by changing the attributes;\nTEXTUAL_FEATURES_TYPE: feature-type\nIMAGE_FEATURES_TYPE: feature-type\n\n# train-topic model\npython3 main.py\n```\n\n\n\n# Project Directory Tree\n\n```\n\u2514\u2500\u2500 Project2/\n    \u251c\u2500\u2500 data/\n    \u2502   \u251c\u2500\u2500 sample_esnlive_train.csv\n    \u2502   \u251c\u2500\u2500 image_features/\n    |   |   \u251c\u2500\u2500 sample_esnlive_emotion_oriented.csv\n    |   |   \u2514\u2500\u2500 sample_esnlive_topic_oriented.csv\n    \u2502   \u251c\u2500\u2500 text_features/\n    |   |   \u251c\u2500\u2500 sample_esnlive_emotion_oriented.csv\n    |   |   \u2514\u2500\u2500 sample_esnlive_topic_oriented.csv\n    \u2502   \u251c\u2500\u2500 sample_esnlive_common_columns.pkl\n    |   \u251c\u2500\u2500 topic_oriented_features_1.pkl\n    |   \u251c\u2500\u2500 topic_oriented_features_2.pkl\n    |   \u2514\u2500\u2500 emotion_oriented_features.pkl\n    \u251c\u2500\u2500 trained_models/\n    \u2502   \u251c\u2500\u2500 sentence_transformers_all-MiniLM-L6-v2_embeddings.npy\n    \u2502   \u2514\u2500\u2500 topic_model\n    \u251c\u2500\u2500 plots/\n    \u251c\u2500\u2500 zero_shot_text_features.py\n    \u251c\u2500\u2500 zero_shot_image_features.py\n    \u251c\u2500\u2500 topic_model.py\n    \u251c\u2500\u2500 config.yaml\n    \u251c\u2500\u2500 main.py\n    \u251c\u2500\u2500 utils.py\n    \u251c\u2500\u2500 utils.py\n    \u251c\u2500\u2500 README.md\n    \u2514\u2500\u2500 requirements.txt\n```\n\n# NOTE\n\n```\nIf there are any dependency issues related to SHAP or LIME not compatibile on local environment try using the .ipynb notebook instead. \n```\n## Tasks\n1.\tPick one multimodal dataset that includes both image & text content. For ex: Multimodal Sentiment - MVSA Single, (pass: mvsa-2023-uni-p), or choose another dataset where the task uses both image and text (both modalities are inputs) to predict. It doesn't apply to tasks where one modality is input and the other is output (e.g. text2image).\n2.\tExtract various visual features (not embeddings) using pre-trained visual models (classifiers, captioning models, etc.). Example: tuples of feature names with probability (or some other score value) => \"image includes a dog\": 0.8, \"kitchen is the scene\": 0.6. In this way, each feature has a name and can be back-traced for the explanation.\nYou can use any pre-trained model(s) of your choice. Some notable examples are CLIP, Recognize Anything Model, OWL-ViT\n3.\tExtract textual features (not embeddings) using pre-trained textual models. Example: tuples of feature names with probability (or some other score value) => \"text includes positive word: amazing\": 0.8, \"text mentions entity: Berlin\": 0.6, \"text has informal writing style\": 0.9, ...\nYou can use any pre-trained model(s) of your choice.\n4.\tImplement a model architecture that uses XGBoost and integrates the extracted features to train a model.\n5.\tPerform feature importance analysis and present the findings (with visualization of explanations), counterfactual examples etc. (as it was done in the other two projects)\n\n## Reference\n\n1. Virginie Do, Oana-Maria Camburu, Zeynep Akata, Thomas Lukasiewicz. e-SNLI-VE: Corrected Visual-Textual Entailment with Natural Language Explanations. arXiv preprint arXiv:2004.03744.\n2. Peter Young, Alice Lai, Micah Hodosh, and Julia Hockenmaier. 2014. From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions. Transactions of the Association for Computational Linguistics, 2:67\u201378.\n\n"}
{"url": "https://github.com/delwarhub/Multimodal_Task_with_Prompting_Large_Language_Models", "owner": "delwarhub", "repository_name": "Multimodal_Task_with_Prompting_Large_Language_Models", "date_all_variable_collection": "2023-09-11", "description": null, "size": 5822, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 6122185}, {"language": "Python", "num_chars": 30275}], "readme": "# XAI Project 4\n## Project 4 - Multimodal Task with Prompting Large Language Models\n\n## Task Data: VQA-X\n\nThe VQA dataset is a popular benchmark dataset for evaluating Visual Question Answering systems. It was created to promote research in the area of combining computer vision and natural language processing. The dataset contains images with associated questions and corresponding answers, making it suitable for training and evaluating models that can understand both visual content and textual questions. \n\nThe VQA dataset includes real-world images from the MS COCO (Microsoft Common Objects in Context) dataset and abstract scenes from the Abstract Scenes dataset. Each image is paired with multiple questions, and each question has ten different answers collected from human annotators. This diversity of answers allows the evaluation of models based on open-ended and multiple-choice questions.\n\n## Training & Testing Set-Up  (Linux SetUp)\n\n1. Clone the repository\n\n```\ngit clone [git clone https URL]\n```\n\n2. Create a Python virtual environment\n\n```\n# Update and upgrade\nsudo apt update\nsudo apt -y upgrade\n\n# check for python version\npython3 -V\n\n# install python3-pip\nsudo apt install -y python3-pip\n\n# install-venv\nsudo apt install -y python3-venv\n\n# Create virtual environment\npython3 -m venv my_env\n\n\n# Activate virtual environment\nsource my_env/bin/activate\n```\n\n3. Install project dependent files\n\n```\npip install requirements.txt\n```\n\n4. Run main.py\n\n```\npython3 main.py\n```\n\n## Download VQA-v2 & VQA-X Dataset \n\n```\n# edit ./config.yaml file\nvim ./config.yaml\n\n# change following attributes\nDOWNLOAD_DATA: True\n\n# download dataset (commands already provided)\npython3 main.py\n```\n\n## Preprocess VQA-X & Sample 100 Instances\n\n```\n# edit ./config.yaml file\nvim ./config.yaml\n\n# change following attributes \nPREPROCESS_DATA: True\n\n# post-process VQA-X dataset and perform sampling\npython3 main.py\n```\n\n## Image Captioning, Prediction & Explanation Generation\n\n```\n# edit ./config.yaml file\nvim ./config.yaml\n\n# change following attributes\nPREDICT_AND_EXPLAIN: True\n\n# applying captioning procedure using blip2 model architecture\n# predict and explain using the flant5xxl\npython3 main.py\n```\n\n# Project Directory Tree\n\n```\n\u2514\u2500\u2500 Project4/\n    \u251c\u2500\u2500 data/\n    \u2502   \u251c\u2500\u2500 vqa_x_data.csv\n    \u2502   \u251c\u2500\u2500 textual/\n    |   |   \u251c\u2500\u2500 sample_esnlive_emotion_oriented.csv\n    |   |   \u2514\u2500\u2500 sample_esnlive_topic_oriented.csv\n    \u2502   \u251c\u2500\u2500 Questions/\n    |   |   \u251c\u2500\u2500 v2_Annotations_Val_mscoco.zip\n    |   |   \u2514\u2500\u2500 v2_mscoco_val2014_annotations.json\n    |   \u251c\u2500\u2500 Annotations/\n    |   |   \u251c\u2500\u2500 v2_Annotations_Val_mscoco.zip\n    |   |   \u2514\u2500\u2500 v2_mscoco_val2014_annotations.json\n    |   \u251c\u2500\u2500 Images/\n    |   |   \u251c\u2500\u2500 val2014.zip\n    |   |   \u2514\u2500\u2500 val2014/\n    \u2502   \u251c\u2500\u2500 vqa_x_sampled_data.csv\n    |   \u2514\u2500\u2500 vqa_x_sampled_data_final.csv\n    \u251c\u2500\u2500 huggingface_hub/\n    \u251c\u2500\u2500 utils.py\n    \u251c\u2500\u2500 data_preprocessor.py\n    \u251c\u2500\u2500 config.yaml\n    \u251c\u2500\u2500 auto_metrics.py\n    \u251c\u2500\u2500 main.py\n    \u251c\u2500\u2500 image_caption_w_blip2.py\n    \u251c\u2500\u2500 predict_and_explain_w_flant5.py\n    \u251c\u2500\u2500 README.md\n    \u2514\u2500\u2500 requirements.txt\n```\n\n``` Note: Please install salesforce-lavis separately, due to some issues with environment configuration we were not able to install it locally.```\n\n## Tasks\n1.\tPick one of the following multimodal tasks: VQA-X, E-SNLI-VE, A-OKVQA, VCR\n2.\tSelect 100 samples from any split of the dataset (distributed equally across class labels, when possible)\n3.\tUse image captioning to obtain textual representations for visual content (BLIP-2 or Instruct-BLIP for captioning)\n4.\tPrompt a large language model (FLAN-T5 XXL model or any other model capable of generating rationale) to solve the task. You can use the prompt templates from a recent paper (see Appendix) and adjust it for your selected task. You can refer to this document on learning what prompting is about. You can refer to this leaderboard on deciding for which open access large language model to choose.\n5.\tPrompt the model to first generate the task-specific prediction (text) and then prompt it again to generate an explanation to the prediction. After appending the model prediction to the prompt text, simply add something like \"Why is that? Generate an explanation\" (or any text that instructs the model to explain why it generated the prediction (X) for the task) and prompt the model again to generate a rationale. Another possible way is to prompt the language model to generate the required task prediction and the related explanation in one step (by adding this instruction into the prompt).\n6.\tCompare generated explanations with ground truth using the metrics (BLEU, ROUGE, METEOR etc.) that are used in the selected dataset and its paper. One metric is sufficient.\n7.\tEvaluate the generated explanations for the 100 samples manually (where each member annotates the same sample and you take a look at the average across the team) by following an annotation scheme from the literature (check how other methods evaluated the generated explanation and how users rated them, based on what aspects, e.g. usefulness, clarity of the explanation, etc.). You can refer to the survey papers that you read previously.\n8.\tPresent the overall findings of the prompting strategy, annotation scheme and analysis of the generated explanations (show good & bad predictions/explanations).\n9.\tYou can run the selected language model on the Colab Notebook (usually requires GPU with VRAM of 25-30 GB), apply for the university account (as described in the forum before but you need to specify that you need access to A100 GPU with 80GB), or via HuggingFace API. Alternatively, you can also look for quanitzed versions of the language models that lets you load them into smaller memory machines or even running them directly on CPU.\n10.\tAlternatively, you can also use GPT models for this project.\n\n\n## Reference\n\n1. DH. Park, LA. Hendricks, Z. Akata, A. Rohrbach, B. Schiele, T. Darrell, M. Rohrbach, Multimodal Explanations: Justifying Decisions and Pointing to the Evidence. in CVPR, 2018.\n2. Y. Goyal, T. Khot, D. Summers-Stay, D. Batra, and D. Parikh. Making the V in VQA matter: Elevating the role of image understanding in Visual Question Answering. In Conference on Computer Vision and Pattern Recognition (CVPR), 2017.\n"}
{"url": "https://github.com/delwarhub/Natural-Language-Processing-Examples", "owner": "delwarhub", "repository_name": "Natural-Language-Processing-Examples", "date_all_variable_collection": "2023-09-11", "description": "Natural-Language-Processing Examples", "size": 13, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 36704}], "readme": "# Natural-Language-Processing"}
{"url": "https://github.com/delwarhub/Project_Module_Tree_Algorithms", "owner": "delwarhub", "repository_name": "Project_Module_Tree_Algorithms", "date_all_variable_collection": "2023-09-11", "description": null, "size": 8113, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 6113551}, {"language": "Python", "num_chars": 15199}], "readme": "# XAI Project 1 \n## Project Module: Models that Exaplin Themselves\n\n# Task Data\n\nThe below link provide direct access to the task the task dataset.\n- [Train data](https://ftp.ncbi.nlm.nih.gov/pub/lu/LitCovid/biocreative/BC7-LitCovid-Train.csv)\n- [Test data](https://ftp.ncbi.nlm.nih.gov/pub/lu/LitCovid/biocreative/BC7-LitCovid-Test.csv)\n- [Test data w/ ground-truth labels](https://ftp.ncbi.nlm.nih.gov/pub/lu/LitCovid/biocreative/BC7-LitCovid-Test-GS.csv)\n\n# Training and Testing Setup(Linux SetUp)\n\n1. Clone the repository\n\n```git clone [git clone https URL]```\n\n2. Create a Python virtual environment\n\n```\n# Update and upgrade\nsudo apt update\nsudo apt -y upgrade\n\n# check for python version \"ideal: 3.8.2\"\npython3 -V\n\n# install python3-pip\nsudo apt install -y python3-pip\n\n# install-venv\nsudo apt install -y python3-venv\n\n# Create virtual environment\npython3 -m venv my_env\n\n\n# Activate virtual environment\nsource my_env/bin/activate\n```\n\n3. Install project dependent files\n\n```\npip install requirements.txt\n```\n\n4. Run main.py\n\n```\npython3 main.py\n```\n\n# Project Directory Tree\n\n```\n\u2514\u2500\u2500 Project1/\n    \u251c\u2500\u2500 data/\n    \u2502   \u251c\u2500\u2500 biocreative_dataset.py\n    \u2502   \u251c\u2500\u2500 BC7-LitCovid-Test-GS.csv\n    \u2502   \u251c\u2500\u2500 BC7-LitCovid-Test.csv\n    \u2502   \u2514\u2500\u2500 BC7-LitCovid-Train.csv\n    \u251c\u2500\u2500 saved_models/\n    \u2502   \u2514\u2500\u2500 100_RFC.pkl\n    \u251c\u2500\u2500 config.yaml\n    \u251c\u2500\u2500 Decision_Tree_XAI.ipynb\n    \u251c\u2500\u2500 main.py\n    \u251c\u2500\u2500 models.py\n    \u251c\u2500\u2500 utils.py\n    \u251c\u2500\u2500 XAI.py\n    \u2514\u2500\u2500 requirements.txt\n```\n\n# NOTE\n\n```\nIf there are any dependency issues related to SHAP or LIME not compatibile on local environment try using the .ipynb notebook instead. \n```"}
{"url": "https://github.com/delwarhub/Python-Course", "owner": "delwarhub", "repository_name": "Python-Course", "date_all_variable_collection": "2023-09-11", "description": "All in One Python", "size": 4028, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 1046997}], "readme": "# Python-Course\nAll in One Python\n"}
{"url": "https://github.com/delwarhub/R-Basic-Programming", "owner": "delwarhub", "repository_name": "R-Basic-Programming", "date_all_variable_collection": "2023-09-11", "description": "R Basic Programming", "size": 260, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# R Basic Programming\nIn this tutorial you will learn the following topics in practice.\n- R Syntax\n- R Comments\n- R Variables\n- R Data Types\n- R Numbers\n- R Math\n- R Strings\n- R Booleans\n### R Operators\n- R If...Else\n- R While Loop\n- R For Loop\n- R Functions\n\n### R Data Structures\n- R Vectors\n- R Lists\n- R Matrices\n- R Arrays\n- R Data Frames\n- R Factors\n\n### R Graphics\n- R Plot\n- R Line\n- R Scatterplot\n- R Pie Charts\n- R Bars\n\n### R Statistics\n- R Statistics Intro\n- R Data Set\n- R Max and Min\n- R Mean Median Mode\n- R Percentiles\n\nRef: https://www.w3schools.com/r/default.asp\n"}
{"url": "https://github.com/delwarhub/School-Management-System-Using-Python-and-MySQL", "owner": "delwarhub", "repository_name": "School-Management-System-Using-Python-and-MySQL", "date_all_variable_collection": "2023-09-11", "description": null, "size": 14, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 7688}], "readme": "## School Management System Using Python and MySQL\n\nThis is a simple course project for the beginner in python. \nIt is a complete project and implemented 3 different features.  \n1. Student Login\n2. Teacher Login\n3. Admin Login\n\n### In Admin Login\nThere are 5 options to do:\n* Admin Menu\n1. Register New Student\n2. Register New Teacher\n3. Delete Existing Student\n4. Delete Existing Teacher\n5. Logout\n\n\n### In Teacher Login\nThere are 3 options to do:\n* Teacher Menu\n1. Mark Student Register\n2. View Register\n3. Logout\n\n### In Student Login\nThere are 3 options to do:\n* Students Menu\n1. View Register\n2. Download Register\n3. Logout\n\n\n"}
{"url": "https://github.com/delwarhub/SeleniumTest", "owner": "delwarhub", "repository_name": "SeleniumTest", "date_all_variable_collection": "2023-09-11", "description": "Selenium with Python Script for Automation Testing", "size": 6847, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "delwarhub", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 528}], "readme": "# SeleniumTest\nSelenium with Python Script for Automation Testing <br>\nConfigure Selenium using Python\nThere are following steps to configure Selenium using Python:\n\n- Download and install Python on Windows\n- Install Selenium libraries in Python\n- Download and install PyCharm\n- Create a new project and write the Selenium test script\n- Run and validate the test scripts.\n- Download and install Python for Windows\n"}
{"url": "https://github.com/delwarhub/Sentiment-Analysis-of-Tweet-Data-Using-R-", "owner": "delwarhub", "repository_name": "Sentiment-Analysis-of-Tweet-Data-Using-R-", "date_all_variable_collection": "2023-09-11", "description": "Programming Language: R  Tools: R Studio  Final Year Project of M. Sc in Computer Science.  Jahangirnagar University.  Dhaka Bangladesh. ", "size": 3492, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 32726}], "readme": "# Sentiment Analysis of Tweet Data\n\n## ABSTRACT\n\nThis project is on \u201cSENTIMENT ANALYSIS OF TWEET DATA\u201d is a sentiment analysis project based on big data analytics. This project will help us to analyze sentiment from twitter text data. This will be able to show the sentimental state for a person or a specific topic or whatever I want. The aim of this project is to build up an application which will be able to connect non-technical people to the field of data mining. Using simple user interface, they will be able to create a report based on their search keyword. This application is very simple and easy to use. So, it will be comfortable for everyone to use it. To develop this project, need to know R language and platform and its library. To create the user interface using shiny, which is a package including PHP and HTML to create a web application. By giving input inside the shiny app and in the background, R will do the data collection, analysis and output generation. Then shiny will print the output in the web application. Its main task is running the application on the browser, which is taking input and providing us output based on input.\n\nProgramming Language: R  \nTools: R Studio  \nFinal Year Project of M. Sc in Computer Science. \nJahangirnagar University. \nDhaka, Bangladesh. \n"}
{"url": "https://github.com/delwarhub/Snipe-IT-Open-Source-Asset-Management-", "owner": "delwarhub", "repository_name": "Snipe-IT-Open-Source-Asset-Management-", "date_all_variable_collection": "2023-09-11", "description": null, "size": 5, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Snipe-IT-Open-Source-Asset-Management\n\n- Easy Install Snipe-IT Asset Management on Windows 10 and 11\n- Start...\n- Requirements:\n- webserver: with version PHP >= 7.4 and < v8.1.2\n- Enable PHP Extensions: LDAP,...\n- OK. Now, download the web server XAMPP for Windows\n- use version: 8.1.12 / PHP 8.1.12\n1. install Xampp server\nwaiting for Xampp install...\nok. xampp install finish.\n2. install composer\nok. check version php, composer has installed yet.\nOpen command line\nphp -v\ncomposer \nPress enter\nOK.\n3. Download and unzip Snipe-IT. After copy and paste into C:\\xampp\\htdocs\n- rename folder snipe-it-6.0.14 to snipe-it\n4. Configuration snipe-it\nCopy and paste file .env.example in C:\\xampp\\htdocs\\snipe-it. Rename to .env\nOpen file .env edit rows:\nAPP_URL=localhost\nSave and close\n- Open file php.ini and un-comment/delete; rows: C:\\xampp\\php\n- extension=ldap\n- extension=gd\n- extension=sodium\n-save and close.\n5. Create a database for snipe-it with name snipeit\n- start apache, MySQL service\n- open browse http://localhost/phpmyadmin\n-building laravel \n- open command prompt\n- cd /\n- C:\\>cd xampp/htdocs/snipe-it\n- composer install\n- 6. Generate Your App Key\n- open command promtp\n- cd /\n- C:\\xampp\\htdocs\\snipe-it\n- php artisan key: generate\n- yes\n7. Pre-Flight & Setup\n- open file .env and edit rows:\n- DB_DATABASE=snipeit\n- DB_USERNAME=root\n- Save and close\n-Config DocumentRoot in Apache\n- C:\\xampp\\apache\\conf\n- open file httpd.conf and add:\n- DocumentRoot \"/xampp/htdocs/snipe-it/public\"\n- <Directory \"/xampp/htdocs/snipe-it/public\">\n- Save and close\n- restart Apache service\n- open browse input http://localhost\n-Yeah!\n- continue...\n- Enter the information in the form:\n+ Domain mail\n+ First name:\n+ Last name\n+ Username...\nOK.\nGoodLuck!\n\nFor Linux: https://syncbricks.com/snipe-it-instsallation-ubuntu-20-04/\n"}
{"url": "https://github.com/delwarhub/Spam-Classifier", "owner": "delwarhub", "repository_name": "Spam-Classifier", "date_all_variable_collection": "2023-09-11", "description": "Spam Classifier", "size": 269, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 77518}], "readme": "SMS Spam Collection v.1\n-------------------------\n\n1. DESCRIPTION\n--------------\n\nThe SMS Spam Collection v.1 (hereafter the corpus) is a set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English of 5,574 messages, tagged acording being ham (legitimate) or spam. \n\n1.1. Compilation\n----------------\n\nThis corpus has been collected from free or free for research sources at the Web:\n\n- A collection of between 425 SMS spam messages extracted manually from the Grumbletext Web site. This is a UK forum in which cell phone users make public claims about SMS spam messages, most of them without reporting the very spam message received. The identification of the text of spam messages in the claims is a very hard and time-consuming task, and it involved carefully scanning hundreds of web pages. The Grumbletext Web site is: http://www.grumbletext.co.uk/\n- A list of 450 SMS ham messages collected from Caroline Tag's PhD Theses available at http://etheses.bham.ac.uk/253/1/Tagg09PhD.pdf\n- A subset of 3,375 SMS ham messages of the NUS SMS Corpus (NSC), which is a corpus of about 10,000 legitimate messages collected for research at the Department of Computer Science at the National University of Singapore. The messages largely originate from Singaporeans and mostly from students attending the University. These messages were collected from volunteers who were made aware that their contributions were going to be made publicly available. The NUS SMS Corpus is avalaible at: http://www.comp.nus.edu.sg/~rpnlpir/downloads/corpora/smsCorpus/\n- The amount of 1,002 SMS ham messages and 322 spam messages extracted from the SMS Spam Corpus v.0.1 Big created by Jos\u00e9 Mar\u00eda G\u00f3mez Hidalgo and public available at: http://www.esp.uem.es/jmgomez/smsspamcorpus/\n\n\n1.2. Statistics\n---------------\n\nThere is one collection:\n\n- The SMS Spam Collection v.1 (text file: smsspamcollection) has a total of 4,827 SMS legitimate messages (86.6%) and a total of 747 (13.4%) spam messages.\n\n\n1.3. Format\n-----------\n\nThe files contain one message per line. Each line is composed by two columns: one with label (ham or spam) and other with the raw text. Here are some examples:\n\nham   What you doing?how are you?\nham   Ok lar... Joking wif u oni...\nham   dun say so early hor... U c already then say...\nham   MY NO. IN LUTON 0125698789 RING ME IF UR AROUND! H*\nham   Siva is in hostel aha:-.\nham   Cos i was out shopping wif darren jus now n i called him 2 ask wat present he wan lor. Then he started guessing who i was wif n he finally guessed darren lor.\nspam   FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! ubscribe6GBP/ mnth inc 3hrs 16 stop?txtStop\nspam   Sunshine Quiz! Win a super Sony DVD recorder if you canname the capital of Australia? Text MQUIZ to 82277. B\nspam   URGENT! Your Mobile No 07808726822 was awarded a L2,000 Bonus Caller Prize on 02/09/03! This is our 2nd attempt to contact YOU! Call 0871-872-9758 BOX95QU\n\nNote: messages are not chronologically sorted.\n\n\n2. USAGE\n--------\n\nWe offer a comprehensive study of this corpus in the following paper that is under review. This work presents a number of statistics, studies and baseline results for several machine learning methods.\n\n[1] Almeida, T.A., G\u00f3mez Hidalgo, J.M., Yamakami, A. Contributions to the study of SMS Spam Filtering: New Collection and Results. Proceedings of the 2011 ACM Symposium on Document Engineering (ACM DOCENG'11), Mountain View, CA, USA, 2011. (Under review)\n\n\n3. ABOUT\n--------\n\nThe corpus has been collected by Tiago Agostinho de Almeida (http://www.dt.fee.unicamp.br/~tiago) and Jos\u00e9 Mar\u00eda G\u00f3mez Hidalgo (http://www.esp.uem.es/jmgomez).\n\nWe would like to thank Dr. Min-Yen Kan (http://www.comp.nus.edu.sg/~kanmy/) and his team for making the NUS SMS Corpus available. See: http://www.comp.nus.edu.sg/~rpnlpir/downloads/corpora/smsCorpus/. He is currently collecting a bigger SMS corpus at: http://wing.comp.nus.edu.sg:8080/SMSCorpus/\n"}
{"url": "https://github.com/delwarhub/Text-Analytics-for-Beginners-using-NLTK", "owner": "delwarhub", "repository_name": "Text-Analytics-for-Beginners-using-NLTK", "date_all_variable_collection": "2023-09-11", "description": null, "size": 4482, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 1423683}], "readme": "# Text-Analytics-for-Beginners-using-NLTK\nText Analytics for Beginners using NLTK\n"}
{"url": "https://github.com/delwarhub/Tweeter-Sentiment-Analysis", "owner": "delwarhub", "repository_name": "Tweeter-Sentiment-Analysis", "date_all_variable_collection": "2023-09-11", "description": "Tweeter Sentiment Analysis", "size": 41, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "delwarhub", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 49748}], "readme": "# Tweeter-Sentiment-Analysis\nTweeter Sentiment Analysis\n"}
{"url": "https://github.com/Deux9/bookprynt", "owner": "Deux9", "repository_name": "bookprynt", "date_all_variable_collection": "2023-09-11", "description": "Program that outputs the correct page order to print a booklet where one sheet of paper forms the cover and back of the book", "size": 144, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "Deux9", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 412}], "readme": "Bookprynt\n=========\nThis program will give the correct order of pagenumbers that are needed to print a double paged booklet that can be stapled together easily, so the first sheet of paper will envelop the remaining ones. The output string can be copied and pasted into the printing window.\n\nIt will only work with an even number of pages to print. We will print 2 pages per sheet and obviously don't want to cut one of them. If you do not meet that requirement, consider adding a blank page at the end of the document.\n\nIn some cases it might be desirable not to print the title page because it will have to be flipped or something. Just enter the page number you want to start printing at.\n\nExample: Your document has `13` pages and start with page `2` will result in `2,13,3,12,4,11,5,10,6,9,7,8`\n"}
{"url": "https://github.com/Deux9/LateX-UP", "owner": "Deux9", "repository_name": "LateX-UP", "date_all_variable_collection": "2023-09-11", "description": "LaTeX - Vorlage f\u00fcr Hausarbeiten an der Universit\u00e4t Potsdam", "size": 37, "stargazers_count": 1, "watchers_count": 1, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "Deux9", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 3304}], "readme": "Vorlage f\u00fcr Hausarbeiten an der Universit\u00e4t Potsdam von Martin Freidank (v.1.2)\n===============================================================================\n    \nAnleitung\n---------\nDiese kleine LaTeX-Vorlage soll eine schlanke, gut aussehende Grundlage f\u00fcr Arbeiten an der Universit\u00e4t Potsdam bieten.\n\n###Deckblatt###\nEinfach die enstprechenden Daten in die jeweiligen Felder der Datei texes/metadaten.tex eintragen.\n\n###Literaturverzeichnis###\nIm Hauptdokument main.tex _ENTWEDER_ Amerikanisch oder Deutsch entkommentieren (\"%\" am Beginn der Zeile l\u00f6schen).\nDie bib-Quelldatei f\u00fcr das Literaturverzeichnis l\u00e4sst sich im entsprechenden Abschnitt einf\u00fcgen.\nAls Prozessor f\u00fcr das Literaturverzeichnis ist Biber zu w\u00e4hlen.\n\n###Eidesstattliche Erkl\u00e4rung###\nNach Wunsch ist am Schluss des Dokuments die eidesstattliche Erkl\u00e4rung (eiderkl.tex), die manchmal verlangt wird, zu entkommentieren.\n\t\nChangelog\n---------\n1.0 - Erste Ver\u00f6ffentlichung\n\n1.0.1 - einige Pakete hinzugef\u00fcgt, die haupts\u00e4chlich Optimierungsarbeiten im Hintergrund leisten (microtype, amsmath, cleveref), die Funktion aber nicht ma\u00dfgeblich ver\u00e4ndern\n\n1.1 - Support f\u00fcr einige Schriften hinzugef\u00fcgt\n\n1.2 - Neue, schickere Titelseite\n"}
{"url": "https://github.com/Deux9/myhome", "owner": "Deux9", "repository_name": "myhome", "date_all_variable_collection": "2023-09-11", "description": null, "size": 207, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Deux9", "contributions": 15}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 7233}, {"language": "CSS", "num_chars": 940}]}
{"url": "https://github.com/Deux9/runtumble", "owner": "Deux9", "repository_name": "runtumble", "date_all_variable_collection": "2023-09-11", "description": "little simulation of a run and tumble movement", "size": 164, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "Deux9", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 3504}], "readme": "Runtumble\n=========\nThis program simulates the trajectory of a bacterial swimmer (such as e.coli). Certain parameters can be adjusted in `execute.py`. The actual algorithms are implemented in `runtumble.py`.\n"}
{"url": "https://github.com/Deux9/sturzbecher_ss_2015", "owner": "Deux9", "repository_name": "sturzbecher_ss_2015", "date_all_variable_collection": "2023-09-11", "description": "Dieses Repository enth\u00e4lt alle Lernunterlagen f\u00fcr die Vorlesung \"Theoretische und empirische Grundlagen der Jugend- und Familiensoziologie\" an der Uni Potsdam im Sommersemester 2015", "size": 820, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "gh-pages", "contributors": [{"contributor": "Deux9", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 40908}, {"language": "CSS", "num_chars": 481}], "readme": "---\ntitle: Jugend- und Familiensoziologie II\nauthor: Martin Freidank\nlicense: GNU Free Documentation License\nlanguage: de\n---\n\n\n\nJV 9.2 -- Risikoverhalten\n=========================\n\n>_Erkl\u00e4ren Sie jugendtypische Geschwindigkeits\u00fcbertretungen im motorisierten Stra\u00dfenverkehr aus der Perspektive kognitions-, emotions- und neuropsychologischer Ans\u00e4tze und erl\u00e4utern Sie, inwieweit diese Ans\u00e4tze jeweils empirisch gesichert sind. Stellen Sie jeweils einen sozialwissenschaftlichen und einen integrativen Ansatz zur Erkl\u00e4rung von Risikoverhalten vor und benennen Sie seinen Inhalt bzw. seine Besonderheiten!_\n\n##Psychologischer Erkl\u00e4rungsansatz\n\n###Kognitionspsychologischer Ansatz\n\n####Adoleszenter Egozentrismus (kognitive Defizite)\n- Selbsteinsch\u00e4tzung als \"einzigartig\" \u2192 Selbst\u00fcbersch\u00e4tzung\n- \"Invincibility Fable\": Unverwundbarkeitseinsch\u00e4tzung aufgrund mangelnder Erfahrung\n- \"Imaginary Audience\": Projektion der eigenen Gedankenwelt auf Andere, Bed\u00fcrfnis nach Selbstproduktion\n- empirisch eher wenig gesichert: hoher Egozentrismus, geringe Risiken\n\n####Decision-Making Perspective \nDefizite bei der Verarbeitung sozialer Informationen\n\n- Verhalten als Folge von Entscheidungen\n- Schritte des Decision-Making:\n\t- Identifizieren m\u00f6glicher Optionen und Konsequenzen\n\t- Bewerten der W\u00fcnschbarkeit und Wahrscheinlichkeit der Konsequenzen\n\t- Zusammenf\u00fchren aller Informationen zu einer Entscheidung\n- Empirie: keine eindeutigen Aussagen \u00fcber Entscheidungsprozesse in Risikosituationen,\n\tJugendliche neigen zum Untersch\u00e4tzen von Langzeitfolgen \u2192 keine Evidenz f\u00fcr bestimmenden Einfluss der Qualit\u00e4t informationsverarbeitender Prozesse\n\n###Emotionspsychologischer Ansatz\n- Risikoverhalten als Folge unzureichender Affektregulation\n- Hypothese: Entscheidungen von Jugendlichen st\u00e4rker durch affektive Zust\u00e4nde beeinflusst, weil F\u00e4higkeiten zur Affektregulation schw\u00e4cher ausgepr\u00e4gt sind\n- Empirie:  Best\u00e4tigung der Hypothese, Hinweise auf alterskorrelierte Impulsivit\u00e4tsunterschiede\n\n###Neuropsychologischer Ansatz\n\n- Hirnregion f\u00fcr Verhaltensplanung, Entscheidungsfindung, Impulskontrolle und Risikoeinsch\u00e4tzung w\u00e4hrend des Jugendalters starker Ver\u00e4nderung unterworfen\n- K\u00f6rper kann Risiko belohnen \u2192 genetische Neigung mancher Menschen\n\n###Pers\u00f6nlichkeitspsychologische Perspektive\n- \"Sensation Seeking\": Suchen abwuchslungsreicher, komplexer und starker Empfindungen und Erfahrungen unter Inkaufnahme von Risiken\n- teilweise genetisch determiniert\n- geachtetes Konstrukt geschlossener biopsychosozialen Pers\u00f6nlichkeitstheorie\n- Kritik: Vernachl\u00e4ssigung von kognitiven Aspekten, Sozialisationskontexten und leistungsthematischen Komponenten \u2192 Umgebungseinfl\u00fcsse, Kritik an der Methode des SS-Tests\n\n##Sozialwissenschaftliche Erkl\u00e4rungsans\u00e4tze (nur einen lernen)\n\n###Sozialpsychologische Perspektive\n\n- \"Risky Shift\"-Ph\u00e4nomen: In der Gruppe getroffene Entscheidung riskanter\n\t- Diffusion der Verantwortung: Individuum \u201eversteckt sich hinter Gruppe\u201c\n\t- Informationsniveau: erh\u00f6hte Anzahl von Argumenten und Sichtweisen \u2192 objektiverer Eindruck\n\t- F\u00fchrerschaft: risikofreudige F\u00fchrerfigur l\u00e4sst verst\u00e4rkende Risikoargumente eher zu und verst\u00e4rkt diese\n\t- Risikobereitschaft als sozialer Wert: Status innerhalb der Gruppe\n\n##Integrative Erk\u00e4rungsans\u00e4tze (nur einen lernen)\n\n###Theorie des jugendlichen Leichtsinns\n\n- Synthese verschiedener Ans\u00e4tze, multidimensional, kultur\u00fcbergreifend\n- gleiche jugendtypische Faktoren: z.B: Sensationssuche\n- damit verbunden: Mangel an verhaltensleitenden Wertorientierung und konventionellen Bindungen\n- Formen und Auftretensh\u00e4ufigkeit von Risikoverhalten durch soziokulturellen Kontext, bzw. Sozialisationskontext bestimmt\n\t- \"Breite Sozialisation\" (Individualit\u00e4t und Autonomie beg\u00fcnstigt) vs.\n\t- \"Enge Sozialisation\" (Gehorsam und Konformit\u00e4t als h\u00f6chste Werte)\n\nJV 10.2 -- Armut\n================\n\n>_\"Wird Armut vererbt?\" \"Einmal arm \u2013 Immer arm?\" Diskutieren Sie diese beiden Fragen unter Ber\u00fccksichtigung des Konzepts der intergenerativen Armutstransfers sowie aktueller Entwicklungen bez\u00fcglich der Einkommensmobilit\u00e4t in Deutschland und den USA! Beschreiben Sie den Zusammenhang zwischen \u00f6konomischem Wandel, Familienentwicklung und Pers\u00f6nlichkeitsentwicklung anhand des theoretischen Modells von Elder & Caspi! Wie wurde dieses Modell erarbeitet?_\n\n##intergenerativer Armutstransfer\n\nAnnahme: Kinder aus armen Familien haben aufgrund ung\u00fcnstiger Sozialisationsbedingungen schlechtere Chancen auf dem Ausbildungs- und  Arbeitsmarkt\n\nArmut hat Einfluss auf:\n\n- Familiengr\u00f6\u00dfe\n- Fehlern\u00e4hrung, Krankheiten und medizinischer Unterversorgung von Kindern\n- soziale und Umweltdeprivation von Kindern\n- Schulversagen\n- schlie\u00dflich Arbeitslosigkeit\n\nEmpirie:\n\n- DE:  keine systematischen Verlaufsuntersuchungen\n- USA: junge Erwachsene mit Sozialhilfehintergrund haben h\u00f6heres Armuts- und Sozialhilferisiko, allerdings mehrheitlich \u00dcberwindung\n\n##Einkommensmobilit\u00e4t\nArmut als mehrheitlich zeitlich begrenze Folge der Dynamik famili\u00e4rer Einkommensverh\u00e4ltnisse\n\n####Gegenkonzept zum integenerativen Transfer: phasenweise Armut\n\n- zeitlich begrenzte Armut\n- 75% nie von relativer Einkommensarmut -- 6% wiederholt betroffen\n\n####Heterogene Armutserfahrungen:\n\n- hohe Einkommensmobilit\u00e4t in unteren Lagen\n- krisenhafte Phasen der Sozialhilfebed\u00fcrftigkeit meist schnell \u00fcberwunden\n- Deprivation und Passivit\u00e4t selten, meist aktive Bew\u00e4ltigungsversuche\n\n##\u00d6konomischer Wandel, Familie und Pers\u00f6nlichkeit: \"Theorie des Lebensverlaufs\"\n\n###Entwicklung der Theorie\n\n- ab 1900: neuartige, multiple Problemlagen und und individuelle Anpassungsprozesse der Lebensgestaltung im Blick der Forschung\n- Mitte 20. Jh: Wechselwirkung zwischen individuellem Verhalten und gesellschaftlichem Wandel \u00fcber Lebensspanne theoretisch konzeptualisieren \u2192 Kohorten-Ans\u00e4tze\n\n###Vergleichsstudie von Elder\n\n####Untersuchung: L\u00e4ngsschnittstudie Jahrg\u00e4nge 1920/21 und 1928/29\n\nin 30er Jahren 3 Arten der Ver\u00e4nderungen als Unterschied von deprivierten und nicht deprivierten Familien\n- Haushalts\u00f6konomie\n- Familienbeziehungen\n- sozial verursachter Stress\n\n####Kohortenunterschied:\n- \u00e4ltere Kohorte:\n\t-  alt genug f\u00fcr gefestigtes Entwicklungsfundament und Verantwortungs\u00fcbernahme\n\t- kaum dauerhafte Nachteile\n- j\u00fcngere Kohorte:\n\t- abh\u00e4ngiger von familialer Zuwendung und Unterst\u00fctzung\n\t- zerst\u00f6rerischer Einfluss der Deprivation auf Familienleben\n\t- weniger Optimismus und Selbstbewusstsein\n\t- geschlechtsspezifische Entwicklungskonsequenzen\n\t\n###Modell\n\n![Schema Lebensverlauf](res/lebensverlauf.png)\\\n\n\n1. Kontrollzyklen\n\t- Diskrepanz zwischen Anspr\u00fcchen und Ressourcen\n\t- Sozialer Wandel und/oder \u00f6konomische Deprivation: Erlebnis Kontrollverlust\n\t- Individuen setzen sich mit Umwelt auseinander, um Kontrolle wieder zu erlangen\n\t- Zyklus: Produktion und Reduktion der Diskrepanzen, h\u00e4ufig Wendung des Lebenslaufs\n2. Situative Gebote\n\t- Wendungen auch von historisch vorstrukturierter Situation im Lebens- und Entwicklungskontext abh\u00e4ngig\n\t- Situation stellt Handlungsanforderungen an den Einzelnen \u2192 \"Situative Gebote\"\n3. Selektive Akzentuierung von Dispositionen\n\t- um situative Gebote zu bew\u00e4ltigen: Anpassung der Betroffenen\n\t- vorhandene Eigenschaften entsprechend ihrer N\u00fctzlichkeit _akzentuiert_\n4. Interdependenz von Lebensl\u00e4ufen:\n\t- sozialer Kontext der Betroffenen und Qualit\u00e4t der sozialen Beziehungen moderiert Effekte des sozialen Wandels\n5. Lebensstufenprinzip\n\t- Entstehung und Bew\u00e4ltigung der Diskrepanzen verlaufen abh\u00e4ngig von den sich im Laufe des Lebens ver\u00e4ndernden Entwicklungsaufgaben und -voraussetungen des Individuums\n\nJV 12.1 -- Jugend und Partizipation\n===================================\n>_Was versteht man unter \"Partizipation\" und \"partizipativem Handeln\" im Vergleich zu \"Kooperation\" und \"kooperativem Handeln\"? Welchen Nutzen haben partizipative Handlungsspielr\u00e4ume in Bildungseinrichtungen? Erl\u00e4utern Sie, wie Partizipation auf der interaktionalen Ebene \"funktioniert\"! Beschreiben Sie kurz konsultative Partizipationsformen Heranwachsender!_\n\n##Begriffe\n\n- Partizipation: Kooperation von Individuen mit einer sozialen Gruppe oder die Kooperation von sozialen Gruppen\n- partizipatives Handeln:\n\t- individuelle Aktionen, die Partizipation anstreben oder verwirklichen\n\t- eigene Intentionen mit Normen und Handlungspl\u00e4nen der Gruppe durch Aushandlungsprozesse in \u00dcbereinstimmung gebracht\n\t- und als Teil eines einvernehmlichen gemeinsamen Handlungsplanes von Individuum und Gruppe verwirklicht\n- Kooperation:\n\t- raum-zeitlich koordiniertes Zusammenwirken von Individuen unter einer Leitung\n\t- gemeinsames Ziel mittels gemeinsamer Strategie verwirklicht\n- kooperatives Handeln:\n\t- individuelle Aktionen, die Kooperation anstreben oder verwirklichen\n\t- eigene Intentionen mit denen anderer durch Aushandlungsprozesse in \u00dcbereinstimmung gebracht.\n\nPartizipation als Sonderform der Kooperation mit spezieller Beteiligung von Gruppen\n\n##Nutzen von partizipativen Handlungsspielr\u00e4umen in Bildungseinrichtungen\n- \u00dcbung demokratischen Handelns - politische Stabilit\u00e4t\n- Akzeptanz f\u00fcr Autorit\u00e4tsentscheidungen\n- Maximierung des Lerngewinns\n\n##Funktion von Partizipation\n\n![Schema Partizipation](res/partizipation.png)\\\n\n\n- in allen Phasen werden soziale Informationen aufgenommen, gespeichert, interpretiert und in Verhalten umgesetzt\n- Anbahnung gelungen: Gruppendruck gegen\u00fcber eigenen Interessen (Gruppenpolarisierung)\n- Durchsetzen eigener Interessen: \"Minorit\u00e4teneinfluss\"\n\t- erfolgreich, wenn abweichende Meinung konsistent vertreten\n\n##Formen konsultativer Einflussnahme von Heranwachsenden\n\n1. offene Formen:\n\t- nicht gew\u00e4hlte Vertreter agieren\n\t- Beteiligung und Meinungs\u00e4u\u00dferung aller\n2. projektorientiert:\n\t- regelm\u00e4\u00dfige Treffen von Kindern \u00fcber begrenzten Zeitraum zu bestimmten Themen\n\t- Kinder besitzen fr\u00fch Partizipationskompetenzen und setzen diese bei geeigneten M\u00f6glichkeiten ein\n3. parlamentarisch\n\t- Gremienwahl, um stellvertretend f\u00fcr Interessen einzutreten\n\t- inhaltliche und formale Orientierung an herk\u00f6mmlichen Politikformen\n\nJV 13.1 -- Werte\n================\n\n>_Was sind \"Werte\" und welche Funktion haben sie? Beschreiben und vergleichen Sie die theoretischen Grundpositionen und methodischen Operationalisierungen (Messinstrumente) von Ronald Inglehart (\"Wertewandel\") und Helmut Klages (\"Wertesynthese\")! Nennen Sie je zwei Beispiele f\u00fcr materialistische und postmaterialistische Wertorientierungen!_\n\n##Definition und Funktion\n\n- grundlegende Orientierungen von Individuen und sozialen Gruppen\n- emotional besetzte Vorstellungen \u00fcber das gerechtfertigt W\u00fcnschenswerte \u2192 handlungswirksam und verhaltenssteuernd\n- verankert in Normen, Pers\u00f6nlichkeits- und Motivationsstruktur in Gesellschaft \u2192 stabilit\u00e4tsf\u00f6rdernd\n- Diagnostische Funktion:\n\t- Kenntnis von gesellschaftlichen Werten \u2192 Kultur\n\t- Kenntnis von Werten einer Person \u2192 Lebensziele\n\n##Wertewandel vs. Wertesynthese\n###Wertewandel nach Inglehart\n- Abl\u00f6sung traditionsgebundener Werter durch Neue \u2192 Wertesubstitution\n- hierarchisch in bipolarem Kontinuum zwischen Materialismus und Postmaterialismus\n\n####Mangelhypothese:\n- Priorit\u00e4ten reflektieren sozio\u00f6konomisches Umfeld\n- gr\u00f6\u00dfter subjektiver Wert sind Dinge, die zu knapp sind\n\n####Sozialisationshypothese:\n- Intra-individuelle Stabilit\u00e4t\n- Wertvorstellungen spiegeln vorherrschende Bedingungen der Jugendzeit wider\n\n####Methodik:\n- Ra _nk_ ing-Verfahren von Wertorientierungen: Inglehart-Index\n- zwei Pole schlie\u00dfen sich aus \u2192 \"Forced choice situation\"\n\n###Wertesynthese nach Klage\n\n- zwei unabh\u00e4ngige Wertgruppen:\n\t- Pflicht- und Akzeptanzwerte: Selbstkontrolle\n\t- Selbstentfaltungswerte: Befreiung von Zw\u00e4ngen\n- Wertesynthese: Beide Wertgruppen von Wertewandel betroffen. Keine exklusiven Pole \u2192 keine Verschiebung sondern Rekombination\n\n####Lebenszyklus-Hypothese\n- Ver\u00e4nderungen individueller Wertorientierungen durch Anpassung an lebensphasenspezifische Rollenanforderungen m\u00f6glich\n\n####Methodik:\n- Ra _t_ ing-Verfahren: voneinander unabh\u00e4ngige Pflicht- und Selbstentfaltungswerte sollen nach Indikatoren einzeln hinsichtlich ihrer Wichtigkeit beurteilt werden\n- M\u00f6glichkeit gleichrangiger Orientierung auf verschiedene Werte\n\n##Beispiele f\u00fcr Wertorientierungen:\n- materialistisch:\n\t- Psychologische Grundbed\u00fcrfnisse: Atmung, Trinken, Nahrung, Schlaf\n\t- Sicherheit: Wohnung, Job, Gesundheit\n- postmaterialistisch:\n\t- Soziale Bed\u00fcrfnisse: Partnerschaft, Kommunikation, Freunde\n\t- Individualbed\u00fcrfnisse: Status, Macht, Karriere\n\nFV 8.2 -- Kinderwunsch\n======================\n>_Beschreiben Sie den historischen Wandel des Kinderwunsches aus der Perspektive des Rational-Choice-Ansatzes! Stellen Sie dar, wie sich die historischen Ver\u00e4nderungen auf die Bedingungen des Aufwachsens f\u00fcr Kinder im Allgemeinen und auf die Eltern-Kind-Beziehung im Besonderen auswirken!_\n\n##Grundlagen Rational Choice\n- Mensch als subjektiv rationaler Akteur: zielgerichtet handelnder Nutzen-Maximierer\n- resourceful, restricted, expecting, evaluating, maximizing man\n- menschliches Handeln als L\u00f6sen von Problemen: Bed\u00fcrfnisse Befriedigen und Ziele erreichen \u2192 Notwendigkeit sozialen Handelns (fremde Ressourcenkontrolle)\n\n##Rational Choice und Kinderwunsch\n- Dimensionen der elterlichen Nutzenerwartungen an Kinder\n\t- materiell\n\t- psychologisch\n\t- sozial-normativ\n- technischer Industrialisierungsgrad ~ immaterielle Nutzenerwartungen\n- Absicherung im Sozial- und Wohlfahrtsstaat: kein materieller Anreiz f\u00fcr Kinder\n\n###Kinder als finanzielle Belastung\n- Ziel: Kindern optimale Bedingungen bieten\n\t- abgeschlossene Ausbildung\n\t- beruflich abgesichert\n\t- gute Finanz- und Wohnverh\u00e4ltnisse\n- heute mehr Leistungen von Eltern mobilisiert (Beziehungen, \u00f6konomischer Aufwand, zeitlicher Umfang)\n- Armutsrisiko steigt mit Kinderzahl\n- Kinder als Schw\u00e4chung der individuellen Arbeitsmarktchancen (Flexibilit\u00e4t etc.)\n\n##Aufwachsen und Wandel der Eltern-Kind-Beziehung\n- Fortgeschrittene Industriegesellschaften: Kind als \"Wunschkind\" immaterieller Sinnerf\u00fcllung\n\t- gro\u00dfe Anspr\u00fcche an Kinder: M\u00e4ngel korrigieren, Anlagen st\u00e4rken\n- Erziehung als Konkurrenzkampf\n\t- Fr\u00fchforderung \u2192 Karrierevorsprung\n\t- Erziehungsdruck: traditionelle Erziehung problematisiert \u2192 \u00dcbererziehung und/oder vernachl\u00e4ssigte Erziehung\n\t- Folgen: Stress und Ersch\u00f6pfung der Kinder\n- Geburtenr\u00fcckgang beeinflusst innerfamiliale Interaktion qualitativ und quantitativ, da Gruppenstruktur und -dynamik durch Gruppengr\u00f6\u00dfe bestimmt\n- Eltern als vermehrte Bezugspersonen, da weniger Geschwister/Gleichaltrige vorhanden\n- stabileres Familiensystem bei elternunabh\u00e4ngigen Triaden: fehlt in Zwei-Kind-Familien \u2192 intensivierte Eltern-Kind-Beziehungen\n\n###Ver\u00e4nderung der Elternrolle\n- Umgang mit Kindern ist wichtiger Bezugspunkt der elterlichen Orientierung geworden \u2192 Kinder als Tr\u00e4ger des Lebenssinns der Eltern\n- erh\u00f6hte Anspr\u00fcche an elterliche Erziehungsleistung\n- Eltern als Partner der Kinder \u2192 M\u00f6glichkeit, individuelle Interessen auszuhandeln\n\n###Liberalisierungstendenzen\n- Rangverminderung von Pflicht- und Akzeptanzwerten, Bedeutungsgewinn von Selbstentfaltungswerten\n- Liberalisierung der Erziehungskultur (Befehls- \u2192 Verhandlungshaushalt)\n\nFV 10.2 -- V\u00e4ter\n================\n>_Beschreiben Sie die f\u00fcnf Phasen in der Entwicklung der Vaterforschung nach Fthenakis! Welche Forschungsfragen sind noch offen (nennen Sie 6 Beispiele)? Erl\u00e4utern Sie, welche Forschungsergebnisse zum v\u00e4terlichen Engagement vorliegen! Skizzieren Sie drei theoretische Ans\u00e4tze und dazugeh\u00f6rige Forschungsbefunde zum Ausma\u00df v\u00e4terlichen Engagements!_\n\n##Phasen in der Entwicklung der Vaterforschung nach Fthenakis\n1. Anfangsphase\n\t- Kulturanthropologische Arbeiten: elterliches Rollenverhalten ist kulturell bedingt und ver\u00e4nderlich\n\t- Tierexperimentelle Arbeiten: Frage nach biologischer Determiniertheit v\u00e4terlichen Verhaltens\n2. Vaterabwesenheit (Kriegsende bis Ende 60er): defizitorientierte Ans\u00e4tze\n\t- kognitive Kindesentwicklung: Vaterverlust am negativsten im fr\u00fchen Kindesalter von langer Dauer\n\t- moralische Kindesentwicklung: viele delinquente Jugendliche vaterlos, Entwicklungsr\u00fcckst\u00e4nde bei Jungen\n3. \u00dcbertragung von Fragestellungen und Methodologie aus Mutterforschung in Vaterforschung (60er-70er): Partizipation des Vaters an haushalts- und kindbezogenen Aufgaben? Qualit\u00e4t der Vater-Kind-Beziehung?\n\t- Kleinkinder k\u00f6nnen \u00e4hnlich intensive Bindungen zu Vater und Mutter entwickeln\n\t- \u00dcberwindung der nat\u00fcrlichen Exklusivit\u00e4t der Mutter-Kind-Beziehung\n4. systemische Perspektiven (Ende 70er)\n\t- gute Partnerschaft f\u00f6rdert Wohlbefinden der werdenden Mutter\n\t- Nachteil der Phase: Rollenverteilung zu wenig differenziert\n5. integrierter Bestandteil der Familienforschung (seit Beginn 90er)\n\t- Integration der soziologischen Perspektiven in Konstrukten der psychologischen Androgynie\n\t- stark an Erziehung beteiligte V\u00e4ter k\u00f6nnen instrumentelle und expressive Funktionen nach Parsons' Rollentheorie haben und zeigen gegen\u00fcber Kindern breiteres Verhaltensspektrum als V\u00e4ter in klassischen Familien\n\t- Kinder engagierter V\u00e4ter empathischer und strebsamer nach besseren Leistungen und Selbstst\u00e4ndigkeit\n\t- Vater- und Mutterrolle nicht mehr mit klassischer Aufteilung zu beschreiben\n\n##Sechs offene Forschungsfragen\n1. Sozialisationsbeitrag eines Vaters, der nicht mit Kind zusammenlebt?\n2. Bedingungen f\u00fcr positive F\u00f6rderbeitr\u00e4ge des Vaters?\n3. Beitrag des Kindes f\u00fcr Engagement des Vaters?\n4. Bedeutung Stiefv\u00e4ter?\n5. Ver\u00e4nderung des v\u00e4terlichen Engagements?\n6. Genetische Bedingung des v\u00e4terlichen Betreuungsbeitrags?\n\n##V\u00e4terliches Engagement\n###Forschungsergebnisse\n- Engagement u.a. abh\u00e4ngig von Berufst\u00e4tigkeit der Mutter, eigener und der Partnerin Geschlechts- und Elternrollenorientierung sowie Partnerzufriedenheit\n- st\u00e4rkeres Engagement bei leiblichen Kindern\n- bei sehr kleinen Kindern weniger Einsatz\n- am aktivsten im Schulalter, besonders beim Spielen\n- Mittelschichtsv\u00e4ter am engagiertesten\n- st\u00e4rker bei S\u00f6hnen\n\n###Theorieans\u00e4tze\n#### New Home Economics Theory\n- Partner mit h\u00f6herem Einkommen weniger Zeit f\u00fcr Haushaltst\u00e4tigkeit \u2192 Maximierung des Haushaltseinkommens\n\n####Rollentheoretische Perspektive\n- geschlechtsspezifische Sozialisation als Schl\u00fcssel zum Verst\u00e4ndnis familialer Aufgabenteilung\n- traditionelles Rollenverst\u00e4ndnis \u2192 traditionellere Rollenteilung\n- viel empirische Best\u00e4tigung\n\n####familienzyklischer Ansatz\n- Entwicklung der Familie \u2192 ver\u00e4nderte Anforderungen und Beziehungsmuster\n- Erkl\u00e4rung f\u00fcr unterschiedliche v\u00e4terliche Partizipation in bestimmten Phasen der Familienentwicklung\n\nFV 11.1 -- Gro\u00dfeltern (wichtig)\n===============================\n>_Welche Rolle spielen Gro\u00dfeltern bzw. welche Funktionen erf\u00fcllen sie? Gehen Sie auf den historischen Wandel der Bedingungen f\u00fcr\nGro\u00dfelternschaft, auf Zukunftstrends und auf das ver\u00e4nderte Rollenverst\u00e4ndnis von Gro\u00dfeltern ein! Skizzieren Sie kurz die Formen\ndes intergenerativen Leistungstransfers zwischen Gro\u00dfeltern und Enkeln und beschreiben Sie die Kontextfaktoren, die auf seine\nRealisierung einwirken!_\n\n##Rolle und Funktion\n- keine feste Rollendefinition \u2192 keine feste gesellschaftliche Funktion\n- Gro\u00dfe Verhaltensvariabilit\u00e4t\n- Unterst\u00fctzungsfunktion im Hinblick auf funktionale, spezialisierte Leistungserf\u00fcllung durch die Familie\n- Unterst\u00fctzung der Sozialisation von erwachsenen Kindern und Enkeln erwartet\n- Selbstzuschreibung der Sozialistationsaufgabe der Enkel\n- erg\u00e4nzend und kompensierend zum Erziehungsauftrag der Eltern\n- Doppelte Eltern-Rolle: direkt bei Kindern, latent bei Enkeln\n- Elternrolle minderen Rechts, weniger Verantwortung f\u00fcr Enkel + reduzierter Kontakt als Eltern\n- Recht auf Umgang mit Enkeln\n\n##Historischer Wandel von Gro\u00dfelternschaft\n- steigende Lebenserwartung im 20. Jahrhundert sorgt f\u00fcr Zeit mit Enkeln\n- Demographische Entwicklung\n- weniger Verbindlichkeit kulturell institutionalisierter Rollenkonzepte\n- modernes System staatlicher Vorsorge\n- ver\u00e4nderte Bedeutung des Kindes\n- Technischer Fortschritt\n- Erfahrungsaustausch zwischen Gro\u00dfeltern und Enkeln\n\n##Zukunftstrends\n- Bohnenstangenfamilie\n- Mehr Einzelkinder von vier Gro\u00dfeltern verw\u00f6hnt\n- Antieg Kinderlosigkeit, steigenden Anzahl von enkellosen alten Menschen\n\n##ver\u00e4ndertes Rollenverst\u00e4ndnis\n- distanziert-respektvolle hierarchisch strukturierte Beziehung \u2192 W\u00e4rme, N\u00e4he Zuneigung und Freundschaft\n- Gemeinsame Freizeitaktivit\u00e4ten\n- Fehlen direkter Erziehungsverantwortung\n- Generationsverh\u00e4ltnis ausgehandelt (Verantwortung, Pflichten, Absprachen)\n\n##intergenerativer Leistungstransfer\n- wechselseitig ausgewogener Austausch immaterieller und materieller Leistungen\n\t- Zeit und F\u00fcrsorge\n\t- Materielle Leistungen\n\t- Wissen und K\u00f6nnen\n- Familie als Solidargemeinschaft in Frage gestellt\n- Freiheit und Selbstverwirklichung \u2192 Abneigungen gegen\u00fcber langfristiger Verpflichtungen\n- materielle Leistungen von oben nach unten\n\n###Kontextfaktoren\n- soziodemographische und \u00f6konomische Faktoren\n- staatliche Transferleistungen\n- Famili\u00e4re Ereignisse und familienzyklische Phasen\n\nFV 11.2 -- Lebenssituation der Gro\u00dfeltern (wichtig)\n===================================================\n>_Beschreiben Sie kurz die Lebenssituation der Gro\u00dfelterngeneration (z.B. Einkommens- und Wohnsituation, Lebenszufriedenheit). Erl\u00e4utern Sie die (soziologische) Herkunft und den Inhalt der Begriffe \"Generation\", \"Generationenkonflikt\" und \"Generationenvertrag\"! Welche Einflussfaktoren beeinflussen die intergenerativen Transfers? Wodurch wird der Fortbestand des Generationenvertrags belastet?_\n\n##Lebenssituation\n- bessere Einkommen, Gesundheit und Bildung als fr\u00fcher\n- wenig Armut und Reichtum\n- leben fast ausschlie\u00dflich in Ein-Generationen-Haushalten, aber viele in Drei-Generationen-Netzwerk\n- sollen l\u00e4nger in Erwerbsleben eingebunden werden\n- kaufkr\u00e4ftige Zielgruppe\n- Zufrieden\n\n##Generationenkonflikt nach Mannheim\n- Menschen derselben Geburtsjahr\u00e4gnge (=Generation) machen im selben Sozialraum w\u00e4hrend des Aufwachsens vergleichbare sozio-politische Erfahrungen \u2192 spezifische soziale Gruppe\n- Zugeh\u00f6rigkeit zu Generation beschr\u00e4nkt Mitglieder in Erlebnis- und Chancenverwertungsm\u00f6glichkeiten und pr\u00e4disponiert f\u00fcr Denkweisen \u2192 Einstellungen und Werte k\u00f6nnen in Konflikt mit \u00e4lteren Generationen geraten\n\n##Generationenvertrag\n- wechselseitige Verpflichtungen und Erwartungen \u00fcber Austausch zwischen Familienmitgliedern verschiedener Generationen\n- drei Arten von Verpflichtungen\n\t1. Biosoziale Nachfolge: Jede Generation zieht Kinder auf (sozialisation)\n\t2. Gerosoziale Nachfolge: Jede Generation stellt zum Aufziehen ihrer Nachkommen ausreichend Ressourcen bereit\n\t3. Geriatrische Abh\u00e4ngigkeit: Jede Generation von Nachkommen respektiert und bekommt Hilfe beim Altern und Sterben\n\n###Kontextfaktoren\n- soziodemographische und \u00f6konomische Faktoren\n- staatliche Transferleistungen\n- Famili\u00e4re Ereignisse und familienzyklische Phasen\n\n###Belastungen\n- demographischer Wandel: wachsender Anteil \u00e4lterer Menschen\n- Pflegenotstand: Defizite der Pflegeversicherung, unzureichende Renten\n- Debatte \"Generationengerechtigkeit\": Vorwurf, \u00e4ltere Generationen w\u00fcrden unfairerweise auf Kosten der J\u00fcngeren profitieren\n\nFV 12.1 -- Jugendhilfe (unwichtig?)\n===================================\n>_Skizzieren Sie die Entstehung des Jugendhilfesystems vom Mittelalter bis zum Reichsjugendwohlfahrtsgesetz (1922) und gehen Sie\ndabei auf markante Meilensteine zur Linderung des Elends und der Bildungsnot von Kindern und Jugendlichen ein! Beschreiben Sie\nkurz, in welchem Turnus und vom wem die \u201eKinder- und Jugendberichte\u201c sowie die \u201eFamilienberichte\u201c der Bundesregierung\nerarbeitet werden und welche Funktion sie haben!_\n\n##Geschichte\n###Mittelalter\n- Bed\u00fcrftige, Waisen, Findlinge als Zielgruppe christlicher Almosent\u00e4tigkeit\n\t- \"Recht\" auf Betteln, sp\u00e4ter reguliert\n\t- Bettlerkinder von Eltern getrennt und Arbeitsplatz vermittelt\n- karitatives Hilfesystem \u2192 \"Elendsherbergen\"\n- Sp\u00e4tmittelalter: Findel- und Waisenh\u00e4user entstehen\n\n###Konzeption von Francke/Halle'sche Anstalten\n- religi\u00f6se Erziehung: ausgepr\u00e4gter Religionsunterricht\n- unerm\u00fcdliche Besch\u00e4ftigung \u2192 M\u00fc\u00dfiggang als S\u00fcnde\n\n###18. Jahrhundert\n- Fr\u00fche industrielle Revolution: Zuspitzung von Armut und Ausbeutung von Kindern und Jugendlichen \u2192 Regulation um langfristig gesunde Rekruten und Arbeitskr\u00e4fte zu garantieren\n- Preu\u00dfen: Schulpflicht von 5 bis 12\n- Verstaatlichung der Armenpflege\n\t- erste Sozialleistungen\n\t- Strafen bei \"M\u00fc\u00dfiggang\" \u2192 z.B. Einweisung ins Arbeitshaus\n\t\n###19. Jahrhundert\n- Schutzbestimmungen f\u00fcr Kinder und Jugendliche unter den schlechten Arbeitsbedingungen (lang, gesundheitsgef\u00e4hrdend)\n\t- Verbot von Kinderarbeit im Bergbau und\n\t- generell unter 10\n\n\n####Fr\u00f6belsche Kinderg\u00e4rten\n- F\u00f6rderung durch spielbasierte Besch\u00e4ftigung\n- Erziehung als Werk von Familie, Kindergarten und Schule\n\n####Rauhes Haus\n- Ersetzung erziehungsunf\u00e4higer Familien\n- freiwillige Erziehung\n- R\u00fcckkehroption zu Eltern\n- 10-12 Kinder + 1 Erzieher\n- elementarer Schulunterricht\n\n####Elberfelder System\n- Verwaltungsstruktur f\u00fcr Armenpflege\n\t- Bed\u00fcrftigkeitspr\u00fcfung\n\t- Individualisierung der Unterst\u00fctzungsleistung\n\t- Dezentralisierung der Entscheidungsbefugnisse\n\t- Quartierssystem\n- kontrollierbare Armenverwaltung mit Rechtsaufsicht:\n\t- ehrenamtlicher Armenpfleger dokumentiert, diagnostiziert und erzieht\n\t- keine Gew\u00e4hrung von Dauerleistungen\n\n####Reichsverfassung\n- Kinder- und Jugendf\u00fcrsorge als Kompetenz der L\u00e4nder\n\n####Bismarcksche Sozialgesetze\n- \"Zuckerbrot\" f\u00fcr die Arbeiter\n- Einf\u00fchrung allgemeiner Sozialversicherungen\n\n###20. Jahrhundert\n####1905 Kommunales Stra\u00dfburger System\n- Zentralisierung: \"Armenamt\" mit alleinigen Entscheidungsbefugnissen\n- professionelle Armenpfleger\n\n####1911 Preu\u00dfischer Jugendpflegeerlass f\u00fcr potentiell gef\u00e4hrdete Jugendliche\n- Intervention im Interesse der sozialen Integration der neuen Generation\n- F\u00fcrsorge im Staatsinne: Erziehung zur Normkonformit\u00e4t \u2192 Rekruten\n\n####Reichsjugendwohlfahrtsgesetz 1922\n- Recht \"auf Erziehung zur leiblichen, seelischen und gesellschaftlichen T\u00fcchtigkeit\"\n- eher Eingriffs- als Leistungsgesetz\n- famili\u00e4re Erziehung mit \u00f6ffentlicher Unterst\u00fctzung \u2192 unabh\u00e4ngig von staatlicher Bevormundung\n- aber staatlich kontrolliert und \u00fcberwacht\n\t- Jugend\u00e4mter als erste einheitliche kommunale Erziehungsbeh\u00f6rde\n\t- Inkorporation freier Wohlfahrtspflege\n- B\u00fcrokratisierung und Konzentration:\n\t- Schutz von Pflegekindern, Amtsvormundschaft\n\t- F\u00fcrsorgeerziehung (Eingriff in elterliche Gewalt)\n\t- Jugendpflege und F\u00fcrsorge f\u00fcr S\u00e4uglinge und Kleinkinder\n\n##Sozialberichterstattung\n\nvon Bundesregierung bei Sachverst\u00e4ndigenkommission in Auftrag gegeben\n\n###Kinder- und Jugendbericht\n- jede Legislaturperiode\n- Bestandsaufnahme, Analyse, Vorschl\u00e4ge zur Weiterentwicklung der Jugendhilfe\n- jeder dritte Bericht: \u00dcberblick \u00fcber Gesamtsituation der Jugendhilfe\n\n###Familienbericht\n- mindestens jede 2. Legislaturperiode\n- mittelfristige Perspektiven erschlie\u00dfen und Handlungsempfehlungen geben\n"}
{"url": "https://github.com/Deux9/toxsync", "owner": "Deux9", "repository_name": "toxsync", "date_all_variable_collection": "2023-09-11", "description": "Sync tox accounts across multiple devices. Only one active device will work.", "size": 184, "stargazers_count": 4, "watchers_count": 4, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 4, "default_branch": "master", "contributors": [{"contributor": "Deux9", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 973}], "readme": "#Toxsync\n\nThis bash script is intended to be used for syncing tox datafiles PGP encrypted. The encrypted file will then be placed in a specific path from where it might be synced to a cloud or whatever. This shouldn't be a problem due to the PGP encryption.\n\n##Usage\nEdit the first section of the script for configuration.\nYou can use arguments \"toxsync [client] [profile]\"\n\n##TODO\n- add uTox\n- add simple help\n"}
{"url": "https://github.com/Diego-Dam/Diego-Dam", "owner": "Diego-Dam", "repository_name": "Diego-Dam", "date_all_variable_collection": "2023-09-11", "description": "Config files for my GitHub profile.", "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["config", "github-config"], "languages": []}
{"url": "https://github.com/Diego-Dam/paper_co_creation_mobility_planning_germany", "owner": "Diego-Dam", "repository_name": "paper_co_creation_mobility_planning_germany", "date_all_variable_collection": "2023-09-11", "description": "This repository provides the scripts and data for recreating the results documented by Michelini G., Dametto D., & Michel in the paper \"Participation to co-creation: methods for the involvement of stakeholders in mobility planning in Germany\"", "size": 961, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "Diego-Dam", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 640349}]}
{"url": "https://github.com/Diego-Dam/radon-targeting-analysis", "owner": "Diego-Dam", "repository_name": "radon-targeting-analysis", "date_all_variable_collection": "2023-09-11", "description": "This repository provide the analysis scripts and the data from the radon online targeting experiment", "size": 450, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "Diego-Dam", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 1483527}]}
{"url": "https://github.com/Diego-Dam/SmartUpLab-Tools-FH-Potsdam", "owner": "Diego-Dam", "repository_name": "SmartUpLab-Tools-FH-Potsdam", "date_all_variable_collection": "2023-09-11", "description": "The repository provide the code for the tools and the models developed as part of the SmartUpLab project at the University of Applied Science Potsdam (May 2019 - August 2022)", "size": 1682, "stargazers_count": 1, "watchers_count": 1, "language": "GAML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "Diego-Dam", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "GAML", "num_chars": 584288}, {"language": "Python", "num_chars": 216693}, {"language": "CSS", "num_chars": 25102}, {"language": "Procfile", "num_chars": 52}], "readme": "# SmartUpLab-Tools-FH-Potsdam\nThe repository provide the code for the tools and the models developed as part of the SmartUpLab project at the University of Applied Science Potsdam (May 2019 - August 2022)\n\nThe repository contains three folder:\n- drt_routing_app provide the code for the online tool (Python) available until the end of 2023 https://smartuplab-mobility-app.herokuapp.com/\n- neuruppin_parking_app provide the code for the online tool (Python) available until the end of 2023 https://smartuplab-mobility-app.herokuapp.com/\n- SmartUpLab Models contains two sub-folder, each one providing the code in GAMA language for the models we used as part of SmartUpLab project\n"}
{"url": "https://github.com/Disc0erg0sum/stream", "owner": "Disc0erg0sum", "repository_name": "stream", "date_all_variable_collection": "2023-09-11", "description": null, "size": 8, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "Disc0erg0sum", "contributions": 14}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 1541}, {"language": "CSS", "num_chars": 85}], "readme": "# stream"}
{"url": "https://github.com/Disc0erg0sum/TheTimeMachine", "owner": "Disc0erg0sum", "repository_name": "TheTimeMachine", "date_all_variable_collection": "2023-09-11", "description": "This is a project created by Pascal Struck and Jendrik Bradaczek as part of the course \u201eZeitmaschine\u201c by Prof. Boris M\u00fcller at the University of Applied Sciences Potsdam during the winter semester 20/21.", "size": 18497, "stargazers_count": 2, "watchers_count": 2, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 2, "default_branch": "main", "contributors": [{"contributor": "strckture", "contributions": 92}, {"contributor": "Disc0erg0sum", "contributions": 23}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["design", "time"], "languages": [{"language": "JavaScript", "num_chars": 20423}, {"language": "HTML", "num_chars": 8086}, {"language": "CSS", "num_chars": 3833}], "readme": "# Time Machine\n\nA website regarding the visualization of time. Basically a place where you can find different clocks created with P5.js.\nHave fun exploring!\n\n[the Website](https://zeitmaschine.xyz/)\n\n## Code of Conduct\n\n_This should help navigating through the code in this repository_\n\n### General\n\n- Don't panic!\n\n- Feel free to download and experiment with the code.\n\n- Easter eggs are welcome!\n\n### Code\n\n- _Time variables_ are always defined as shown in the following snippet.\n\n```\nlet h = hour();\nlet m = minute();\nlet s = second();\nlet mil = millis();\n```\n\n- General _variables_ are written in **camelCase**.\n\n```\nvar hThinkingThisShouldBeCamelCase;\n```\n\n- _Functions_ are written in **camelCase**.\n\n```\nfunction whatTheFuckIsGoingOn(i,d,k){\n\tpush();\n\tpop();\n}\n```\n\n- _Classes_ are **capitalized**.\n\n```\nclass Clock {\n\tconstructor() {\n\t}\n\tyeet(){\n\t}\n}\n```\n\n## Dependencies\n\n- p5.js\n- jQuery\n"}
{"url": "https://github.com/discourse-lab/arg-microtexts-part2", "owner": "discourse-lab", "repository_name": "arg-microtexts-part2", "date_all_variable_collection": "2023-09-11", "description": "An annotated corpus of argumentative microtexts - Part 2", "size": 3181, "stargazers_count": 3, "watchers_count": 3, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "peldszus", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "An annotated corpus of argumentative microtexts - part 2\n========================================================\n\nThe second part of the arg-microtexts corpus contains 171 additional short\nargumentative texts in English, annotated with argumentation structure.\n\nFor a list of the topics and trigger questions, see\n[topics_triggers.md](topics_triggers.md).\n\nOne of the features new in this part of the corpus are implicit main claims\n(see Section 4.1 of our paper). Note that discourse units that have been\nintroduced to represent implicit claims are marked in the xml-files with the\n`implicit=\"true\"` property. In the source text, they are highlighted as fully\nuppercase segments (which do not exist otherwise in the corpus). See e.g. this\n[xml-file](corpus/micro_c002.xml#L6) and [source text](corpus/micro_c002.txt).\n\nLicense\n-------\n\nThe arg-microtexts-part2 corpus is released under a Creative Commons\nAttribution-NonCommercial-ShareAlike 4.0 International License. You can find a\nhuman-readable summary of the licence agreement here:\n\nhttps://creativecommons.org/licenses/by-nc-sa/4.0/\n\nIf you are using our corpus for research purposes, please cite the following\npaper:\n\nMaria Skeppstedt, Andreas Peldszus, Manfred Stede. [More or less controlled\nelicitation of argumentative text: Enlarging a microtext corpus via\ncrowdsourcing](http://www.aclweb.org/anthology/W/W18/W18-5218.pdf).\nIn: Proceedings of the 5th Workshop on Argument Mining.\nEMNLP 2018, Belgium, Brussels, November 2018\n\n\nSee also\n--------\n\n[arg-microtexts](https://github.com/peldszus/arg-microtexts) - First part of\nthe corpus.\n"}
{"url": "https://github.com/discourse-lab/chinese-dimlex", "owner": "discourse-lab", "repository_name": "chinese-dimlex", "date_all_variable_collection": "2023-09-11", "description": "A lexicon of Chinese discourse connectives", "size": 32, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "PeterBourgonje", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 2914}], "readme": "# chinese-dimlex\nA lexicon of Chinese discourse connectives\n"}
{"url": "https://github.com/discourse-lab/conflict-annotation-guidelines", "owner": "discourse-lab", "repository_name": "conflict-annotation-guidelines", "date_all_variable_collection": "2023-09-11", "description": "Annotation guidelines for annotating Conflicts in the UN Security Council. ", "size": 281, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "linatal", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# conflict-annotation-guidelines\nAnnotation guidelines for annotating Conflicts in the UN Security Council. \n"}
{"url": "https://github.com/discourse-lab/Connective-Lex.info", "owner": "discourse-lab", "repository_name": "Connective-Lex.info", "date_all_variable_collection": "2023-09-11", "description": "A web app for a multilingual connective database.", "size": 19153, "stargazers_count": 2, "watchers_count": 2, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "FelixDombek", "contributions": 41}, {"contributor": "PeterBourgonje", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 962175}, {"language": "XSLT", "num_chars": 53821}, {"language": "HTML", "num_chars": 47499}, {"language": "PHP", "num_chars": 14638}, {"language": "CSS", "num_chars": 7166}, {"language": "Batchfile", "num_chars": 2678}, {"language": "Perl", "num_chars": 1486}], "readme": "\nThis is the Readme for the CD-ROM that accompanies the Bachelor thesis:\n\n\n                       Connective-Lex.info\n\n         A Web App for a Multilingual Connective Database\n\n             by Felix Dombek (Matriculation No. 739122)\n\n                   Computational Linguistics B.Sc.,\n                     Department of Linguistics,\n                       University of Potsdam\n\n                           Supervisors:\n                     Prof. Dr. Manfred Stede\n                      Dr. Tatjana Scheffler\n\n\nThis CD-ROM contains the following files and directories:\n\n - Connective-Lex.info - Bachelor thesis.pdf   \n   The thesis text.\n\n - Original lexicons/\n   The source lexicons in XML format and their associated data.\n\n - Conversion scripts/\n   The scripts used for conversion of the source XML to DiMLex format,\n   as well as intermediate scripts used for creating inventories of \n   used values and tag mapping. It also contains the DTD that was \n   created to validate the converted lexicons.\n\n - Web app/\n   The app directory structure as described in the thesis.\n\n - Tools/\n   Contains installers for the Saxon HE 9.7 (.NET) XSLT preprocessor \n   and for the XML Copy Editor used to validate the lexicons.\n\n\n                 UNIVERSIT\u00c4T POTSDAM, 30.7.2017\n"}
{"url": "https://github.com/discourse-lab/dimlex", "owner": "discourse-lab", "repository_name": "dimlex", "date_all_variable_collection": "2023-09-11", "description": "A Lexicon of German discourse markers", "size": 136, "stargazers_count": 5, "watchers_count": 5, "language": "XSLT", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 5, "default_branch": "master", "contributors": [{"contributor": "TScheffler", "contributions": 9}, {"contributor": "arne-cl", "contributions": 6}, {"contributor": "peldszus", "contributions": 3}, {"contributor": "PeterBourgonje", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "XSLT", "num_chars": 3022}], "readme": "# DiMLex\n\nA Lexicon of German discourse markers. \n\nThis repository contains two versions of the lexicon.\n`DimLex.xml` contains the 'original' version.\nFor the *ConAno* annotation tool\n(Stede and Heintze 2004, [download](https://www.ling.uni-potsdam.de/acl-lab-old/Forsch/pcc/Conano-Distrib.zip)),\nthe file `ConAnoConnectorLexicon.xml` was generated from the original\nusing an XSLT stylesheet (`dimlex2conano.xsl`).\n(Slight modifications were made to the *ConAno* version after the conversion.)\n\n## License\n\nThe DimLex lexicon of German discourse markers is released under a Creative\nCommons Attribution-NonCommercial-ShareAlike 4.0 International License.\nYou can find a human-readable summary of the licence agreement here:\n\nhttps://creativecommons.org/licenses/by-nc-sa/4.0/\n\nIf you use DiMLex for your research, please cite the following paper:\n\nManfred Stede. \n\"DiMLex: A Lexical Approach to Discourse Markers\"\nIn: A. Lenci, V. Di Tomaso (eds.): *Exploring the Lexicon - Theory and Computation*.\nAlessandria (Italy): Edizioni dell'Orso, 2002. \\[[pdf](http://www.ling.uni-potsdam.de/~stede/Papers/lenci02.pdf)\\]\n\n## References\n\nManfred Stede and Carla Umbach.\n\"DiMLex: A lexicon of discourse markers for text generation and understanding.\"\n*Proceedings of the 17th international conference on Computational linguistics - Volume 2*.\nAssociation for Computational Linguistics, 1998. \\[[pdf](http://www.aclweb.org/anthology/C/C98/C98-2197.pdf)\\]\n\nManfred Stede. \n\"DiMLex: A Lexical Approach to Discourse Markers\"\nIn: A. Lenci, V. Di Tomaso (eds.): *Exploring the Lexicon - Theory and Computation*.\nAlessandria (Italy): Edizioni dell'Orso, 2002. \\[[pdf](http://www.ling.uni-potsdam.de/~stede/Papers/lenci02.pdf)\\]\n\nDaniela Berger, David Reitter and Manfred Stede.\n\"XML/XSL in the dictionary: the case of discourse markers.\"\n*Proceedings of the 2nd workshop on NLP and XML* (pp. 21-28).\nAssociation for Computational Linguistics, 2002. \\[[pdf](http://aclweb.org/anthology/W/W02/W02-1704.pdf)\\]\n\nManfred Stede and Silvan Heintze.\n\"Machine-assisted rhetorical structure annotation.\"\n*Proceedings of the 20th international conference on Computational Linguistics*.\nAssociation for Computational Linguistics, 2004. \\[[pdf](http://www.aclweb.org/anthology/C/C04/C04-1061.pdf)\\]\n\nTatjana Scheffler and Manfred Stede. \n\"Adding Semantic Relations to a Large-Coverage Connective Lexicon of German.\" \n*Proceedings of LREC*. \nPortoro\u017e, Slovenia. 2016. \n\\[[pdf](http://www.lrec-conf.org/proceedings/lrec2016/pdf/274_Paper.pdf)\\]"}
{"url": "https://github.com/discourse-lab/DiMLex-Bangla", "owner": "discourse-lab", "repository_name": "DiMLex-Bangla", "date_all_variable_collection": "2023-09-11", "description": "DiMLex Bangla is a lexicon of Bangla discourse connectives", "size": 51, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "PeterBourgonje", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# DiMLex-Bangla\nDiMLex Bangla is a lexicon of Bangla discourse connectives\n\n-TODO: part:type should only be one of single/phrasal (not cont, as it is sometimes now, check for consistency!)\n"}
{"url": "https://github.com/discourse-lab/DisCoDict", "owner": "discourse-lab", "repository_name": "DisCoDict", "date_all_variable_collection": "2023-09-11", "description": "A Dictionary of Dutch Discourse Connectives", "size": 95, "stargazers_count": 1, "watchers_count": 1, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "PeterBourgonje", "contributions": 21}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# DisCoDict\nA Dictionary of Dutch Discourse Connectives.\n\nContributors to this resource are (in alphabetical order): Peter Bourgonje, Jacqueline Evers-Vermeul, Jet Hoek, Gisela Redeker, Ted Sanders and Manfred Stede.\n\n## License\n\nThe DisCoDict dictionary of Dutch discourse connectives is released under a Creative\nCommons Attribution-NonCommercial-ShareAlike 4.0 International License.\nYou can find a human-readable summary of the licence agreement here:\n\nhttps://creativecommons.org/licenses/by-nc-sa/4.0/\n\n## References\n\nPeter Bourgonje, Jet Hoek, Jacqueline Evers-Vermeul, Gisela Redeker, Ted Sanders, and Manfred Stede. \n\"Constructing a Lexicon of Dutch Discourse Connectives\"\nComputational Linguistics in the Netherlands Journal, 8:163-175, 12/2018 2018. \\[[pdf](https://clinjournal.org/sites/clinjournal.org/files/Bourgonje2018.pdf)\\]\n\nManfred Stede. \n\"DiMLex: A Lexical Approach to Discourse Markers\"\nIn: A. Lenci, V. Di Tomaso (eds.): *Exploring the Lexicon - Theory and Computation*.\nAlessandria (Italy): Edizioni dell'Orso, 2002. \\[[pdf](http://www.ling.uni-potsdam.de/~stede/Papers/lenci02.pdf)\\]\n\nManfred Stede and Carla Umbach.\n\"DiMLex: A lexicon of discourse markers for text generation and understanding.\"\n*Proceedings of the 17th international conference on Computational linguistics - Volume 2*.\nAssociation for Computational Linguistics, 1998. \\[[pdf](http://www.aclweb.org/anthology/C/C98/C98-2197.pdf)\\]\n\n\n\n"}
{"url": "https://github.com/discourse-lab/DiscourseSegmenter", "owner": "discourse-lab", "repository_name": "DiscourseSegmenter", "date_all_variable_collection": "2023-09-11", "description": "A collection of various discourse segmenters", "size": 32671, "stargazers_count": 9, "watchers_count": 9, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 1, "watchers": 9, "default_branch": "master", "contributors": [{"contributor": "WladimirSidorenko", "contributions": 58}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 265132}, {"language": "Java", "num_chars": 2244}, {"language": "Shell", "num_chars": 174}], "readme": "===================\nDiscourse Segmenter\n===================\n\n.. image:: https://img.shields.io/badge/license-MIT-blue.svg\n   :alt: MIT License\n   :align: right\n   :target: http://opensource.org/licenses/MIT\n\nA collection of various discourse segmenters (with pre-trained models for German texts).\n\n\nDescription\n===========\n\nThis python module currently comprises three discourse segmenters:\n**edseg**, **bparseg**, and **mateseg**.\n\n**edseg**\n is a rule-based system that uses shallow discourse-oriented\n parsing to determine boundaries of elementary discourse units in\n text.  The rules are hard-coded in the `submodule's file`_ and are\n only applicable to German input.\n\n**bparseg**\n is an ML-based segmentation module that operates on\n syntactic constituency trees (output from BitPar_) and decides\n whether a syntactic constituent initiates a discourse segment or not\n using a pre-trained linear SVM model.  This model was trained on the\n German PCC_ corpus, but you can also train your own classifer for any\n language using your own training data (cf. ``discourse_segmenter\n --help`` for further instructions on how to do that).\n\n**mateseg**\n is an ML-based segmentation module that operates on syntactic\n dependency trees (output from Mate_) and decides whether a\n sub-structure of the dependency graph initiates a discourse segment\n or not using a pre-trained linear SVM model.  Again, this model was\n trained on the German PCC_ corpus.\n\n\n*Since the current model is a serialized file and, therefore, likely  to be incompatible with future releases of `numpy`, we will probably  remove the model files from future versions of this package,  including source data instead and performing training during the  installation.*\n\n\nInstallation\n============\n\nTo install this package from the PyPi index, run\n\n.. code-block:: shell\n\n    pip install dsegmenter\n\nAlternatively, you can also install it directly from the source\nrepository by executing:\n\n.. code-block:: shell\n\n    git clone git@github.com:discourse-lab/DiscourseSegmenter.git\n    pip install -r DiscourseSegmenter/requirements.txt DiscourseSegmenter/ --user\n\n\nUsage\n=====\n\nAfter installation, you can import the module in your python scripts\n(see an example here_), e.g.:\n\n.. code-block:: python\n\n    from dsegmenter.bparseg import BparSegmenter\n\n    segmenter = BparSegmenter()\n\nor, alternatively, also use the delivered front-end script\n`discourse_segmenter` to process your parsed input data, e.g.:\n\n.. code-block:: shell\n\n    discourse_segmenter bparseg segment DiscourseSegmenter/examples/bpar/maz-8727.exb.bpar\n\nNote that this script requires two mandatory arguments: the type of\nthe segmenter to use (`bparseg` in the above case) and the operation\nto perform (which are specific to each segmenter).\n\n\nEvaluation\n==========\n\nIntrinsic evaluation scores of the machine learning models on the\npredicted vectors will be printed when training and evaluating a\nsegmentation model.\n\nExtrinsic evaluation scores on the predicted segmentation trees can be\ncalculated with the evaluation script.\n\n.. code-block:: shell\n\n    evaluation {FOLDER:TRUE} {FOLDER:PRED}\n\nNote, that the script internally calls the `DKpro agreement library`_,\nwhich requires Java 8.\n\n\n\n.. _`Bitpar`: http://www.cis.uni-muenchen.de/~schmid/tools/BitPar/\n.. _`Mate`: http://code.google.com/p/mate-tools/\n.. _`PCC`: http://www.lrec-conf.org/proceedings/lrec2014/pdf/579_Paper.pdf\n.. _`here`: https://github.com/discourse-lab/DiscourseSegmenter/blob/master/scripts/discourse_segmenter\n.. _`submodule's file`: https://github.com/discourse-lab/DiscourseSegmenter/blob/master/dsegmenter/edseg/clause_segmentation.py\n.. _`DKpro agreement library`: https://dkpro.github.io/dkpro-statistics/\n"}
{"url": "https://github.com/discourse-lab/en_dimlex", "owner": "discourse-lab", "repository_name": "en_dimlex", "date_all_variable_collection": "2023-09-11", "description": "A Lexicon of English discourse markers", "size": 89, "stargazers_count": 2, "watchers_count": 2, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "PeterBourgonje", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# en_dimlex\nA Lexicon of English discourse markers\n\n## License\n\nThe en_dimlex lexicon of English discourse markers is released under a Creative\nCommons Attribution-NonCommercial-ShareAlike 4.0 International License.\nYou can find a human-readable summary of the licence agreement here:\n\nhttps://creativecommons.org/licenses/by-nc-sa/4.0/\n\nIf you use en_dimlex for your research, please cite the following paper:\n\nDebopam Das, Tatjana Scheffler, Peter Bourgonje and Manfred Stede. \n\"Constructing a Lexicon of English Discourse Connectives\"\nIn: K. Komatani, D. Litman, K. Yu, A. Papangelis, L. Cavedon, M. Nakano (eds.): *Proceedings of the 19th Annual SIGdial Meeting on Discourse and Dialogue*. Melbourne, Australia , July 2018. \\[[pdf](http://aclweb.org/anthology/W18-5042)\\]\n\n## Documentation\n\nThe structure of en_dimlex is based on the original [DiMLex German lexicon](https://github.com/discourse-lab/dimlex/blob/master/DimLex-documentation.md). Depending on the source of the entry (see the [paper](http://aclweb.org/anthology/W18-5042) for details), the sense, usage example, frequency and syntactic information is automatically extracted or manually assigned.\n"}
{"url": "https://github.com/discourse-lab/GraPat", "owner": "discourse-lab", "repository_name": "GraPat", "date_all_variable_collection": "2023-09-11", "description": "A tool for graph annotations", "size": 492, "stargazers_count": 8, "watchers_count": 8, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 4, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 4, "open_issues": 0, "watchers": 8, "default_branch": "master", "contributors": [{"contributor": "jonathansonntag", "contributions": 239}, {"contributor": "peldszus", "contributions": 17}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 58195}, {"language": "Java", "num_chars": 22717}, {"language": "CSS", "num_chars": 10270}, {"language": "HTML", "num_chars": 440}, {"language": "Shell", "num_chars": 196}], "readme": "# GraPat\n\nGraPAT (Graph-based Potsdam Annotation Tool, [Sonntag and Stede 2014], http://www.lrec-conf.org/proceedings/lrec2014/pdf/824_Paper.pdf) is web-based\nand provides annotators with a natural visualisation of their annotations and thus supports the \nintuitions of annotators to follow graph-based annotation schemes.\n\nSupported annotations are\n- Relation-based sentiment\n- Argumentation structure\n\nThe tool provides a graph structure annotation on top of text. Certain parts of the text can be connected to\nnodes in the graph, and those nodes can be connected with relations of the relevant annotation scheme.\nEdges also have attributes to describe them.\n"}
{"url": "https://github.com/discourse-lab/naijalex", "owner": "discourse-lab", "repository_name": "naijalex", "date_all_variable_collection": "2023-09-11", "description": "Nigerian Pidgin Connective Lexicon", "size": 12, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "PeterBourgonje", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# naijalex\nA connective lexicon for Nigerian Pidgin.\n\n## References\n\nMarian Marchal, Merel Scholman and Vera Demberg. \n\"Semi-automatic discourse annotation in a low-resource language: Developing a connective lexicon for Nigerian Pidgin\"\nIn: Proceedings of the Second Workshop on Computational Approaches to Discourse (CoDi 2021). \\[[pdf](https://aclanthology.org/2021.codi-main.)\\]\n"}
{"url": "https://github.com/discourse-lab/pocores", "owner": "discourse-lab", "repository_name": "pocores", "date_all_variable_collection": "2023-09-11", "description": "coreference resolution for German", "size": 946, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 8, "license": "GNU Affero General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 8, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "arne-cl", "contributions": 116}, {"contributor": "jonathansonntag", "contributions": 4}, {"contributor": "WladimirSidorenko", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 65956}, {"language": "Makefile", "num_chars": 390}], "readme": "pocores\n=======\n\n`pocores` is a rule-based coreference resolution system for German using the\n*filters and preferences* approach (Lappin and Leass 1994; Stuckardt 2001).\nIt requires dependency parsed input sentences in CoNLL 2009/2010 format, which can i.a. be produced by [mate-tools](http://code.google.com/p/mate-tools/) (Bohnet 2010).\n\nThe code was originally written by Tobias G\u00fcnther for his Bachelor's thesis (G\u00fcnther 2011),\nbut has been heavily refactored and is now based on the\n[discoursegraphs](https://github.com/arne-cl/discoursegraphs) library (Neumann, to appear).\n\n\nReferences\n----------\n\nBohnet, B. (2010).  \nVery high accuracy and fast dependency parsing is not a contradiction. In *Proceedings of the 23rd International Conference on Computational Linguistics* (pp. 89-97). Association for Computational Linguistics.\n\nG\u00fcnther, T. (2011).  \nAutomatische Anaphernresolution im Deutschen: Entwurf und Implementierung. Bsc thesis. Universit\u00e4t Potsdam, Germany.\n\nNeumann, A. (to appear).  \ndiscoursegraphs: A Graph-Based Merging Tool and Converter for Multilayer Annotated Corpora. In *Proceedings of the 20th Nordic Conference of Computational Linguistics* (Nodalida 2015). Northern European Association for Language Technology.\n\nLappin, S., & Leass, H. J. (1994).  \nAn algorithm for pronominal anaphora resolution. *Computational linguistics*, 20(4), 535-561.\n\nStuckardt, R. (2001).  \nDesign and enhanced evaluation of a robust anaphor resolution algorithm. *Computational Linguistics*, 27(4), 479-506.\n"}
{"url": "https://github.com/discourse-lab/russian-dimlex", "owner": "discourse-lab", "repository_name": "russian-dimlex", "date_all_variable_collection": "2023-09-11", "description": "A lexicon of Russian discourse connectives", "size": 39, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "PeterBourgonje", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# russian-dimlex\nA lexicon of Russian discourse connectives\n"}
{"url": "https://github.com/discourse-lab/turkish_connective_lexicon", "owner": "discourse-lab", "repository_name": "turkish_connective_lexicon", "date_all_variable_collection": "2023-09-11", "description": null, "size": 74, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "PeterBourgonje", "contributions": 10}, {"contributor": "erolcan-er", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# turkish_connective_lexicon\nA Lexicon of Turkish discourse markers\n\n## License\n\nThe lexicon of Turkish discourse markers is released under a Creative\nCommons Attribution-NonCommercial-ShareAlike 4.0 International License.\nYou can find a human-readable summary of the licence agreement here:\n\nhttps://creativecommons.org/licenses/by-nc-sa/4.0/\n\nIf you use this lexicon for your research, please cite https://aclanthology.org/W19-3308/.\n\n## Documentation\n\nThe structure of TCL is based on the original [DiMLex German lexicon](https://github.com/discourse-lab/dimlex/blob/master/DimLex-documentation.md). Depending on the source of the entry (see the [paper](https://aclanthology.org/W19-3308/) for details), the sense, usage example, frequency and syntactic information is automatically extracted or manually assigned.\n"}
{"url": "https://github.com/domoritz/arrow-6-7-perf-test", "owner": "domoritz", "repository_name": "arrow-6-7-perf-test", "date_all_variable_collection": "2023-09-11", "description": null, "size": 115, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "domoritz", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 5406}]}
{"url": "https://github.com/domoritz/arrow-browser-bundle-test", "owner": "domoritz", "repository_name": "arrow-browser-bundle-test", "date_all_variable_collection": "2023-09-11", "description": null, "size": 101, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": false, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "domoritz", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 550227}]}
{"url": "https://github.com/domoritz/arrow-deno", "owner": "domoritz", "repository_name": "arrow-deno", "date_all_variable_collection": "2023-09-11", "description": "Deno wrapper for Apache Arrow", "size": 4, "stargazers_count": 0, "watchers_count": 0, "language": "TypeScript", "has_issues": true, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "domoritz", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TypeScript", "num_chars": 360}], "readme": "# Deno Wrapper for [Apache Arrow](https://arrow.apache.org)\n\nThe wrapper is available as a\n[third party module for deno land](https://deno.land/x/arrow).\n\n```ts\nimport * as arrow from \"https://deno.land/x/arrow@v8.0.0/mod.ts\";\n```\n"}
{"url": "https://github.com/domoritz/arrow-rollup", "owner": "domoritz", "repository_name": "arrow-rollup", "date_all_variable_collection": "2023-09-11", "description": "repo to demonstrate an issue", "size": 152, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "domoritz", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 420285}, {"language": "HTML", "num_chars": 262}]}
{"url": "https://github.com/domoritz/arrow-tools", "owner": "domoritz", "repository_name": "arrow-tools", "date_all_variable_collection": "2023-09-11", "description": "A collection of handy CLI tools to convert CSV and JSON to Apache Arrow and Parquet", "size": 151, "stargazers_count": 81, "watchers_count": 81, "language": "Rust", "has_issues": true, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 5, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 7, "license": "Apache License 2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 5, "open_issues": 7, "watchers": 81, "default_branch": "main", "contributors": [{"contributor": "domoritz", "contributions": 54}, {"contributor": "dependabot[bot]", "contributions": 16}, {"contributor": "corneliusroemer", "contributions": 2}, {"contributor": "lsh", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 27717}], "readme": "# Arrow CLI Tools\n\n[![Rust](https://github.com/domoritz/arrow-tools/actions/workflows/rust.yml/badge.svg)](https://github.com/domoritz/arrow-tools/actions/workflows/rust.yml)\n\nA collection of handy CLI tools to convert CSV and JSON to [Apache Arrow](https://arrow.apache.org) and [Parquet](https://parquet.apache.org).\n\nThis repository contains five projects:\n* [`csv2arrow`](https://github.com/domoritz/arrow-tools/tree/main/crates/csv2arrow) to convert CSV files to Apache Arrow.\n* [`csv2parquet`](https://github.com/domoritz/arrow-tools/tree/main/crates/csv2parquet) to convert CSV files to Parquet.\n* [`json2arrow`](https://github.com/domoritz/arrow-tools/tree/main/crates/json2arrow) to convert JSON files to Apache Arrow.\n* [`json2parquet`](https://github.com/domoritz/arrow-tools/tree/main/crates/json2parquet) to convert JSON files to Parquet.\n* [`arrow-tools`](https://github.com/domoritz/arrow-tools/tree/main/crates/arrow-tools) shared utilities used by the other four packages.\n"}
{"url": "https://github.com/domoritz/arrow-wasm", "owner": "domoritz", "repository_name": "arrow-wasm", "date_all_variable_collection": "2023-09-11", "description": "Apache Arrow in WebAssembly", "size": 18007, "stargazers_count": 67, "watchers_count": 67, "language": "Rust", "has_issues": true, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 9, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 16, "license": "Apache License 2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 9, "open_issues": 16, "watchers": 67, "default_branch": "main", "contributors": [{"contributor": "domoritz", "contributions": 94}, {"contributor": "dependabot[bot]", "contributions": 94}, {"contributor": "cscheid", "contributions": 1}, {"contributor": "marcprux", "contributions": 1}, {"contributor": "dependabot-preview[bot]", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 20142}, {"language": "JavaScript", "num_chars": 1942}, {"language": "TypeScript", "num_chars": 55}], "readme": "# WASM Arrow ![.github/workflows/test.yml](https://github.com/domoritz/arrow-wasm/workflows/.github/workflows/test.yml/badge.svg) [![npm version](https://img.shields.io/npm/v/arrow-wasm.svg)](https://www.npmjs.com/package/arrow-wasm)\n\nThis package compiles the Rust library of [Apache Arrow](https://arrow.apache.org/) to WebAssembly. This might be a viable alternative to the [pure JavaScript library](https://arrow.apache.org/docs/js/). Right now, this library is incomplete and the API will change so we recommend using JavaScript library.\n\nYou can try this library in Observable at https://observablehq.com/@domoritz/apache-arrow-in-webassembly.\n\n## Documentation\n\nComing later. The API is somewhat similar to the Rust version (https://docs.rs/arrow/3.0.0/arrow/) although there are some differences to make the API more familiar to JavaScript users.\n\n## Building and testing\n\n### Node\n\nRun with `wasm-pack build --target nodejs && node examples/flights.js`.\n\nTo use a debug build, run `wasm-pack build --target nodejs --dev && node examples/flights.js`.\n\n### Browser\n\nBuild with `wasm-pack build --target web`. Then run `python3 -m http.server` and open http://localhost:8000/examples/.\n\n## Publishing\n\nRun `npm publish` to build a bundle and release it to NPM.\n\n## Linting\n\nRun `cargo fmt && cargo clippy` before committing.\n\n## Check file size\n\nWe can check how large the WASM file is after compression (which every web server probably does).\n\n`gzip -9 <pkg//arrow_wasm_bg.wasm | wc -c`\n"}
{"url": "https://github.com/domoritz/assign-projects", "owner": "domoritz", "repository_name": "assign-projects", "date_all_variable_collection": "2023-09-11", "description": "Logic ASP program to calculate optimal placement of students in projects depending on a per student ranking.", "size": 128, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "domoritz", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 446}], "readme": "# Assign Projects to Students\n\nSimple [Answer Set Programming](https://en.wikipedia.org/wiki/Answer_set_programming) program that that calculates the optimal assignment of students to projects after the students provided a list of ranked choices.\n\n# Requirements\n\n_gringo_ and _clasp_ from [Potassco](http://potassco.sourceforge.net/).\n\n# Speed\n\nWe used the program to calculate the assignment of 80 students to 13 projects. Each student has 5 choices.\n\n# How to use it\n\n## Create a `projects.lp` and `students.lp` file\n\nThese files should contain data about which projects students chose and what projects are available.\n\nThe `students.lp` file should contain `select` entries of the following form.\n\n```prolog\nselect(S,P,N).\n```\n\n<dl>\n  <dt>S</dt>\n  <dd>Number representing a student</dd>\n\n  <dt>P</dt>\n  <dd>Number representing a project</dd>\n  \n  <dt>N</dt>\n  <dd>Ranking of this choice</dd>\n</dl>\n\nAlso create the `projects.lp` file that contains the available projects in the following form.\n\n```prolog\nproject(P,MIN,MAX).\n```\n\n<dl>\n  <dt>MIN and MAX</dt>\n  <dd>Minimum and maximum number of students per project</dd>\n</dl>\n\n## Run the program\n\n```bash\ngringo penalty.lp students.lp projects.lp encoding.lp | clasp\n```\n\n# Attribution\n\nThanks to [Martin](http://www.cs.uni-potsdam.de/~gebser/) for his help with speeding up computation significantly.\n"}
{"url": "https://github.com/domoritz/backbone-eventdata", "owner": "domoritz", "repository_name": "backbone-eventdata", "date_all_variable_collection": "2023-09-11", "description": "This small backbone plugin allows you to pass eventData to your actions", "size": 95, "stargazers_count": 6, "watchers_count": 6, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 2, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 2, "watchers": 6, "default_branch": "master", "contributors": [{"contributor": "abstraktor", "contributions": 11}, {"contributor": "domoritz", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1214}], "readme": "Backbone Eventdata\n==================\n\nThis small backbone plugin allows you to pass eventData to your actions. This is reached while providing a convenience syntax extension to _Backbone.View.prototype.events_.\n\n```javascript\nevents: {\n  \n  //in general\n  \"namespace:eventName[eventData] sizzleSelector\": \"anAction\",\n  \n  //blanks are all right!\n  //e.g. for menues\n  \"dblclick[new Window] a.menu\": \"navigateTo\",\n  \n  //e.g. for jquery.hotkeys by jeresig\n  \"keydown[ctrl+a]\": \"selectAll\",\n  \n  //just one action for that much links\n  \"click[1]   .turn_1_page_right\":    \"turnPage\",\n  \"click[5]   .turn_5_pages_right\":   \"turnPage\",\n  \"click[20]  .turn_20_pages_right\":  \"turnPage\",\n  \"click[-1]  .turn_1_page_left\":     \"turnPage\",\n  \"click[-5]  .turn_5_pages_left\":    \"turnPage\",\n  \"click[-20] .turn_20_pages_left\":   \"turnPage\",\n\n  }\n```\n\nhow do I use it?\n----------------\n1. Include backbone.eventdata.js into your project __after__ Backbone.\n1. evaluate event.data in your callback\n1. add eventdata in brackets to your eventbindings (directly after the events name)\n\nhow does it work?\n-----------------\nThis script overloads _Backbone.View.prototype.delegateEvents_ and adds basically just a few statements to it.\n\nexample\n-------\n```javascript\nview = new Backbone.View({\n  \n  events: {\n    //on doubleclick call something like navigateTo({data:\"newWindow\", ...})\n    \"dblclick[new Window] a.menu\": \"navigateTo\",\n  },\n  \n  navigateTo: function(event, ui){\n    if(event && event.data == \"new Window\")\n      //the magic happens!\n      this.openWindow();\n    else\n      this.doOtherMagic();\n  }\n    \n  openWindow: function(){\n    //...\n    }\n  }\n});\n```\n\nwhat backbone version do I need?\n--------------------------------\nThe latest patch will work with backbone 0.9.1. If you are still using backbone 0.5.3, take the patch from 4dfc1c88f1d."}
{"url": "https://github.com/domoritz/beacon", "owner": "domoritz", "repository_name": "beacon", "date_all_variable_collection": "2023-09-11", "description": "React to beacons", "size": 180, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "BSD 3-Clause \"New\" or \"Revised\" License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "domoritz", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 5257}]}
{"url": "https://github.com/domoritz/bias-study", "owner": "domoritz", "repository_name": "bias-study", "date_all_variable_collection": "2023-09-11", "description": "App to run study about bias as a result of exposure to incorrect data", "size": 81973, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 2, "license": "BSD 3-Clause \"New\" or \"Revised\" License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "domoritz", "contributions": 107}, {"contributor": "depstein", "contributions": 58}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 350408}, {"language": "Jupyter Notebook", "num_chars": 212850}, {"language": "JavaScript", "num_chars": 54090}, {"language": "HTML", "num_chars": 15034}, {"language": "R", "num_chars": 7689}, {"language": "Ruby", "num_chars": 3982}, {"language": "CSS", "num_chars": 1587}, {"language": "Shell", "num_chars": 22}], "readme": "# bias-study\nApp to run study about bias as a result of exposure to incorrect data\n\n## Use\n\nGo to [domoritz.github.io/bias-study](https://domoritz.github.io/bias-study). The data is on [firebase](https://console.firebase.google.com/project/bias-study/database/data).\n\n## Run\n\n* `bundle install`\n* `bundle exec jekyll serve`\n"}
{"url": "https://github.com/domoritz/bob-was-here", "owner": "domoritz", "repository_name": "bob-was-here", "date_all_variable_collection": "2023-09-11", "description": "bob was here", "size": 333, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "domoritz", "contributions": 46}, {"contributor": "robbiemouat", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 5256}], "readme": "TapIn (bob-was-here)\n============\n\nTapIn is an exciting online, cross platform, NFC and QR-coding, mobile, social application.\n\nYou can use it for pub crawls and scavenger hunts. Simply find TapIns and TapIn using NFC (or QR codes)."}
{"url": "https://github.com/domoritz/breakfast", "owner": "domoritz", "repository_name": "breakfast", "date_all_variable_collection": "2023-09-11", "description": "Friday breakfast", "size": 191, "stargazers_count": 5, "watchers_count": 5, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 5, "default_branch": "master", "contributors": [{"contributor": "domoritz", "contributions": 12}, {"contributor": "jenniferrogers", "contributions": 2}, {"contributor": "gussmith23", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["breakfast", "calendar", "google-sheets", "reminder-emails", "sheet", "tally"], "languages": [{"language": "JavaScript", "num_chars": 6770}, {"language": "HTML", "num_chars": 5205}], "readme": "# Friday breakfast for CSE\n\nThis is the code to manage Friday breakfast at UW CSE. The code is deployed from `/cse/web/community/breakfast`. \n\n## Features\n\n* Sign up in a Google Sheet\n* Send reminder emails to the person who signed up\n* Calendar automatically generated (and updated) from the spreadsheet\n* Breakfast tally that shows how often one has brought breakfast\n\n## How does the magic work?\n\nAll the data is hosted in a Google Sheet at https://docs.google.com/spreadsheets/d/1ofQZCbGJSaHsGjG5v7QOjtN1ksHD_tYIrw0HC17NKP8/edit. The spreadsheet has 5 sheets.\n\n* **SignUp**: Contains the sign ups for the current quarter\n* **Past** (hidden): All the past data. At the end of the quarter, the person in charge has to move data from SignUp here.\n* **All** (hidden): Automatically generated. Union of the data for the current quarter and the past for the tally. This is done with `=UNIQUE({SignUp!A1:C;Past!A1:C})`.\n* **Tally**: Automatically generated as a SQL query that computes the top breakfast bringers. The query is `=QUERY(All!A1:C,\"select max(B), C, count(A) where B !='' and A < now() group by C order by count(A) desc label max(B) 'Name', count(A) 'Count'\")`\n* **Templates** (hidden): A sheet with templates for the reminder emails.\n\nTo send reminder emails and synchronize the calendar, we have a couple of [Google Apps scripts](https://developers.google.com/apps-script/).\n\nThe scripts are in a project at https://script.google.com/macros/d/M0pV2KSX5V009GYhTKLyknTqujjucHJmb/edit. A copy of the scripts are also in the scripts folder.\n\nThe functions in these scripts get run by a set of [triggers](https://developers.google.com/apps-script/guides/triggers/).\n\n![Triggers](triggers.png)\n\nThe send reminder script goes through the sign up sheet and sends an email either 1 or 4 days before the set date. The template for the email is defined in the spreadsheet.\n\nThe calendar synchronization adds or updates events in this calendar: https://goo.gl/BdOI7K. To keep track of the events, there is a hidden column in the sign up sheet with the event id.\n"}
{"url": "https://github.com/domoritz/cdr", "owner": "domoritz", "repository_name": "cdr", "date_all_variable_collection": "2023-09-11", "description": "data analysis scripts", "size": 104, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "domoritz", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 3669}, {"language": "Shell", "num_chars": 67}]}
{"url": "https://github.com/domoritz/ckanext-krzn", "owner": "domoritz", "repository_name": "ckanext-krzn", "date_all_variable_collection": "2023-09-11", "description": "Custom CKAN extension for KRZN", "size": 224, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU Affero General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "domoritz", "contributions": 19}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 2487}, {"language": "CSS", "num_chars": 1523}, {"language": "JavaScript", "num_chars": 1248}], "readme": "# ckanext-krzn\n\nCustom CKAN extension for KRZN\n\n## How to Install Locally for Development\n\n1. Install CKAN from source.\n\n2. Install ckanext-krzn. Activate your CKAN virtual environment and:\n\n```bash\ngit clone git@github.com:okfn/ckanext-krzn.git\ncd ckanext-krzn\npython setup.py develop\npip install -r pip-requirements.txt\n```\n\n3. Edit the following settings in the `[app:main]` section of your CKAN config\n   file (e.g. `development.ini` or `production.ini`):\n\n```\nckan.plugins = krzn\n```\n\n4. Run CKAN, e.g. `paster serve production.ini`\n\n## Edit the style\n\nAfter editing the less files, they need to be recompiled. This can be done by calling `ckanext/krzn/theme/less`.\n"}
{"url": "https://github.com/domoritz/clasp-pb", "owner": "domoritz", "repository_name": "clasp-pb", "date_all_variable_collection": "2023-09-11", "description": "Fork of clasp from potassco with support for pseudo boolean constraint learning", "size": 1196, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "GNU General Public License v2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "domoritz", "contributions": 93}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 1515471}, {"language": "C", "num_chars": 92348}, {"language": "Shell", "num_chars": 16507}], "readme": "clasp-pb\n========\n\nFork of clasp from potassco with support for pseudo boolean learning"}
{"url": "https://github.com/domoritz/clingo-wasm", "owner": "domoritz", "repository_name": "clingo-wasm", "date_all_variable_collection": "2023-09-11", "description": "Clingo on the web", "size": 8505, "stargazers_count": 21, "watchers_count": 21, "language": "TypeScript", "has_issues": true, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": true, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 5, "license": "Apache License 2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 5, "watchers": 21, "default_branch": "main", "contributors": [{"contributor": "dependabot[bot]", "contributions": 200}, {"contributor": "dependabot-preview[bot]", "contributions": 116}, {"contributor": "domoritz", "contributions": 63}, {"contributor": "d4hines", "contributions": 2}, {"contributor": "peter-gy", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": true, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TypeScript", "num_chars": 6681}, {"language": "Shell", "num_chars": 2084}, {"language": "JavaScript", "num_chars": 1696}, {"language": "HTML", "num_chars": 619}], "readme": "# Clingo WebAssembly\n\n[![npm version](https://img.shields.io/npm/v/clingo-wasm.svg)](https://www.npmjs.com/package/clingo-wasm)\n[![CDN](https://data.jsdelivr.com/v1/package/npm/clingo-wasm/badge?style=rounded)](https://www.jsdelivr.com/package/npm/clingo-wasm)\n[![Clingo version](https://img.shields.io/badge/Clingo-5.6.2-blue)](https://github.com/potassco/clingo)\n[![Lua version](https://img.shields.io/badge/Lua-5.3.6-blue)](https://github.com/lua/lua)\n[![Emscripten version](https://img.shields.io/badge/Emscripten-3.1.18-blue)](https://emscripten.org)\n[![Build WASM](https://github.com/domoritz/clingo-wasm/actions/workflows/release.yml/badge.svg)](https://github.com/domoritz/clingo-wasm/actions/workflows/release.yml)\n\n[Clingo](https://github.com/potassco/clingo) compiled to [WebAssembly](https://webassembly.org/) with [Emscripten](https://kripken.github.io/emscripten-site/).\nTry it online at https://observablehq.com/@cmudig/clingo or https://domoritz.github.io/clingo-wasm.\n\nThis repo combines work from two previous repos: https://github.com/Aluriak/webclingo-example and https://github.com/domoritz/wasm-clingo.\n\n## Installation and Usage\n\n### Node\n\n`npm install clingo-wasm` or `yarn add clingo-wasm`.\n\n```js\nconst clingo = require(\"clingo-wasm\");\n\nclingo.run(\"a. b:- a.\").then(console.log);\n```\n\n### In the Browser\n\nLoad Clingo from the [JSDelivr CDN](https://www.jsdelivr.com/package/npm/clingo-wasm).\n\n```html\n<script src=\"https://cdn.jsdelivr.net/npm/clingo-wasm@VERSION\"></script>\n```\n\nWe expose an UMD bundle that runs Clingo in a separate worker thread. Therefore, all commands need to be asynchronous.\n\n```html\n<script>\n  async function main() {\n    // optionally pass URL to WASM file:\n    // await clingo.init(\"https://cdn.jsdelivr.net/npm/clingo-wasm@VERSION/dist/clingo.wasm\")\n    console.log(await clingo.run(\"a. b :- a.\"));\n    console.log(await clingo.run(\"{a; b; c}.\", 0));\n  }\n\n  main();\n</script>\n```\n\n## Developers\n\n### Build WASM file\n\nRun `yarn build:wasm` if you have Docker. For testing purposes, you can run `scripts/build_clingo.sh` from the root directory of the project.\n\n### Build and Test JavaScript\n\nRun `yarn build` to build the js files. Run `yarn test` to run tests in node.\n\n### Update Lua, Clingo, or Emscripten\n\nUpdate the versions in `scripts/versions.sh` and in the badges in this `README.md`. Then push to a new branch and let GitHub actions build the new WASM file.\n"}
{"url": "https://github.com/domoritz/CSE512-reports", "owner": "domoritz", "repository_name": "CSE512-reports", "date_all_variable_collection": "2023-09-11", "description": "Reports for CSE 512", "size": 1712, "stargazers_count": 1, "watchers_count": 1, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "domoritz", "contributions": 44}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 92688}, {"language": "Shell", "num_chars": 71}], "readme": "CSE512-reports\n==============\n"}
{"url": "https://github.com/domoritz/CSE552-Proposal", "owner": "domoritz", "repository_name": "CSE552-Proposal", "date_all_variable_collection": "2023-09-11", "description": "Project proposal for course CSE 552", "size": 2671, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": false, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "domoritz", "contributions": 89}, {"contributor": "stechu", "contributions": 36}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "CSE552 Proposal - Profiling and Visualizing Query Execution in Distributed Database System\n==========================================================================================\n\n\n## Background\n* Database system need to transform user's high level queries, eg. SQL, Datalog into physical query plan for the execution of the query\n* Physical query plan is the actual exectution map of a database system. Usually it can be viewed as a DAG which consisted by basic operators, such as JOIN, GROUP BY, SCAN, APPLY and relational tables (if the data).\n* In distributed database system, the introduction of SHUFFLE operator and data partitioning will make query plan more complicated.\n\n## Objective\n\n* Profile the execution of a physical query plan of distributed database\n* Visually present the profiling of the physical query plan execution \n* Use the Visualization to analyze and improve the physical plan\n\n## Platform\n\n* Use Myria, the under development distributed big data management system\n* Visualization as web aplication with front and backend. \n\n## Question we want to answer with our visualization\n\n* The implicit dependencies between operators\n* What is the bottleneck of the execution? Improving which part could best boost the performance?\n* How good is the load balancing? If it is skewed, how bad it can affect the performance?\n* Is an execution IO/ Network or CPU bound?\n\n## Tasks\n\n* Log events of operators.\n* Collect the logs on one node.\n* Evaluate the logs and write summaries to local database.\n* Visualize query execution on a web page.\n* Analyze the query execution and find patterns that suggest a problem. Visualize the problem or give a desciption. \n\n## Visualization\n\n* Gantt chart which also shows the hierarchy of the operators and possibly where an operator is executed.\n\n\n## Quantitative output\n\n* There will not be a measurable output.\n* We hope to answer questions about the Myria query execution and develop physical optimization rules based on the observations. \n\n\n\n## TODO\n\n\n### Visualization \n\n#### QF\n\n* start, end, duration\n* percentages of states on hover over name\n\n### Data (TBD)\n\n#### Routes\n\n* `/query/query-2/qf=1/worker=1` specific data for one worker and one qf\n* `/query/query-2/qf=4` aggregated per worker, working/ not working for root\n"}
{"url": "https://github.com/domoritz/csv2arrow", "owner": "domoritz", "repository_name": "csv2arrow", "date_all_variable_collection": "2023-09-11", "description": "Convert CSV files to Apache Arrow.", "size": 138, "stargazers_count": 15, "watchers_count": 15, "language": "Rust", "has_issues": true, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": "Apache License 2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 15, "default_branch": "main", "contributors": [{"contributor": "dependabot[bot]", "contributions": 90}, {"contributor": "domoritz", "contributions": 48}, {"contributor": "github-actions[bot]", "contributions": 9}, {"contributor": "andyredhead", "contributions": 2}, {"contributor": "dependabot-preview[bot]", "contributions": 2}, {"contributor": "boudra", "contributions": 1}, {"contributor": "yurivish", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["arrow", "rust"], "languages": [{"language": "Rust", "num_chars": 3730}], "readme": "# CSV to Arrow\n\n**This repo is archived and the code moved to [Arrow CLI Tools](https://github.com/domoritz/arrow-tools).**\n\n[![Crates.io](https://img.shields.io/crates/v/csv2arrow.svg)](https://crates.io/crates/csv2arrow)\n[![Rust](https://github.com/domoritz/csv2arrow/actions/workflows/rust.yml/badge.svg)](https://github.com/domoritz/csv2arrow/actions/workflows/rust.yml)\n\nConvert CSV files to Apache Arrow. You may also be interested in [json2arrow](https://github.com/domoritz/json2arrow), [csv2parquet](https://github.com/domoritz/csv2parquet), or [json2parquet](https://github.com/domoritz/json2parquet).\n\n## Installation\n\n### Download prebuilt binaries\n\nYou can get the latest releases from https://github.com/domoritz/csv2arrow/releases/.\n\n### With Cargo\n\n```\ncargo install csv2arrow\n```\n\n## Usage\n\n```\nUsage: csv2arrow [OPTIONS] <CSV> [ARROW]\n\nArguments:\n  <CSV>    Input CSV file\n  [ARROW]  Output file, stdout if not present\n\nOptions:\n  -s, --schema-file <SCHEMA_FILE>\n          File with Arrow schema in JSON format\n  -m, --max-read-records <MAX_READ_RECORDS>\n          The number of records to infer the schema from. All rows if not present. Setting max-read-records to zero will stop schema inference and all columns will be string typed\n      --header <HEADER>\n          Set whether the CSV file has headers [possible values: true, false]\n  -d, --delimiter <DELIMITER>\n          Set the CSV file's column delimiter as a byte character [default: ,]\n  -p, --print-schema\n          Print the schema to stderr\n  -n, --dry\n          Only print the schema\n  -h, --help\n          Print help information\n  -V, --version\n          Print version information\n```\n\nThe --schema-file option uses the same file format as --dry and --print-schema.\n"}
{"url": "https://github.com/domoritz/csv2parquet", "owner": "domoritz", "repository_name": "csv2parquet", "date_all_variable_collection": "2023-09-11", "description": "Convert CSV files to Apache Parquet.", "size": 208, "stargazers_count": 73, "watchers_count": 73, "language": "Rust", "has_issues": true, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 13, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 2, "license": "Apache License 2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 13, "open_issues": 2, "watchers": 73, "default_branch": "main", "contributors": [{"contributor": "dependabot[bot]", "contributions": 79}, {"contributor": "domoritz", "contributions": 59}, {"contributor": "github-actions[bot]", "contributions": 13}, {"contributor": "andyredhead", "contributions": 2}, {"contributor": "mrhrzg", "contributions": 1}, {"contributor": "mikekenneth", "contributions": 1}, {"contributor": "yurivish", "contributions": 1}, {"contributor": "dependabot-preview[bot]", "contributions": 1}, {"contributor": "snoe925", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 7956}], "readme": "# CSV to Parquet\n\n**This repo is archived and the code moved to [Arrow CLI Tools](https://github.com/domoritz/arrow-tools).**\n\n[![Crates.io](https://img.shields.io/crates/v/csv2parquet.svg)](https://crates.io/crates/csv2parquet)\n[![Rust](https://github.com/domoritz/csv2parquet/actions/workflows/rust.yml/badge.svg)](https://github.com/domoritz/csv2parquet/actions/workflows/rust.yml)\n\nConvert CSV files to [Apache Parquet](https://parquet.apache.org/). You may also be interested in [json2parquet](https://github.com/domoritz/json2parquet), [csv2arrow](https://github.com/domoritz/csv2arrow), or [json2arrow](https://github.com/domoritz/json2arrow).\n\n## Installation\n\n### Download prebuilt binaries\n\nYou can get the latest releases from https://github.com/domoritz/csv2parquet/releases/.\n\n### With Cargo\n\n```\ncargo install csv2parquet\n```\n\n## Usage\n\n```\nUsage: csv2parquet [OPTIONS] <CSV> <PARQUET>\n\nArguments:\n  <CSV>      Input CSV file\n  <PARQUET>  Output file\n\nOptions:\n  -s, --schema-file <SCHEMA_FILE>\n          File with Arrow schema in JSON format\n      --max-read-records <MAX_READ_RECORDS>\n          The number of records to infer the schema from. All rows if not present. Setting max-read-records to zero will stop schema inference and all columns will be string typed\n      --header <HEADER>\n          Set whether the CSV file has headers [possible values: true, false]\n  -d, --delimiter <DELIMITER>\n          Set the CSV file's column delimiter as a byte character [default: ,]\n  -c, --compression <COMPRESSION>\n          Set the compression [possible values: uncompressed, snappy, gzip, lzo, brotli, lz4, zstd]\n  -e, --encoding <ENCODING>\n          Sets encoding for any column [possible values: plain, rle, bit-packed, delta-binary-packed, delta-length-byte-array, delta-byte-array, rle-dictionary]\n      --data-pagesize-limit <DATA_PAGESIZE_LIMIT>\n          Sets data page size limit\n      --dictionary-pagesize-limit <DICTIONARY_PAGESIZE_LIMIT>\n          Sets dictionary page size limit\n      --write-batch-size <WRITE_BATCH_SIZE>\n          Sets write batch size\n      --max-row-group-size <MAX_ROW_GROUP_SIZE>\n          Sets max size for a row group\n      --created-by <CREATED_BY>\n          Sets \"created by\" property\n      --dictionary\n          Sets flag to enable/disable dictionary encoding for any column\n      --statistics <STATISTICS>\n          Sets flag to enable/disable statistics for any column [possible values: none, chunk, page]\n      --max-statistics-size <MAX_STATISTICS_SIZE>\n          Sets max statistics size for any column. Applicable only if statistics are enabled\n  -p, --print-schema\n          Print the schema to stderr\n  -n, --dry\n          Only print the schema\n  -h, --help\n          Print help information\n  -V, --version\n          Print version information\n```\n\nThe --schema-file option uses the same file format as --dry and --print-schema.\n\n## Examples\n\n### Convert a CSV to Parquet\n```bash\ncsv2parquet data.csv data.parquet\n```\n\n### Convert a CSV with no `header` to Parquet\n```bash\ncsv2parquet --header false <CSV> <PARQUET>\n```\n\n### Get the `schema` from a CSV with header\n```bash\ncsv2parquet --header true --dry <CSV> <PARQUET>\n```\n\n### Convert a CSV using `schema-file` to Parquet\n\nBelow is an example of the `schema-file` content:\n\n```json\n{\n  \"fields\": [\n    {\n      \"name\": \"col1\",\n      \"data_type\": \"Utf8\",\n      \"nullable\": false,\n      \"dict_id\": 0,\n      \"dict_is_ordered\": false,\n      \"metadata\": {}\n    },\n    {\n      \"name\": \" col2\",\n      \"data_type\": \"Utf8\",\n      \"nullable\": false,\n      \"dict_id\": 0,\n      \"dict_is_ordered\": false,\n      \"metadata\": {}\n    }\n  ],\n  \" metadata\": {}\n}\n```\n\nThen add the schema-file `schema.json` in the command:\n```\ncsv2parquet --header false --schema-file schema.json <CSV> <PARQUET>\n```\n"}
{"url": "https://github.com/domoritz/D3-App-Template", "owner": "domoritz", "repository_name": "D3-App-Template", "date_all_variable_collection": "2023-09-11", "description": "A template for an interactive web application with D3", "size": 305, "stargazers_count": 8, "watchers_count": 8, "language": "TypeScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": true, "has_discussions": false, "forks_count": 7, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "BSD 3-Clause \"New\" or \"Revised\" License", "allow_forking": true, "is_template": true, "web_commit_signoff_required": false, "visibility": "public", "forks": 7, "open_issues": 0, "watchers": 8, "default_branch": "main", "contributors": [{"contributor": "domoritz", "contributions": 26}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TypeScript", "num_chars": 6191}, {"language": "HTML", "num_chars": 524}, {"language": "CSS", "num_chars": 379}], "readme": "# D3-App-Template\n\nA template for an interactive web application with D3.\n\n## Launch the app\n\nInstall [node](https://nodejs.org/en/) and then install the dependencies.\n\n```bash\nnpm install\n```\n\nThen you can run the app.\n\n```bash\nnpm run dev\n```\n\nThis launches the app in developer mode. To run the app in production mode, run `npm run build` or see below.\n\n## Code style\n\nWe recommed using [VSCode](https://code.visualstudio.com) for development. You can run `npm run lint` to check for linting errors.\nNote that these tests automatically run when you comit your code to GitHub. See `test.yml` for details.\nYou can fix a lot of issues autoamtically with `npm run format`. If you see TypeScript errors that you don't want to fix, you can silence them with a comment `// @ts-ignore`.\n\n## Deployment\n\nWhen you push to GitHub, the app automatically deploys to GitHub Pages. As an example, this template repository is deployed at [domoritz.github.io/D3-App-Template](https://domoritz.github.io/D3-App-Template/). See `deploy.yml` for details. Make sure to update the `base` property in `vite.config.ts` to match your repo name.\n\n## Notes\n\n- Uses [Vite](https://vitejs.dev/)\n- Bootstrapped with `npx create vite app --template vanilla-ts`\n- Uses [D3](https://d3js.org/)\n- Built with [TypeScript](https://www.typescriptlang.org/)\n- Supports [DuckDB-wasm](https://github.com/duckdb/duckdb-wasm)\n"}
{"url": "https://github.com/domoritz/datafusion-wasm", "owner": "domoritz", "repository_name": "datafusion-wasm", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "domoritz", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 1218}], "readme": "# DataFusion in WebAssembly\n\nJust a stub for now. Needs https://issues.apache.org/jira/browse/ARROW-11615. \n\nBuild with `cargo build --target wasm32-unknown-unknown`.\n"}
{"url": "https://github.com/Dudderle/mueller-lyer-illusion", "owner": "Dudderle", "repository_name": "mueller-lyer-illusion", "date_all_variable_collection": "2023-09-11", "description": "Projektabgabe des Kurses \"Multimedia-Technologie\" der Universit\u00e4t Potsdam", "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/Dudderle/Unity-Breakout-Tutorial", "owner": "Dudderle", "repository_name": "Unity-Breakout-Tutorial", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1316, "stargazers_count": 0, "watchers_count": 0, "language": "ShaderLab", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "Dudderle", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "ShaderLab", "num_chars": 80492}, {"language": "HLSL", "num_chars": 13994}, {"language": "C#", "num_chars": 8895}]}
{"url": "https://github.com/e-zolotarevskaya/Ancillary_services_SP", "owner": "e-zolotarevskaya", "repository_name": "Ancillary_services_SP", "date_all_variable_collection": "2023-09-11", "description": null, "size": 321, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "e-zolotarevskaya", "contributions": 77}, {"contributor": "p-prochaska", "contributions": 16}, {"contributor": "FHell", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 108637}, {"language": "Julia", "num_chars": 66465}], "readme": "# Ancillary_services_SP"}
{"url": "https://github.com/edward-loves-github/creativeChatbot", "owner": "edward-loves-github", "repository_name": "creativeChatbot", "date_all_variable_collection": "2023-09-11", "description": "I am working on a research project that has the aim to create a chatbot that improves your creativity.", "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": true, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "edward-loves-github", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# creativeChatbot\nThe research groupe seven of the Weizenbaum Institute is working on a research project that has the aim to create a chatbot, that helps people to be more creative at work.\n\nWhat already know or what we have already done\n- we have an idea about how that chatbot should work in order to help people to be more creative\n- we know that we need our own training data in order to have a chatbot that works for our purpose correctly\n- we are using the python module chatterbot to create our chatbot\n\nWhat we need to do next\n- we need to get to know how that structure of the traning data has to be in order to feed our bot with this data\n- we need to simulate creative conversations in order to create our own training data\n"}
{"url": "https://github.com/eileenkammel/AdventOfCode22", "owner": "eileenkammel", "repository_name": "AdventOfCode22", "date_all_variable_collection": "2023-09-11", "description": null, "size": 17, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "eileenkammel", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 1126}, {"language": "Go", "num_chars": 1118}]}
{"url": "https://github.com/eileenkammel/AoC2021", "owner": "eileenkammel", "repository_name": "AoC2021", "date_all_variable_collection": "2023-09-11", "description": null, "size": 23, "stargazers_count": 1, "watchers_count": 1, "language": "Go", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "datosh", "contributions": 5}, {"contributor": "eileenkammel", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Go", "num_chars": 13772}, {"language": "Python", "num_chars": 3657}], "readme": "# Advent of Code 2021\n\nPuzzles will be available\n[here](https://adventofcode.com/2021)."}
{"url": "https://github.com/eileenkammel/Approximate_String_Matching", "owner": "eileenkammel", "repository_name": "Approximate_String_Matching", "date_all_variable_collection": "2023-09-11", "description": "Approximate String Matching using Burkhard-Keller-Trees", "size": 15210, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 25383}], "readme": "# Approximate String Matching using BK-Trees\n\n\n\n## Description\n\nThis project implements approximative string matching using [Burkard-Keller-Trees](https://en.wikipedia.org/wiki/BK-tree). The implemented matching metrics consist of [Levenshtein Distance](https://en.wikipedia.org/wiki/Levenshtein_distance) as the default and [S\u00f8rensen-Dice Coefficient](https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient) as another option to choose from. The BK-Trees can be set up from scratch, passing your own textfile containing a word list, where each line contains a single word. Once set up, you can save (in python pickle format) and relaod the tree for later usage. A pre-build BK-Tree is included in the folder ```model/data```. The tree is based on [DeReWo List](https://www.ids-mannheim.de/digspra/kl/projekte/methoden/derewo/) which after being cleaned up yields a BK-Tree containing 326.939 German word forms. For this tree you will also find a DOT-file representing it in the same folder. The clean up script can also be found in this repository in the folder ```data_cleanup/DeReWo_cleaner.py```.\n\\\nWhenever a tree is set up from a word list, a DOT file representing the tree is generated. That file can be used to visualize the tree with a tool of your choice. **Important**: After the DOT-file is generated, you need to rename the file, so it does not get overridden the next time you generate a tree.\nOnce the BK-Tree is set up or loaded, the program starts an interactive mode, where you can enter a word to find approximate matches for and an edit distance tolerance limit of your choice. The program will output any words that match your query.\n\nThe implementation follows the Model-View-Controller design pattern. An overview of the architecture is shown below.\n\n\n![Architecture](resources/ApproxMatching.png?raw=true \"Approximate String Matching using BK-Trees in MVC design pattern.\")\n\n***\n## Requirements\n[Python](https://www.python.org/downloads/) 3.10.4\n\\\n\\\nnumpy 1.22.3\\\npydot 1.4.2\\\npytest 7.1.2\\\n\\\nRequirements besides Python can be installed with pip by running\n```pip3 install -r requirements.txt```\n***\n## Installation\nDownload and unzip Repository. Save to location of your choice. Install requirements above as needed. \n***\n## Demo\nA demo containing a pre-build tree with english word forms and Levenshtein Distance can be executed by running\n```python3 demo.py```\n\\\nTo exit the demo, enter an empty line instead of a query word.\n***\n## Usage\n```python3 approx_matching.py [-h] [--file FILE] [--save] [--metric [METRIC]]```\\\n\\\nFor file either a .txt file containing a word list or a .pkl file containing a pickled BK-Tree can be passed. Note that the save flag ```--save``` should only be set when setting up the tree from a text file as should a metric name only be passed when setting up a new tree. For metric a valid metric name can be passed. At state, only Sorensen-Dice Coefficient can be chosen by entering one of the allowed names for it: SorensenDiceCoefficient, SDC, sdc. If no name is given, the Levenshtein Distance that is set as default is loaded. If you opt to save the tree, you will be prompted to enter a filename for saving the tree after the tree has been set up:\\\n\\\n![Saving](resources/save_prompt.png?raw=true \"Saving prompt.\")\\\n\\\nAfter the tree has been set up or loaded successfully, status output will inform you about the tree stats.\\\n\\\n![Stats](resources/stats_output.png?raw=true \"Stats output.\")\\\n\\\nAfterwards the interactive mode starts, where you are repeatedly prompted to enter a query word and an edit distance tolerance limit and are shown the output of your query. To exit the query loop, enter an empty line for query word.\\\n\\\n![Query](resources/query_loop.png?raw=true \"Query Loop.\")\\\n\\\nThe maximum edit distance: The appropriate values depend on the metric chosen. If your tree is set up with Levenshtein Distance, the maximum edit distance can be any whole number greater than zero. The greater the distance, the less the similarity between the two words. For the Sorensen-Dice Coefficient, the maximum edit distance is a decimal number grater than zero and less than one. Words with an edit distance of zero have no similarity at all, whereas words with distance one are identical.\n\n***\n## Tests\nTests are implemented for the BK-Tree and each of the Metrics. To run all, run ```pytest```\\\n\\\nTo run them individually, run ```pytest model/metrics/test_levenshtein.py``` for Levenstein Distance, ```pytest model/metrics/test_sorensen_dice.py``` for Sorensen-Dice Coefficient and ```pytest model/test_bk_tree.py``` for the BK-Tree.\n\n***\n## Author\nEileen Kammel eileen.niedenfuehr@uni-potsdam.de"}
{"url": "https://github.com/eileenkammel/EventCal", "owner": "eileenkammel", "repository_name": "EventCal", "date_all_variable_collection": "2023-09-11", "description": "Slot-Filling Skill for Furhat", "size": 81, "stargazers_count": 0, "watchers_count": 0, "language": "Kotlin", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "eileenkammel", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Kotlin", "num_chars": 13568}, {"language": "HTML", "num_chars": 675}, {"language": "CSS", "num_chars": 276}], "readme": "# EventCal Skill\nSlot-Filling skill\n\n## Description\nLet the user add en Event to a calendar. Slots to fill are Event Date, Time and Type. A forth boolean slot, Reminder, determines if a reminder is added and subsequently if the fifth slot, the reminder time has to be filled.\n\n\n## Usage\nMax number of users is set to: 1\nDefault interaction distance is set to: 1 m\nNo other specific requirements. "}
{"url": "https://github.com/ekaterinailin/AltaiPony", "owner": "ekaterinailin", "repository_name": "AltaiPony", "date_all_variable_collection": "2023-09-11", "description": "Find flares in Kepler and TESS light curves. Notebooks for quickstart inside.", "size": 17082, "stargazers_count": 22, "watchers_count": 22, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 9, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 19, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 9, "open_issues": 19, "watchers": 22, "default_branch": "master", "contributors": [{"contributor": "ekaterinailin", "contributions": 497}, {"contributor": "lupitatovar", "contributions": 7}, {"contributor": "barentsen", "contributions": 1}, {"contributor": "gully", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": true, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 760587}, {"language": "Python", "num_chars": 278016}], "readme": "|docs-badge| |license-badge| |joss-badge| |zenodo-badge|\n\n\n.. |joss-badge| image:: https://joss.theoj.org/papers/10.21105/joss.02845/status.svg\n   :target: https://doi.org/10.21105/joss.02845\n\n..  |zenodo-badge| image:: https://zenodo.org/badge/DOI/10.5281/zenodo.5040830.svg\n                    :target: https://doi.org/10.5281/zenodo.5040830\n\n.. |docs-badge| image:: https://readthedocs.org/projects/altaipony/badge/?version=latest\n\t      :target: https://altaipony.readthedocs.io/en/latest/?badge=latest\n\t      :alt: Documentation Status\n\t      \n.. |license-badge|  image:: https://img.shields.io/github/license/mashape/apistatus.svg   \n\t\t    :target: https://github.com/ekaterinailin/AltaiPony/blob/master/LICENSE \n\t\t    :alt: GitHub\t\n\n.. image:: logo.png\n   :height: 100px\n   :width: 100px\n   :alt: Logo credit: Elizaveta Ilin, 2018\n\nAltaiPony\n=========\n\nDe-trend light curves from Kepler, and TESS missions, and search them for flares. Inject and recover synthetic flares to account for de-trending and noise loss in flare energy and determine energy-dependent recovery probability for every flare candidate. Uses ``lightkurve`` under the cover, as well as ``pandas``, ``numpy``, ``pytest``, ``astropy`` and more.\n\nFind the documentation at altaipony.readthedocs.io_\n\nInstallation\n^^^^^^^^^^^^^\n\nUse pip to install AltaiPony\n\n>>> pip install altaipony\n\n\nOr install directly from the repository:\n\n>>> git clone https://github.com/ekaterinailin/AltaiPony.git\n>>> cd AltaiPony\n>>> python setup.py install\n\n\n\nGetting Started\n^^^^^^^^^^^^^^^^\n\nSee this notebook_ for an easy introduction, also docs_.\n\n\nProblems?\n^^^^^^^^^\n\n Often, when something does not work in **AltaiPony**, and this documentation is useless, troubleshooting can be done by diving into the extensive **lightkurve** docs_. Otherwise, you can always shoot Ekaterina an email_ or directly open an issue on GitHub_. Many foreseeable problems will be due to bugs in **AltaiPony** or bad instructions on this website.\n\n\nContribute to AltaiPony\n^^^^^^^^^^^^^^^^^^^^^^^\n\n**AltaiPony** is under active development on Github_. If you use **AltaiPony** in your research and find yourself missing a functionality, I recommend opening an issue on GitHub_ or shooting Ekaterina an email_. Please do either of the two before you open a pull request. This may save you a lot of development time.\n\nHow to cite this work\n^^^^^^^^^^^^^^^^^^^^^\n\nIf you end up using this package for your science, please cite Ilin et al. (2021) [a]_ and Davenport (2016) [b]_.\n\nPlease also cite `lightkurve` as indicated in their docs [1]_. \n\nDepending on the methods you use, you may also want to cite \n\n  - Maschberger and Kroupa (2009) [2]_ (MMLE power law fit)\n  - Wheatland (2004) [3]_ (MCMC power law fit)\n  - Aigrain et al. (2016) [4]_ and their software [5]_ (K2SC de-trending -- DEPRECATED)\n  - Davenport et al. (2014) [6_] or Mendoza et al. (2022) [7_] (injection-recovery analysis)\n\n\n.. [a] Ekaterina Ilin, Sarah J. Schmidt, Katja Poppenh\u00e4ger, James R. A. Davenport, Martti H. Kristiansen, Mark Omohundro (2021). \"Flares in Open Clusters with K2. II. Pleiades, Hyades, Praesepe, Ruprecht 147, and M67\" Astronomy & Astrophysics, Volume 645, id.A42, 25 pp.  \thttps://doi.org/10.1051/0004-6361/202039198 \n\n.. [b] James R. A. Davenport \"The Kepler Catalog of Stellar Flares\" The Astrophysical Journal, Volume 829, Issue 1, article id. 23, 12 pp. (2016). https://doi.org/10.3847/0004-637X/829/1/23\n\n.. [1] https://docs.lightkurve.org/about/citing.html\n\n.. [2] Thomas Maschberger, Pavel Kroupa, \"Estimators for the exponent and upper limit, and goodness-of-fit tests for (truncated) power-law distributions\" Monthly Notices of the Royal Astronomical Society, Volume 395, Issue 2, May 2009, Pages 931\u2013942, https://doi.org/10.1111/j.1365-2966.2009.14577.x\n\n.. [3] Wheatland, Michael S. \"A Bayesian approach to solar flare prediction.\" The Astrophysical Journal 609.2 (2004): 1134. https://doi.org/10.1086/421261\n\n.. [4] Aigrain, Suzanne; Parviainen, Hannu; Pope, Benjamin \"K2SC: flexible systematics correction and detrending of K2 light curves using Gaussian process regression\" Monthly Notices of the Royal Astronomical Society, Volume 459, Issue 3, p.2408-2419 https://doi.org/10.1093/mnras/stw706\n\n.. [5] Aigrain, Suzanne; Parviainen, Hannu; Pope, Benjamin \"K2SC: K2 Systematics Correction.\" Astrophysics Source Code Library, record ascl:1605.012 https://ui.adsabs.harvard.edu/abs/2016ascl.soft05012A/abstract\n\n.. [6] J. R. A. Davenport et al., \u201cKepler Flares. II. The Temporal Morphology of White-light Flares on GJ 1243,\u201d The Astrophysical Journal, vol. 797, p. 122, Dec. 2014, doi: 10.1088/0004-637X/797/2/122.\n\n.. [7] G. T. Mendoza, J. R. A. Davenport, E. Agol, J. A. G. Jackman, and S. L. Hawley, \u201cLlamaradas Estelares: Modeling the Morphology of White-light Flares,\u201d The Astronomical Journal, Volume 164, Issue 1, id.17, <NUMPAGES>12</NUMPAGES> pp., vol. 164, no. 1, p. 17, Jul. 2022, doi: 10.3847/1538-3881/ac6fe6.\n\n\n\n\n.. _Appaloosa: https://github.com/jradavenport/appaloosa/\n.. _altaipony.readthedocs.io: https://altaipony.readthedocs.io/en/latest/\n.. _notebook: https://github.com/ekaterinailin/AltaiPony/blob/master/notebooks/Getting_Started.ipynb\n.. _docs: https://altaipony.readthedocs.io/en/latest/\n.. _Github: https://github.com/ekaterinailin/AltaiPony/issues/new\n.. _email: eilin@aip.de\n"}
{"url": "https://github.com/ekaterinailin/aumic-flaring-spi", "owner": "ekaterinailin", "repository_name": "aumic-flaring-spi", "date_all_variable_collection": "2023-09-11", "description": null, "size": 7188, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "ekaterinailin", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# aumic-flaring-spi"}
{"url": "https://github.com/ekaterinailin/code-review-up", "owner": "ekaterinailin", "repository_name": "code-review-up", "date_all_variable_collection": "2023-09-11", "description": "The University of Potsdam Code Review Group shares their code here.", "size": 627, "stargazers_count": 3, "watchers_count": 3, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "ekaterinailin", "contributions": 32}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 10814}, {"language": "MATLAB", "num_chars": 2270}], "readme": "Code Review at the University of Potsdam\n-------------------------------------------\n-------------------------------------------\n\nFAQ\n----------------------------\n\n_What is a code review?_\n\nA code review is when a group of people get together and talk about a\npart of one person's code. This code can either be something really\ncool you discovered and would like to share, something you would like\nfeedback on (optimization, stuck on a problem, \u2026), or simply\nsomething representative of your work. It is a common practice in\nsoftware development and has been found to be the most effective way\nto find bugs in code. Here is an interesting piece on introducing code\nreview to scientists: http://arxiv.org/pdf/1407.5648v2.pdf [1]\n\n_Why are you founding this group?_\n\nI have found code reviews to be a great place to learn. When I present\nmy code it is useful to hear comments and feedback and gain a\ndifferent perspective on my work. When other people present I learn\nnew techniques, am introduced to new packages, and pick up tricks I\nnever would have otherwise seen.\n\n_Who should attend?_\n\nAll levels are welcome and encouraged to attend - I believe it will be\nmost successful with a full spectrum of coding levels (from thinking\nabout coding to expert). To begin I would like to stick with Python as\nlanguage. However, once we have established the group we can discuss\nexpanding to other languages and people. Feel free to invite\nundergrads and research staff, too!\n\n_When?_\n\nWe will be meeting bi-weekly, starting October 25, 2017 in 2.28.2.080 (Campus Golm)\n\n_How?_\n\nIn the beginning of our meetings in October I will provide an introduction to git and\ngithub to anyone who does not feel comfortable using the tool. Every\nother week a different person will volunteer to present their code to\nthe group. The code presented should be fairly self-contained and not\nmore than a page. It should also include some comments for the ease of\nuse of the group. Code should be available at least 24 hours prior to\nthe meeting. If you have time, you can comment on the code directly on\ngithub. In our meeting, the person presenting the code will give a\nlittle background on why they are writing the code and then walk the\ngroup through it. We will then discuss it.\n\n\nCode of Conduct\n-----------------\n\nCode Review is dedicated to providing a welcoming and supportive environment for all people, regardless of background or identity. However, we recognise that some groups in our community are subject to historical and ongoing discrimination, and may be vulnerable or disadvantaged. Membership in such a specific group can be on the basis of characteristics such as such as gender, sexual orientation, disability, physical appearance, body size, race, nationality, sex, colour, ethnic or social origin, pregnancy, citizenship, familial status, veteran status, genetic information, religion or belief, political or any other opinion, membership of a national minority, property, birth, age, or choice of text editor. **We do not tolerate harassment of participants on the basis of these categories, or for any other reason.**\nHarassment is any form of behaviour intended to exclude, intimidate, or cause discomfort. Because we are a diverse community, we may have different ways of communicating and of understanding the intent behind actions. Therefore we have chosen to prohibit certain forms of behaviour in our community, regardless of intent. Prohibited harassing behaviour includes but is not limited to:\n\n- written or verbal comments which have the effect of excluding people on the basis of membership of a specific group listed above\ncausing someone to fear for their safety, such as through stalking, following, or intimidation\n- the display of sexual or violent images\n- unwelcome sexual attention\n- nonconsensual or unwelcome physical contact\n- sustained disruption of talks, events or communications\n- incitement to violence, suicide, or self-harm\n- continuing to initiate interaction (including photography or recording) with someone after being asked to stop\n- publication of private communication without consent\n\nBehaviour not explicitly mentioned above may still constitute harassment. The list above should not be taken as exhaustive but rather as a guide to make it easier to enrich all of us and the communities in which we participate. All Code Review interactions should be professional regardless of location: harassment is prohibited whether it occurs on- or offline, and the same standards apply to both.\n\n**Enforcement of the Code of Conduct will be respectful and not include any harassing behaviors.**\n\n_Thank you for helping make this a welcoming, friendly community for all._\n\nThis code of conduct adopted from the Software Carpentry and Data Carpentry Code of Conduct which is a modified version of that used by PyCon, which in turn is forked from a template written by the Ada Initiative and hosted on the Geek Feminism Wiki. Contributors to this document: Adam Obeng, Aleksandra Pawlik, Bill Mills, Carol Willing, Erin Becker, Hilmar Lapp, Kara Woo, Karin Lagesen, Pauline Barmby, Sheila Miguez, Simon Waldman, Tracy Teal.\n\n"}
{"url": "https://github.com/ekaterinailin/dustycrocodile", "owner": "ekaterinailin", "repository_name": "dustycrocodile", "date_all_variable_collection": "2023-09-11", "description": "Hack HPI about://environment EU: Digging into European Union Open Data Portal for Water Use ", "size": 13381, "stargazers_count": 1, "watchers_count": 1, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "ekaterinailin", "contributions": 21}, {"contributor": "jeMATHfischer", "contributions": 18}, {"contributor": "thomoseidler", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 48438075}, {"language": "Jupyter Notebook", "num_chars": 840769}, {"language": "Python", "num_chars": 316}], "readme": "# dustycrocodile\nHack HPI about://environment EU: Digging into European Union Open Data Portal for Water Use \n"}
{"url": "https://github.com/ekaterinailin/ekaterinailinCV", "owner": "ekaterinailin", "repository_name": "ekaterinailinCV", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1907, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ekaterinailin", "contributions": 30}, {"contributor": "friggeri", "contributions": 20}, {"contributor": "JelmerT", "contributions": 13}, {"contributor": "eklenske", "contributions": 9}, {"contributor": "MDCore", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 18947}], "readme": "# About\nA new version of the famous Friggeri CV. My much simpler version now works without external font files, with regular (pdf)latex and without biber.\n\n\n# License\n\nCopyright (C) 2015, Edgar Klenske  \nCopyright (C) 2014, Jelmer Tiete  \nCopyright (C) 2012, Adrien Friggeri\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"}
{"url": "https://github.com/ekaterinailin/exoplanets-seminar", "owner": "ekaterinailin", "repository_name": "exoplanets-seminar", "date_all_variable_collection": "2023-09-11", "description": "Useful calculations for the \"Exoplanet detection, formation and evolution\" seminar run @ Uni Potsdam.", "size": 147, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ekaterinailin", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 214696}]}
{"url": "https://github.com/ekaterinailin/flare-locations-ensembles", "owner": "ekaterinailin", "repository_name": "flare-locations-ensembles", "date_all_variable_collection": "2023-09-11", "description": null, "size": 361, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "ekaterinailin", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 164522}, {"language": "PostScript", "num_chars": 15627}], "readme": "% readme.txt\n%\n% MNRAS journal LaTeX package\n% v3.0 for LaTeX 2e\n%\n%\n% This work may be distributed and/or modified under the\n% conditions of the LaTeX Project Public License, either version 1.3\n% of this license or (at your option) any later version.\n% The latest version of this license is in\n%   http://www.latex-project.org/lppl.txt\n% and version 1.3 or later is part of all distributions of LaTeX\n% version 2005/12/01 or later.\n%\n% This work has the LPPL maintenance status `author-maintained'.\n% \n% The Current Maintainer of this work is: Royal Astronomical Society,\n% MNRAS Editorial Office, who can be contacted on mn@ras.org.uk\n%\n% This work consists of all the files listed in readme.txt\n%\n%\n% Last updated 22 May 2015\n%\n% Copyright (C) Royal Astronomical Society 2015, Blackwell Science 2001,\n% Cambridge University Press 1994\n%\n% See each file for a detailed author list and change log.\n%\n% This package consists of the following files:\n\nreadme.txt          This file\n\nmnras.cls           MNRAS LaTeX document class\nmnras.bst           MNRAS BibTeX style\n\nmnras_guide.tex     User guide, LaTeX format\nmnras_guide.pdf     User guide, PDF format\nmnras_template.tex  A simple template paper\n\nexample.eps         An example image used in the guide\nexample.png         An example image used in the guide\nexample.ps          An example image used in the guide\n\nlegacy\\legacy.txt   Description of the legacy releases\nlegacy\\mn2e.cls     v2.2 of mn2e.cls (deprecated)\nlegacy\\mn2e.bst     v1.1b of mn2e.bst (deprecated)\n\n\n% Disclaimer:\n%\n% This LaTeX package is provided free to the community in the hope that it\n% assists them in preparing papers for the journal Monthly Notices of the\n% Royal Astronomical Society.\n% The files are provided 'as-is' with no guarantee of their suitability,\n% freedom from errors or omissions, or compatibility with any software.\n% The Royal Astronomical Society cannot provide user support for this package,\n% LaTeX, or for any other software.\n% Authors are free to use other styles or programmes if they wish.\n% Please see the journal instructions to authors for guidance.\n% This disclaimer is in addition to the No Warranty section of the licence,\n% at the link given above."}
{"url": "https://github.com/ekaterinailin/flare-locations-ensembles-science", "owner": "ekaterinailin", "repository_name": "flare-locations-ensembles-science", "date_all_variable_collection": "2023-09-11", "description": null, "size": 15633, "stargazers_count": 2, "watchers_count": 2, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "flares", "contributors": [{"contributor": "ekaterinailin", "contributions": 62}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 115505}, {"language": "TeX", "num_chars": 1727}], "readme": "# Flaring Latitudes in Ensembles of Low Mass Stars\n\n*Ilin et al. (accepted to MNRAS)*\n\nThe contents of this repository can be divided in three parts:\n\n- a preparatory part that can be run prior to producing synthetic flare light curves and waiting time distributions at scale,\n- instructions on how to produce synthetic data at scale\n- scripts that analyse and summarize the synthetic data\n\nScripts that produce figures and tables to appear in Ilin et al. (2023) are noted in the name of the script.\n\n**If you just want the data: Simulation outputs, as well as Tables 2 and 3 can be found on [Zenodo](https://zenodo.org/record/7996929).**\n\n## Scripts that can be run prior to generating synthetic data at scale\n\nScripts 01, 03, 05, 06 can be run prior to running simulations.\n\n- Script 01 explores the night length distribution for different active latitudes at varying inclinations.\n- Script 03 produces a **minimal example** of fleck usage with flares.\n- Script 05 derives the empirical equivalent duration to amplitude to duration conversion based flaring ultracool dwarf systems observed with TESS.\n- Script 06 produces model illustrations for the paper.\n\n## How to generate synthetic training data and use them to find properties that predict active latitude\n\n#### Generate training data\n\nOpen `09_make_script_for_generate_training_data.py` and check the parameters defined in the script. Don't change anything unless you know what you are doing!\n\nThen run `python 09_make_script_for_generate_training_data.py <number of light curves> <batches>`\n\nThis will generate a bash script named `09_script_generate_data.sh` that calls `09_generate_training_data.py` a `<batches>` times to give you the desired total `<number of light curves>`. It will also store the input parameters from the script in a file called `results/overview_synthetic_data.csv`.\n\nAdditionally, `09_script_generate_data.sh` will also call `09_generate_training_data.py` a `<batches>` times to give you the desired total `<number of light curves>` / 10, which will serve as a validation data set.\n\nHowever, we don't store the actual light curves, but only the flares we find in the data set. These flares appear modulated in brightness due to their latitude on the rotating star, which we hope to retrieve from the ensemble analysis.\n\nIn summary:\n\nInput: `python 09_make_script_for_generate_training_data.py <number of light curves> <batches>`\n\nOutput:\n\n- `09_script_generate_data.sh`\n- two new rows in `results/overview_synthetic_data.csv`\n\nInput: `bash 09_script_generate_data.sh`\n\nOutput:\n\n- `results/<timestamp1>_flares_train.csv`\n- `results/<timestamp1>_flares_validate.csv`\n\n#### Get summary statistics\n\nNow that we have our training and validation data sets, let's compute summary statistics. We do this because we don't want to use the information about individual flares, because they are randomly generated from a power law distribution, but statistics that give a single number for each light curve or even ensembles of light curves with similar active latitude, e.g., the total number of flares or the waiting times between flares.\n\nCall `python 10_make_script_for_get_aggregate_parameters.py <training/validation data set> <number of splits>`\n\n\nInput:\n\n- `python 10_make_script_for_get_aggregate_parameters.py <training data set> <number of splits>`\n- `python 10_make_script_for_get_aggregate_parameters.py <validation data set> <number of splits>`\n\nOutput:\n\n- `11_applyscript_<timestamp2>_<timestamp1>_flares_train.sh`\n- `12_merge_<timestamp2>_<timestamp1>_flares_train.sh`\n- `11_applyscript_<timestamp2>_<timestamp1>_flares_validate.sh`\n- `12_merge_<timestamp2>_<timestamp1>_flares_validate.sh`\n\nIf you are doing aggregate statistics for ensembles of light curves, take care not to split the training and validation data into too small chunks, in particular the validation set.  Divide `<total number of LCs> / <number of splits> / 200` to get the number of lc per ensemble. It should be at least 200 to effectively marginalize over inclinations, and get a decently narrow active latitude width. \n\nIn the paper, we ran theses scripts for a number of different configurations (number of active regions, flare rates, active latitude widths). **You can find the outputs from the above procedure on [Zenodo](https://zenodo.org/record/7996929).**\n\n\n## Scripts that can be run after the synthetic data have been created and processed\n\nScripts 13-18 can only be run after the synthetic data have been processed.\n\n- Script 13 fits a polynomial expression to the data, and writes out best-fit parameters and **covariance matrices** to the ``results/`` folder.\n- Script 14 plots the residuals of the fits done in Script 13 on a validation data set that was not used in 13.\n- Script 15 just convert the fit parameters .csv table to a LaTeX document (Table 2).\n- Script 16 shows the results for varying active latitude width. 16b is the version of the figure that appears in the paper.\n- Script 17 shows the results for varying power law exponent alpha. 17b is the version of the figure that appears in the paper.\n- Script 18 produces a figure that shows the parameter range covered by the mean and standard deviation of waiting time distributions.\n- Script 19 produces Table 3 in the paper\n- Script 20 produces Figure 9 that illustrates the flaring latitudes derived from the G dwarf flare sample in [Okamoto et al. (2021)](https://ui.adsabs.harvard.edu/abs/2021ApJ...906...72O/abstract), and convert Table 3 to LaTeX.\n\n**Machine readable versions of Tables 2 and 3 can be found on [Zenodo](https://zenodo.org/record/7996929).**\n"}
{"url": "https://github.com/ekaterinailin/flares-in-clusters-ii-draft", "owner": "ekaterinailin", "repository_name": "flares-in-clusters-ii-draft", "date_all_variable_collection": "2023-09-11", "description": "Paper draft corresponding to the project", "size": 130821, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ekaterinailin", "contributions": 128}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 1064094}, {"language": "Jupyter Notebook", "num_chars": 98257}]}
{"url": "https://github.com/ekaterinailin/flares-in-clusters-with-k2-ii", "owner": "ekaterinailin", "repository_name": "flares-in-clusters-with-k2-ii", "date_all_variable_collection": "2023-09-11", "description": "Here tables, analysis code, additional information, and ancillary plots for Ilin+2020 (in prep.) are stored. ", "size": 596320, "stargazers_count": 2, "watchers_count": 2, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 3, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 3, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "ekaterinailin", "contributions": 75}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 8482675}, {"language": "Shell", "num_chars": 529213}, {"language": "Python", "num_chars": 414212}], "readme": "# Flares in Clusters with K2. II. \n_Ilin+2019 (in prep.)_\n\nThe project is structured as follows:\n\n1. *Membership matching* from different sources\n2. *Stellar parameters* and quiescent luminosities from color-temperature relations and model spectra.\n3. *Flare finding* and injection-recovery characterization of flare candidates with  with [*AltaiPony*](https://github.com/ekaterinailin/AltaiPony).\n4. *Analysis* of flaring activity with respect to stellar mass and age.\n\nEach part is enclosed in one folder that contains\n\n- a README with instructions for those who wish to reproduce the results\n- Jupyter notebooks that are introduced in the README file\n- modules and scripts (Python 3.5)\n- the resulting tables and plots\n- relevant ancillary and raw data\n- plots that are included in Ilin+2019 (in prep.)\n\nNOTE: Some folders do not yet exist but will be added soon.\n\n## Installation instructions\n\nClone this repository, create a virtual environment, activate it, then run the installation file, like so:\n\n```\ngit clone https://github.com/ekaterinailin/flares-in-clusters-with-k2-ii.git\ncd flares-in-clusters-with-k2-ii\n\npython3 -m pip install --user virtualenv\npython3 -m venv flaresinclustersii\nsource flaresinclustersii/bin/activate\n\nbash installation.sh\n```\n\nFeel free to roam through the project, try the code, and browse the tables.\n\nQuestions, remarks, ideas for improvement? Open an issue in this repository or send an email to [Ekaterina Ilin](eilin@aip.de).\n"}
{"url": "https://github.com/ekaterinailin/flares-q-learning", "owner": "ekaterinailin", "repository_name": "flares-q-learning", "date_all_variable_collection": "2023-09-11", "description": "Mapping detected flares in TESS and Kepler light curves to the underlying flare event via injection-recovery with Q-learning", "size": 415, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 1, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "ekaterinailin", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 497474}, {"language": "Python", "num_chars": 13251}], "readme": "# flares-q-learning\n\nMapping detected flares in TESS and Kepler light curves to the underlying flare event via injection-recovery with Q-learning\n\nThis project was developed in part at the online.tess.science meeting, which took place globally in 2020 September.\n"}
{"url": "https://github.com/ekaterinailin/flaring-spi", "owner": "ekaterinailin", "repository_name": "flaring-spi", "date_all_variable_collection": "2023-09-11", "description": null, "size": 27787, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ekaterinailin", "contributions": 219}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 1746527}, {"language": "Python", "num_chars": 285534}], "readme": "# Flaring Star-Planet Interactions in Kepler and TESS Data\n\nThis repository contains the statistical analysis modules, and scripts to produce the figures and tables in the two following works:\n\n1. [Ilin, E. and Poppenh\u00e4ger K., (2022). *Searching for flaring star-planet interactions in AU Mic TESS observations.*](https://ui.adsabs.harvard.edu/abs/2022MNRAS.513.4579I/abstract)\n2. Ilin, E., Poppenh\u00e4ger K. et al. (2023, in prep.) *Searching for flaring star-planet interactions in Kepler and TESS observations.*\n\nThe first introduces the statistical method used in the second, and demonstrates it on the popular case of AU Mic.\n\n#### How to navigate this repository\n\n**Nomenclature:**\n\n- File names that contain `AU_Mic` are from project 1. \n- File names that begin with `_` belong to project 2.\n\n**Folders:**\n\n- `notebooks/` contains all the notebooks and scripts \n  - also contains the modules used in both, stored in `funcs/`\n- `data/` contains ancillary data, such as the TESS transmission curve\n- `results/` contain the flare table, the results of the A-D tests\n\n## Project 1: Searching for flaring star-planet interactions in AU Mic TESS observations\n\nNotebooks that produce the figures and tables in the paper found in `notebooks/`:\n\n- `AU_Mic_flare_catalog_with_phases_TABLE1.ipynb`\n  - example script of how to use the de-trending and flare finding described in Methods: `notebooks/findflares.py`\n  - flaring finding method described in 2.1: `notebooks/funs/detrend.py`\n  - electronic table of all flares: `results/2021_12_AU_Mic_2021_12_AU_Mic_final_flare_table.csv`\n- `AU_Mic_AD_test_analysis_TABLE2.ipynb`\n  - all A-D tests: `results/adtests.csv` (time stamped within the table) \n- `AU_Mic_illustrate_flares_FIGURE1.ipynb`\n- `AU_Mic_FFD_FIGURE2.ipynb`\n- `AU_Mic_cumdist_plot_FIGURE3.ipynb`\n- `AU_Mic_illustrate_observability_FIGURE4.ipynb`\n\nLook into A-D tests with doubled and tripled sample: `AU_Mic_AD_test_doubled_sample_DISCUSSION.ipynb`\n\nCalculation of quiescent flux in the TESS band: `AU_Mic_quiescent_flux_in_TESS_band_RESULTS.ipynb`\n\n## Project 2: Searching for flaring star-planet interactions in Kepler and TESS observations\n\n*TBD*\n\n`notebooks/`\n\n\n\n\n\n## Required Python packages\n\n- numpy\n- scipy\n- astropy\n- matplotlib\n- lightkurve\n- altaipony\n- emcee\n- corner`\n"}
{"url": "https://github.com/ekaterinailin/flaring-spi-paper", "owner": "ekaterinailin", "repository_name": "flaring-spi-paper", "date_all_variable_collection": "2023-09-11", "description": "Flaring SPI paper including all TESS and Kepler confirmed transiting planets", "size": 7753, "stargazers_count": 2, "watchers_count": 2, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "main", "contributors": [{"contributor": "ekaterinailin", "contributions": 92}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 4733745}, {"language": "Python", "num_chars": 71082}, {"language": "Shell", "num_chars": 616}], "readme": "<p align=\"center\">\n<a href=\"https://github.com/showyourwork/showyourwork\">\n<img width = \"450\" src=\"https://raw.githubusercontent.com/showyourwork/.github/main/images/showyourwork.png\" alt=\"showyourwork\"/>\n</a>\n<br>\n<br>\n<a href=\"https://github.com/ekaterinailin/flaring-spi-paper/actions/workflows/build.yml\">\n<img src=\"https://github.com/ekaterinailin/flaring-spi-paper/actions/workflows/build.yml/badge.svg?branch=main\" alt=\"Article status\"/>\n</a>\n<a href=\"https://github.com/ekaterinailin/flaring-spi-paper/raw/main-pdf/arxiv.tar.gz\">\n<img src=\"https://img.shields.io/badge/article-tarball-blue.svg?style=flat\" alt=\"Article tarball\"/>\n</a>\n<a href=\"https://github.com/ekaterinailin/flaring-spi-paper/raw/main-pdf/ms.pdf\">\n<img src=\"https://img.shields.io/badge/article-pdf-blue.svg?style=flat\" alt=\"Read the article\"/>\n</a>\n</p>\n\nThis is an open source scientific article created using the [showyourwork](https://github.com/showyourwork/showyourwork) workflow. --\n\n\nPlease find the data analysis scripts and modules over at [this other Github repository](https://github.com/ekaterinailin/flaring-spi). \n\nThe scripts producing tables and plots in the UPCOMING PAPER are under ``src/scripts/``. Put the required input data into ``src/data`` to make the scripts run. You can find the input data under ZENODO LINK.\n"}
{"url": "https://github.com/ekaterinailin/GaiaK2PSF", "owner": "ekaterinailin", "repository_name": "GaiaK2PSF", "date_all_variable_collection": "2023-09-11", "description": "PSF photometry on K2 with Gaia centroids", "size": 1508, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ekaterinailin", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 965952}, {"language": "Python", "num_chars": 14346}], "readme": "# GaiaK2PSF\nPSF photometry on K2 with Gaia centroids\n"}
{"url": "https://github.com/ekaterinailin/k2-panstarrs-sampedro", "owner": "ekaterinailin", "repository_name": "k2-panstarrs-sampedro", "date_all_variable_collection": "2023-09-11", "description": "Matching catalogs for cluster samples.", "size": 13321, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ekaterinailin", "contributions": 69}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 117828}, {"language": "Python", "num_chars": 33847}]}
{"url": "https://github.com/ekaterinailin/lean-site-template", "owner": "ekaterinailin", "repository_name": "lean-site-template", "date_all_variable_collection": "2023-09-11", "description": "Static site template for EA local group website", "size": 14469, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ekaterinailin", "contributions": 52}, {"contributor": "mondayrain", "contributions": 40}, {"contributor": "henryaj", "contributions": 6}, {"contributor": "guisers", "contributions": 2}, {"contributor": "Richenda", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# LEAN site template\n\nWelcome to the GitHub repository containing all the code/files you'll need in order to start a new Local EA site! You can see an example of what it'll look like at https://rtcharity.github.io/lean-site-template/.\n\n\nTo get a shiny new site for your local EA chapter, follow the instructions below or see the [video tutorials on YouTube](https://www.youtube.com/playlist?list=PLwIpjsfqxSaz2ptYuBTRdk8xPbUDs7syN).\n\n\n(**NOTE**: The \"home\" buttons on the demo site do not work because a proper domain name has not been set up for it. Once you direct a domain name like \"eamycity.org\" to your site, you will not have this problem)\n\n\n## Table of Contents\n[Initial Setup](https://github.com/rtcharity/lean-site-template#initial-setup)\n\n[Customizing the Site](https://github.com/rtcharity/lean-site-template#customizing-the-site)\n\n[Deployment & Setting Up Your Domain Name](https://github.com/rtcharity/lean-site-template#deployment--setting-up-your-domain-name)\n\n[Setting Up the Contact Form](https://github.com/rtcharity/lean-site-template#setting-up-the-contact-form)\n\n[Multilanguage Support](https://github.com/rtcharity/lean-site-template#multilanguage-support)\n\n[Developing/Customizing the Site Generator](https://github.com/rtcharity/lean-site-template#developingcustomizing-the-site-generator)\n\n[Contributors](https://github.com/rtcharity/lean-site-template#contributors)\n\n\n## Initial Setup\n\n1. First, [create a free GitHub account](https://github.com/join).\n1. After you've signed back into GitHub with your account, go to the top of this page and hit the 'Fork' button at the top-right of the page. Forking will create a copy of this repository of code that you can work with in your GitHub account. Once the copy has been made, GitHub should automatically redirect you to your copy at https://www.github.com/YOUR-USERNAME/lean-site-template.\n![Fork a repo](https://user-images.githubusercontent.com/4016519/34449760-f1726ca8-ecb0-11e7-9529-3b194657dcb6.png)\n1. Once at your forked copy of the code on Github, click on \"Branch: master\". A field should appear; type in gh-pages and then click \"Create branch: gh-pages\".\n![Create a gh-pages branch](https://user-images.githubusercontent.com/4016519/34450049-6a239ac4-ecb5-11e7-9bf9-7d04c699d95b.png)\n1. Go to https://github.com/settings/tokens and hit \"Generate new token\". Fill in Token description with \"Travis deployment\" and check the \"Repo\" checkbox. Then scroll down and hit the green \"Generate token\" button.\n![Generate a new token](https://user-images.githubusercontent.com/4016519/34449783-316a7d78-ecb1-11e7-9b7b-ffd6ae437cbf.png)\n1. Copy the token in the green bar into your clipboard, or into a text file. You'll need it later!\n![Copy token](https://user-images.githubusercontent.com/4016519/34449804-7122c86c-ecb1-11e7-893a-85a08a01a2b6.png)\n1. Go to [travis-ci.org/](https://travis-ci.org/) and sign in with your GitHub account.\n1. Once Travis has \"synced\" all your repositories from GitHub, you should be able to see the \"lean-site-template\" on your Travis dashboard. Click on the \"X\" beside the repository name, and it should turn into a checkmark.\n![Dashboard](https://user-images.githubusercontent.com/4016519/34449787-4b4043a4-ecb1-11e7-99d9-1a47f3b18656.png)\n1. Click on the little gear next to the checkmark; this should take you to the settings page.\n1. Scroll down to \"Environment Variables\". Enter GITHUB_TOKEN into the Name field and paste the token you copied before into the Value field. Then hit \"Add\".\n![Env vars](https://user-images.githubusercontent.com/4016519/34449807-7aac73ba-ecb1-11e7-839f-8fe9ad52584c.png)\n1. Last step! Scroll back up to the top of the page and click on the \"More options\" button on the right, then hit \"Trigger build\" and \"Trigger custom build\" on the popup.\n![Env vars](https://user-images.githubusercontent.com/4016519/34449795-5e828c4c-ecb1-11e7-8949-af77c97cc5b4.png)\n\nAt this point, you should be able to see a live version of your site at https://YOUR-USERNAME.github.io/lean-site-template/.\n\n**NOTE**: Because we haven't correctly set the base URL yet, the photos may be broken and the layout won't display properly. The \"Home\" button may also be broken. If this is the case, no worries: we'll fix this quickly in the next section. The important thing here is to make sure that things were set up properly and that we have a way to see the site as we change it.\n\nMost of the text values are placeholder values for now. As we customize the values in the next section, you should be able to see the changes take place immediately.\n\n\n## Customizing the Site\n\nThe static site comes with default values (e.g. site title, your EA group name, page content, etc) that need to be changed for your group. These values are held in one of two places:\n\n1. The `config.toml` configuration file, which holds config such as your site name, your contact email, your Facebook/Twitter/Meetup URLs, what languages you support, what the navigation bar text is, and so on.\n1. The markdown (`.md`) files inside the `content` folder. These files hold all the written copy for your pages. For example, if you want to change the information on the \"Reading Materials\" page, you would go to `content/reading-materials.md` and change the writing in there.\n\nIn the next few sections we'll step through changing both the `config.toml` and `.md` files in order to customize your site.\n\n\n#### Editing default configuration values in `config.toml`\n\nGo to the repo that you forked on GitHub (the link should be `www.github.com/YOUR-USERNAME/lean-site-template`) and click on the `config.toml` file. This is the file that contains your site title, button names, navigation bar text, and so on. There are reasonable defaults for English, but there will be certain things you'll need to change such as the title, contactEmail, and so forth.\n\nTo change the file, hit the pencil icon near the top-right of the page.\n![Edit file](https://user-images.githubusercontent.com/4016519/34449766-fe7d9fd0-ecb0-11e7-998a-5f3016dc95fc.png)\n\nThe first thing you'll need to do is to enter the correct value for \"baseURL\", so that the live site will display properly. **Make sure you do this!** You should change the value \"https://YOUR-USERNAME.github.io/lean-site-template/\". Don't forget the trailing slash!\n![baseURL](https://user-images.githubusercontent.com/4016519/34449814-8a3070f2-ecb1-11e7-80b0-ff012e1b5b2d.png)\n\n\nOnce you've done that, you can change the rest of the placeholder values to whatever applies to your group. If you need an example to follow, see the [example config.toml file](https://github.com/rtcharity/lean-site-template/blob/master/example-config.toml) as a guide. If you need multilanguage support, be sure to read the [**Multilanguage Support** section](https://github.com/rtcharity/lean-site-template/blob/master/README.md#multilanguage-support) below.\n\n\nWhen you're done, commit your changes (the big green button at the bottom of the edit page). \u2018Commit\u2019 is the equivalent of \u2018apply\u2019 or \u2018save\u2019 in GitHub terms. As a reminder, you should be able to see your changes live at https://YOUR-USERNAME.github.io/lean-site-template/ within a couple minutes of each commit.\n\n\n#### Editing the written content\n\nAll the written copy for the site is held in the \"content\" folder. If you go back to the index of your forked repository, and click on it, you should see a bunch of files such as `_footer-left.md`, `contact.md`, `reading-material.md` and so forth. Feel free to explore and change the content as you please.\n\n\nMost of the files are pretty self-explanatory by their name or content. However, a few to note:\n- `_footer-left.md` - This holds the content that shows up on the left-side of the footer that appears on every page. By default it holds \"More on EA\" links.\n- `_footer-right.md` - This holds the content that shows up on the left-side of the footer that appears on every page. By default it holds \"Useful links\", but EA Dubai and EA NYU etc have used this section to instead link to pages more specific to their group. Perhaps you may want to as well.\n- `_index.md` - This file is not used at all at the time being so feel free to ignore it.\n- `contact.md` - This file needs to exist for in order for the contact page to be created, but the contents in it are not used at all. Feel free to ignore it.\n- `homepage` - This folder contains the text that gets created on the front page, under the homepage section headers (that you can define in `config.toml`). If you change a homepage section header (e.g. `firstSectionHeader`) in `config.toml`, you'll probably want to change the content in a homepage .md file as well.\n\n\nPlease note that the .md files used here use **Github-flavoured markdown** for formatting. Markdown is a simple code for making stylistic changes to the content of your webpage. If you're not familiar with it, this [awesome Markdown Cheatsheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) should help.\n\n\n#### Changing banner photos\n\nThe site uses default banner photos. You can find the photos used in the [`static/img`](https://github.com/rtcharity/lean-site-template/tree/master/static/img) folder of this repository.\n\nIf you want to replace a banner photo (for example, the banner photo under \"Who are we?\" is usually of your city), just make sure that the **name** of the photo stays the same, since the site generator depends on the name of the file in order to display the picture.\n\nYou can do the following to replace a banner photo:\n1. Go to the `static/img` folder.\n1. Click on the photo file you want to replace, and click on the trash can button on the top-right to delete it.\n1. Once its been deleted, go back to the `static/img` folder and click \"Upload files\"\n1. Choose the photo you want to use as the new banner. **Make sure you name it the same thing as the file you deleted**.\n\nPlease remember that large image files can slow down your website and potentially cause other problems. We recommend using image files no larger than 5mb. If you have an image that is too large, you can easily and freely resize it using websites such as https://imgur.com/ or https://pixlr.com/express/. If you are a Mac user, the \u2018Preview\u2019 application in OSX will also allow you to resize your images.\n\nPlease also remember to **pay attention to copyright permissions for images that you choose**. An easy way to find free images is to search for images with creative commons licenses on https://commons.wikimedia.org/wiki/Main_Page or to use content from https://unsplash.com/.\n\n\n## Deployment & Setting Up Your Domain Name\n\nDeployment is the step where your content goes live and your site becomes accessible to the public on the Internet.\n\n1. If you correctly set up your forked repo on Travis, any commit (change) to a file will trigger a 'build' on Travis \u2013 that is, Travis will turn your config and the site template into nice HTML file (set of instructions to a browser to display your content how you want it) to be served up.\n1. It's time to hook up a domain to the site! Contact the tech team at tech [at] rtcharity.org and provide a) The domain name you want to use, if you have one in mind, and b) the link to your GitHub repository.\n1. Once the domain is set up (this may take a few days), go to the file called `CNAME` and add your domain in one single line without any slashes or https (e.g. mydomain.com). Example: https://github.com/Martin-Riekert/lean-site-template/blob/master/CNAME\n1. Now go to `config.toml` and change the baseURL value to whatever your new domain is, *with* a trailing slash and the https (e.g. https://mydomain.com/). It is important to use https instead of http. Once you save this change and Travis has finished building your site, you should be able to access your site through the new domain name.\n1. If you run into any trouble during this process, *first* go to 'Settings' > 'Collaborators & teams' and add 'mondayrain' as well as 'guisers' as collaborators with 'Write' privileges. Then email tech [at] rtcharity.org with a description of your issues.\n\n**Note**: at this point, all the links on your site should work (the Home button was, for example, broken because we had a weird GitHub `baseURL`). Multilanguage support should also work once the domain name is set up. If not, feel free to reach out to us.\n\n\n## Setting Up the Contact Form\n\nThe site uses [Formspree](https://formspree.io/) in order to forward Contact messages from the site to the contactEmail you define in `config.toml`. However, before they'll forward messages for you, you will need to confirm your email.\n\nYou don't actually need to do anything ahead of time; the first time somebody sends a message through your contact form, Formspree will send an email to you asking you to confirm your email.\n![Confirm email](https://user-images.githubusercontent.com/4016519/34537832-c20e41cc-f07e-11e7-97ca-96c5bb864080.png)\n\n\nOnce you've confirmed your email, Formspree will forward all messages entered into the contact form to your email.\n![Forwarded message](https://user-images.githubusercontent.com/4016519/34537841-c7cf9386-f07e-11e7-9fcf-f23a8dcb833b.png)\n\n\nRemember that if you would like an official EA email address for privacy reasons, LEAN can set this up for you if we have not already. Email Richenda at richenda [at] rtcharity.org\n\n\n**Note**: If you don't want to wait for somebody to send you a message in order to set up your contact form, you can submit a test message into the contact form yourself.\n\n\n## Multilanguage Support\n\n**This will only work if you have already set up your domain name!**\n\nYour site can support as many languages as you want. For each language you want to support, 2 things will need to be done:\n\n1. **You'll need to add the appropriate sections to `config.toml`.** Basically what you'll need to do is duplicate everything from `[Languages.en]` onwards, but change the language code from `en` to whatever language you want to use. All you'll have to do then is fill in the parameter values as needed for that given language. See [example-config.toml](https://github.com/rtcharity/lean-site-template/blob/master/example-config.toml) for an example `config.toml` that supports both English and German, with `de` being the German language code.\n1. **You'll have to create <language-code>.md versions of every file inside the `content` and `content/homepage` folders** and populate them with translated copy as needed. This is the text that will be shown on the site for that language. For example, if I want to add German language support (and gave German the `de` code in `config.toml`), then I would have to create `_footer-left.de.md`, `faq.de.md`, `homepage/_first_section_text.de.md` and so on. You can create a file by going into the `content` folder then clicking \"Create new file\" at the top-right. **Make sure you get the name of the .md files right!** Aside from the extra language code, they must be the same as the English version! If the site can't find the correct translation file based on the filename, it will just fall back on the English copy.\n\n\nThe URLS for translated content will always be www.your-domain.com/language-code/url. So, the German version of www.your-domain.com/about will be found at www.your-domain.com/de/about.\n\n\nTo see an example site structure with multilingual support, see [this Hugo multilingual example](https://github.com/rayjolt/hugo-multilingual-example) or the official [Hugo documentation on Multilingual Mode](https://gohugo.io/content-management/multilingual/).\n\n\n## Developing/Customizing the Site Generator\n\nIf this site generator is too inflexible for you and you would like to develop the site generator further, here are a few pointers to get you started.\n\n**Please note that we do not have the resources to teach individual folks how to develop the site generator. If the resources/notes below are not enough, please consider simply using the site as it comes.**\n\n1. The site generator is built on [Hugo](https://gohugo.io/), an open-source static site generator written in Go. They have great [written documentation](https://gohugo.io/documentation/), as well as a [Youtube playlist of tutorial screencasts](https://www.youtube.com/watch?v=qtIqKaDlqXo&list=PLLAZ4kZ9dFpOnyRlyS-liKL5ReHDcj4G3) to get you started.\n1. The site is split into 2 parts: [the custom LEAN Hugo theme](https://github.com/rtcharity/local-ea-template), and the [actual site generator/template](https://github.com/rtcharity/lean-site-template) (this repo) which uses the theme. The template references the theme as a [git submodule](https://git-scm.com/docs/git-submodule). When you clone the `lean-site-template` generator, you'll need to run `git submodule update --init --recursive` in order to initialize the theme submodule.\n1. This repository contains all the config, written content, and static images; the theme repo contains all of the HTML and CSS for the site.\n1. The site generator is tied to a specific *commit* of the theme. Therefore, if you ever push an update the theme, you will need to also update this repo to point to the new theme commit. Otherwise, the site generator will keep using the older version of the theme. `git submodule update --init --recursive` should always pull the latest version of the theme, so all you need to do is run that and then commit the changes to git.\n\n\n## Contributors\n\nThe 1.0 version of this site generator was built by [@henryaj](https://github.com/henryaj) & [@mondayrain](https://github.com/mondayrain).\n\nAdditional thanks to those in the LEAN network for proofreading and editing!\n"}
{"url": "https://github.com/ekaterinailin/MalachiteMountains", "owner": "ekaterinailin", "repository_name": "MalachiteMountains", "date_all_variable_collection": "2023-09-11", "description": null, "size": 246179, "stargazers_count": 2, "watchers_count": 2, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "ekaterinailin", "contributions": 153}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 90693}], "readme": "![Malachite Mountains](mm_hl.png)\n\n_logo design: Elizaveta Ilin (2021)_\n\n# MalachiteMountains\n\nThe name of this repository refers to Russian folklore, a fairy tale about the [Malachite Casket](https://en.wikipedia.org/wiki/The_Malachite_Casket_(fairy_tale)).\n\n## Relevant contents of this repository\n\n\n### master branch\n\nBare bones package only, updated to be more modular, using classes.\n\n### ilin2021 branch\n\nThis branch contains the necessary data, model code and scripts to reproduce the results, figures, and tables that appear in [Ilin et al. (2021)](https://ui.adsabs.harvard.edu/abs/2021MNRAS.507.1723I/abstract)\n\n- data/\n  - inclinations/\n    - *post_compound.p\n    - *post.dat\n    - inclination_output.dat\n  - solar/\n    - sars.csv (solar superactive regions)\n  - summary/\n    - inclination_input.csv (rotation period, vsini, stellar radius)\n    - inits\\_decoupled\\_GP.csv (inits for MCMC model fit)\n    - lcs.csv (other stellar and light curve properties)\n  - lcs/\n    - *.csv (light curves including quiescent model flux array)\n\n- analysis/\n  - notebooks/\n    - funcs/\n        - `model.py` - FlareModulator class\n    - *.ipynb\n        - the majority of scripts used in this work as notebooks\n    - *.py\n        - some pure python scripts\n    \n\n"}
{"url": "https://github.com/ekaterinailin/multiperiod-flares-draft", "owner": "ekaterinailin", "repository_name": "multiperiod-flares-draft", "date_all_variable_collection": "2023-09-11", "description": "Paper draft for Malachite Mountains", "size": 13810, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ekaterinailin", "contributions": 43}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 316448}]}
{"url": "https://github.com/ekaterinailin/my-first-blog", "owner": "ekaterinailin", "repository_name": "my-first-blog", "date_all_variable_collection": "2023-09-11", "description": "Personal blog: Astrophysics, Effective Altruism.", "size": 9, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ekaterinailin", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 8882}, {"language": "HTML", "num_chars": 2080}, {"language": "CSS", "num_chars": 792}]}
{"url": "https://github.com/ekaterinailin/Orbital_Flare_Declustering", "owner": "ekaterinailin", "repository_name": "Orbital_Flare_Declustering", "date_all_variable_collection": "2023-09-11", "description": "Orbital phase flare de-clustering in close-in star-planet systems", "size": 1306, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "ekaterinailin", "contributions": 21}, {"contributor": "jeMATHfischer", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 486117}, {"language": "TeX", "num_chars": 69315}, {"language": "Python", "num_chars": 29226}], "readme": "# Flaring star-planet interactions\n## Orbital phase flare de-clustering in close-in star-planet systems\n\n## Abstract\n\ntba\n\n## Introduction\n\n### Flaring star-planet interactions\n\nStars with masses below about 1.4 $M_\\text{Sun}$ possess an outer convection zone. In this zone convective motion and differential rotation of the plasma drives a dynamo that generates magnetic flux. This flux emerges on the surface of the star ([Schatzman 1962](http://articles.adsabs.harvard.edu/full/1962AnAp...25...18S). When these magnetic field lines reconnect in the stellar outer atmosphere, energy is released in an explosion that we call a flare. Reconnection on the surface occurs when an instability is triggered by the stochastic motion of magnetic field lines at the photosphere([Svestka 1976](https://ui.adsabs.harvard.edu/abs/1976sofl.book.....S/abstract), [Priest and Forbes 2002](https://ui.adsabs.harvard.edu/abs/2002A%26ARv..10..313P/abstract)).\n\nBut flares can also be caused by a planet that orbits within the Alfv\u00e9n zone of a star. In that case, the planet triggers the instability by disturbing the magnetic field through which it travels on its orbit ([Lanza 2018](https://ui.adsabs.harvard.edu/abs/2018A%26A...610A..81L/abstract)). \n\nWhile the phenomenon is expected to show the same morphology, the origin for these two types of flares are different. We can call the former instrinsic flares, and the latter star-planet interaction flares, or SPI flares. Intrinsic flares are well-studied. Their occurence times are best described as a Poisson process, and their energy distribution follows a power law over several orders of magnitude. These characteristics are not known for SPI flares apart from estimates of maximum flare energy ([Lanza 2018](https://ui.adsabs.harvard.edu/abs/2018A%26A...610A..81L/abstract)). \n\nIn any given light curve of a star with a known planet in close orbit an observed flare could have been caused by either process. How can we tell them apart? One clue is the planet's orbital motion. A statistical clustering of flares around a certain orbital phase is indicative of SPI flares as we expect flares to be induced at the magnetic subplanetary point. Its location is the region where the stellar magnetic flux connects to the planet. On the planet's course around the host star the point moves in and out of the line of sight.\n\nOur goal is to find SPI flares in stacked and scaled light curves of transiting close-in Hot Jupiters around low-mass stars, or else provide upper limits on its effect size. In the following section we describe the data, Kepler light curves with confirmed transits and observed flares. Next, we detail the method by which we intend to distinguish SPI flares from instrinsic flares using a technique widely applied in earthquake research - thinning. We then apply the method to a synthetic but realistic example light curve stack to demonstrate the technique. Finally, we apply the technique to a stack with and without transiting planets.  \n\n## Data\n\n- Synthetic data with realistic values\n- Kepler light curves with transiting Hot Jupiters in close orbits around flaring stars\n- A control sample of Kepler light curves with transiting Hot Jupiters\n\n### Assumptions about the data\n\n1. The intrinsic flare production process is a Poisson process with a characteristic time scale that depends on the individual flaring activity of the star (source!)\n2. Assuming 1. we can also assume periodic boundary conditions that allows us to search for clusters of flares during secondary eclipse.\n3. The characteristic time scale for each light curve does not change in the period of observation.\n4. The overdensity of flares occurs at similar orbital phases for all star-planet systems.\n\n## Methods\n\n### Scaling and stacking\n\nLight curves with transits have different orbital periods, and typically multiple transits occur in a single light curve for a confirmed exoplanet. We phase-fold all available light curves and stack them. The resulting time dependence of flare occurrences remains a Poisson process with a different characteristic time scale $\\lambda$ from the individual light curves.\n\n### Thinning\n\nThinning is a probabilistic tool to recover a sample of some underlying point process from a set of measurements. Classically, Thinning is used in the context of earthquake research ([van Stiphout, T., J. Zhuang, and D. Marsan 2012](http://www.corssa.org/export/sites/corssa/.galleries/articles-pdf/vanStiphout_et_al.pdf)). Data in this field consists of catalogues containing all earthquake events within a timeframe. Since not all earthquakes are triggered due to a region's seismicity but most are aftershocks, which cluster around the mainshocks, finding the mainshocks is statisically demanding. To estimate the background intensity of the mainshocks the data has to be declustered, removing the the aftershocks in the process ([Zhuang, Ogata, Vere-Jones 2002] (https://doi.org/10.1198/016214502760046925)). One way of declustering is stochastic declustering or Thinning ([van Stiphout, T., J. Zhuang, and D. Marsan 2012](http://www.corssa.org/export/sites/corssa/.galleries/articles-pdf/vanStiphout_et_al.pdf)). using this method, the sample recovered by Thinning consists of the most probable mainshocks given that they are distributed according to a homogenous Poisson process.\nIn particular, under the assumption that the underlying point process is Poisson, theory exists for Thinning to be applicable in a consistent way ([Vere-Jones 1970] (https://www.jstor.org/stable/2984402)). \n\nWe extend the methodoly to flare occurences in star-planet interactions by identifying mainshocks with intrinsic flares and aftershocks with SPI flares. In contrast to earthquakes, there is no causal structure between intrinsic flares and SPI flares. Nonetheless, the mathematical framework allows for an application lacking the causal structure. We use a variation of the ETAS model ([Ogata 1999] (https://link.springer.com/chapter/10.1007/978-3-0348-8677-2_14)) proposing a combination of a homogenous Poisson process for the intrinsic flares combined with an inhomogeonous Poisson process for the SPI flares. The full model is, hence, an inhomogenous Poisson process with intensity $\\lambda(\\phi) = \\mu + \\psi(\\phi)$ where $\\mu > 0$ is the intrinsic flare rate and $\\psi$ a periodic function capturing the SPI flare rate. Thinning is than applied to the data based on this process.\n\n\n### Poisson process fitting\n\nWe fit an inhomogenous Poisson process to the data by using maximum likelihood estimation for the intensity $\\lambda$ (see e.g. ([Vere-Jones 1970] (https://www.jstor.org/stable/2984402)) ). The estimated value $\\hat{\\mu}$ for $\\mu$ is then an estimator for the intrinsic flare rate. To make this work, we assume a parametric form of $\\psi$ being linked to the distance between planet and star. \n\n\n_relevant when dealing with real data_\n\n\n## Analysis of results\n\nSome notes:\n\n- Circular orbits:\n        - If the planet moves inside the Alfven zone, and if we assume that the field structure is mostly dipolar, we expect the magnetic subplanetary point (MSP) to reside at higher latitudes with increasing planetary distance. \n        - The MSP longitudes will lag behind or precede the longitude of the planet \n\n- Eccentric orbits:\n        - \n\n# To-Dos:\n\n- [] Implement thinning algorithm (J)\n- [] Review thinning algorithm (J+K)\n- [x] Write description of the problem (K)\n- [] Generate synthetic but realistic data sets to determine upper limits (K)\n- [] Implement cluster detection in sets of thinned events (K)\n- [] Describe mathematical foundations for Poisson process stacking and thinning \n\n\n\n\n\n"}
{"url": "https://github.com/ekaterinailin/plots-of-the-week", "owner": "ekaterinailin", "repository_name": "plots-of-the-week", "date_all_variable_collection": "2023-09-11", "description": "Weekly science plots.", "size": 67743, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ekaterinailin", "contributions": 36}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 107942}]}
{"url": "https://github.com/ekaterinailin/SiberianPine", "owner": "ekaterinailin", "repository_name": "SiberianPine", "date_all_variable_collection": "2023-09-11", "description": "Analyse statistical samples of stellar flares.", "size": 923, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 2, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ekaterinailin", "contributions": 16}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 296506}, {"language": "Python", "num_chars": 35124}], "readme": "# siberianpine\nAnalyse statistical samples of stellar flares.\n"}
{"url": "https://github.com/ekaterinailin/TESS-UCD-Paper-1", "owner": "ekaterinailin", "repository_name": "TESS-UCD-Paper-1", "date_all_variable_collection": "2023-09-11", "description": null, "size": 4810, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ekaterinailin", "contributions": 15}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 315235}]}
{"url": "https://github.com/ekaterinailin/TESS_UCD_flares", "owner": "ekaterinailin", "repository_name": "TESS_UCD_flares", "date_all_variable_collection": "2023-09-11", "description": "Find and analyse flares in TESS UCD light curves", "size": 130434, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "ekaterinailin", "contributions": 71}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 1960742}, {"language": "Python", "num_chars": 77761}, {"language": "Shell", "num_chars": 275}], "readme": "# Flares on ultracool dwarfs with TESS - Find and analyse flares in TESS UCD light curves\n\nSchmidt et al. (2020) (in prep.) studied flare in ultracool dwarfs in TESS Cycle 1 light curves. Here we present the de-trending prescription,\nthe flare finding, and the procedure of injection-recovery of synthetic flares, which are all based on the [lightkurve](https://docs.lightkurve.org/api/index.html) based package for flare studies in Kepler, K2, and TESS - [AltaiPony](https://altaipony.readthedocs.io/en/latest/).\n\n## Contents\n\n- `custom_apertures/`: custom aperture light curve fits files\n- `flare_tables/`: final results \n- `notebook/`\n  - `sample_injrec.py`: Use this script to sample injection and recovery of flares in a set of light curves\n  - `analyse_injrec.py`: Use this script to combine stored injection recovery tables with light curves to characterize them and store final  results in `flare_tables/`\n  - `NB1_Find_flares_in_custom_aperture_light_curves.ipynb`: A notebook to simply show how to de-trend and find flares using a custom detrending procedure, adn then characterize the candidates with injection-recovery of synthetic flares.\n  - `NB4_Vet_flares.ipynb`: A notebook that allows you to look at the light curve and its flares at different stages of the analysis process. **NEEDS CLEANING** \n  - `NB3_....ipynb`: A notebook in which you can use your injection-recovery sample to characterize flares that you found. **NEEDS CLEANING**\n  - `funcs/`\n    - `helper.py` reading files, masking light curves, etc.\n    - `custom_detrending.py` custom_detrending function lives here with all the functions that it calls\n    - `tests/` tests to run with `pytest funcs/`\n    \n\n## Installation requirements\n\n### AltaiPony\n\nFollow the installation instructions for AltaiPony [here](https://altaipony.readthedocs.io/en/latest/install.html#installation).\n\n### Other requirements\n\n- numpy\n- pandas\n- scipy\n- astropy\n\n## Custom de-trending\n\nTESS ultracool dwarf light curves exhibit various trends, both astrophysical and systematic that we need to remove before searching the residual time series for flares. The main trends are\n\n- movement of the spacecraft resulting in both linear and non-linear trends,\n- stellar rotational modulation caused by spots that is sometimes strictly periodic and sinusoidal.\n\nThe latter can be an extremely fast modulation of the order of a few hours. \n\nTo account for these effects we adopted the following procedure:\n\n1. If the difference in flux from the beginning to the end of the light curve is >20% we fitted a 3rd order spline to the binned light curve to remove strong global trends that take effect on time scales of multiple days. \n2. When no strong global trends are present, strong rotational modulation can be removed iteratively using sine fits with periods obtained from Lomb-Scargle periodograms until not strong periods are left in the light curve.\n3. Next, we remove remaining trends with using a rolling median on time scales of 10 h.\n4. To remove trends on shorter time scales, we mask and pad outliers, and apply a Savitzky-Golay filter with window sizes that are three times shorter that the dominant residual frequency. The minimum window size is 2.5 h and is determined using a FFT of the residual light curve.\n5. In a final step we filter the light curve with the minimum window size  and estimate the scatter in the light curve using a rolling standard deviation (window size= 30 min) with masked and padded positive outliers, i.e. flare candidates. The masked and padded values are assigned the mean uncertainty from the rest of the light curve.\n\n## Flare finding\n\nAfter de-trending we find flare candidates as >3 data points and >3 sigma outliers in the residual light curve using the `find_flares()` method, see [AltaiPony docs](https://altaipony.readthedocs.io/en/latest/api/altai.html)\n\n## Injection-recovery\n\nWhen an iterative and complex but deterministic procedure is used to de-trend a light curve there is no analytic way to determine\n\n- the recovery probability or\n- the true energy \n\nof a flare. Every light curve is different, and recovery probability and measured energy largely depend on its amplitude and duration convolved with time sampling, and de-trending effects. Injecting and recovering synthetic flares spanning the parameter space of amplitude and duration into the not yet de-trended light curve resolves both problems at once. The light curve with synthetic flares injected can undergo the same de-trending procedure as the one without. Recovering the injected flares results in a measure for recovery probability as a function of amplitude and duration, and the difference between the injected and recovered flare energies can be used as a correction factor for the flares found in the original light curve. \n\nInjection-recovery involves the following seven steps:\n\n1. Randomly generate flare amplitude, duration and peak time for a synthetic flare. Mask the flare candidates from the original light curve to avoid overlap.\n2. Add the synthetic flare to the original light curve.\n3. De-trend that light curve using the same procedure that was used to detect the original flare candidates.\n4. Determine the properties for the recovered flare and save them together with the injected ones.\n5. Repeat 1.-4. such that the parameter space covers the properties of the original flares.\n6. Apply the correction factor to amplitude and duration of the original flare to find its intrinsic properties.\n7. Find the recovery probability of flares with these intrinsic properties.\n\nInjection recovery must be performed on every light curve individually, and computational cost scales with the complexity of the de-trending prescription. The procedure assumes that the flares follow a certain flare shape, here as it is described in [Davenport et al. (2014)](https://ui.adsabs.harvard.edu/link_gateway/2014ApJ...797..122D/doi:10.1088/0004-637X/797/2/122). Recovery probabilities and energy ratios for complex shaped flares will be less accurate the more they deviate from the model.\n\n\n"}
{"url": "https://github.com/ekaterinailin/tic277", "owner": "ekaterinailin", "repository_name": "tic277", "date_all_variable_collection": "2023-09-11", "description": null, "size": 3355, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "ekaterinailin", "contributions": 23}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 45076}]}
{"url": "https://github.com/ekaterinailin/xmm-flareloci-proceedings-2021", "owner": "ekaterinailin", "repository_name": "xmm-flareloci-proceedings-2021", "date_all_variable_collection": "2023-09-11", "description": null, "size": 3675, "stargazers_count": 1, "watchers_count": 1, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "ekaterinailin", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 416106}, {"language": "Jupyter Notebook", "num_chars": 2226}]}
{"url": "https://github.com/ekaterinailin/xmm_for_tic277", "owner": "ekaterinailin", "repository_name": "xmm_for_tic277", "date_all_variable_collection": "2023-09-11", "description": "XMM-Newton follow-up of TIC 277, an M7 dwarf with a near-polar giant flare", "size": 147, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "ekaterinailin", "contributions": 26}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 271375}, {"language": "Python", "num_chars": 34323}], "readme": "<p align=\"center\">\n<a href=\"https://github.com/showyourwork/showyourwork\">\n<img width = \"450\" src=\"https://raw.githubusercontent.com/showyourwork/.github/main/images/showyourwork.png\" alt=\"showyourwork\"/>\n</a>\n<br>\n<br>\n<a href=\"https://github.com/ekaterinailin/xmm_for_tic277/actions/workflows/build.yml\">\n<img src=\"https://github.com/ekaterinailin/xmm_for_tic277/actions/workflows/build.yml/badge.svg?branch=main\" alt=\"Article status\"/>\n</a>\n<a href=\"https://github.com/ekaterinailin/xmm_for_tic277/raw/main-pdf/arxiv.tar.gz\">\n<img src=\"https://img.shields.io/badge/article-tarball-blue.svg?style=flat\" alt=\"Article tarball\"/>\n</a>\n<a href=\"https://github.com/ekaterinailin/xmm_for_tic277/raw/main-pdf/ms.pdf\">\n<img src=\"https://img.shields.io/badge/article-pdf-blue.svg?style=flat\" alt=\"Read the article\"/>\n</a>\n</p>\n\nAn open source scientific article created using the [showyourwork](https://github.com/showyourwork/showyourwork) workflow.\n"}
{"url": "https://github.com/everornever/Personal-Website", "owner": "everornever", "repository_name": "Personal-Website", "date_all_variable_collection": "2023-09-11", "description": "My first personal wbesite", "size": 2811, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 3, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 3, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "everornever", "contributions": 53}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["css", "html", "website-design"], "languages": [{"language": "HTML", "num_chars": 10208}, {"language": "CSS", "num_chars": 8675}], "readme": "# Personal-Website\nMy personal website wrote with HTML, CSS and JavaScript\n\nThis website was built with a simple CSS grid and consists of 3 sections. The font is from Google Font and icons were obtained from Iconscout as unicons.\n\n## Screens Mobile\n<div>\n<img src=\"Assets/Image/Screen1.png\" alt=\"drawing\" width=\"300\"/>\n<img src=\"Assets/Image/Screen2.png\" alt=\"drawing\" width=\"300\"/>\n</div>\n"}
{"url": "https://github.com/everornever/Project-Air", "owner": "everornever", "repository_name": "Project-Air", "date_all_variable_collection": "2023-09-11", "description": "This project involves a compact cube made of various components to measure and display indoor air quality.", "size": 11265, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": false, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "everornever", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 9383}], "readme": "# Projekt Air\n\nThis project involves a compact cube made of various components to measure and display indoor air quality.\n\n## Hardware\nThe following parts are needed for the construction of the project:\n\n|Bauteile        |Kosten| Beschreibung |                      \n|----------------|----------------|----------------|\n|[Seed Studio Lotus](https://www.seeedstudio.com/Seeeduino-Lotus-ATMega328-Board-with-Grove-Interface-p-1942.html)|20,00\u20ac|- The Lotus is needed for programming and has several Grove Connecter built in |\n|Plexigla\u00df| 0,00\u20ac|- Plexiglass can be used arbitrarily to build the housing|\n|[M3 Messing Gewinde Bolzen](https://www.amazon.de/gp/product/B0825XY6VD/ref=ppx_yo_dt_b_asin_title_o01_s00?ie=UTF8&psc=1)| 11,09\u20ac|- Is needed to connect the plexiglass discs|\n|[Grove Air Quality Sensor](https://www.seeedstudio.com/Grove-Air-Quality-Sensor-v1-3-Arduino-Compatible.html) |12,99\u20ac|- The Grove Air Quality Sensor can detect carbon monoxide, alcohol, acetone, paint thinner, formaldehyde and other mildly toxic gases|\n|[Grove Dust Sensor](https://www.seeedstudio.com/Grove-Dust-Sensor-PPD42NS.html) |12,99\u20ac|- The Grove Dust Sensor, which can detect not only cigarette smoke but also house dust\n|[Grove Temp. & Humi Sensor](https://www.seeedstudio.com/Grove-Temperature-Humidity-Sensor-DHT11.html) | 6,50\u20ac|- Measures the temperature and humidity|\n|[Grove OLED Display](https://www.seeedstudio.com/Grove-OLED-Display-0-96-SSD1315-p-4294.html) | 5,50\u20ac|- Displays all measured values|\n|**Summ** |**69,07\u20ac** |\n\n# Construction plan sketch\n\nThis construction plan was not implemented exactly as it is, since components have changed and experimentation was still going on with the from of the housing.\n\n<img src=\"Assets/Notiz_07.01.2022.jpg\" width=\"800\" height=\"1000\">\n\n# Step 1. Function test\n\nAll components are tested for functionality and each sensor is tested individually.\n\n<img src=\"Assets/IMG_5740.JPG\" width=\"600\" height=\"800\">\n\n# Step 2. Code customization\n\nAll components must now be controlled together in a project and connected with logic. More about this in the [Code](/Code) folder\n\n# Step 3. Build housing\n\nIf everything works so far, the housing must be built. For this purpose Plexi glass plates are cut and holes must be left for the cables.\n\n## Prototyp 1.0:\n\n<img src=\"Assets/IMG_5754.JPG\" width=\"500\" height=\"600\">\n<img src=\"Assets/IMG_5755.JPG\" width=\"500\" height=\"600\">\n<img src=\"Assets/IMG_5756.JPG\" width=\"500\" height=\"600\">\n<img src=\"Assets/IMG_5757.JPG\" width=\"500\" height=\"600\">\n\n"}
{"url": "https://github.com/everornever/React-Website", "owner": "everornever", "repository_name": "React-Website", "date_all_variable_collection": "2023-09-11", "description": "This is a personal portfolio Website I created with react. It is not my main website and was only a small project I did for university. ", "size": 10299, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": false, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "everornever", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["firebase", "react", "react-router"], "languages": [{"language": "JavaScript", "num_chars": 30007}, {"language": "CSS", "num_chars": 22902}, {"language": "HTML", "num_chars": 2047}], "readme": "# React Test Website\nIt is not my main website and was only a small project I did for university.\nIt was build using Firebase as a database for the user login, React as a base for the website and every components where wirtten in CSS vanilla.\n\n\n## Packages:\n\n**NPM Packages:**\n- react\n- react-router-dom\n- firebase --save\n\n# Login\nThe login page is the entry point for the website.\nIn the backend the user is checked via a Firebase Auth.\nI created a dummy account to log in.\nThe page is fully responsive and has a small login animation.\n\n**Login-Daten:**\n\n**Email:** test@mail.com\n\n**Passwort:** passwort\n\n![Alt](/Assets/Login.png?raw=true \"Optional Title\")\n\n# Website\nThe website was built entirely with React and React Route DOM and designed with vanilla CSS.\nThere are several sections like #About or #Skills.\nThe site is responsive in 3 levels (Large, Med, small). The navigation bar also adapts and moves down in mobile.\nA darkmode can be used and adjusts all colors. (Unfortunately buggy, therefore deactivated)\n\n![Alt](/Assets/HomeLight.png?raw=true \"Optional Title\")\n![Alt](/Assets/Home2Light.png?raw=true \"Optional Title\")\n![Alt](/Assets/Home3Light.png?raw=true \"Optional Title\")\n![Alt](/Assets/HomeDark.png?raw=true \"Optional Title\")\n![Alt](/Assets/Home2Dark.png?raw=true \"Optional Title\")\n\n\n"}
{"url": "https://github.com/everornever/SimpleFit-Website", "owner": "everornever", "repository_name": "SimpleFit-Website", "date_all_variable_collection": "2023-09-11", "description": "A simple website for my iOS Fitness App", "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "DEV", "contributors": [{"contributor": "everornever", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# SimpleFit-Website\nA simple website for my iOS Fitness App\n"}
{"url": "https://github.com/everornever/WRIP", "owner": "everornever", "repository_name": "WRIP", "date_all_variable_collection": "2023-09-11", "description": "WRIP is short for Weather Road Trip and is a React based Website with a Google Maps API that shows you specific places on a Map with the corresponding weather Information", "size": 5719, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": false, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "everornever", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["google-maps-api", "react", "webdesign"], "languages": [{"language": "JavaScript", "num_chars": 28642}, {"language": "CSS", "num_chars": 10228}, {"language": "HTML", "num_chars": 2496}], "readme": "# WRIP\nWRIP is short for Weather Road Trip and is a React based Website with a Google Maps API that shows you specific places on a Map with the corresponding weather Information. This project was created as part of a University course and is not in a bug free state.\nThere is a live version wich might shut down one day. The Link is under the About section. There are also some documents wich where created in the planing phase of the project and where part of the grading.\n\n![Image](Dokumentation/screen.png)\n\n\n![Image](Dokumentation/screen2.png)\n\n\n"}
{"url": "https://github.com/ezair/Autograding-System", "owner": "ezair", "repository_name": "Autograding-System", "date_all_variable_collection": "2023-09-11", "description": "Web application (using django, docker, bootstrap, gradle, etc...) that compares student submitted assignments to test cases and produces the success rate.", "size": 714, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 159}, {"contributor": "cstannard007", "contributions": 79}, {"contributor": "demaraj198", "contributions": 10}, {"contributor": "mastoffate", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["docker", "python3"], "languages": [{"language": "Python", "num_chars": 72275}, {"language": "HTML", "num_chars": 42391}, {"language": "Java", "num_chars": 14020}, {"language": "CSS", "num_chars": 5783}, {"language": "JavaScript", "num_chars": 5252}, {"language": "Dockerfile", "num_chars": 496}], "readme": "Some notes on running our docker:\n\t\n\tYou can run our project by using the run.py script (located in the autograder/ folder next to manage.py).\n\n\tNOTE:\n\t\tIf using run.py, you may have to get rid of the sudo commands (if you are on windows or any machine that you do not have sudo access to).\n\n\t\tIf you do have sudo access, then this will not be a problem.\n\n\t\tThe script has instructions as to how it works.\n\n\n\n\nImportant note on running project:\n\tAll commands stated may need to be run with sudo, varying on your computer and operating system.\n\n\tBefore doing anything, you want to run \"docker-compose build\" so that you can make any needed install changes that are required.\n\n\tNext, run \"docker-compose run web python3 manage.py migrate\" (this will perform the migrations needed to populate the database)\n\n\tThen you can simply type \"docker-compose up\" to begin running the project's web server.\n\n\tTo sign into admin page, Username: \"admin\", Password: \"password\"\n\n\tTo sign into as a basic, Username: \"user\", Password: \"userpassword\"\n\n\tVarying on your computer, you may have to put sudo in front of the command.\n\n\nRecommended way to run project:\n\tIn the main directory of the project \"autograder/\", run the following:\n\t\t\"python3 run.py all\"\t(leave the quotes out...)\n\n\tThis will launch a script and deal with all the steps of building and loading tables.\n\n\tTHIS WILL ONLY WORK ON MAC AND LINUX COMPUTERS\n"}
{"url": "https://github.com/ezair/Average-Statistics-GUI", "owner": "ezair", "repository_name": "Average-Statistics-GUI", "date_all_variable_collection": "2023-09-11", "description": "Contains Average.exe, a program that calculate mean, median, and mode using C# and microsoft .net framework to make a gui", "size": 413, "stargazers_count": 0, "watchers_count": 0, "language": "C#", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C#", "num_chars": 7451}, {"language": "sed", "num_chars": 2956}], "readme": "Program location: \\bin\\debug\\average.exe\r\n\r\nSetup installer location: \\bin\\debug\\setupAverage.exe\r\n\r\nGUI made using microsoft's C# and .net framework\r\n\r\nPlatforms:\r\n  Windows 7, 10\r\n"}
{"url": "https://github.com/ezair/Bank-Account-Mongo-Fun", "owner": "ezair", "repository_name": "Bank-Account-Mongo-Fun", "date_all_variable_collection": "2023-09-11", "description": "Just having fun testing out the mongodb C++ api. Using bank account records as an example.", "size": 7, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": ""}
{"url": "https://github.com/ezair/Beat-Saber-Song-Scrapper", "owner": "ezair", "repository_name": "Beat-Saber-Song-Scrapper", "date_all_variable_collection": "2023-09-11", "description": "A quick way to download beatsaber custom songs.", "size": 43, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 25}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 22691}], "readme": "# TBA\n"}
{"url": "https://github.com/ezair/Chocolate-Rating-Prediction", "owner": "ezair", "repository_name": "Chocolate-Rating-Prediction", "date_all_variable_collection": "2023-09-11", "description": "Predicting the rating 1.0 - 5.0 of a given chocolate bar, based off of X features.", "size": 71, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 152056}]}
{"url": "https://github.com/ezair/CNN-Number-Classification", "owner": "ezair", "repository_name": "CNN-Number-Classification", "date_all_variable_collection": "2023-09-11", "description": "0 - 9 number classification on the MNIST dataset using a custom trained CNN", "size": 3, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 5177}]}
{"url": "https://github.com/ezair/Covid-19-Data-Analysis", "owner": "ezair", "repository_name": "Covid-19-Data-Analysis", "date_all_variable_collection": "2023-09-11", "description": "Data Analysis done on a dataset containing columns about covid-19 cases over the course of time.", "size": 1694, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 286940}]}
{"url": "https://github.com/ezair/Crytrography-Ciphers", "owner": "ezair", "repository_name": "Crytrography-Ciphers", "date_all_variable_collection": "2023-09-11", "description": "This repository contains a bunch of different class files for different cryptographic ciphers.", "size": 29, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 31}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 12915}], "readme": "# Crytrography-Ciphers\n"}
{"url": "https://github.com/ezair/Database-Project", "owner": "ezair", "repository_name": "Database-Project", "date_all_variable_collection": "2023-09-11", "description": "Database project. Contains a website that links to a local server. A game made in UE4 also connects to database.", "size": 5625, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 59365}, {"language": "CSS", "num_chars": 28846}, {"language": "HTML", "num_chars": 9042}, {"language": "Python", "num_chars": 2178}], "readme": "# Database-Project\nDatabase project. Contains a website that links to a local server. A game made in UE4 also connects to database.\n\n\n#REQUIREMENTS TO RUN PROGRAM\n  #The following python libraries are required to run the main.py script.\n    1) pip & python-setuptools\n    2  bootstrap\n    3) flask\n    4) wtforms\n    5) flask_bootstrap\n    6) pyodbc\n    7) flask_wtf\n    \n\n    If you have any trouble with this just remember that you need to make the following dependencies exist:\n        from flask import Flask, render_template, flash\n        from flask_wtf import Form \n        from wtforms import StringField, PasswordField\n        from wtforms.validators import InputRequired, Email, Length, AnyOf\n        from flask_bootstrap import Bootstrap\n        import pyodbc  \n\n\n#Make sure to change the connection to the database (located in the main.py file) to your Dns servername.\n\n\n\n#Make sure to change all of the cursor.pyodbc commands to work with your database table names. They will have to be changed in the main.py script to flow with your database and your tables.\n\n\n\n#The main.py script must be created in order for your login page to be displayed.\n"}
{"url": "https://github.com/ezair/DataStructures", "owner": "ezair", "repository_name": "DataStructures", "date_all_variable_collection": "2023-09-11", "description": "This is a collection of Data Structures that I created.", "size": 22, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 19}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 16616}, {"language": "Python", "num_chars": 1833}], "readme": "# DataStructures\nThis is a collection of Data Structures that I created In the past.\n\nI like to use this as a milestone to remember how much better of a programmer I have become and how I could re-implement these data structures using much better style and much faster algorithmic complexity.\n"}
{"url": "https://github.com/ezair/Detecting-Prostate-Cancer", "owner": "ezair", "repository_name": "Detecting-Prostate-Cancer", "date_all_variable_collection": "2023-09-11", "description": "Repo containing code on creating a dataset for detecting prostate cancer.", "size": 354, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "ezair", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 4697}, {"language": "Shell", "num_chars": 73}], "readme": "# detecting-prostate-cancer\nRepo containing code on creating a dataset for detecting prostate cancer.\n\nDataset: https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=68550661\n\n## Directions...\nRun `pip install -r requirements.txt`\nMove your dataset of images that you have locally to the root of this repository.\nRun `python -m create_dataset` to execute the creation of the dataset.\n"}
{"url": "https://github.com/ezair/Encrypted-Chat-Program", "owner": "ezair", "repository_name": "Encrypted-Chat-Program", "date_all_variable_collection": "2023-09-11", "description": "The purpose of this project was to create a peer to peer 2 person encrypted chat program using both AES and Elgamal key exchange", "size": 82, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 52}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 11898}], "readme": "chat.py (main program)\n\nDecription:\n\tThe purpose of this project was to create an encrypted peer to peer chat program.\n\tThe program handles encryption for only 2 users at the moment.\n\tThis program uses Elgamal to generate the private keys and then uses AES to Encrypt/Decrypt messages sent between  users.\n\nHow to run this program:\n\tpython3 chat.py\n\nRequirements to run this program:\n\tMust have python3\n\tpyaes (deb file available online)\n\tpygame (sudo apt-get install pygame)\n\tFiles required:\n\t\tchat.py\n\t\tElgamal.py\n"}
{"url": "https://github.com/ezair/Grading-Scripts", "owner": "ezair", "repository_name": "Grading-Scripts", "date_all_variable_collection": "2023-09-11", "description": "This repository contains a collection of python scripts used for grading SUNY Potsdam computer science assignments.", "size": 12, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 8487}], "readme": "# Grading-Scripts\n\n#This repo contains python2 scripts that are used to help me effectively and efficiently grade students hw assignments.\n"}
{"url": "https://github.com/ezair/Iris-Species-Classification", "owner": "ezair", "repository_name": "Iris-Species-Classification", "date_all_variable_collection": "2023-09-11", "description": "Code for classifying the species of an iris flower using KNN supervised machine learning.", "size": 717, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 259004}]}
{"url": "https://github.com/ezair/Kings", "owner": "ezair", "repository_name": "Kings", "date_all_variable_collection": "2023-09-11", "description": "This is a python2 program for the purpose of playing the kings card game on any given device.", "size": 25, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 6514}], "readme": "Description:\n\tThis is a python2 script written for the purpose of\n\tbeing able to play the card game, kings on your\n\tandroid phone (or pretty much any platform).\n\tThe program is fairly straight forward.\n\tThe program is completed as well (no more updates).\n\nIMPORTANT NOTE:\n\tDo NOT move the sound folder's location or\n\tthe sounds inside of it (unless you want to replace them).\n\nProgramming Language:\n\tPython2\n\nRequirements:\n\tMust have the following installed:\n\t\tPython2\n\t\tpyttsx: API for text to voice in python.\n\t\t\t\t(pip install pyttsx)\n\t\tpygame: Used for sound.\n\t\t\t\t(pip install pygame)\nPlatforms:\n\tWindows 7, 10\n\tMacOS\n\tLinux\n\tAndroid"}
{"url": "https://github.com/ezair/Linear-Regression-Practice", "owner": "ezair", "repository_name": "Linear-Regression-Practice", "date_all_variable_collection": "2023-09-11", "description": "Practice linear regression from scratch and then using Turicreate. ", "size": 953, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 14}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 791395}, {"language": "Python", "num_chars": 488}], "readme": "# ID BLOCK\n\n- Eric Zair\n- Gradient Descent (Singular)\n- 02/03/2020\n\n## Project Description\n\nThe goal of this project was to implement 3 different ways to do linear regression on a database that contains used car information. After collecting all of the data using turicreate, the goal was simple, given only the mileage of the car how can we estimate the expected cost for the car?\n\nNote this program is built specifically for single feature gradient descent not multiple.\n\n## The three different methods\n\n1. Built in linear regression model in turicreate\n\n2. Calculating the closed for for our gradient equations\n\n3. Hand implementing gradient decent\n\n## Using the built in linear regression model\n\nUsing the built in features was rather easy and yields a better answer than my implementation of gradient descent. Granted this hold true because...my implementation of gradient descent will generate `nan`s and loop for quite the long time due to not finding the correct step size. As it turns out if your step size and magnitude used are not sufficient, then your descent gradient never actually converges, which becomes quite the issue.\n\n## Closed form\n\nClosed form appears to be the way that linear regression should really be done (at least for a small amount of features). The closed form method provides you with a straightforward mathematical way of accomplish your linear regression. Since you do not have to worry about things like step size and all we are really doing are a few simple linear calculations (and later with more features matrix multiplications), we get straight to the point. The speed of doing this is arguably faster than that of gradient descent. We do not loop and loop until we find the estimated or close to perfect solution, but rather we know for a fact that the solution is 100% optimal, since it was mathematically calculated.\n\n## My gradient descent\n\nAs it turns out, my implementation of gradient descent is truly flawed. When run, it may appear to be working, but then shortly after you will run into things such as an `inf` values, which clearly is a problem. I believe that the result of this has to do with having to find the proper step size or magnitude, but I could be wrong as well. Assuming that this implementation...worked properly, we should be receiving a number that is near similar to that of what is produced in the turicreate linear regression model.\n\n## Setup\n\nIf you want to make sure that you have the proper python packages to run any of the implantation (that are stored in the `src/` folder) run the `dev_setup.py` script.\n\n## Running each implementation\n\nEach implementation is stored in it's own `.ipynb` file. Simply use something like anaconda, conda, jupyter notebook, or google collab in order to run the programs.\n\n`closed_form.ipynb` contains the closed form implementation.\n\n`my_gradient_implementation.ipynb` contains my implementation.\n\n`turicreate_linear_regression_using.ipynb` contains the linear regression model implementation.\n"}
{"url": "https://github.com/ezair/Logistic-Regression-Classification", "owner": "ezair", "repository_name": "Logistic-Regression-Classification", "date_all_variable_collection": "2023-09-11", "description": "Classification using logistic regression on Amazon data. (check out py notebook file for details).", "size": 41355, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 121840}]}
{"url": "https://github.com/ezair/Machine-Learing-Practice", "owner": "ezair", "repository_name": "Machine-Learing-Practice", "date_all_variable_collection": "2023-09-11", "description": "This will contain a few seperate machine learning programs. Each program will for the purpose of practice and nothing more.", "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Machine-Learing-Practice\nThis will contain a few seperate machine learning programs. Each program will be written for the purpose of practice and nothing more."}
{"url": "https://github.com/ezair/Multiple-Linear-Regression", "owner": "ezair", "repository_name": "Multiple-Linear-Regression", "date_all_variable_collection": "2023-09-11", "description": "My own implementation of multiple linear regression from scratch (using numpy).", "size": 920, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 54100}], "readme": ""}
{"url": "https://github.com/ezair/Pokemon-Gen1-Image-Classification", "owner": "ezair", "repository_name": "Pokemon-Gen1-Image-Classification", "date_all_variable_collection": "2023-09-11", "description": "Producing a Convolutional Neural Network for classifying the first 150 pokemon.", "size": 10, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 49971}]}
{"url": "https://github.com/ezair/Pytorch-Binary-Weather-Classification", "owner": "ezair", "repository_name": "Pytorch-Binary-Weather-Classification", "date_all_variable_collection": "2023-09-11", "description": "Construct a feed forward NN to simulate logistic regression on a weather dataset. We determine if it is going to rain or not. Currently the model performs with 100% accuracy.", "size": 4766, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "ezair", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 8539}]}
{"url": "https://github.com/ezair/Recipe-Scraper", "owner": "ezair", "repository_name": "Recipe-Scraper", "date_all_variable_collection": "2023-09-11", "description": "Scrape online recipes that I may want to use later.", "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": ""}
{"url": "https://github.com/ezair/Reddit-Sentiment-Analysis", "owner": "ezair", "repository_name": "Reddit-Sentiment-Analysis", "date_all_variable_collection": "2023-09-11", "description": "Built an object for analyzing the negativity and positivity level of a given subreddit submission or entire subreddit. The object is built with the intent that it can be used for multiple different projects. Database contains all submissions and there is a script to add to it.", "size": 38638, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 49}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 50820}, {"language": "Shell", "num_chars": 1204}], "readme": "# PROJECT INFORMATION\n\n- @author Eric Zair\n- @updated 03/17/2020\n- @brief Program that uses the `praw` API and `mongod` API in order to grab information from reddit and add it to a mongodb database. From there the user can then create any models or programs they want that are built around the `reddit_collector.py` program.\n\n## Project Goal\n\nThere are two different goals for this project.\n\nThe first part is the `reddit_collector.py` program which is used to grab data from given subreddits and add the data to a mongodb database.\n\nThe second part of the project is to take the data that is in the mongodb database and analyze it via natural language processing.\n\nI will be creating my own NLP \"model\" for analyzing reddit data from the database, however, the beauty of this project is that users can create their own models and use the `reddit_collector.py` script to grab the data that they wanna find. All they have to do is slightly tweak. The program is setup so that you can use your own database with it, so it is quite easy, just swap your database and auth keys and you should have no problems.\n\n## reddit_collector\n\nThis is program is used to grab data off of reddit.\n\nMore specifically, given a `.sub` file containing multiple different subreddits, we grab N amount of comments on K amount of posts.\n\nThis program has a flag for adding a subreddit to the `.sub` file, removing a flag from the `.sub` file, and also collecting the data based of the subreddits in the `.sub` file.\n\n*Program Usage Information:*\n\n```ignore\nusage: reddit_post_collector.py [-h] [--collect | --add ADD | --remove REMOVE]\n\noptional arguments:\n  -h, --help       show this help message and exit\n  --collect        Prompt the user for a data range and being collecting the\n                   data. When we are done with collecting, we add the data to\n                   the database.\n  --add ADD        Add the sub-reddit passed in by the user to the list of\n                   sub-reddits that we will collect data from.\n  --remove REMOVE  Remove the subreddit passed in by the user.\n```\n\nThe best way to run the `reddit_post_collector.py` program is actually through the `reddit_post_collector.sh` bash script, as all the paths are accurate and such.\n\n*Example run of the program for collecting data:*\n`./reddit_collector.sh --collect`\n\n*Example run of the program for adding a subreddit to the `.sub` list:*\n`./reddit_collector.sh --add <name_of_subreddit_to_add>`\n\n*Example run of the program for removing a subreddit from the `.sub` list:*\n`./reddit_collector.sh --remove <name_of_subreddit_to_remove>`\n\n## Models\n\nMore on this later.\n\n## Credentials\n\n*IMPORTANT:* There are *TWO* different `python3` files that are required in order for this project to work. These files *MUST* be created by the user. These two files are in the `.gitignore` file because they contain information that you don not want to be publicly known to anyone but you, the user.\n\nThe code for both files is available below, all you have to do is copy the content and make the files in the `src/credentials/` folder.\n\nThese files contains required global variables that will be imported directly into our `python3` files e.g. in `collector.py`.I figured that this is the neatest way to handle secret credentials while still being able to have a lot of flexibility in these programs.\n\n## mongo_credentials.py\n\nThe first file that we need to make is called `mongo_credentials.py` and must be created in the `src/credentials/` folder.\n\nThe only things that need to be changed in this file is the `client_id` and the `client_secret`. Everything else in the entire file can remain exactly as is.\n\n```python\nAPI_INSTANCE = get_api_instance(client_id='YOUR CLIENT ID',\n                                client_secret='YOUR SECRET KEY',\n                                user_agent='my user agent')\n```\n\n```python\n\"\"\"\nAuthor: Eric Zair\nFile: reddit_credentials.py\nDescription: This file contains the api_instance needed to use\n             the reddit api(praw). This will be imported in by\n             the user.\n\"\"\"\nimport praw\n\n\ndef get_api_instance(client_id, client_secret, user_agent):\n    \"\"\"\n    :Desc:  Method sets up connecting to the reddit api for the user.\n            The purpose of this method is to be called into the main program,\n            so that the praw instance will have been connected.\n    :param client_id: This is the user's praw client ID.\n    :type: str\n    :param client_secret: User's client secret for the praw API.\n    :type: str\n    :param user_agent: This is the user's praw user_agent. (This can be what ever).\n    :return: praw.Reddit\n    \"\"\"\n    return praw.Reddit(client_id=client_id,\n                       client_secret=client_secret,\n                       user_agent=user_agent)\n\n\ndef test(api_instance):\n    \"\"\"\n    :Desc: Very simple test to see that the reddit api is working normally.\n    :param: api_instance: Instance that you are returning.\n    :type: praw.Reddit()\n    :return:    None\n    \"\"\"\n    for submission in api_instance.subreddit(\"soccer\").hot(limit=11):\n        print(submission.title)\n        print(\"IT WORKS, The test works.\")\n\n\n# Variable that the user must import into their program,\n# in order for the reddit\n# api to work correctly. This is an api instance.\n\n# Change the client_id field and the cliend_secret.\nAPI_INSTANCE = get_api_instance(client_id='YOUR CLIENT ID',\n                                client_secret='YOUR SECRET KEY',\n                                user_agent='my user agent')\n\n\"\"\"\nVariable in the reddit_crenentials.py, If run_test == True, the test runs, False.\n\"\"\"\nRUN_TEST = False\nif RUN_TEST:\n    test(API_INSTANCE)\n```\n\n### reddit_credentials.py\n\nThe next file that we must have created is called `reddit_credentials.py` and must be created in the `src/credentials/` folder.\n\nAll you have to do is change the variable `mongo_auth_token` to your mongodb authorization token for your database.\n\nIf you would like to (but this is more up to how you wanna customize your database) you can change the name of your database for `DB_COLLECTION`.\n\n*Content of reddit_credentials.py*:\n\n```python\n\"\"\"\nAuthor: Eric Zair\nFile: mongo_credentials.py\nDescription: This file all of the setup done for the user's database.\n             We set it up completely, and then just return the instance\n             of the database to our collector program when it is needed.\n\n            NOTE:\n                (This is done so that we KNOW the user's database will work\n                fluently within out reddit_collector.py file.)\n\"\"\"\nfrom pymongo import MongoClient\n\n\n# We setup the database so that it can be directly imported into the programs\n# that it will be needed in.\n# This is very nice because no matter how the user sets up their program,\n# our main program (reddit_post_collector) can handle it all the same.\ntry:\n    # My current auth token is python3.4 or higher.\n    mongo_auth_token = 'YOUR MONGO AUTH TOKEN GOES HERE!'\n    client = MongoClient(mongo_auth_token)\n    db = client.get_database('reddit')\n\n    # This collection is what will be imported directly into the\n    # reddit_post_collector.py file.\n    DB_COLLECTION = db['post_comment']\n\nexcept Exception:\n    print('Error, either you database:\\n'\n          '\\t1. Does not exist\\n'\n          '\\t2. Has not properly been setup or\\n'\n          '\\t3. The incorrect token has been given.')\n```\n\n## Doxygen & Documentation\n\nComments in this program are done in a format that supports using doxygen to generate .html documentation.\n\n### Generating Doxygen Documentation\n\nTo Generate doxygen documentation make sure that doxygen is properly installed on your system.\n\nIf it is not installed on your system and you are running linux, run the following command:\n\n`sudo apt-get install doxygen`\n\nThis will install doxygen on your computer.\n\n### The generate_open_docs.py script\n\nTo do a quickly generate and open documentation, simply run the command `./generate_open_docs.py` and the documentation will be built and then opened up in your web browser.\n\nNOTE: If you already have a web browser open, then the documentation will open in that window.\n\nNow that doxygen is installed on your computer, you can run the following command to generate the documentation:\n\n`cd doc; doxygen Doxyfile`\n\nOnce executed, the documentation will be generated successfully.\n\nTo Easily view it, inside of the `doc/` folder look for `html/index.html` and open it.\n"}
{"url": "https://github.com/ezair/Ridege-Regression-Housing-Data", "owner": "ezair", "repository_name": "Ridege-Regression-Housing-Data", "date_all_variable_collection": "2023-09-11", "description": null, "size": 966, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 139314}, {"language": "Python", "num_chars": 8393}]}
{"url": "https://github.com/ezair/Ridge-Lasso-Regularization", "owner": "ezair", "repository_name": "Ridge-Lasso-Regularization", "date_all_variable_collection": "2023-09-11", "description": "Example and statistics of running Ridge/Lasso regression. (No need  for readme, I use pynotebooks).", "size": 857, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 804203}, {"language": "Python", "num_chars": 8393}]}
{"url": "https://github.com/ezair/Rock-Paper-Scissors", "owner": "ezair", "repository_name": "Rock-Paper-Scissors", "date_all_variable_collection": "2023-09-11", "description": "2 Player Rock Paper Scissors game", "size": 7, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 7660}], "readme": "First Commit\n\nThis project creates and runs a Rock Paper Scissors game.\nCompile RockPaperScissors.java and run it to play game.\n\n# Rock-Paper-Scissors\n2 Player Rock Paper Scissors game\n"}
{"url": "https://github.com/ezair/Scheme-Token-Word-Displayer", "owner": "ezair", "repository_name": "Scheme-Token-Word-Displayer", "date_all_variable_collection": "2023-09-11", "description": "Display the content of a scheme program with the comments stripped out.", "size": 40, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 14294}, {"language": "Python", "num_chars": 958}], "readme": "# ID Block Information\n\n* @author Eric Zair\n* @email zairea200@potsdam.edu\n\n## Description\n\nI will write a symbol (or \"word\") count program. The quotes indicate that the definition of \"word\" is not quite standard. A word is basically an integer, a sequence of letters and digits, or a punctuation symbol. The code will process a set of files listed on the command-line, reading each file, breaking it down into a series of words, and use `Map` to count the number of times each word occurs.\n\nNote that This version of the word counter is comment aware, meaning that we will be completely ignoring anything in a Scheme comment.\n\n### Scheme Comments\n\n* Anything between `#|` and `|#` will be ignored.\n\n* Anything after `;` will be ignored.\n\nWhen run, `WordCounter` will check the command-line for arguments.\n\nIf there are no arguments, terminate with an appropriate error message.\n\n For each argument, treat it as a file name and open it for input.\n\n If the file cannot be opened for input, produce an appropriate error message and go to next parameter.\n\n If the file opens for input:\n\n Read the contents of the file, one \"word\" at a time:\n\n A \"word\" is:\n\n* A sequence of decimal integers; begins with a digit, ends on first non-digit Example: 233\n* A sequence of letters and integers; begins with a letter, ends on first character that is neither a letter nor a digit Example: mutant999\n* A punctuation symbol; begins with the symbol, ends on next character Example: .\n\n## How To Compile && run\n\n### Building/Compiling the program\n\nTo build/compile the program, simply run the following command:\n\n`gradle clean build`\n\nThis will build the program for you (assuming that you have gradle installed on your computer).\n\n### Running the program\n\nAfter building the program, simply run it by doing the following:\n\n`gradle run --args <file_to_pass_in_to_program>`\n\nNote that if you do not run this with the file name, you will receive the following message from the program:\n\n```Ignore\nProgram must take a file as an argument.\nRun without gradle: java WordCounter <path_to_file>\nRun with gradle: gradle run --args <path_to_file>\n```\n\n### Build & Run all in one\n\nAlternatively you can build and run the program in one step by doing the following:\n\n`gradle clean build run --args <file_to_pass_in_to_program>`\n\n## Testing\n\nIn order to test the program, I have build a few text files to test with. These test files are located in the root project directory `tests/` folder. `alligator_test_with_comments.txt`\n\nBelow I will show an example of the file content, then I will show the results my program reduces.\n\n### File Content\n\n```Ignore\n# ##|all|#igator ;[11]\nx37] 1.1.1\n\n```\n\n### Output of WordCounter.java\n\n```Ignore\n > Task :run\nOutput for \"tests/alligator_test_with_comments.txt\":\n# : 2\n. : 2\n1 : 3\n] : 1\nigator : 1\nx37 : 1\n\nBUILD SUCCESSFUL in 1s\n7 actionable tasks: 7 executed\n```\n\n## Doxygen & Documentation\n\nComments in this program are done in a format that supports using doxygen to generate .html documentation.\n\n### Generating Doxygen Documentation\n\nTo Generate doxygen documentation make sure that doxygen is properly installed on your system.\n\nIf it is not installed on your system and you are running linux, run the following command:\n\n`sudo apt-get install doxygen`\n\nThis will install doxygen on your computer.\n\n### The generate_open_docs.py script\n\nTo do a quickly generate and open documentation, simply run the command `./generate_open_docs.py` and the documentation will be built and then opened up in your web browser.\n\nNOTE: If you already have a web browser open, then the documentation will open in that window.\n\nNow that doxygen is installed on your computer, you can run the following command to generate the documentation:\n\n`cd doc; doxygen Doxyfile`\n\nOnce executed, the documentation will be generated successfully.\n\nTo Easily view it, inside of the `doc/` folder look for `html/index.html` and open it.\n"}
{"url": "https://github.com/ezair/Shapes", "owner": "ezair", "repository_name": "Shapes", "date_all_variable_collection": "2023-09-11", "description": "Collection of classes that are used to calculate area and perimeter of shape", "size": 9, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 2906}], "readme": "# Shapes\nExample of interface use in java to show to students that I am tutoring / TAing\nCollection of classes that are used to calculate area and perimeter of shape\n"}
{"url": "https://github.com/ezair/Student", "owner": "ezair", "repository_name": "Student", "date_all_variable_collection": "2023-09-11", "description": "This Program creates a Class for students", "size": 2, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 3188}]}
{"url": "https://github.com/ezair/Terminal", "owner": "ezair", "repository_name": "Terminal", "date_all_variable_collection": "2023-09-11", "description": "My own implimentation of a Linux Shell.", "size": 336, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 9382}, {"language": "Makefile", "num_chars": 7422}, {"language": "Python", "num_chars": 2257}], "readme": "# ID Block Information\n\n* @author Eric Zair\n* @email zairea200@potsdam.edu\n* @course CIS 310 Operating Systems\n* @assignment p002\n* @due 09/16/2019\n\n## Program Description\n\nGoal: To turn vssh-b from a simple string processor (that extracts wordsfrom lines of text) into a shell.A shell (like sh, bash, csh, etc.)\n\n1. Prompts the user.\n\n2. Keeps track of the current working directory (cwd).\n\n    (a) The prompt often indicates the current working directory.\n\n3. Reads input a line at a time.\n\n    (a) Most (not ours) support some sort of line continuation for longer commands.\n\n4. Extracts the words from the command-line\n\n    (a) The first word is assumed to name a command (executable file) to run.\n\n    (b) Remaining words are command-line parameters passed into the command.\n\n5. Search apath(list of standard paths) for the named command.\n\n6. Execute the standard command, waiting until the command finishes, and looping backto the prompt.\n\n## How To Run\n\nThere are 2 very simple ways to execute this program.\n\n## The run.py script\n\nInside of the base directory there is a file called run.py\n\nEssentially, this file removes current version of the build/ dir (if it exists) and the calls make, makes sure that it properly works. Assuming that the make command does work, the script then executes the main program `build/vssh-b`.\n\nTo run the run.py script, simply run the following command:\n\n`./run.py`\n\n## Directly Calling The vssh-b program\n\nThe other way to run the program is to call the following command:\n\n`make;./build/vssh-b`\n\nThis will build and run the program.\n\n## Doxygen & Documentation\n\nComments in this program are done in a format that supports using doxygen to generate .html documentation.\n\n### Generating Doxygen Documentation\n\nTo Generate doxygen documentation make sure that doxygen is proeprly installed on your system.\n\nIf it is not installed on your system and you are running linux, run the following command:\n\n`sudo apt-get install doxygen`\n\nThis will install doxygen on your computer.\n\nNow that doxygen is installed on your computer, you can run the following command to generate the documentation:\n\n`cd doc; doxygen Doxyfile`\n\nOnce executed, the documentation will be generated successfully.\n\n## Testing\n\nNOTE: Normally I would create/build unit tests for testing purposes, however, that feels a bit overkill for this assignment.\n\n### Testing Cases Used\n\n1. The case where a user uses a command such as `ls`:\n\n    ``` Bash\n    /home/ez/Workspace/Classes/OS/p002/CIS-310-vssh-b ls\n    build  doc  Makefile  program  README.md  run.py  src\n    /home/ez/Workspace/Classes/OS/p002/CIS-310-vssh-b ls -a\n    .   build  .git        Makefile  README.md  src\n    ..  doc    .gitignore  program\t run.py     .vscode\n    /home/ez/Workspace/Classes/OS/p002/CIS-310-vssh-b\n    ```\n\n2. The case where the user uses the `cd` command:\n\n    ``` Bash\n    /home/ez/Workspace/Classes/OS/p002/CIS-310-vssh-b ls\n    build  doc  Makefile  program  README.md  run.py  src\n    /home/ez/Workspace/Classes/OS/p002/CIS-310-vssh-b cd src\n    /home/ez/Workspace/Classes/OS/p002/CIS-310-vssh-b/src ls\n    allModule.mk  executables  parser\n    ```\n\n3. The case where the user uses the `cd` command to back a directory e.g. `cd ..`:\n\n    ```Bash\n    /home/ez/Workspace/Classes/OS/p002/CIS-310-vssh-b ls\n    build  doc  Makefile  program  README.md  run.py  src\n    /home/ez/Workspace/Classes/OS/p002/CIS-310-vssh-b cd src\n    /home/ez/Workspace/Classes/OS/p002/CIS-310-vssh-b/src ls\n    allModule.mk  executables  parser\n    /home/ez/Workspace/Classes/OS/p002/CIS-310-vssh-b/src\n    ```\n\n4. The case where a user runs a script in their current directory:\n\n    ```Bash\n    /home/ez/Workspace/Classes/OS/p002/CIS-310-vssh-b ls\n    build  doc  Makefile  program  README.md  run.py  src  test.py\n    /home/ez/Workspace/Classes/OS/p002/CIS-310-vssh-b /test.py\n    this is a really really really simple test\n    /home/ez/Workspace/Classes/OS/p002/CIS-310-vssh-b\n    ```\n\n5. The case where a user a test program in the same directory with command line argument:\n\n    ```Bash\n    /home/ez/Workspace/Classes/OS/p002/CIS-310-vssh-b ls\n    build  doc  Makefile  program  README.md  run.py  src  test.py\n    /home/ez/Workspace/Classes/OS/p002/CIS-310-vssh-b /test.py --test\n    this is a really really really simple test\n    --test was given as a sys argument.\n    /home/ez/Workspace/Classes/OS/p002/CIS-310-vssh-b\n    ```\n"}
{"url": "https://github.com/ezair/Token-Word-Counter", "owner": "ezair", "repository_name": "Token-Word-Counter", "date_all_variable_collection": "2023-09-11", "description": "Find all \"words\" in a given file and displays then in sorted order. Definition of a \"word\" is in readme.", "size": 42, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 11193}, {"language": "Python", "num_chars": 958}], "readme": "# ID Block Information\n\n* @author Eric Zair\n* @email zairea200@potsdam.edu\n\n## Description\n\nThe Goal of this project is to do two main things:\n\n### (1) Simulate the Linux command line program called `cat`\n\nThe normal linux cat program takes command line arguments which are the names of some given files. The cat program simply takes the name of those files and prints out the file content to the terminal.\n\nHowever, the version that I have does the same thing except it removes all scheme comments from the output that is sent to the terminal.\n\n### (2) Create a class `SansLittleUFilterReader` that extends Java's `FilterReader` class\n\nA filter reader is essentially a type of abstract `Reader` that is also implements the `Readable` interface in java.\n\nThe class that I will be making will extend `FilterReader` and take a `Reader` as an argument to its constructor. Instead I will then override the each and everyone one of the `read()` methods (and the `skip()` method) to make it read any data from the passed in `Reader`, but also ignore any scheme comments that are contained in the given `Reader`. (Examples wil be show in the testing section).\n\n## How To Compile && run\n\n### Building/Compiling the program\n\nTo build/compile the program, simply run the following command:\n\n`gradle clean build`\n\nThis will build the program for you (assuming that you have gradle installed on your computer).\n\n### Running the program\n\nAfter building the program, simply run it by doing the following:\n\n`gradle run --args <file_to_pass_in_to_program>`\n\nNote that if you do not run this with the file name, you will receive the following message from the program:\n\n```Ignore\nThis Program requires AT LEAST one argument for a filename.\ncat.java <name_of_file>\nIf using gradle: 'gradle run' --args <name_of_file(s)\n```\n\n### Build & Run all in one\n\nAlternatively you can build and run the program in one step by doing the following:\n\n`gradle clean build run --args <file_to_pass_in_to_program>`\n\n## Testing\n\nIn order to test the program, I have build a few text files to test with. These test files are located in the root project directory's `tests/` folder. `test1.txt` is a more intense test that covers edge cases. `test2.txt` is a more basic test that proves the functionality in a simple and easy to understand example.\n\nBelow I will show an example of the Cat program, followed by my implementation of the Cat program.\n\n### Output of the Linux Cat program\n\n```Ignore\nThis is a test...#\n\n    And this is the second ; line of the test.\nStill doing testing and stuffs #;\n\nWoot woot\n    I'm here now :)\n\n    #|This is should be deleted|# but not this; this can.\n\n        Still though: #| here to | right about here |# should be taken out.\n\n                Finally, #| from here #| to al the way over here | was |# taken out ;\n#   :)\n```\n\n### Output of my Cat program\n\n```Ignore\nTask :run\nOutput of tests/test1.txt:\n\n     This is a test...#\n\n    And this is the second\nStill doing testing and stuffs #\n\nWoot woot\n    I'm here now :)\n\n      but not this\n\n        Still though:   should be taken out.\n\n                Finally,   taken out\n#   :)\n\nBUILD SUCCESSFUL in 1s\n9 actionable tasks: 9 executed\n\n```\n\nNOTE: My program intentionally adds the line that says \"Output of tests/test1.txt\" for the sake of when multiple files are passed into it.\n\nALSO The very bottom line shown is a result of gradle itself :)\n\n## Doxygen & Documentation\n\nComments in this program are done in a format that supports using doxygen to generate .html documentation.\n\n### Generating Doxygen Documentation\n\nTo Generate doxygen documentation make sure that doxygen is properly installed on your system.\n\nIf it is not installed on your system and you are running linux, run the following command:\n\n`sudo apt-get install doxygen`\n\nThis will install doxygen on your computer.\n\n### The generate_open_docs.py script\n\nTo do a quickly generate and open documentation, simply run the command `./generate_open_docs.py` and the documentation will be built and then opened up in your web browser.\n\nNOTE: If you already have a web browser open, then the documentation will open in that window.\n\nNow that doxygen is installed on your computer, you can run the following command to generate the documentation:\n\n`cd doc; doxygen Doxyfile`\n\nOnce executed, the documentation will be generated successfully.\n\nTo Easily view it, inside of the `doc/` folder look for `html/index.html` and open it.\n"}
{"url": "https://github.com/ezair/Twitter", "owner": "ezair", "repository_name": "Twitter", "date_all_variable_collection": "2023-09-11", "description": "This is repository will contain a collection of programs using the twitter api \"tweepy\"", "size": 7457, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 17}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 4025}], "readme": "# Twitter\nThis is repository will contain a collection of programs using the twitter api \"tweepy\"\n\n\n# For all programs in this repo you must have the twitter api \"tweepy\" installed.\n## This API can be installed by using the following command on linux:\n###  pip install tweepy\n  \n\n#To use tweepy you must sign up with twitter and be granted acces to the tweepy api.\n\n# Rememeber to change the following in every program in this repo:\n##   consumer_key\n##   consumer_secret\n##   access_token\n##   access_token_secret\n\n\n# Some programs in this repo may require you to install pymongo\n## This API can be installed by using the following command on linux:\n###  pip install pymongo\n\n\nYou must make sure that you are also have mongodb installed on your computer\n\nAll files were written in Python2\n"}
{"url": "https://github.com/ezair/Weather-Data-Binomial-Clasisfication", "owner": "ezair", "repository_name": "Weather-Data-Binomial-Clasisfication", "date_all_variable_collection": "2023-09-11", "description": "Running logistic regression on weather data in order to classify that a day will snow or not snow.", "size": 2295, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ezair", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 15503}]}
{"url": "https://github.com/fahaddeshmukh/Causes-of-death-analysis", "owner": "fahaddeshmukh", "repository_name": "Causes-of-death-analysis", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1579, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "fahaddeshmukh", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": true, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 807082}, {"language": "Python", "num_chars": 12270}], "readme": "# Exploring Mortality Patterns: A Comprehensive Analysis of Diverse Causes of Death\n\nThis project aims to perform an exploratory data analysis (EDA) on a dataset containing information about causes of deaths over the past decade. The dataset is stored in the \"data\" directory, and the analysis is conducted using the Python programming language.\n\n## Directories\n\nThe project is structured as follows:\n\n- **bin**: This directory contains the source code files required to run the analysis.\n  - `src.py`: This Python script is the main entry point for running the exploratory data analysis. It contains the code that reads the dataset and performs various data processing and visualization tasks.\n  - `data_processing.py`: This script contains functions for processing the data, such as cleaning, transforming, and aggregating it for analysis purposes.\n  - `Deaths_EDA.ipynb`: This Jupyter Notebook file provides an alternative interface for running the analysis interactively. It contains the same code as `src.py` but provides easy accessablity along with a narrative.\n\n- **data**: This directory contains the dataset used for the analysis.\n  - `Death_DE.csv`: The CSV file that contains the data on causes of deaths over the past decade. The file is required for running the analysis. Please ensure that it is located in this directory.\n\n- **docs**: This directory contains any documentation related to the project.\n## User Guide\nTo use this project, follow the steps below:\n\n1. Clone the repository: git clone https://github.com/fahaddeshmukh/Causes-of-death-analysis\n\n\n2. Install the required dependencies: pip install -r requirements.txt\n\n\n\n3. Prepare the dataset:\n- Place the dataset file (e.g., `Deaths_DE.csv`) in the project directory.\n\n4. Run the analysis:\n- Open the command-line interface.\n- Navigate to the project directory.\n- Execute the following command from the project repository:\n  ```\n   python bin/src.py data/Death_DE.csv\n\n  ```\n\n5. View the results:\n- The program will present the answers to the  research questions in the command-line interface. Additionally, plots will be displayed sequentially in separate windows. After viewing each plot, the corresponding window should be closed before the next plot appears.\n\n6. You can also run the Computational Narrative file (Deaths_EDA.ipynb) which gives comprahensive overview and summary for the results.\n## License\nThis project is licensed under the MIT License. Feel free to modify and adapt the code for your own purposes.\nURL for License: https://github.com/fahaddeshmukh/Causes-of-death-analysis/blob/main/LICENSE.MD\n\n## Citation Information\n\nCitation information for this project can be found in the Citation files in the directory.\nURL for Citations: https://github.com/fahaddeshmukh/Causes-of-death-analysis/blob/main/CITATION.cff\n## Acknowledgments\nThe data used in this project was obtained from [https://www.destatis.de/EN/Themes/Society-Environment/Population/Current-Population/_node.html]. \n## Contact Information\nFor any questions, suggestions, or issues, please feel free to contact:\n\n- Name: Fahad Deshmukh\n- Email: deshmukh@uni-potsdam.de\n"}
{"url": "https://github.com/fahaddeshmukh/dataport", "owner": "fahaddeshmukh", "repository_name": "dataport", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1368, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "fahaddeshmukh", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 2005085}]}
{"url": "https://github.com/fahaddeshmukh/git", "owner": "fahaddeshmukh", "repository_name": "git", "date_all_variable_collection": "2023-09-11", "description": null, "size": 4, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 12273}]}
{"url": "https://github.com/fahaddeshmukh/house-price", "owner": "fahaddeshmukh", "repository_name": "house-price", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1185, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 1055399}, {"language": "Python", "num_chars": 9095}], "readme": "\n## House price prediction using Machine learning\n\n\n\n### Overview\n\nThe aim of the project  centers around the utilization of machine learning techniques for the accurate prediction of housing prices. The precise estimation of property sale prices holds immense significance within real estate markets, serving various purposes such as aiding investment choices, determining property values, and facilitating market analysis. Leveraging machine learning algorithms and a dataset replete with pertinent housing features, the objective is to craft a predictive model capable of estimating housing prices with a high degree of accuracy.\n\nThe approach is systematic, commencing with data preprocessing, followed by exploratory data analysis (EDA), feature selection, and feature engineering. Subsequently, an assortment of machine learning algorithms is employed to train and evaluate predictive models using the processed dataset.\n\n## Installation\n\nTo use this script, you need to have Python installed on your system (3.8 or higher). You also need to install the required dependencies by running the following command:\n\n```\npip install -r requirements.txt\n```\n## Directories\n\nThe project is structured as follows:\n\n- **bin**: This directory contains the source code files required to run the analysis.\n  - `house.py`: This Python script is the main entry point for running the project. It contains the code that reads the dataset and performs various data processing, visualization and modelling tasks.\n \n  - `house.ipynb`: This Jupyter Notebook file provides an alternative interface for running the analysis interactively. It contains the same code as `house.py` but provides easy accessablity along with a narrative.\n\n- **data**: This directory contains the dataset used for the analysis.\n  - `train.csv`: The CSV file that contains the data on the sale price of various properties. The file is required for running the analysis. Please ensure that it is located in this directory.\n\n- **modules**: This directory contains the modules used project.\n- `modules.py`: The modules.py script contains utility functions used by the house.py script to preprocess data and evaluate models.\n- **plots**: This directory contains the EDA plots used for the analysis.\n## Usage\n\nThe script requires two input files: house.py and train.csv. Place these files in the data directory of your project. Then, run the following command to execute the preprocessing script:\n\n```\npython bin/house.py data/train.csv\n```\n\nThe script will perform the following steps:\n\n1. Data Preprocessing: The script performs data preprocessing, including handling missing values and transforming numerical features.\n2. Data Visualization: It generates histograms and box plots to visualize the data distribution and relationships between variables.\n3. Model Evaluation: The script evaluates multiple machine learning models (Linear Regression, Random Forest, and LGBM) and provides Mean Squared Error (MSE) and R-squared scores.\n4. Results: The evaluation results are saved in the results/ directory, including yPred_yTrue_table_{model_name}.txt files.\n\n\n\n\n## Requirements\n\nThe script requires the following Python packages:\n\n- pandas\n- numpy\n- matplotlib\n- seaborn\n- scikit-learn\n- lightgbm\n- scipy\n\nYou can install these packages by running the command mentioned in the \"Installation\" section.\n\n## Functions\n\nThe modules.py script contains utility functions used by the house.py script to preprocess data and evaluate models:\n<ul>\n    <li><b>count_null_data</b>: Counts and prints the number of missing values in each column of the dataset.</li>\n    <li><b>delete_columns_with_zero_data</b>: Removes columns with a high number of zero values from the dataset.</li>\n    <li><b>separate_categorical_numerical</b>: Separates categorical and numerical columns in the dataset.</li>\n    <li><b>drop_columns_with_zero_threshold</b>: Drops columns with a high number of zero values based on the specified threshold.</li>\n    <li><b>plot_categorical_columns</b>: Plots bar charts for categorical columns to visualize value counts.</li>\n    <li><b>apply_1_plus_log_transformation</b>: Applies the 1 plus log transformation to specified numerical columns.</li>\n    <li><b>model_evaluation</b>: Evaluates machine learning models and returns the Mean Squared Error (MSE) and R-squared scores.</li>\n</ul>\n\n\n## License\n\nThis project is licensed under the MIT License. See the [LICENSE](LICENSE.md) file for details.\n\n## Contact Information\nFor any questions, suggestions, or issues, please feel free to contact:\n\n- Name: Fahad Deshmukh\n- Email: deshmukh@uni-potsdam.de\n\n\n"}
{"url": "https://github.com/fahaddeshmukh/multiple-distributions", "owner": "fahaddeshmukh", "repository_name": "multiple-distributions", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1615, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Comparing multiple distributions\n\nThis project aims to is to compare distributions of competetion times in various swimming categories. The dataset is stored in the \"data\" directory, and the analysis is conducted using the R programming language.\n\n## Directories\n\nThe project is structured as follows:\n\n- /multiple-distributions\n    - Bin\n        - source.rmd\n        - source.md\n    - Data\n        - SwimmingTimes.csv\n    - Plots\n        - generated_plots.png\n    - Report\n        - Report-Comparison-of-multiple-distributions.pdf\n\n\n\n- **bin**: This directory contains the source code files required to run the analysis.\n  - `source.rmd`: This R script is the main entry point for running the exploratory data analysis. It contains the code that reads the dataset and performs various data processing and visualization tasks.\n  \n  - `source.md`: This markdown file provides an alternative interface for running the analysis interactively. It contains the same code as `source.rmd` but provides easy accessablity along with a computational narrative.\n\n- **data**: This directory contains the dataset used for the analysis.\n  - `SwimmingTimes.csv`: The CSV file that contains time taken by athletes in 5 swimming categories. The file is required for running the analysis. Please ensure that it is located in this directory.\n\n- **Plots**: This directory contains eda plots made for descriptive analysis.\n- **Report**: This directory contains a detailed report on the analysis in pdf format.\n\n\n## License\nThis project is licensed under the MIT License. Feel free to modify and adapt the code for your own purposes.\nURL for License: https://github.com/fahaddeshmukh/multiple-distributions/blob/master/LICENSE.MD\n\n\n## Acknowledgments\nThe data used in this project was obtained from [https://roma2022.microplustimingservices.com/indexRoma2022_web.php]. \n## Contact Information\nFor any questions, suggestions, or issues, please feel free to contact:\n\n- Name: Fahad Deshmukh\n- Email: deshmukh@uni-potsdam.de\n"}
{"url": "https://github.com/fahaddeshmukh/Myfaker", "owner": "fahaddeshmukh", "repository_name": "Myfaker", "date_all_variable_collection": "2023-09-11", "description": null, "size": 2911, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "fahaddeshmukh", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 20492661}, {"language": "HTML", "num_chars": 884}, {"language": "CoffeeScript", "num_chars": 233}], "readme": "# faker.js - generate massive amounts of fake data in the browser and node.js\n\n![Faker.js](https://raw.githubusercontent.com/Marak/faker.js/master/logo.png)\n\n[![Build Status](https://travis-ci.org/Marak/faker.js.svg?branch=master)](https://travis-ci.org/Marak/faker.js) [![Coverage Status](https://coveralls.io/repos/github/Marak/faker.js/badge.svg?branch=master)](https://coveralls.io/github/Marak/faker.js?branch=master)\n\n[![npm version](https://badge.fury.io/js/faker.svg)](http://badge.fury.io/js/faker)\n\n[![OpenCollective](https://opencollective.com/fakerjs/backers/badge.svg)](#backers)\n[![OpenCollective](https://opencollective.com/fakerjs/sponsors/badge.svg)](#sponsors)\n\n## Demo\n\n[https://rawgit.com/Marak/faker.js/master/examples/browser/index.html](https://rawgit.com/Marak/faker.js/master/examples/browser/index.html)\n\n## Hosted API Microservice\n\n[http://faker.hook.io](http://faker.hook.io/)\n - Supports all Faker API Methods\n - Full-Featured Microservice\n - Hosted by [hook.io](http://hook.io)\n\n```bash\ncurl http://faker.hook.io?property=name.findName&locale=de\n```\n\n## Usage\n\n### Browser\n\n    <script src = \"faker.js\" type = \"text/javascript\"></script>\n    <script>\n      var randomName = faker.name.findName(); // Caitlyn Kerluke\n      var randomEmail = faker.internet.email(); // Rusty@arne.info\n      var randomCard = faker.helpers.createCard(); // random contact card containing many properties\n    </script>\n\n### Node.js\n\n    var faker = require('faker');\n\n    var randomName = faker.name.findName(); // Rowan Nikolaus\n    var randomEmail = faker.internet.email(); // Kassandra.Haley@erich.biz\n    var randomCard = faker.helpers.createCard(); // random contact card containing many properties\n\n## API\n\n\n### Faker.fake()\n\nfaker.js contains a super useful generator method `Faker.fake` for combining faker API methods using a mustache string format.\n\n**Example:**\n\n``` js\nconsole.log(faker.fake(\"{{name.lastName}}, {{name.firstName}} {{name.suffix}}\"));\n// outputs: \"Marks, Dean Sr.\"\n```\n\nThis will interpolate the format string with the value of methods `name.lastName()`, `name.firstName()`, and `name.suffix()`\n\n### JSDoc API Browser\n\n[http://marak.github.io/faker.js/](http://marak.github.io/faker.js/)\n\n### API Methods\n\n* address\n  * zipCode\n  * city\n  * cityPrefix\n  * citySuffix\n  * streetName\n  * streetAddress\n  * streetSuffix\n  * streetPrefix\n  * secondaryAddress\n  * county\n  * country\n  * countryCode\n  * state\n  * stateAbbr\n  * latitude\n  * longitude\n* commerce\n  * color\n  * department\n  * productName\n  * price\n  * productAdjective\n  * productMaterial\n  * product\n* company\n  * suffixes\n  * companyName\n  * companySuffix\n  * catchPhrase\n  * bs\n  * catchPhraseAdjective\n  * catchPhraseDescriptor\n  * catchPhraseNoun\n  * bsAdjective\n  * bsBuzz\n  * bsNoun\n* database\n  * column\n  * type\n  * collation\n  * engine\n* date\n  * past\n  * future\n  * between\n  * recent\n  * soon\n  * month\n  * weekday\n* fake\n* finance\n  * account\n  * accountName\n  * mask\n  * amount\n  * transactionType\n  * currencyCode\n  * currencyName\n  * currencySymbol\n  * bitcoinAddress\n  * ethereumAddress\n  * iban\n  * bic\n* hacker\n  * abbreviation\n  * adjective\n  * noun\n  * verb\n  * ingverb\n  * phrase\n* helpers\n  * randomize\n  * slugify\n  * replaceSymbolWithNumber\n  * replaceSymbols\n  * shuffle\n  * mustache\n  * createCard\n  * contextualCard\n  * userCard\n  * createTransaction\n* image\n  * image\n  * avatar\n  * imageUrl\n  * abstract\n  * animals\n  * business\n  * cats\n  * city\n  * food\n  * nightlife\n  * fashion\n  * people\n  * nature\n  * sports\n  * technics\n  * transport\n  * dataUri\n* internet\n  * avatar\n  * email\n  * exampleEmail\n  * userName\n  * protocol\n  * url\n  * domainName\n  * domainSuffix\n  * domainWord\n  * ip\n  * ipv6\n  * userAgent\n  * color\n  * mac\n  * password\n* lorem\n  * word\n  * words\n  * sentence\n  * slug\n  * sentences\n  * paragraph\n  * paragraphs\n  * text\n  * lines\n* name\n  * firstName\n  * lastName\n  * findName\n  * jobTitle\n  * prefix\n  * suffix\n  * title\n  * jobDescriptor\n  * jobArea\n  * jobType\n* phone\n  * phoneNumber\n  * phoneNumberFormat\n  * phoneFormats\n* random\n  * number\n  * float\n  * arrayElement\n  * objectElement\n  * uuid\n  * boolean\n  * word\n  * words\n  * image\n  * locale\n  * alphaNumeric\n  * hexaDecimal\n* system\n  * fileName\n  * commonFileName\n  * mimeType\n  * commonFileType\n  * commonFileExt\n  * fileType\n  * fileExt\n  * directoryPath\n  * filePath\n  * semver\n\n\n## Localization\n\nAs of version `v2.0.0` faker.js has support for multiple localities.\n\nThe default language locale is set to English.\n\nSetting a new locale is simple:\n\n```js\n// sets locale to de\nfaker.setLocale(\"de\");\n// or\nfaker.locale = \"de\";\n```\n\n * az\n * cz\n * de\n * de_AT\n * de_CH\n * en\n * en_AU\n * en_BORK\n * en_CA\n * en_GB\n * en_IE\n * en_IND\n * en_US\n * en_ZA\n * en_au_ocker\n * es\n * es_MX\n * fa\n * fr\n * fr_CA\n * ge\n * id_ID\n * it\n * ja\n * ko\n * nb_NO\n * nep\n * nl\n * pl\n * pt_BR\n * pt_PT\n * ru\n * sk\n * sv\n * tr\n * uk\n * vi\n * zh_CN\n * zh_TW\n\n\n### Individual Localization Packages\n\nAs of vesion `v3.0.0` faker.js supports incremental loading of locales.\n\nBy default, requiring `faker` will include *all* locale data.\n\nIn a production environment, you may only want to include the locale data for a specific set of locales.\n\n```js\n// loads only de locale\nvar faker = require('faker/locale/de');\n```\n\n## Setting a randomness seed\n\nIf you want consistent results, you can set your own seed:\n\n```js\nfaker.seed(123);\n\nvar firstRandom = faker.random.number();\n\n// Setting the seed again resets the sequence.\nfaker.seed(123);\n\nvar secondRandom = faker.random.number();\n\nconsole.log(firstRandom === secondRandom);\n```\n\n## Tests\n\n    npm install .\n    make test\n\nYou can view a code coverage report generated in coverage/lcov-report/index.html.\n\n## Projects Built with faker.js\n\n### Fake JSON Schema\n\nUse faker generators to populate JSON Schema samples.\nSee: https://github.com/pateketrueke/json-schema-faker/\n\n### CLI\n\nRun faker generators from Command Line.\nSee: https://github.com/lestoni/faker-cli\n\n**Want to see your project added here? Let us know!**\n\n### Meteor\n\n#### Meteor Installation\n\n```\nmeteor add practicalmeteor:faker\n```\n\n#### Meteor Usage, both client and server\n\n```js\nvar randomName = faker.name.findName(); // Rowan Nikolaus\nvar randomEmail = faker.internet.email(); // Kassandra.Haley@erich.biz\nvar randomCard = faker.helpers.createCard(); // random contact card containing many properties\n```\n\n## Building faker.js\n\nfaker uses [gulp](http://gulpjs.com/) to automate its build process. Running the following build command will generate new browser builds, documentation, and code examples for the project.\n\n```\nnpm run-script build\n```\n\n## Building JSDocs\n\n```\nnpm run-script doc\n```\n\n## Version Release Schedule\n\nfaker.js is a popular project used by many organizations and individuals in production settings. Major and Minor version releases are generally on a monthly schedule. Bugs fixes are addressed by severity and fixed as soon as possible.\n\nIf you require the absolute latest version of `faker.js` the `master` branch @ http://github.com/marak/faker.js/ should always be up to date and working.\n\n## Maintainer\n\n#### Marak Squires\n\nfaker.js - Copyright (c) 2017\nMarak Squires\nhttp://github.com/marak/faker.js/\n\nfaker.js was inspired by and has used data definitions from:\n\n * https://github.com/stympy/faker/ - Copyright (c) 2007-2010 Benjamin Curtis\n * http://search.cpan.org/~jasonk/Data-Faker-0.07/ - Copyright 2004-2005 by Jason Kohles\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n## Backers\n\nSupport us with a monthly donation and help us continue our activities. [[Become a backer](https://opencollective.com/fakerjs#backer)]\n\n<a href=\"https://opencollective.com/fakerjs/backer/0/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/0/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/1/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/1/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/2/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/2/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/3/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/3/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/4/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/4/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/5/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/5/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/6/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/6/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/7/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/7/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/8/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/8/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/9/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/9/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/10/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/10/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/11/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/11/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/12/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/12/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/13/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/13/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/14/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/14/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/15/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/15/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/16/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/16/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/17/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/17/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/18/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/18/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/19/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/19/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/20/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/20/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/21/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/21/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/22/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/22/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/23/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/23/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/24/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/24/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/25/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/25/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/26/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/26/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/27/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/27/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/28/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/28/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/backer/29/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/backer/29/avatar.svg\"></a>\n\n## Sponsors\n\nBecome a sponsor and get your logo on our README on Github with a link to your site. [[Become a sponsor](https://opencollective.com/fakerjs#sponsor)]\n\n<a href=\"https://opencollective.com/fakerjs/sponsor/0/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/0/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/1/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/1/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/2/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/2/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/3/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/3/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/4/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/4/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/5/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/5/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/6/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/6/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/7/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/7/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/8/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/8/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/9/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/9/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/10/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/10/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/11/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/11/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/12/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/12/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/13/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/13/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/14/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/14/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/15/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/15/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/16/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/16/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/17/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/17/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/18/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/18/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/19/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/19/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/20/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/20/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/21/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/21/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/22/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/22/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/23/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/23/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/24/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/24/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/25/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/25/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/26/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/26/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/27/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/27/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/28/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/28/avatar.svg\"></a>\n<a href=\"https://opencollective.com/fakerjs/sponsor/29/website\" target=\"_blank\"><img src=\"https://opencollective.com/fakerjs/sponsor/29/avatar.svg\"></a>\n"}
{"url": "https://github.com/fahaddeshmukh/Question-pair-nlp", "owner": "fahaddeshmukh", "repository_name": "Question-pair-nlp", "date_all_variable_collection": "2023-09-11", "description": null, "size": 29822, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": true, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 3722273}], "readme": "# Semantic Duplicate Detection: Quora Question Pairs Analysis using Machine Learning\n\nThis repository contains files for a machine learning (ML)-based solution to the Quora Question Pairs problem, hosted on Kaggle. This challenge falls within the scope of natural language processing (NLP) and involves the task of identifying whether pairs of questions from the Quora platform are duplicates.\n\n## Directories\n\nThe project is structured as follows:\n\n- **bin**: This directory contains the source code files required to run the analysis.\n - `quora.ipynb`: This Jupyter Notebook file provides an alternative interface for running the analysis interactively. It contains the same code as `src.py` but provides easy accessablity along with a narrative.\n\n- **data**: This directory contains the dataset used for the analysis.\n  - `train.csv`: The CSV file that contains the original dataset, that contains questions. This file is required for running the analysis. Please ensure that it is located in this directory.\n\n- **docs**: This directory contains any documentation related to the project.\n- **plots**: This directory contains the EDA plots used for the analysis.\n## Installation\n\nTo use this script, you need to have Python installed on your system (3.8 or higher). You also need to install the required dependencies by running the following command:\n\n```\npip install -r requirements.txt\n```\n\n## Requirements\n\nThe script requires the following Python packages:\n\n- pandas\n- numpy\n- matplotlib\n- seaborn\n- scikit-learn\n- lightgbm\n- spacy\n- FuzzyWuzzy\n\nYou can install these packages by running the command mentioned in the \"Installation\" section.\n\n## License\n\nThis project is licensed under the MIT License. See the [LICENSE](LICENSE.md) file for details.\n\n## Citation Information\n\nCitation information for this project can be found in the Citation files in the directory.\nSee the [CITATION](CITATION.cff) file for details.\n## Contact Information\nFor any questions, suggestions, or issues, please feel free to contact:\n\n- Name: Fahad Deshmukh\n- Email: deshmukh@uni-potsdam.de\n"}
{"url": "https://github.com/fahaddeshmukh/RSE-project2", "owner": "fahaddeshmukh", "repository_name": "RSE-project2", "date_all_variable_collection": "2023-09-11", "description": null, "size": 684, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "fahaddeshmukh", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 990480}]}
{"url": "https://github.com/fahaddeshmukh/test", "owner": "fahaddeshmukh", "repository_name": "test", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "fahaddeshmukh", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/FalkMaximilian/lkm_list_mutex_timer", "owner": "FalkMaximilian", "repository_name": "lkm_list_mutex_timer", "date_all_variable_collection": "2023-09-11", "description": null, "size": 10, "stargazers_count": 0, "watchers_count": 0, "language": "C", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "FalkMaximilian", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C", "num_chars": 9494}, {"language": "Shell", "num_chars": 182}, {"language": "Makefile", "num_chars": 164}]}
{"url": "https://github.com/FalkMaximilian/ParallelProgramming", "owner": "FalkMaximilian", "repository_name": "ParallelProgramming", "date_all_variable_collection": "2023-09-11", "description": null, "size": 552, "stargazers_count": 0, "watchers_count": 0, "language": "C", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "FalkMaximilian", "contributions": 17}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C", "num_chars": 33660}, {"language": "Makefile", "num_chars": 644}, {"language": "Shell", "num_chars": 251}], "readme": "# ParallelProgramming\n\nIn this repository you can find several programs which are made parallel using different tools/methods.\n\nConcurrency:\n* pthreads\n* OpenMP\n* MPI\n\n"}
{"url": "https://github.com/FalkMaximilian/Penfactory", "owner": "FalkMaximilian", "repository_name": "Penfactory", "date_all_variable_collection": "2023-09-11", "description": "Software zum Management des Lagerbestandes der Penfactory", "size": 214, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "FalkMaximilian", "contributions": 21}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 82830}], "readme": "# Penfactory Lagerbestand-Management-Tool\nDiese Software mit GUI erm\u00f6glicht es der Penfactory ihren Lagerbestand zu verwalten.\n\n## Features:\n* Manuelles hinzuf\u00fcgen, bearbeiten und entfernen von Artikeln\n* Speichert im Lager vorhandene Anzahl einzelner Artikel\n* Speichert den Lagerbestand permanent\n* Erm\u00f6glicht die Suche nach Artikeln durch Name oder Kategorie\n\n"}
{"url": "https://github.com/FalkMaximilian/Python", "owner": "FalkMaximilian", "repository_name": "Python", "date_all_variable_collection": "2023-09-11", "description": "Some things done with python.", "size": 3, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "FalkMaximilian", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 6356}], "readme": "# Python\nSome things done with python.\n"}
{"url": "https://github.com/ff6347/.wilfred", "owner": "ff6347", "repository_name": ".wilfred", "date_all_variable_collection": "2023-09-11", "description": null, "size": 9, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 3213}, {"language": "HTML", "num_chars": 542}], "readme": ".wilfred folder\n==============\n\nCreating some boilerplates.  \n\n\n[https://github.com/michaelowens/wilfred](https://github.com/michaelowens/wilfred)\n\n\nCopyright (c) Jahr 2016, Fabian \"fabiantheblind\" Mor\u00f3n Zirfas\n\nPermission to use, copy, modify, and/or distribute this software for any\npurpose with or without fee is hereby granted, provided that the above\ncopyright notice and this permission notice appear in all copies.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES\nWITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF\nMERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR\nANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\nWHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\nACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF\nOR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.  \n\n"}
{"url": "https://github.com/ff6347/11EG-B-WS1314-bildspaziergang", "owner": "ff6347", "repository_name": "11EG-B-WS1314-bildspaziergang", "date_all_variable_collection": "2023-09-11", "description": "These sketch are part of the course [\"Eingabe, Ausgabe. Grundlagen der prozessorientierten Gestaltung\"](https://incom.org/workspace/4693) by Monika Hoinkis", "size": 330, "stargazers_count": 0, "watchers_count": 0, "language": "Processing", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 4, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 4, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "davidroettger", "contributions": 5}, {"contributor": "pfingstday", "contributions": 4}, {"contributor": "fabiantheblind", "contributions": 2}, {"contributor": "tomie89", "contributions": 2}, {"contributor": "Nushin", "contributions": 1}, {"contributor": "ebird-design", "contributions": 1}, {"contributor": "jensra", "contributions": 1}, {"contributor": "thrill2212", "contributions": 1}, {"contributor": "wookeeeee", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Processing", "num_chars": 6913}, {"language": "Shell", "num_chars": 1240}], "readme": "11EG-B-WS1314-bildspaziergang\n=============================\n\nThese sketch are part of the course [\"Eingabe, Ausgabe. Grundlagen der prozessorientierten Gestaltung\"](https://incom.org/workspace/4693) by Monika Hoinkis  \n\n###Results  \n\n[davidroettger](https://github.com/davidroettger)  \n![davidroettger/image](davidroettger/screenshot.png)  \n[thrill2212](https://github.com/thrill2212)  \n![thrill2212/image](thrill2212/screenshot.png)  \n[wookeeeee](https://github.com/wookeeeee)  \n![wookeeeee/image](wookeeeee/screenshot.png)  \n[martinlexow](https://github.com/martinlexow)  \n![martinlexow/image](martinlexow/screenshot.png)  \n[ronleisner](https://github.com/ronleisner)  \n![ronleisner/image](ronleisner/screenshot.png)  \n[tilokrueger](https://github.com/tilokrueger)  \n![tilokrueger/image](tilokrueger/screenshot.png)  \n[dueuel](https://github.com/dueuel)  \n![dueuel/image](dueuel/screenshot.png)  \n[pfingstday](https://github.com/pfingstday)  \n![pfingstday/image](pfingstday/screenshot.png)  \n[nushin](https://github.com/nushin)  \n![nushin/image](nushin/screenshot.png)  \n[jonij](https://github.com/jonij)  \n![jonij/image](jonij/screenshot.png)  \n[tomie89](https://github.com/tomie89)  \n![tomie89/image](tomie89/screenshot.png)  \n[jensra](https://github.com/jensra)  \n![jensra/image](jensra/screenshot.png)  \n[lightwaveez](https://github.com/lightwaveez)  \n![lightwaveez/image](lightwaveez/screenshot.png)  \n[sacred45](https://github.com/sacred45)  \n![sacred45/image](sacred45/screenshot.png)  \n[dasrehman](https://github.com/dasrehman)  \n![dasrehman/image](dasrehman/screenshot.png)  \n[ebird-design](https://github.com/ebird-design)  \n![ebird-design/image](ebird-design/screenshot.png)  \n\n##LICENSE  \nIf there is no other note by the author it is under MIT license  \nsee --> http://www.opensource.org/licenses/mit-license.php\n\n\n"}
{"url": "https://github.com/ff6347/11EG-B-WS1314-bildspaziergang-gpx-data", "owner": "ff6347", "repository_name": "11EG-B-WS1314-bildspaziergang-gpx-data", "date_all_variable_collection": "2023-09-11", "description": "the collection of all gpx data. This data is part of the course [\"Eingabe, Ausgabe. Grundlagen der prozessorientierten Gestaltung\"](https://incom.org/workspace/4693) by Monika Hoinkis", "size": 202, "stargazers_count": 0, "watchers_count": 0, "language": "Processing", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Nushin", "contributions": 3}, {"contributor": "fabiantheblind", "contributions": 3}, {"contributor": "jonij", "contributions": 3}, {"contributor": "tomie89", "contributions": 2}, {"contributor": "davidroettger", "contributions": 1}, {"contributor": "pfingstday", "contributions": 1}, {"contributor": "jensra", "contributions": 1}, {"contributor": "sacred45", "contributions": 1}, {"contributor": "wookeeeee", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 2069}], "readme": "11EG-B-WS1314-bildspaziergang-gpx-data\n======================================\n\nthe collection of all gpx data\n\nThis data is part of the course [\"Eingabe, Ausgabe. Grundlagen der prozessorientierten Gestaltung\"](https://incom.org/workspace/4693) by Monika Hoinkis  \n\n##License  \nCopyright (c) lies by the respective authors as in the folder names\nIf not further noticed under MIT License  \n \nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software  without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to  permit persons to whom the Software is furnished to do so, subject to the following conditions:  \nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.  \nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A  PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF  CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  \n\nsee also http://www.opensource.org/licenses/mit-license.php\n\n"}
{"url": "https://github.com/ff6347/3d-earth-locations-aep", "owner": "ff6347", "repository_name": "3d-earth-locations-aep", "date_all_variable_collection": "2023-09-11", "description": "This is the repo to my After Effects 3D Locations Tutorial", "size": 1032, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "#After Effects 3D Locations Tutorial  \nThis tutorial will show you how to use VC Element and Locations.jsx to create a Globe in 3D space with a geo marker and text overlay.  \n\n0 . Prerequisites\n- [AE CS 4+](http://www.adobe.com/products/aftereffects.html)  \n- [Videocopilot Element](https://www.videocopilot.net/products/element/)  \n- [Sublime Text 2](http://www.sublimetext.com)  \n- [Locations Script](http://aescripts.com/locations/)  \n- [AEMap Script](http://aescripts.com/aemap/)  \n- [Zorro Script](http://aescripts.com/zorro-the-layer-tagger/)  \n- (optional) [Optical Flares](https://www.videocopilot.net/products/opticalflares/) / [Knoll Light Factory](http://www.redgiantsoftware.com/products/all/knoll-light-factory/) / or other 3D flare generator  \n\n1 . Get the Data  \n- [Natural Earth](http://www.shadedrelief.com/natural3/pages/textures.html) by Tom Patterson  \n- NASA VIIRS [Earth At Night](http://earthobservatory.nasa.gov/NaturalHazards/view.php?id=79765)  \n- [VideoCopilot 3D Earth](http://www.videocopilot.net/blog/2012/08/free-earth-project-for-element-3d/)  \n- [Moon](http://www.celestiamotherlode.net/catalog/show_creator_details.php?creator_id=205) by Philip Iveic  \n- [Sun](http://www.celestiamotherlode.net/catalog/sol.php) by Frank Gregorio  \n- [US State Capitals Geocommos](http://geocommons.com/overlays/165342)  \n\n\n##For The Nerds  \n\n1. Create bigger normal Map  \n2. Get Geo Data from geoTiff  \n\n-----------------  \n\n###Normal Maps  \nUse [normal-map](https://github.com/sinisterchipmunk/normal-map) by sinisterchipmunk  \n> Command line tool and Ruby library for generating normal maps.  \n> Generates DOT3 bump maps, also known as normal maps, for use in 3D computing.  \nby sinisterchipmunk\nWorks fine! Cool thing.  \n[github Link](https://github.com/sinisterchipmunk/normal-map)  \nMAC Requirements  \nneeds XCode and Command Line Tools installed, [rmagick](http://rmagick.rubyforge.org) which needs [ImageMagick](http://www.imagemagick.org/script/index.php):\n    \n    sudo port install ImageMagick  \n\nthan  \n\n    sudo gem install rmagick  \n\n if the installation of ImageMagick fails it helped for me to fully uninstall zlib and jpeg using:    \n    \n    # clean out zlib  \n    port clean --all zlib  \n    sudo port clean --all zlib  \n    sudo port install zlib  \n    \n    # clean out jpeg\n    port clean --all jpeg  \n    sudo port clean --all jpeg  \n    sudo port install jpeg  \n\n\n###Geo Data from geoTiff  \n\nuse this python script readgeoinfo.py  \n\n\n    !/usr/bin/env python    \n    from sys import argv    \n    from osgeo import gdal    \n    filetoread = argv    \n    # print type(filetoread)    \n    ds = gdal.Open(filetoread[1])    \n    width = ds.RasterXSize    \n    height = ds.RasterYSize    \n    gt = ds.GetGeoTransform()    \n    minx = gt[0]    \n    miny = gt[3] + width * gt[4] + height * gt[5]    \n    maxx = gt[0] + width * gt[1] + height * gt[2]    \n    maxy = gt[3]\n    \n    if not gt is None:\n        print 'Origin = (', gt[0] , ',', gt[3] ,')'\n        print 'Pixel Size = (', gt[1] , ',', gt[5] , ')'\n        print ''\n        print 'min X = ',minx\n        print 'min Y = ', miny\n        print ''\n        print 'max X = ' , maxx\n        print 'max Y = ' , maxy\n\n"}
{"url": "https://github.com/ff6347/actions-playground", "owner": "ff6347", "repository_name": "actions-playground", "date_all_variable_collection": "2023-09-11", "description": "repo to test actions triggering", "size": 8, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 14}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Playing with actions\n\nTest"}
{"url": "https://github.com/ff6347/ae-comps-to-graphviz", "owner": "ff6347", "repository_name": "ae-comps-to-graphviz", "date_all_variable_collection": "2023-09-11", "description": "Export flow of current comp to graphviz", "size": 244, "stargazers_count": 2, "watchers_count": 2, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1121}], "readme": "ae comps to graphviz\n====================\n\nExport flow of current comp to [graphviz](http://graphviz.org/)  \n\n![](comp.png)  \nImage created with [Omnigraffle](http://www.omnigroup.com/omnigraffle/)  \n\n    digraph {\n        \"Comp 1\" -> \"Comp 2\";\n        \"Comp 2\" -> \"Black Solid 3 Comp 1\";\n        \"Black Solid 3 Comp 1\" -> \"Black Solid 3\";\n        \"Comp 2\" -> \"Black Solid 2\";\n        \"Comp 2\" -> \"Black Solid 1\";\n        \"Comp 2\" -> \"Comp 3\";\n        \"Comp 3\" -> \"Null 1\";\n        \"Comp 1\" -> \"Black Solid 3 Comp 1\";\n        \"Comp 1\" -> \"Comp 3\";\n    }\n\n####install graphviz with homebrew\n\n    brew install graphviz  \n\nexport image:  \n\n      dot -Tpng comp.dot -o raw-comp.png; open raw-comp.png\n\n####Graphviz export  \n\n![](raw-graphviz-output.png)  \n\n####comps only export  \n\u2026   \n![](comps-only.png)  \n##Todo:  \n\n- fix recursion (not working correctly, double entries in array)\n- add label if comp, layer, camera, light, text or or or\n- exclude layer option\n- ...\n\nCopyright 2014 Fabian \"fabiantheblind\" Mor\u00f3n Zirfas\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:  \n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.  \n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.  \n\n\n"}
{"url": "https://github.com/ff6347/AEMap-footage", "owner": "ff6347", "repository_name": "AEMap-footage", "date_all_variable_collection": "2023-09-11", "description": null, "size": 476, "stargazers_count": 2, "watchers_count": 2, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "AEMap-footage\n=============\n\nfootage created from AEMap Data\n\nThese files are created with [AEMap](http://aescripts.com/aemap/) and they are like the [world.geo.json](https://github.com/johan/world.geo.json) UNLICENSED \n\nUnless otherwise noted in individual files or directories, this is\nfree and unencumbered software released into the public domain.\n\nAnyone is free to copy, modify, publish, use, compile, sell, or\ndistribute this software, either in source code form or as a compiled\nbinary, for any purpose, commercial or non-commercial, and by any\nmeans.\n\nIn jurisdictions that recognize copyright laws, the author or authors\nof this software dedicate any and all copyright interest in the\nsoftware to the public domain. We make this dedication for the benefit\nof the public at large and to the detriment of our heirs and\nsuccessors. We intend this dedication to be an overt act of\nrelinquishment in perpetuity of all present and future rights to this\nsoftware under copyright law.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR\nOTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,\nARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\nOTHER DEALINGS IN THE SOFTWARE.\n\nFor more information, please refer to <http://unlicense.org/> "}
{"url": "https://github.com/ff6347/AEMap-Utilities.jsx", "owner": "ff6347", "repository_name": "AEMap-Utilities.jsx", "date_all_variable_collection": "2023-09-11", "description": "AEMap-Utilities.jsx util scripts for AEMap", "size": 140, "stargazers_count": 3, "watchers_count": 3, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 33308}], "readme": "AEMap-Utilities.jsx\n===================\n\nAEMap-Utilities.jsx util scripts for AEMap\n"}
{"url": "https://github.com/ff6347/AESettingsControl", "owner": "ff6347", "repository_name": "AESettingsControl", "date_all_variable_collection": "2023-09-11", "description": "A Extendscript Class for controlling AE Settings", "size": 128, "stargazers_count": 6, "watchers_count": 6, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 6, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 5830}], "readme": "AESettingsControl\n=================\n\nA Extendscript Class for controlling AE Settings  \nCheck out [this example script](https://github.com/fabiantheblind/after-effects-script-snippets/blob/master/set-get-settings.jsx) to see how to use it  \n\nCopyright (c)  2013 Fabian \"fabiantheblind\" Mor\u00f3n Zirfas  \nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software  without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to  permit persons to whom the Software is furnished to do so, subject to the following conditions:  \nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.  \nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A  PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF  CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  \n\nsee also http://www.opensource.org/licenses/mit-license.php\n\n"}
{"url": "https://github.com/ff6347/after-effects-script-snippets", "owner": "ff6347", "repository_name": "after-effects-script-snippets", "date_all_variable_collection": "2023-09-11", "description": "this is a loose collection of js snippets for After Effects ", "size": 75, "stargazers_count": 157, "watchers_count": 157, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 34, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 34, "open_issues": 0, "watchers": 157, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 76203}], "readme": "after-effects-script-snippets\n=============================\n\nthis is a loose collection of js snippets for After Effects\n\n##Autogenerated TOC  \n###[__movetotop.jsx](https://raw.github.com/fabiantheblind/after-effects-script-snippets/master/__movetotop.jsx)  \n/**\n * @author fabiantheblind\n * @description moves all selected layers to the top of the comp\n *\n *\n * @todo [description]\n */\n\n--------------  \n\n###[add-text.jsx](https://raw.github.com/fabiantheblind/after-effects-script-snippets/master/add-text.jsx)  \n\ufeff/**\n * @author fabiantheblind\n * @description add textlayers from string.\n * layers will be splitted by whitespaces\n *\n * @todo [description]\n */\n\n--------------  \n\n###[automagically-sort-layers-by-name.jsx](https://raw.github.com/fabiantheblind/after-effects-script-snippets/master/automagically-sort-layers-by-name.jsx)  \n\ufeff/**\n * This script tries to sort layers by name\n * more a proof of concept thingy\n * using this technique can hold some problems\n * - in this case the \"et\" gets found in \"consectetur\" \"et\" \"amet\"\n * - the last matching pattern will be the one that gets executed\n */\n\n--------------  \n\n###[automagically-sort-selectedlayers-by-name.jsx](https://raw.github.com/fabiantheblind/after-effects-script-snippets/master/automagically-sort-selectedlayers-by-name.jsx)  \n\ufeff/**\n * This script tries to sort layers by name\n * more a proof of concept thingy\n * using this technique can hold some problems\n * - in this case the \"et\" gets found in \"consectetur\" \"et\" \"amet\"\n * - the last matching pattern will be the one that gets executed\n */\n\n--------------  \n\n###[comp_with_text.jsx](https://raw.github.com/fabiantheblind/after-effects-script-snippets/master/comp_with_text.jsx)  \n\ufeff/**\n * @author fabiantheblind\n * @description should create comps from a csv file\n *\n *\n * @todo check if it works\n */\n\n--------------  \n\n###[connect-with-path.jsx](https://raw.github.com/fabiantheblind/after-effects-script-snippets/master/connect-with-path.jsx)  \n\ufeff/**\n * @author fabiantheblind\n * @description tries to connect selected layers with a path\n *\n *\n * @todo get also parented position and position with expressions\n */\n\n--------------  \n\n###[cycle-labels.jsx](https://raw.github.com/fabiantheblind/after-effects-script-snippets/master/cycle-labels.jsx)  \n\ufeff/**\n * @author fabiantheblind\n * @description cycle thru label colors\n * this is CS6+ feature I think\n *\n * @todo [description]\n */\n\n--------------  \n\n###[disable-expression.jsx](https://raw.github.com/fabiantheblind/after-effects-script-snippets/master/disable-expression.jsx)  \n\ufeff/**\n * @author fabiantheblind\n * @description enable expression\n *\n *\n * @todo [description]\n */\n\n--------------  \n\n###[distort-rotate-at-time.jsx](https://raw.github.com/fabiantheblind/after-effects-script-snippets/master/distort-rotate-at-time.jsx)  \n\ufeff/**\n * @author fabiantheblind\n * @description Distord rotation keyframes at a certain time\n *\n *\n * @todo [description]\n */\n\n--------------  \n\n###[duplicate_layer.jsx](https://raw.github.com/fabiantheblind/after-effects-script-snippets/master/duplicate_layer.jsx)  \n\ufeff/**\n * @author fabiantheblind\n * @description duplicates a layer 99 times\n *\n *\n * @todo [description]\n */\n\n--------------  \n\n###[project_selection_to_grid.jsx](https://raw.github.com/fabiantheblind/after-effects-script-snippets/master/project_selection_to_grid.jsx)  \n\ufeff/**\n * @author fabiantheblind\n * @description creates from the selected layer in the project panel a grind in te current comp\n *\n *\n * @todo [description]\n */\n\n--------------  \n\n###[randomOrderSelectedLayers.jsx](https://raw.github.com/fabiantheblind/after-effects-script-snippets/master/randomOrderSelectedLayers.jsx)  \n\ufeff/**\n * @author Dan Ebberts\n * @description randomize order of layers\n * random order found on: http://forums.creativecow.net/thread/227/10609\n * by Dan Ebberts\n * @todo [description]\n */\n\n--------------  \n\n###[rename-layers-with-padded-number.jsx](https://raw.github.com/fabiantheblind/after-effects-script-snippets/master/rename-layers-with-padded-number.jsx)  \n\ufeff/**\n * @author fabiantheblind\n * @description pad all layernames\n *\n *\n * @todo [description]\n */\n\n--------------  \n\n###[rename-layers.jsx](https://raw.github.com/fabiantheblind/after-effects-script-snippets/master/rename-layers.jsx)  \n/**\n * @author fabiantheblind\n * @description rename selected layers with number\n * this happens in comp and project panel\n *\n *\n * @todo catch error if layer as no source\n\n--------------  \n\n###[select-all-masks-on laayer.jsx](https://raw.github.com/fabiantheblind/after-effects-script-snippets/master/select-all-masks-on laayer.jsx)  \n\ufeff/**\n * @author redefinery with some edits by fabiantheblind\n * @description select all masks on layer\n * take a look into the fundamentals\n * http://www.redefinery.com/ae/fundamentals/\n * @todo [description]\n */\n\n--------------  \n\n###[set-get-settings.jsx](https://raw.github.com/fabiantheblind/after-effects-script-snippets/master/set-get-settings.jsx)  \n\ufeff/**\n * @author fabiantheblind\n * @description this is a AE Settings Class\n *\n *\n * @todo implement features like Array and Object saving\n */\n\n--------------  \n\n###[sort_text_layers_by_content.jsx](https://raw.github.com/fabiantheblind/after-effects-script-snippets/master/sort_text_layers_by_content.jsx)  \n\ufeff/**\n * @author fabiantheblind\n * @description this sorts layers by their content\n *\n *\n * @todo [description]\n */\n\n--------------  \n\n###[text_to_comp.jsx](https://raw.github.com/fabiantheblind/after-effects-script-snippets/master/text_to_comp.jsx)  \n/**\n * @author fabiantheblind\n * @description adds text to a comp with UI\n *\n *\n * @todo check if it works\n */\n\n--------------  \n\n"}
{"url": "https://github.com/ff6347/agent", "owner": "ff6347", "repository_name": "agent", "date_all_variable_collection": "2023-09-11", "description": "Art direction Hektor U. programming me.", "size": 977, "stargazers_count": 1, "watchers_count": 1, "language": "Processing", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Processing", "num_chars": 1610}], "readme": "# Agent\n\nArt direction Hektor U. programming me. \n\n![](agent.gif)  "}
{"url": "https://github.com/ff6347/AI-connectedNodes", "owner": "ff6347", "repository_name": "AI-connectedNodes", "date_all_variable_collection": "2023-09-11", "description": "create connected nodes in illustrator. Nuff said?", "size": 219, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 12283}], "readme": "#create connected nodes in illustrator. Nuff said?\n  \nunder MIT License  \nCopyright (c)  2012 Fabian \"fabiantheblind\" Mor\u00f3n Zirfas  \nPermission is hereby granted, free of charge, to any person obtaining a copy of this\nsoftware and associated documentation files (the \"Software\"), to deal in the Software \nwithout restriction, including without limitation the rights to use, copy, modify, \nmerge, publish, distribute, sublicense, and/or sell copies of the Software, and to \npermit persons to whom the Software is furnished to do so, subject to the following \nconditions:  \nThe above copyright notice and this permission notice shall be included in all copies \nor substantial portions of the Software.  \nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, \nINCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A \nPARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT \nHOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF \nCONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE \nOR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  \n  \nsee also [http://www.opensource.org/licenses/mit-license.php](http://www.opensource.org/licenses/mit-license.php)  \n"}
{"url": "https://github.com/ff6347/alfred-color-names", "owner": "ff6347", "repository_name": "alfred-color-names", "date_all_variable_collection": "2023-09-11", "description": "Paste named CSS colors into the frontmost app", "size": 256, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 4, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 4, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 9}, {"contributor": "renovate-bot", "contributions": 5}, {"contributor": "dependabot[bot]", "contributions": 4}, {"contributor": "renovate[bot]", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 370}], "readme": "# Alfred Color Names\n\nCMD: Copy the Names (default)\nALT: Copy the HEX value\n\n## Downloads  \n\nDownload the workflow here:\n\n- [v0.1.0](https://github.com/fabianmoronzirfas/alfred-color-names/releases/download/0.1.0/color-names-workflow-v0.1.0.zip)\n  \n## License\n\nCopyright 2018 Fabian Mor\u00f3n Zirfas\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"}
{"url": "https://github.com/ff6347/alfred-duckduckgo-bangs", "owner": "ff6347", "repository_name": "alfred-duckduckgo-bangs", "date_all_variable_collection": "2023-09-11", "description": "A Alfred workflow to insert !bangs (around 13505) into the frontmost app. ", "size": 2457, "stargazers_count": 1, "watchers_count": 1, "language": "TypeScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 12, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 12, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 24}, {"contributor": "renovate-bot", "contributions": 19}, {"contributor": "renovate[bot]", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TypeScript", "num_chars": 927}], "readme": "# Alfred DuckDuckGo Bangs\n\n![gif of the alfred wf](alfred-duckduckgo-bangs.gif)\n\nAlfred DDG workflow to trigger bangs from `;;bangs` snippet or `bangs` keyword. Will be pasted into the frontmost app. Bangs are aggregated from [https://duckduckgo.com/bang_lite.html](https://duckduckgo.com/bang_lite.ht).\n\n## Downloads\n\nDownload the latest release version [here](https://github.com/fabianmoronzirfas/alfred-duckduckgo-bangs/releases) "}
{"url": "https://github.com/ff6347/ama", "owner": "ff6347", "repository_name": "ama", "date_all_variable_collection": "2023-09-11", "description": "Ask me anything. (Maybe I'll answer)", "size": 2, "stargazers_count": 1, "watchers_count": 1, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "The Unlicense", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# A.M.A.\nAsk me anything [\u21d2 there](https://github.com/fabianmoronzirfas/ama/issues) (Maybe I'll answer)\n"}
{"url": "https://github.com/ff6347/analogio", "owner": "ff6347", "repository_name": "analogio", "date_all_variable_collection": "2023-09-11", "description": "Sketches for teaching arduino analog input output @FH-Potsdam", "size": 11472, "stargazers_count": 2, "watchers_count": 2, "language": "Arduino", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 3, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 3, "open_issues": 1, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Arduino", "num_chars": 20625}, {"language": "C", "num_chars": 3902}, {"language": "Python", "num_chars": 2013}], "readme": "analogio\n========\n\nThese sketches are part of the course [\"Input Output (Eingabe Ausgabe)Fundamentals of process-oriented design.\"](https://interface.fh-potsdam.de/eingabe-ausgabe/)  \n\nIn the repository for the digital input output [github.com/fabiantheblind/digitalio](https://github.com/fabiantheblind/digitalio) we have example for the Raspberry Pi and for Arduino. Unfortunately the analog io capabilities of the Pi are limited. We can have soft and hard PWM but thats it. We have no ADC (analog to digital converter). So having an analog input is not possible. You can have an Arduino talking to your pi via serial. For some examples how to do this take a look into [github.com/fabiantheblind/c2c](https://github.com/fabiantheblind/c2c).  \n\n##License  \nIf not further noted  \n\nThis is free and unencumbered software released into the public domain.  \n\nAnyone is free to copy, modify, publish, use, compile, sell, or distribute this software, either in source code form or as a compiled binary, for any purpose, commercial or non-commercial, and by any means.  \n\nIn jurisdictions that recognize copyright laws, the author or authors of this software dedicate any and all copyright interest in the software to the public domain. We make this dedication for the benefit of the public at large and to the detriment of our heirs and successors. We intend this dedication to be an overt act of relinquishment in perpetuity of all present and future rights to this software under copyright law.  \n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  \n\nFor more information, please refer to <http://unlicense.org>  \n"}
{"url": "https://github.com/ff6347/anscombe-quartet-in-cran", "owner": "ff6347", "repository_name": "anscombe-quartet-in-cran", "date_all_variable_collection": "2023-09-11", "description": "Plotting Anscombe's quartet in R", "size": 357, "stargazers_count": 1, "watchers_count": 1, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}, {"contributor": "fabiantheblind", "contributions": 1}, {"contributor": "renovate-bot", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 6016}, {"language": "HTML", "num_chars": 3365}, {"language": "TeX", "num_chars": 964}], "readme": "anscombe-quartet-in-cran\n========================\n\nPlotting Anscombe's quartet in R\n\n> Anscombe's quartet comprises four datasets that have nearly identical simple statistical properties, yet appear very different when graphed. Each dataset consists of eleven (x,y) points. They were constructed in 1973 by the statistician Francis Anscombe to demonstrate both the importance of graphing data before analyzing it and the effect of outliers on statistical properties.\n> [wikipedia](https://en.wikipedia.org/wiki/Anscombe%27s_quartet)\n\n    +------+------+------+------+-------+------+-------+------+\n    |  x1  |  x2  |  x3  |  x4  |  y1   |  y2  |  y3   |  y4  |\n    +======+======+======+======+=======+======+=======+======+\n    |  10  |  10  |  10  |  8   | 8.04  | 9.14 | 7.46  | 6.58 |\n    +------+------+------+------+-------+------+-------+------+\n    |  8   |  8   |  8   |  8   | 6.95  | 8.14 | 6.77  | 5.76 |\n    +------+------+------+------+-------+------+-------+------+\n    |  13  |  13  |  13  |  8   | 7.58  | 8.74 | 12.74 | 7.71 |\n    +------+------+------+------+-------+------+-------+------+\n    |  9   |  9   |  9   |  8   | 8.81  | 8.77 | 7.11  | 8.84 |\n    +------+------+------+------+-------+------+-------+------+\n    |  11  |  11  |  11  |  8   | 8.33  | 9.26 | 7.81  | 8.47 |\n    +------+------+------+------+-------+------+-------+------+\n    |  14  |  14  |  14  |  8   | 9.96  | 8.1  | 8.84  | 7.04 |\n    +------+------+------+------+-------+------+-------+------+\n    |  6   |  6   |  6   |  8   | 7.24  | 6.13 | 6.08  | 5.25 |\n    +------+------+------+------+-------+------+-------+------+\n    |  4   |  4   |  4   |  19  | 4.26  | 3.1  | 5.39  | 12.5 |\n    +------+------+------+------+-------+------+-------+------+\n    |  12  |  12  |  12  |  8   | 10.84 | 9.13 | 8.15  | 5.56 |\n    +------+------+------+------+-------+------+-------+------+\n    |  7   |  7   |  7   |  8   | 4.82  | 7.26 | 6.42  | 7.91 |\n    +------+------+------+------+-------+------+-------+------+\n    |  5   |  5   |  5   |  8   | 5.68  | 4.74 | 5.73  | 6.89 |\n    +------+------+------+------+-------+------+-------+------+\n\n![](output.png)  "}
{"url": "https://github.com/ff6347/apple-mail-list-sender", "owner": "ff6347", "repository_name": "apple-mail-list-sender", "date_all_variable_collection": "2023-09-11", "description": "trying to build own blacklist and whitelists by selection", "size": 120, "stargazers_count": 0, "watchers_count": 0, "language": "AppleScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "AppleScript", "num_chars": 1919}], "readme": "apple-mail-list-sender\n======================\n\ntrying to build own blacklist and whitelists by selection"}
{"url": "https://github.com/ff6347/ask-me-anything", "owner": "ff6347", "repository_name": "ask-me-anything", "date_all_variable_collection": "2023-09-11", "description": "A place where you an ask me questions", "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# ask-me-anything\nA [place](https://github.com/fabiantheblind/ask-me-anything/issues) where you an ask me questions\n"}
{"url": "https://github.com/ff6347/atom-run-in-indesign", "owner": "ff6347", "repository_name": "atom-run-in-indesign", "date_all_variable_collection": "2023-09-11", "description": "a starter to run scripts from Atom in InDesign WIP", "size": 10, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 2, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 5569}, {"language": "CSS", "num_chars": 243}], "readme": "# atom-run-in-indesign package\na starter to run scripts from Atom in InDesign WIP\n"}
{"url": "https://github.com/ff6347/AudioScanner", "owner": "ff6347", "repository_name": "AudioScanner", "date_all_variable_collection": "2023-09-11", "description": "Does not scan audio", "size": 412, "stargazers_count": 0, "watchers_count": 0, "language": "Processing", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Processing", "num_chars": 3336}], "readme": "AudioScanner\n============\n\n*Does not scan audio*  \n\nThis is a rough visualization for a student project @FH-Potsdam  \n\n![](screenshot.png)  \n##License  \n\nCopyright (c)  2015 Fabian \"fabiantheblind\" Mor\u00f3n Zirfas  \nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software  without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to  permit persons to whom the Software is furnished to do so, subject to the following conditions:  \nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.  \nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A  PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF  CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  \n\nsee also http://www.opensource.org/licenses/mit-license.php\n\n\n"}
{"url": "https://github.com/ff6347/auto-typo-adbe-id", "owner": "ff6347", "repository_name": "auto-typo-adbe-id", "date_all_variable_collection": "2023-09-11", "description": "This is the code repository for the FH-Potsdam ;-\u27e9 project week \"Typografie und Automation\"", "size": 38975, "stargazers_count": 24, "watchers_count": 24, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 6, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 6, "open_issues": 0, "watchers": 24, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 8}, {"contributor": "PDXIII", "contributions": 8}, {"contributor": "ce0311", "contributions": 4}, {"contributor": "felixharle", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 269935}, {"language": "Shell", "num_chars": 5167}, {"language": "Python", "num_chars": 851}], "readme": "auto-typo-adbe-id\n=================\n\n\nThis is the code repository for the FH-Potsdam ;-\u27e9 project week [\"Typography & Automation\"](http://fabiantheblind.github.com/Typography-And-Automation/). For further info have a look into [the wiki](https://github.com/fabiantheblind/auto-typo-adbe-id/wiki).  \n=======\n![splash](https://raw.github.com/fabiantheblind/auto-typo-adbe-id/gh-pages/assets/images/teaser/a_auto-typo.png)  \nThis is the code repository for the FH-Potsdam ;-\u27e9 project week \"Typography & Automation\".\nThe goal was to learn the basics of JavaScript for Adobe applications to apply this in automated layouts and generative art. Bring raw text into shape by rules.  \n  \nThe project begun with an introduction to JavaScript and how it works with InDesign, then project and idea development to follow in individual and group meetings. At the end there was a short presentations. For further info have a look into [the wiki](https://github.com/fabiantheblind/auto-typo-adbe-id/wiki).    \n##Results  \nThe results will be generated from the projects the contributers create.  \n\n##Submodules  \nFor some of the results there is also a git submodule included. This is the link to the original repo where the code my be developed further.  \n\n##Known Issues and To-Dos  \nIn a lot of these scripts the authors used specific fonts. So you have to change the fonts to make them work properly.  \nAlso there could be some issues with pointSize if you use diffrent fonts. Keep a eye on that. If you run into any problems add an [issue over here](https://github.com/fabiantheblind/auto-typo-adbe-id/issues) and we will get back to you with a fix. \n\n##Licenses  \n\nCopyright (c)  2012 Auto-Typo-Adbe-Id Team  \nIf not further noticed all code is under MIT License  \nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software  without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to  permit persons to whom the Software is furnished to do so, subject to the following conditions:  \nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.  \nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A  PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF  CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  \n\nsee also http://www.opensource.org/licenses/mit-license.php\n\n\n\n"}
{"url": "https://github.com/ff6347/automate-build", "owner": "ff6347", "repository_name": "automate-build", "date_all_variable_collection": "2023-09-11", "description": "testing automated build", "size": 6, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 2, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "traviscibot", "contributions": 2}, {"contributor": "ff6347", "contributions": 2}, {"contributor": "renovate-bot", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["travis-ci"], "languages": [{"language": "JavaScript", "num_chars": 258}, {"language": "HTML", "num_chars": 93}], "readme": "# automate-build\ntesting automated build\n\n- first build test\n- second build test\n- third test"}
{"url": "https://github.com/ff6347/aWordpress-ChildTheme", "owner": "ff6347", "repository_name": "aWordpress-ChildTheme", "date_all_variable_collection": "2023-09-11", "description": "abandonware", "size": 464, "stargazers_count": 0, "watchers_count": 0, "language": "CSS", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "CSS", "num_chars": 288910}, {"language": "PHP", "num_chars": 46625}, {"language": "JavaScript", "num_chars": 6189}], "readme": "aWordpress-ChildTheme\n=====================\n\nabandonware\n"}
{"url": "https://github.com/ff6347/basic-graphs-in-cran", "owner": "ff6347", "repository_name": "basic-graphs-in-cran", "date_all_variable_collection": "2023-09-11", "description": "Building basic graphs with ggplot", "size": 2676, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 5690}], "readme": "basic graphs in cran\n====================\n\nBuilding basic graphs with ggplot\n\nMostly taken from the web and the [R Graphics Cookbook](http://shop.oreilly.com/product/0636920023135.do)  \n\nall rights to their respectfull owners  \n\n![](all-plots.png)  "}
{"url": "https://github.com/ff6347/basil-projects-jekyll-poc", "owner": "ff6347", "repository_name": "basil-projects-jekyll-poc", "date_all_variable_collection": "2023-09-11", "description": "A proof of concept", "size": 7, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 1, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 1803}, {"language": "CSS", "num_chars": 616}, {"language": "JavaScript", "num_chars": 47}], "readme": "Basil.js Projects with Jekyll\n=============================\n\nThis is a proof of concept for creating a simple structure where users can submit projects that can be parsed with Jekyll.  \n\n## Structure\n\nThe folder and file structure for a project should be as simple as possible. It could be like this:  \n\n    projects/example/\n    \u251c\u2500\u2500 images\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 boom.png\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 canvas.png\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 foobah.png\n    \u251c\u2500\u2500 index.js\n    \u2514\u2500\u2500 index.md\n\n- The images folder can contain as many images as the user wants.\n- The index.js contains the code for the project. It must be one file currently and it has to be named index.js\n- The index.md contains a YAML header to discribe the project and some additional text if the user feels to write something about it.  \n\n## YAML Header\n\nThis is the only point where errors might occur. If something is typed wrong it might produce errors. It ould be like this:  \n\n    ---\n    # The name for the layout to use\n    # should always be project\n    layout: project\n    # The title for this project\n    # needs to be in \"\"\n    title: \"This is my funky Basil.js project\"\n    # we could also add things like\n    # authors: \n    #    - \"Bugs Bunny\"\n    #    - \"Duffy Duck\"\n    # Or even contact or URLs\n    # The type. This is for identifying project pages\n    type: project\n    # All the images that are in the images folder that should be displayed\n    images:\n        - \"boom.png\"\n        - \"canvas.png\"\n        - \"foobah.png\"\n    # A short summery of the project\n    summary: \"This is a short summary of my funky basil.js Project\"\n    ---\n\nOf course the above yaml header has lots of comments. A boiled down version would look like [this](https://raw.githubusercontent.com/fabianmoronzirfas/basil-projects-jekyll-poc/master/projects/example/index.md).  \n\nTo be continued (eventually)\n\n## License\n\nCopyright (c)  2017 Fabian Mor\u00f3n Zirfas  \nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software  without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to  permit persons to whom the Software is furnished to do so, subject to the following conditions:  \nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.  \nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A  PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF  CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  \n\nsee also http://www.opensource.org/licenses/mit-license.php\n\n"}
{"url": "https://github.com/ff6347/basil.js.user", "owner": "ff6347", "repository_name": "basil.js.user", "date_all_variable_collection": "2023-09-11", "description": "My basil.js user folder http://basiljs.ch", "size": 132, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 607}], "readme": "basil.js.user\n=============\n\nMy basil.js user folder http://basiljs.ch\n"}
{"url": "https://github.com/ff6347/batch-find-and-replace", "owner": "ff6347", "repository_name": "batch-find-and-replace", "date_all_variable_collection": "2023-09-11", "description": "This is a Adobe InDesign script for batch processing FNR xmls", "size": 1644, "stargazers_count": 18, "watchers_count": 18, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 9, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 9, "watchers": 18, "default_branch": "master", "contributors": [{"contributor": "renovate-bot", "contributions": 5}, {"contributor": "ff6347", "contributions": 5}, {"contributor": "fabiantheblind", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 58421}, {"language": "Shell", "num_chars": 149}], "readme": "batch-find-and-replace\n======================\n\nThis is a Adobe InDesign script for batch processing find and replace xmls. You can process\nGREP, TEXT, GLYPH and OBJECT searches.  \n@author: fabiantheblind  \n@version: 0.1.4  \n\n<!-- toc -->\n\n* [Download](#download)\n* [Purpouse](#purpouse)\n* [files](#files)\n* [prerequisites](#prerequisites)\n* [Usage](#usage)\n* [TOML](#toml)\n  * [MUST HAVE Settings](#must-have-settings)\n  * [CAN HAVE Settings](#can-have-settings)\n* [FAQ](#faq)\n* [Version History](#version-history)\n* [To Dos](#to-dos)\n* [develop](#develop)\n* [License](#license)\n\n<!-- toc stop -->\n\n##Download  \nI know people don't want to read a lot - so here is a direct link to the [release package of version 0.1.4](https://github.com/fabiantheblind/batch-find-and-replace/releases/download/v0.1.4/batch-find-and-replace.v0.1.4.zip)\n\nThanks go to:   \n- [Tom's Obvious, Minimal Language](https://github.com/mojombo/toml) By [Tom Preston-Werner](https://github.com/mojombo)  \n- [toml.js]( https://github.com/JonAbrams/tomljs) by [JonAbrams](https://github.com/JonAbrams)  \n- [JsonDiffPatch.js](https://github.com/benjamine/JsonDiffPatch) by [benjamine](https://github.com/benjamine)   \n\nWithout these three open source projects this would not be possible.\n\n##Purpouse\nWhile creating books in InDesign with several documents we always come across some find change queries that need to be used again, and again, and again. To make this process easier you can just grab their names and put them into a list. The script will than try to precess all your queries in one click.  \n\n##files  \nIn the folder __dist__ you can find the full script (batch-find-and-replace.jsx) with the libraries enclosed and an example toml file (batch-find-and-replace.toml) or use the link from the download section. This is all you need to get started right away. Place them both into your [Scripts Panel](http://help.adobe.com/en_US/indesign/cs/using/WS0836C26E-79F9-4c8f-8150-C36260164A87a.html#WSDCB06999-2544-48c9-B348-888301FC6BA0a)  \n\n##prerequisites\n1. make sure you have a toml file.\n2. make sure the toml file is next to the script.\n3. make sure the toml file has the right formatting (see below in section TOML)\n4. if you want the script to autoexecute (without toml file selection), make sure the .toml file has the right name: \"batch-find-and-replace.toml\"\n5. make sure your fcqueries work right \n\n##Usage\n- Place the script and the toml file into your [Scripts Panel Folder](http://help.adobe.com/en_US/indesign/cs/using/WS0836C26E-79F9-4c8f-8150-C36260164A87a.html#WSDCB06999-2544-48c9-B348-888301FC6BA0a)  \n- define some find and change queries and save them via the [InDesign dialogue](http://help.adobe.com/en_US/indesign/cs/using/WSFB3603CC-8D84-48d8-9F77-F3E0644CB0B6a.html#WS293D91C6-1153-4f92-A260-24B1A59E10B4a).\n- get the xml file names and add them to the __\"batch-find-and-replace.toml\"__ file in the right spot. text search goes into `text.files = []`, grep search goes into `grep.files = []` and so on. Make shure to remove the .xml from the filename. You can find these files on:\n- - __Mac OS__ Users\\[username]\\Library\\Preferences\\Adobe InDesign\\[Version]\\[Language]\\Find-Change Queries\\[query type]  \n- - __Windows XP__ Documents and Settings\\[username]\\Application Data\\Adobe\\InDesign\\[Version]\\[Language]\\Find-Change Queries\\[query type]  \n- - __Windows Vista and Windows 7__ Users\\[username]\\AppData\\Roaming\\Adobe\\InDesign\\[Version]\\[Language]\\Find-Change Queries\\[query type]  \n- the .toml file should be located next to the script file and have the  appropriate name (batch-find-and-replace.toml). If so the script wont ask for the toml file and process the data right away. If not the script will ask you to select the .toml file.\n- Thats it. Watch the magick happen.\n\n##TOML\n[Tom's Obvious, Minimal Language](https://github.com/mojombo/toml) is a simple markup language that makes settings human readable. It is still in development and may change a lot. But still. It is a pretty easy language and can be learned by anyone.  \nThe basic toml filer looks like this:  \n\n    # these are the basic settings\n    # the MUST be there\n    do_text = true\n    do_grep = true\n    do_glyph = true\n    do_object = false\n    do_all_docs = true\n    # now the file names\n    # they have to be in one line\n    # the toml specs say you can break lines in arrays\n    # but the toml.js does not allow that at the moment\n    [text]\n    files = [\"my_first_text_find_and_change\",\"another one\"]\n    [grep]\n    files = [\"somegrepsearch\", \"find tabs\", \"something else\"]\n    [glyph]\n    files = []\n    [objects]\n    files = []\n\n###MUST HAVE Settings\nWith the `do_text`, `do_object`, `do_grep` and `do_glyph` you can define if the script should do the corresponding find and replace. Set them to `true` or `false`.  \nWith the `do_all_docs` setting you can define to use just the front most document or all open documents. Set it to `true` if you want to process all open documents.  \n\n###CAN HAVE Settings\nIn the `[text]`,`[grep]`,`[glyph]` and `[objects]` areas you can define the filenames that should be processed. Make sure the filenames are written right. If there is a file mentioned that does not exist the script will throw an error. It will try to process all the .xml files it can find. __!IMPORTANT!__ you MUST remove the .xml from the filename in the list as shown above.\n\n##FAQ  \nNothing yet. Feel free to ask and report issues ;)  \n\n##Version History  \n- 0.1.4 fixed typo. Do all docs can hang itself when having to many files\n- - maybe we should switch to book usage instead\n- 0.1.3 working on do all docs. more grunt\n- 0.1.2 working on do all docs. added grunt\n- 0.1.1 Added do all docs feature  \n- 0.1 initial release  \n\n##To Dos  \n\n- Make it work with InDesign Books or an folder of InDesign docs.  \n- add support for several docs\n\n\n##develop  \n\nIf you want to develop on this project fork it or clone it with git\n\n    git clone https://github.com/fabiantheblind/batch-find-and-replace.git\n    cd batch-find-and-replace\n\n\nIn the __src__ folder you will find the development files. The libraries are external and enclosed in the repository as submodules. If you want to set up these you have to run first:  \n\n    git submodule init  \n\nThan update the submodules with  \n\n    git submodule update  \n\nSee the progit documentation on submodules [here](http://git-scm.com/book/ch6-6.html).\n\nInstall [nodejs and npm](https://gist.github.com/isaacs/579814) the way you like it.  \n\nTo build the release script with all files put together I use [grunt](http://gruntjs.com/). install this as well.  \n\nThen run\n\n    npm install   \n    \nin the root of the project.  \nThen run grunt  \n\n    grunt  \n\nThis should build the whole script into the __dist__ folder.  \n\n    grunt dev  \n\nThis should run a watch task and compile your script everytime you change something.  \n\n##License\nAll code is under MIT License\nCopyright (c)  2013 - 2014 Fabian \"fabiantheblind\" Mor\u00f3n Zirfas  \nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software  without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to  permit persons to whom the Software is furnished to do so, subject to the following conditions:  \nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.  \nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A  PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF  CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  \n\nsee also http://www.opensource.org/licenses/mit-license.php\n\n"}
{"url": "https://github.com/ff6347/bed-and-breakfast", "owner": "ff6347", "repository_name": "bed-and-breakfast", "date_all_variable_collection": "2023-09-11", "description": "website for Laila Niklaus", "size": 73940, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "PDXIII", "contributions": 15}, {"contributor": "fabiantheblind", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 93845}, {"language": "Ruby", "num_chars": 2479}], "readme": "bed-and-breakfast\n=================\n\nwebsite for Bett&Bread \"Helene\" build with [jekyll](http://jekyllrb.com) and [twitter-bootstrap](http://twitter.github.com/bootstrap/) by @PDXIII and @fabiantheblind  \n\nAll images and texts are poperty of Laila & Lutz Kleveman \u00a9 2012  \nFor further info have a look at [helene-gut-ankelohe.de](http://helene-gut-ankelohe.de) or write to <anfrage@gut-ankelohe.de>   \n\nAll coding with jekyll and tw-bootstrap is under MIT License  \nCopyright (c)  2012 Peter \"PDXIII\" Sekan & Fabian \"fabiantheblind\" Mor\u00f3n Zirfas  \nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software  without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to  permit persons to whom the Software is furnished to do so, subject to the following conditions:  \nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.  \nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A  PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF  CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  \n\nsee also [www.opensource.org/licenses/mit-license.php](http://www.opensource.org/licenses/mit-license.php)\n\n"}
{"url": "https://github.com/ff6347/best-rest-test", "owner": "ff6347", "repository_name": "best-rest-test", "date_all_variable_collection": "2023-09-11", "description": "a small app running on zeit/now https://best-rest-test.now.sh/ to test if there is a possibility for a http connection", "size": 67, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1323}], "readme": "# best-rest-test\na small app running on zeit/now https://best-rest-test.now.sh/ to test if there is a possibility for a http connection\n"}
{"url": "https://github.com/ff6347/Beyond-Processing-Scribbles", "owner": "ff6347", "repository_name": "Beyond-Processing-Scribbles", "date_all_variable_collection": "2023-09-11", "description": "FHP WS2010/11 Project", "size": 2009, "stargazers_count": 1, "watchers_count": 1, "language": "Java", "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/ff6347/bin", "owner": "ff6347", "repository_name": "bin", "date_all_variable_collection": "2023-09-11", "description": "Some scripts I created. Stored into /usr/local/bin and than always forget about. Read [this article](http://www.leancrew.com/all-this/2013/05/dropboxbin/) and thought: \"Hey good idea but not into the dropbox\" ", "size": 112, "stargazers_count": 0, "watchers_count": 0, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 4911}], "readme": "bin\n===\n\nSome scripts I created. Stored into /usr/local/bin and than always forget about. Read [this article](http://www.leancrew.com/all-this/2013/05/dropboxbin/) and thought: \"Hey good idea but not into the dropbox\" \n"}
{"url": "https://github.com/ff6347/bitmapboogie-imagescanner-jsx", "owner": "ff6347", "repository_name": "bitmapboogie-imagescanner-jsx", "date_all_variable_collection": "2023-09-11", "description": "This is an ExtendScript for importing data from the bitmapboogie-imagescanner-of into After Effects", "size": 116, "stargazers_count": 2, "watchers_count": 2, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 7417}], "readme": "bitmapboogie-imagescanner-jsx\n=============================\n\nThis is an ExtendScript for importing data from the [bitmapboogie-imagescanner-of](https://github.com/fabiantheblind/bitmapboogie-imagescanner-of) into After Effects\n"}
{"url": "https://github.com/ff6347/bitmapboogie-imagescanner-of", "owner": "ff6347", "repository_name": "bitmapboogie-imagescanner-of", "date_all_variable_collection": "2023-09-11", "description": "This is a small OF tool for scanning images", "size": 4108, "stargazers_count": 0, "watchers_count": 0, "language": "C", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C", "num_chars": 352644}, {"language": "Objective-C", "num_chars": 324702}, {"language": "C++", "num_chars": 33881}], "readme": "bitmapboogie-imagescanner-of\n============================\n\nThis is a small OF tool for scanning images. See also [bitmapboogie-imagescanner-jsx](https://github.com/fabiantheblind/bitmapboogie-imagescanner-jsx)\n"}
{"url": "https://github.com/ff6347/block-facebook", "owner": "ff6347", "repository_name": "block-facebook", "date_all_variable_collection": "2023-09-11", "description": "Little snitch rule group for blocking Facebook", "size": 340, "stargazers_count": 16, "watchers_count": 16, "language": "TypeScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": true, "forks_count": 9, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "Creative Commons Zero v1.0 Universal", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 9, "open_issues": 1, "watchers": 16, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 26}, {"contributor": "renovate[bot]", "contributions": 8}, {"contributor": "renovate-bot", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TypeScript", "num_chars": 1539}, {"language": "JavaScript", "num_chars": 569}], "readme": "Little Snitch Block Facebook Rule Set\n=====================================\n\n\nYou will need to use this URL to subscribe\n\nhttps://ff6347.github.io/block-facebook/block-facebook.lsrules\n\n## Todos\n\nSee these [issues](https://github.com/fabianmoronzirfas/block-facebook/issues) and add new ones.  \n"}
{"url": "https://github.com/ff6347/buildx-test", "owner": "ff6347", "repository_name": "buildx-test", "date_all_variable_collection": "2023-09-11", "description": "\u00f6\u00f6\u00f6", "size": 5, "stargazers_count": 1, "watchers_count": 1, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "ff6347", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# buildx-test\n\u00f6\u00f6\u00f6\n"}
{"url": "https://github.com/ff6347/c2c", "owner": "ff6347", "repository_name": "c2c", "date_all_variable_collection": "2023-09-11", "description": "Sketches for teaching computer 2 computer communication with arduino and processing @FH-Potsdam", "size": 4753, "stargazers_count": 2, "watchers_count": 2, "language": "Processing", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 3, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 3, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Processing", "num_chars": 22015}, {"language": "Arduino", "num_chars": 9984}, {"language": "Python", "num_chars": 2505}], "readme": "c2c\n===\n\nA collection of sketches for teaching computer to computer communication [@FH-Potsdam](https://github.com/FH-Potsdam).\nThese sketches are part of the seminars taking place in the Interface Lab.  \n\n\n\n\n## Arduino And Processing  \n\n### Needed Komponents  \n\n- Computer  \n- Arduino (Uno)  \n- Arduino IDE  \n- Processing IDE  \n- Light Dependend Resistor  \n- LED  \n- RGB LED  \n- 10k Ohm Resistor  \n- 3 * 220 Ohm Resistor  \n- Breadboard  \n- Some wires  \n\n#### 00 Serial Ports And Fritzing  \n##### prerequisites  \nSet up your Arduino with a LDR (light dependend resistor) and the LED like this.  \n![fritzing-layout](00_Serial-Ports-And-Fritzing/fritzing/fritzing-layout.png)  \n\n- One LDR leg goes to the 5V pin \n- one LDR leg to the analog 0 pin\n- connect the 10k Ohm resistor to the analog 0 pin as well\n- connect the other leg of the resitor to the GND pin\n- connect the long leg of the LED to the 13 digital pin\n- connect the short leg to the GND pin\n\n\n##### Port Detection  \nConnect your Arduino Board to your computer adn use the sketck [00_Serial-Ports-And-Fritzing/list_serial_ports/list_serial_ports.pde](00_Serial-Ports-And-Fritzing/list_serial_ports/list_serial_ports.pde) to see which port number is the one you choose in the Arduino IDE.  \n**Yo need to modify all the .pde sketches to select the right serial port**  \n\n#### 01 Arduino 2 Processing  \n\n- Open and run the Processing sketch: 01_Arduino-2-Processing/pde/pde.pde  \n- Open and upload the Arduino sketch: 01_Arduino-2-Processing/ino/ino.ino   \n\nby waving your hand over the LDR you should be able to change the background color of the processing sketch.  \n\n#### 02 Processing 2 Arduino\n\n- Open and run the Processing sketch: 02_Processing-2-Arduino/pde/pde.pde  \n- Open and upload the Arduino sketch: 02_Processing-2-Arduino/ino/ino.ino   \n\npressing UP and DOWN on your keyboard you can turn on a LED connected to pin 13  \n\n#### 03 Poor Mans Oscilloscope\n\n- Open and run the Processing sketch: 03_Poor-Mans-Oscilloscope/pde/pde.pde  \n- Open and upload the Arduino sketch: 03_Poor-Mans-Oscilloscope/ino/ino.ino   \n\n![poor mans oscilloscope](03_Poor-Mans-Oscilloscope/poor-mans-oscilloscope.png)  \n\nBy waving your hand over the LDR you should be able to change the line.\nThe sketches written by [@chrismeyersfsu](https://gist.github.com/chrismeyersfsu/3270358) with edits from [@positron96](https://gist.github.com/positron96/7269466).  \n\n#### 04 Round Trip\n\n- Open and run the Processing sketch: 04_Round-Trip/pde/pde.pde  \n- Open and upload the Arduino sketch: 04_Round-Trip/ino/ino.ino  \n\n![serial-monitor](04_Round-Trip/serial-monitor.gif)  \n\nwatch what happens in the serial monitor and the processing console. Messages are passed around...\n\n#### 05 Processing 2 Arduino Motion Detection\n\n- Open and run the Processing sketch: 05_Processing-2-Arduino-Motion-Detection/pde/pde.pde  \n- Open and upload the Arduino sketch: 05_Processing-2-Arduino-Motion-Detection/ino/ino.ino  \n\nby using the build in cam of our laptop or an webcam you can blink an LED by just moving infront of the camera.  \n\n#### 06 Processing 2 Arduino Multiple Values\n\n- Make a new arduino setup like this image  \n\n![fritzing-layout](06_Processing-2-Arduino-Multiple-Values/fritzing/fritzing-layout.png)  \n\n- Open and run the Processing sketch: 06_Processing-2-Arduino-Multiple-Values/pde/pde.pde  \n- Open and upload the Arduino sketch: 06_Processing-2-Arduino-Multiple-Values/ino/ino.ino  \n\nYou can set the color of the RGB-LED from Processing.\n\n\n### License  \nIf not further noted \n\nThis is free and unencumbered software released into the public domain.  \n\nAnyone is free to copy, modify, publish, use, compile, sell, or distribute this software, either in source code form or as a compiled binary, for any purpose, commercial or non-commercial, and by any means.  \n\nIn jurisdictions that recognize copyright laws, the author or authors of this software dedicate any and all copyright interest in the software to the public domain. We make this dedication for the benefit of the public at large and to the detriment of our heirs and successors. We intend this dedication to be an overt act of relinquishment in perpetuity of all present and future rights to this software under copyright law.  \n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  \n\nFor more information, please refer to <http://unlicense.org>  \n\n\n###Poor mans ocilloscope\nis under GNU General Public License  \n\n(c) 2008 Sofian Audry (info@sofianaudry.com)  \nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.  \n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.  \n\nYou should have received a copy of the GNU General Public License  \nalong with this program.  If not, see <http://www.gnu.org/licenses/>.  \n\n"}
{"url": "https://github.com/ff6347/c2c-with-nodejs", "owner": "ff6347", "repository_name": "c2c-with-nodejs", "date_all_variable_collection": "2023-09-11", "description": "Computer 2 Computer Communication done with Node.js, Express.js, Johnny Five and Socket.io.", "size": 110, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 1, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 5229}, {"language": "HTML", "num_chars": 980}, {"language": "CSS", "num_chars": 958}], "readme": "# c2c-with-nodejs\n\nThese files are the starting point for the \"Computer 2 Computer Communication\" done with Node.js, Express.js, Johnny Five and Socket.io workshop @ University of Applied Sciences Potsdam (Germany).  \n\n\n## ToDo:  \n\n- [x] start the [server][start] `node index.js`\n- [x] add [Johnny Five][j5] to simple [express][ex] server and [blink][blink] from frontend via [socket.io][sio]\n- [x] move frontend [JS][js] and [CSS][css] into files\n- [ ] add [pullup push button][button] and [toggle][sto1] body [background-color][mdn1]\n- [ ] send a Tweet on button push using [Twit][tw]\n\n\n[start]: https://stackoverflow.com/questions/15206849/how-to-execute-a-hello-world-javascript-file-in-node-js\n[tw]: https://github.com/ttezel/twit\n[ex]: http://expressjs.com/de/\n[j5]: http://johnny-five.io/\n[sio]: https://socket.io/\n[blink]: http://johnny-five.io/examples/led-blink/\n[button]: http://johnny-five.io/examples/button-pullup/\n[sto1]: https://stackoverflow.com/questions/5195303/set-css-property-in-javascript\n[mdn1]: https://developer.mozilla.org/de/docs/Web/CSS/background-color\n[css]: https://developer.mozilla.org/en-US/docs/Learn/CSS/Introduction_to_CSS/How_CSS_works#How_to_apply_your_CSS_to_your_HTML\n[js]: https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/JavaScript_basics#A_hello_world_example"}
{"url": "https://github.com/ff6347/camWithDolly", "owner": "ff6347", "repository_name": "camWithDolly", "date_all_variable_collection": "2023-09-11", "description": "creates a cam with a dolly", "size": 3, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}, {"contributor": "marwahaha", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 4000}], "readme": "camWithDolly\n============\n\nThis is abandon ware use it if you like\n"}
{"url": "https://github.com/ff6347/cheatsets", "owner": "ff6347", "repository_name": "cheatsets", "date_all_variable_collection": "2023-09-11", "description": "A collection of cheatsets I like to keep on my desktop. These are commands I use on a not daily basis. To not have to browse through my shell history over and over again, I worte them down.  ", "size": 50, "stargazers_count": 3, "watchers_count": 3, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 28}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 642}], "readme": "# Cheatsets\n\nA collection of cheatsets I like to keep on my desktop. These are commands I use on a not daily basis. To not have to browse through my shell history over and over again, I worte them down.\n\n## Usage\n\nI recommend sometinhg like [msee](https://www.npmjs.com/package/msee) if you like to see them in your shell.\n\n    npm install -g msee\n\nThen clone them to a place where you can find them\n\n    git clone https://github.com/fabianmoronzirfas/cheatsets.git ~/bin/Cheatsets/\n\nWatch them in your shell or just open them with your favorite markdown viewer.\n\n    msee ~/bin/Cheatsets/git.md\n\n## License\n\nCopyright 2017 (c) Fabian Mor\u00f3n Zirfas\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"}
{"url": "https://github.com/ff6347/CircleText", "owner": "ff6347", "repository_name": "CircleText", "date_all_variable_collection": "2023-09-11", "description": "Text in a circle using openFrameworks and c++", "size": 3136, "stargazers_count": 2, "watchers_count": 2, "language": "C", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C", "num_chars": 117570}, {"language": "C++", "num_chars": 18725}, {"language": "Shell", "num_chars": 275}]}
{"url": "https://github.com/ff6347/citylab-goes-2-diversitylab", "owner": "ff6347", "repository_name": "citylab-goes-2-diversitylab", "date_all_variable_collection": "2023-09-11", "description": "A little journey we took", "size": 34896, "stargazers_count": 1, "watchers_count": 1, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "ff6347", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 6296}], "readme": "# CityLab visits the DiversityLab\n\n## We went to visit the diversity lab and took a group photo,\n\n[![](images/01.png)](https://labs.openai.com/s/MB2pcHEAp43gh3fGjqjX3Evd)\n\n## and enjoyed the morning sun on the balcony.\n\n[![](images/02.png)](https://labs.openai.com/s/ZUaUPzsHDVcXK4YqB3AZr1vG)\n\n## We played some computer games.\n\n[![](images/03.png)](https://labs.openai.com/s/EoJaZptThmU2vcJ84jq70nvX)\n\n## Played some table tennis.\n\n[![](images/04.png)](https://labs.openai.com/s/SbQ4aVS66GS8Mf8JTk1njKTK)\n\n## Brainstormed a lot about things.\n\n[![](images/05.png)](https://labs.openai.com/s/tBH9nBDTSwRkgFlFTEqAN8f8)\n\n## Watched a funny movie.\n\n[![](images/06.png)](https://labs.openai.com/s/3j1ztsxmCsBbgKOrqFbxj7zL)\n\n## Slept and left in the morning.\n\n[![](images/07.png)](https://labs.openai.com/s/eZVEbNzyOZbBjzhdm0gKPxl0)\n\n## Got stranded on a train station.\n\n[![](images/08.png)](https://labs.openai.com/s/Xf3b4c2GXOVl1eNM8368rTt1)\n\n## Got back on the train and where happy about it.\n\n[![](images/09.png)](https://labs.openai.com/s/El8U2vatKRAoe0upCyT1VcMg)\n\n## Had to leave the train again.\n\n[![](images/10.png)](https://labs.openai.com/s/K4ocNOqHE6yZiLsxkfBb7Glw)\n\n## Got annoyed because we had to take the bus.\n\n[![](images/11.png)](https://labs.openai.com/s/ZMNDIcur5KJyq5nqOq8A1zku)\n\n## Finally took the bus to another train station.\n\n[![](images/12.png)](https://labs.openai.com/s/No2D1XDQicSJbTofoMG4Rqg5)\n\n## Got on our train.\n\n[![](images/13.png)](https://labs.openai.com/s/DplPyxIwh45VZ8MXHrOB00e7)\n\n## Finally got to the subway home.\n\n[![](images/14.png)](https://labs.openai.com/s/bLRID1JerCJ4EAvHyI8378Xf)\n\n## Finally got home to our families.\n\n[![](images/15.png)](https://labs.openai.com/s/jE9yz1b424CQmRbvIJCyDspU)\n\n## Finally got to the end of the story.\n\n[![](images/16.png)](https://labs.openai.com/s/6xJWraMPS6dVQB1UNdU20m6Y)\n\n## Had a idea for a screenplay based on this story.\n\n[![](images/17.png)](https://labs.openai.com/s/afPxoJ910sVzVB47IK4qPdoD)\n\n## And for a musical.\n\n[![](images/18.png)](https://labs.openai.com/s/Qu2BzNsWssHdBVCO5Em6o9Jj)\n\n## And for a Tokyo drift sequel.\n\n[![](images/19.png)](https://labs.openai.com/s/ZxNhuI0qCaXJwgzBych5kgP9)\n\n## And had a cold afterwards.\n\n[![](images/20.png)](https://labs.openai.com/s/hvPsbTOsnGQcU1vaPoNQq1ni)\n\n## License\n\n<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/80x15.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>.\n"}
{"url": "https://github.com/ff6347/color_thief", "owner": "ff6347", "repository_name": "color_thief", "date_all_variable_collection": "2023-09-11", "description": null, "size": 93, "stargazers_count": 1, "watchers_count": 1, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 2}, {"contributor": "gitter-badger", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 28227}, {"language": "Processing", "num_chars": 1150}], "readme": "color_thief\n===========\n\n[![Join the chat at https://gitter.im/fabiantheblind/color_thief](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/fabiantheblind/color_thief?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)  \nin Processing.  \n\n![](ldr-palette.png)  \n\n------\n\n###How to compile the class?\n\nUse these commands:  \n\n    javac de/androidpit/colorthief/ColorThief.java\n\nCreate the .jar:  \n\n\n    jar cfm ColorThief.jar de/androidpit/colorthief/Manifest.txt de/androidpit/colorthief/ColorThief.class de/androidpit/colorthief/MMCQ.class de/androidpit/colorthief/MMCQ\\$1.class de/androidpit/colorthief/MMCQ\\$2.class de/androidpit/colorthief/MMCQ\\$CMap.class de/androidpit/colorthief/MMCQ\\$VBox.class\n\n\n###Links:\n\n[SvenWoltmann/color-thief-java \u00b7 GitHub](https://github.com/SvenWoltmann/color-thief-java)\n\n[PImage to BufferedImage - Processing Forum](http://forum.processing.org/one/topic/pimage-to-bufferedimage.html)\n\nCredits and license\n\n###Thanks\n\nLokesh Dhakar - for the original Color Thief JavaScript version, available at [http://lokeshdhakar.com/projects/color-thief/](http://lokeshdhakar.com/projects/color-thief/)\nLicense\n\n##Licensed\n\nunder the Creative Commons Attribution 2.5 License  \n\nFree for use in both personal and commercial projects.\nAttribution requires leaving author name, author homepage link, and the license info intact.\n"}
{"url": "https://github.com/ff6347/color_wheel", "owner": "ff6347", "repository_name": "color_wheel", "date_all_variable_collection": "2023-09-11", "description": "simple color wheel in processing", "size": 140, "stargazers_count": 0, "watchers_count": 0, "language": "Processing", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Processing", "num_chars": 2240}], "readme": "color_wheel\n===========\n\nbuilding color wheels to understand the hsb model"}
{"url": "https://github.com/ff6347/color_wheel_p5js", "owner": "ff6347", "repository_name": "color_wheel_p5js", "date_all_variable_collection": "2023-09-11", "description": "simple color wheel", "size": 287, "stargazers_count": 0, "watchers_count": 0, "language": "CSS", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 1, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "CSS", "num_chars": 17816}, {"language": "JavaScript", "num_chars": 4203}], "readme": "This is a simple setup to get started with [p5.js](http://p5js.org) using a bit of[nodejs](http://nodejs.org/) [bower](http://bower.io/) and [grunt](http://gruntjs.com/).  \nWritten by Fabian [@fabiantheblind](https://github.com/fabiantheblind) Mor\u00f3n Zirfas.  \n\n"}
{"url": "https://github.com/ff6347/compify2_slim", "owner": "ff6347", "repository_name": "compify2_slim", "date_all_variable_collection": "2023-09-11", "description": "reduced version of the compify2.jsx", "size": 112, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 7424}], "readme": " compify2_slim.jsx\n==\nThis is for using the effect: *Keylight 1.2* on tons of greenscreen images\n--\nYou can use any other Effect- / RenderSettings- / OutputSettings-Preset  \n--\n**compify2_slim.jsx** for After Effects CS4/CS5 by fabiantheblind Nov 2010 based on:  \n \n**compify2.jsx** by Joseph M. Morgan - April 2005 based on:  \n \n**Compify.jsx** Byron Nash, Edited and Improved by Paul Tuersley  October 2004  \n \nStripped of most UI stuff. Thanx to the great documentation and the straight structure within the code    \n \n**The script works as follows:**  \n- make a selection in project window. -> **this MUST be on the lowest level of the project window**   \n- make a target folder (with prompt)  \n- make a comp of every item in selection with 12 fps, 1 frame long, in the footage size  \n- apply a effect preset. **-> The applied Preset has to be in the same folder as the script**  \n- adds the comp to the renderqueue as singleframe. and sets the render location **-> the render presets have to exist**  \n \n**bugs:** works only woth footage from lowest level of project window  \n      this seems to be a problem in compify, compify2 and COMPIFYv5.JSX  \n  \n"}
{"url": "https://github.com/ff6347/connected-nodes", "owner": "ff6347", "repository_name": "connected-nodes", "date_all_variable_collection": "2023-09-11", "description": "create connected nodes. nuff said?", "size": 290, "stargazers_count": 1, "watchers_count": 1, "language": "Processing", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Processing", "num_chars": 4304}], "readme": "#create connected nodes in processing. Nuff said?\n\n\nneeds [controlP5](http://www.sojamo.de/libraries/controlP5/)!  \n\n![](nodes.jpg)  \nunder MIT License  \nCopyright (c)  2012- 2014 Fabian \"fabiantheblind\" Mor\u00f3n Zirfas  \nPermission is hereby granted, free of charge, to any person obtaining a copy of this\nsoftware and associated documentation files (the \"Software\"), to deal in the Software\nwithout restriction, including without limitation the rights to use, copy, modify,\nmerge, publish, distribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to the following\nconditions:  \nThe above copyright notice and this permission notice shall be included in all copies\nor substantial portions of the Software.  \nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,\nINCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A\nPARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\nHOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF\nCONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE\nOR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  \n\nsee also [http://www.opensource.org/licenses/mit-license.php](http://www.opensource.org/licenses/mit-license.php)  \n"}
{"url": "https://github.com/ff6347/DC40175", "owner": "ff6347", "repository_name": "DC40175", "date_all_variable_collection": "2023-09-11", "description": "A Arduino library for the DC40175 decimal counter", "size": 536, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "DC40175 Decade Counter  \n======================\nA Arduino library for the [DC40175](http://www.ti.com/lit/ds/symlink/cd4017b.pdf) decimal counter  \n\n![](examples/extended/extended-fritzing-layout.png)  \n\nbased on work by Leonel Machava  \nhttp://codentronix.com  \nhttp://codentronix.com/2011/06/05/arduino-led-bar-graph-driven-by-a-4017-counter/  \nhttp://codentronix.com/2011/06/05/arduino-led-bar-graph-with-a-4017-counter-and-potentiometer/  \n\n###Pin Functions CD4017B\n\n- PIN 16 - V DC\n- PIN 15 - RESET\n- PIN 14 - CLOCK\n- PIN 13 - CLOCK INHIBIT (STOP COUNTING)\n- PIN 12 - CARRY OUT (INDICATE DECIMAL)\n- PIN 11 - 9\n- PIN 10 - 4\n- PIN 09 - 8\n- PIN 08 - GND\n- PIN 07 - 3\n- PIN 06 - 7\n- PIN 05 - 6\n- PIN 04 - 2\n- PIN 03 - 0\n- PIN 02 - 1\n- PIN 01 - 5\n\nThe MIT License (MIT)\n\nCopyright (c) 2013 fabiantheblind\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\nthe Software, and to permit persons to whom the Software is furnished to do so,\nsubject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\nFOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\nIN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\nCONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"}
{"url": "https://github.com/ff6347/debugging-ae-scripts", "owner": "ff6347", "repository_name": "debugging-ae-scripts", "date_all_variable_collection": "2023-09-11", "description": "some debugging and test scripts for use with Adobes Extendscript Engine", "size": 69, "stargazers_count": 11, "watchers_count": 11, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 3, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 3, "open_issues": 1, "watchers": 11, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 19751}], "readme": "debugging-ae-scripts\n====================\n\nsome debugging and test scripts for use with Adobes Extendscript Engine\n\n\n##Test with prototyping array functions in After Effects  \nEnclosing the whole script in a function does not solve the problem. I snooped arround in [Zorro-The Layer Tagger.jsx](http://aescripts.com/zorro-the-layer-tagger/) to replicate an enclosed structure and came up with [this example](https://github.com/fabiantheblind/debugging-ae-scripts/blob/master/example_panel_enclosed.jsx). The function 'run_script_exPanel_enclosed' encloses everything.  \n\nFrom that I created [this version](https://github.com/fabiantheblind/debugging-ae-scripts/blob/master/_example_panel_withProto_enclosed.jsx) that has an Array prototyped function for clearing arrays and [this one](https://github.com/fabiantheblind/debugging-ae-scripts/blob/master/_example_panel_callProto.jsx) that uses the prototype without having it.  \n\nWhen I start the _example_panel_withProto_enclosed.jsx and then start the _example_panel_callProto.jsx I can use the myArray.clear() command. Also the Array.clear() is still available if I close the script that created this proto. Only after a restart from After Effects the Array.clear() function is gone.  \n\n\nCopyright (C) 2012  Fabian \"fabiantheblind\" Mor\u00f3n Zirfas\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program. If not, see <http://www.gnu.org/licenses/>.\n"}
{"url": "https://github.com/ff6347/depth-sorting-outer-space", "owner": "ff6347", "repository_name": "depth-sorting-outer-space", "date_all_variable_collection": "2023-09-11", "description": "just for keeping the script accesible", "size": 136, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "depth-sorting-outer-space\n=========================\n\njust for keeping the script accesible"}
{"url": "https://github.com/ff6347/details-in-readme", "owner": "ff6347", "repository_name": "details-in-readme", "date_all_variable_collection": "2023-09-11", "description": "Did you know that you can have some details in a readme here on GitHub?", "size": 1, "stargazers_count": 2, "watchers_count": 2, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["html", "markdown", "readme"], "languages": [], "readme": "# details-in-readme\nDid you know that you can have some details in a readme here on GitHub?\n\n<details>\n  <summary>You want to know what hides behind this triangle? Just click it</summary>\n  <p>Aweseom isnt it? Just add a little HTML to your README like <a href=\"https://raw.githubusercontent.com/fabianmoronzirfas/details-in-readme/master/README.md\">this-></a></p>\n</details>\n"}
{"url": "https://github.com/ff6347/digilogio", "owner": "ff6347", "repository_name": "digilogio", "date_all_variable_collection": "2023-09-11", "description": "Sketches for teaching arduino digital/analog input output @FH-Potsdam - you get it? digilogio = digital  + analog  + input + output.", "size": 552, "stargazers_count": 1, "watchers_count": 1, "language": "Arduino", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Arduino", "num_chars": 484}], "readme": "digilogio\n=========\n\nSketches for teaching arduino digital/analog input output @FH-Potsdam - you get it? digilogio = digital  + analog  + input + output.\n\nCopyright 2014 FH-Potsdam & Fabian \"fabiantheblind\" Mor\u00f3n Zirfas\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"}
{"url": "https://github.com/ff6347/digital-logic-gates", "owner": "ff6347", "repository_name": "digital-logic-gates", "date_all_variable_collection": "2023-09-11", "description": "Fritzing examples and Arduino code for \"Digital Logic Gates Just Using Transistors\" by DeanGPotts", "size": 124, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# digital-logic-gates\nFritzing examples and Arduino code for \"Digital Logic Gates Just Using Transistors\" by DeanGPotts [http://www.instructables.com/id/Digital-Logic-Gates-Just-Using-Transistors/](http://www.instructables.com/id/Digital-Logic-Gates-Just-Using-Transistors/)  \n\nW.I.P. come back later\n"}
{"url": "https://github.com/ff6347/digitalio", "owner": "ff6347", "repository_name": "digitalio", "date_all_variable_collection": "2023-09-11", "description": "Sketches for teaching arduino digital input output @FH-Potsdam", "size": 35449, "stargazers_count": 7, "watchers_count": 7, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 8, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 2, "license": "The Unlicense", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 8, "open_issues": 2, "watchers": 7, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 3}, {"contributor": "fabiantheblind", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 14279}, {"language": "Python", "num_chars": 8805}, {"language": "Shell", "num_chars": 1929}], "readme": "digitalio\n=========\n\nThese sketches are part of the course [\"Input Output (Eingabe Ausgabe)Fundamentals of process-oriented design.\"](https://interface.fh-potsdam.de/eingabe-ausgabe/)  \n\nMost of the examples are build for the Arduino Uno and the Raspberry Pi. Use at your own risk.\n\n###blink\n![](blink/images/blink.png)\n\n\nSimple blink sketches  \n\n###blink_with_serial\n![](blink_with_serial/images/fritzing-layout.png)\n\nBlink and write info to serial  \n\n###tiltswitch\n![](tiltswitch/images/circuit-layout.png)\n![](tiltswitch/images/fritzing-layout.png)\n![](tiltswitch/images/pi-tiltswitch_bb.png)\n![](tiltswitch/images/pi-tiltswitch_schem.png)\n![](tiltswitch/images/tiltswitch.png)\nHow to use a tiltswitch  \n\n###pushbutton\n\n![](pushbutton/images/circuit-layout.png)\n![](pushbutton/images/fritzing-layout.png)\n![](pushbutton/images/pi-pushbutton_bb.png)\n![](pushbutton/images/pi-pushbutton_schem.png)\n![](pushbutton/images/pushbutton.png)\n\nHow to use a pushbutton  \n\n###button_pull_up  \n\n![](button_pull_up/images/button_pull_up_bb.png)\n![](button_pull_up/images/button_pull_up_schem.png)\n![](button_pull_up/images/pi-button_pull_up_bb.png)\n![](button_pull_up/images/pi-button_pull_up_schem.png)\n\nHow to use internal pull ups and buttons\n\n###transistor\n![](transistor/images/bc237-npn-transistor.png)\n![](transistor/images/fritzing-layout.png)\n![](transistor/images/pi-transistor_bb.png)\n![](transistor/images/pi-transistor_schem.png)\n![](transistor/images/transistor_bb.png)\n![](transistor/images/transistor_schem.png)\nHow to use a transistor  \n\n###infrared\n![](infrared/images/fritzing-layout.png)\n\nHow to use infrared  \n\n###optocoupler\n![](optocoupler/images/fritzing-layout.png)\n\nHow to use an optocoupler\n\n###relay\n![](relay/images/fritzing-layout.png)\n![](relay/images/pi-relay-and-transistor_bb.png)\n![](relay/images/pi-relay-and-transistor_schem.png)\n![](relay/images/pi-relay_bb.png)\n![](relay/images/pi-relay_schem.png)\n![](relay/images/Relais FRS1 5V 1A-bottom view.png)\nHow to control a relay  \n\n###capacitive_touch_paperclip\n![](capacitive_touch_paperclip/images/capacitive_touch_paperclip_bb.png)\n![](capacitive_touch_paperclip/images/capacitive_touch_paperclip_schem.png)\nHow to create a capcitve touch button (arduino only)\n\n###L293D_motor_driver\n\n\n![](L293D_motor_driver/images/circuit-layout.png)\n![](L293D_motor_driver/images/fritzing-layout.png)\n![](L293D_motor_driver/images/l293d_bb.png)\n![](L293D_motor_driver/images/pi-l293d_bb.png)\nHow to control motors with a H-Bridge  \n\n###IC_74HC595_Graph\n![](IC_74HC595_Graph/74hc595-chart/graph.png)\n![](IC_74HC595_Graph/images/fritzing-layout.png)\n![](IC_74HC595_Graph/images/IC_74HC595_Graph_layout.png)\nShiftregister an bar graph  \n\n###IC_4017B_Graph\n![](IC_4017B_Graph/images/4017-functional-diagram.png)\n![](IC_4017B_Graph/images/4017-pinlayout.png)\n![](IC_4017B_Graph/images/fritzing-layout.png)\nDecade counter and bar graph\n\n###IC_4017B_Graph_PushDetect\n![](IC_4017B_Graph_PushDetect/images/4017-functional-diagram.png)\n![](IC_4017B_Graph_PushDetect/images/4017-pinlayout.png)\n![](IC_4017B_Graph_PushDetect/images/fritzing-layout.png)\nDecade counter and bar graph with button  \n\n###SevenSegmentDisplay\n![](SevenSegmentDisplay/images/fritzing-layout.png)\n\nControling a seven segment display  \n\n##License  \n\nAll datasheets in this repository are property of their respectfull owner everything else if not further noted:  \n\nThis is free and unencumbered software released into the public domain.  \n\nAnyone is free to copy, modify, publish, use, compile, sell, or distribute this software, either in source code form or as a compiled binary, for any purpose, commercial or non-commercial, and by any means.  \n\nIn jurisdictions that recognize copyright laws, the author or authors of this software dedicate any and all copyright interest in the software to the public domain. We make this dedication for the benefit of the public at large and to the detriment of our heirs and successors. We intend this dedication to be an overt act of relinquishment in perpetuity of all present and future rights to this software under copyright law.  \n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  \n\nFor more information, please refer to <http://unlicense.org>  \n\n\n"}
{"url": "https://github.com/ff6347/DIGITALIO_4017B_Graph", "owner": "ff6347", "repository_name": "DIGITALIO_4017B_Graph", "date_all_variable_collection": "2023-09-11", "description": "Using CD4017B Decade counter to control a LED Bar", "size": 1768, "stargazers_count": 0, "watchers_count": 0, "language": "Arduino", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Arduino", "num_chars": 1590}], "readme": "DIGITALIO_4017B_Graph\n=====================\n\nThis little sketch shows the usage of the CD4017B Decade counter by controlling a LED Bar with a pushbutton\nThe 4017 is used to save pins on the arduino.\nwritten by Fabian Mor\u00f3n Zirfas  \n##based on work by\n##[Leonel Machava](http://codentronix.com/2011/06/05/arduino-led-bar-graph-driven-by-a-4017-counter/)  \n##[DojoDave & Tom Igoe](http://arduino.cc/en/Tutorial/Button)\n\n![fritzing-layout](fritzing-layout.png)  \n![4017-pinlayout](4017-pinlayout.png)  \n![4017-functional-diagram](4017-functional-diagram.png)  \n\n-[CD4017B Datasheet](http://www.ti.com/lit/ds/symlink/cd4017b.pdf)  \n__Pin Functions CD4017B__  \n\n- PIN 16 - V DC\n- PIN 15 - RESET\n- PIN 14 - CLOCK\n- PIN 13 - CLOCK INHIBIT (STOP COUNTING)\n- PIN 12 - CARRY OUT (INDICATE DECIMAL)\n- PIN 11 - 9\n- PIN 10 - 4\n- PIN 09 - 8\n- PIN 08 - GND\n- PIN 07 - 3\n- PIN 06 - 7\n- PIN 05 - 6\n- PIN 04 - 2\n- PIN 03 - 0\n- PIN 02 - 1\n- PIN 01 - 5\n\n##License  \nThis code is release under the \"MIT License\" available at  \nhttp://www.opensource.org/licenses/mit-license.php"}
{"url": "https://github.com/ff6347/DIGITALIO_74HC595_Graph", "owner": "ff6347", "repository_name": "DIGITALIO_74HC595_Graph", "date_all_variable_collection": "2023-09-11", "description": "Controlling a LED Bargraph with a 74HC595 Shiftregister", "size": 1224, "stargazers_count": 0, "watchers_count": 0, "language": "Arduino", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Arduino", "num_chars": 1698}], "readme": "DIGITALIO_74HC595_Graph\n=======================\n\nControlling a [LED Bargraph](https://www.sparkfun.com/products/9937) with a [74HC595 Shiftregister](https://www.sparkfun.com/datasheets/IC/SN74HC595.pdf)\n\n![DIGITALIO_74HC595_Graph_layout](DIGITALIO_74HC595_Graph_layout.png)  \nwritten by Fabian Mor\u00f3n Zirfas  \nbased on  \n\nAdafruit Arduino - Lesson 4. 8 LEDs and a Shift Register  \n[http://learn.adafruit.com/adafruit-arduino-lesson-4-eight-leds/arduino-code](http://learn.adafruit.com/adafruit-arduino-lesson-4-eight-leds/arduino-code)  \n  \nShiftout tutorial  \n[http://arduino.cc/en/tutorial/ShiftOut](http://arduino.cc/en/tutorial/ShiftOut)  \n\n- PINS 1-7, 15     Q0 \" Q7     Output Pins  \n- PIN 8    GND     Ground, Vss  \n- PIN 9    Q7\"     Serial Out  \n- PIN 10   MR  Master Reclear, active low  \n- PIN 11   SH_CP   Shift register clock pin  \n- PIN 12   ST_CP   Storage register clock pin (latch pin)  \n- PIN 13   OE  Output enable, active low  \n- PIN 14   DS  Serial data input  \n- PIN 16   Vcc     Positive supply voltage   \n\n##License\n\nCopyright (c)  2013 Fabian \"fabiantheblind\" Mor\u00f3n Zirfas  \nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software  without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to  permit persons to whom the Software is furnished to do so, subject to the following conditions:  \nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.  \nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A  PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF  CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  \n\nsee also [http://www.opensource.org/licenses/mit-license.php](http://www.opensource.org/licenses/mit-license.php)  \n\n##Some Links  \n[Cain Shiftregisters](http://www.protostack.com/blog/2010/05/introduction-to-74hc595-shift-register-controlling-16-leds/)  \n[https://www.sparkfun.com/products/9519](https://www.sparkfun.com/products/9519)  \n[http://arduino.cc/en/tutorial/ShiftOut](http://arduino.cc/en/tutorial/ShiftOut)  \n[file:///Applications/Arduino.app/Contents/Resources/Java/reference/ByteCast.html](file:///Applications/Arduino.app/Contents/Resources/Java/reference/ByteCast.html)  \nhttp://learn.adafruit.com/adafruit-arduino-lesson-4-eight-leds/overview  \n[https://www.sparkfun.com/datasheets/IC/SN74HC595.pdf](https://www.sparkfun.com/datasheets/IC/SN74HC595.pdf)  "}
{"url": "https://github.com/ff6347/dispatch-from-srht", "owner": "ff6347", "repository_name": "dispatch-from-srht", "date_all_variable_collection": "2023-09-11", "description": "Testing", "size": 2, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "[![builds.sr.ht status](https://builds.sr.ht/~fabianmoronzirfas/dispatch-from-srht/.build.yml.svg)](https://builds.sr.ht/~fabianmoronzirfas/dispatch-from-srht/.build.yml?)\n\n# dispatch-from-srht\nTesting foo\n"}
{"url": "https://github.com/ff6347/docker-network-with-nginx-reverse-proxy-and-websockets", "owner": "ff6347", "repository_name": "docker-network-with-nginx-reverse-proxy-and-websockets", "date_all_variable_collection": "2023-09-11", "description": "docker-network-with-nginx-reverse-proxy-and-websockets", "size": 194, "stargazers_count": 2, "watchers_count": 2, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 9}, {"contributor": "renovate-bot", "contributions": 6}, {"contributor": "dependabot[bot]", "contributions": 2}, {"contributor": "renovate[bot]", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1512}, {"language": "HTML", "num_chars": 1006}, {"language": "Dockerfile", "num_chars": 320}], "readme": "# Docker Network With Nginx Reverse Proxy And Websockets\n\nA test setup that runs two Node.js Express servers in a docker network with Nginx as reverse proxy in-front of it. The `api/` has a webocket server running. The `client/` connects to it.\n\n\n## Setup\n\n```bash\n# one session\ncd client\nnpm install\ncd ..\ncd api\nnpm install\ncd ..\ndocker-compose up\n```\n\n```bash\n#other session\nopen http://localhost:8888\n```\n\nWatch the console of the localhost:8888\n"}
{"url": "https://github.com/ff6347/docker-playground", "owner": "ff6347", "repository_name": "docker-playground", "date_all_variable_collection": "2023-09-11", "description": "my little playground for CI", "size": 149, "stargazers_count": 0, "watchers_count": 0, "language": "TypeScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TypeScript", "num_chars": 6725}, {"language": "HTML", "num_chars": 1586}, {"language": "CSS", "num_chars": 848}, {"language": "Shell", "num_chars": 748}, {"language": "Dockerfile", "num_chars": 357}], "readme": "# docker-playground\nmy little playground for CI\n"}
{"url": "https://github.com/ff6347/down-under", "owner": "ff6347", "repository_name": "down-under", "date_all_variable_collection": "2023-09-11", "description": null, "size": 130, "stargazers_count": 0, "watchers_count": 0, "language": "Ruby", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "The Unlicense", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Ruby", "num_chars": 982}], "readme": "\u0279\u01ddpu\u2229 u\u028dop\n==========\n\nbased on work by [Brett Terpstra](http://brettterpstra.com/2013/02/12/uop-psdn-s-plo-on-w/)\n\nUse the hot key ^ \u2325 \u2318 U or the key word \"Down Under\".\nThe hotkey takes the text in the frontmost application.\nSelected text gets replaced.  \nCopies also to the clipboard.  \n\n\n![](screenshot.png)  \nThis is free and unencumbered software released into the public domain.\n\nAnyone is free to copy, modify, publish, use, compile, sell, or\ndistribute this software, either in source code form or as a compiled\nbinary, for any purpose, commercial or non-commercial, and by any\nmeans.\n\nIn jurisdictions that recognize copyright laws, the author or authors\nof this software dedicate any and all copyright interest in the\nsoftware to the public domain. We make this dedication for the benefit\nof the public at large and to the detriment of our heirs and\nsuccessors. We intend this dedication to be an overt act of\nrelinquishment in perpetuity of all present and future rights to this\nsoftware under copyright law.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR\nOTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,\nARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\nOTHER DEALINGS IN THE SOFTWARE.\n\nFor more information, please refer to <http://unlicense.org>\n"}
{"url": "https://github.com/ff6347/dummy-images", "owner": "ff6347", "repository_name": "dummy-images", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1962, "stargazers_count": 0, "watchers_count": 0, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "ISC License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 114}], "readme": "Dummy Images\n============\n\nI always need some dummies.\n\n![](rgb/feet.jpg)\n![](rgb/fly.jpg)\n![](rgb/frog.jpg)\n![](rgb/hammock.jpg)\n![](rgb/head.jpg)\n![](rgb/sky.jpg)\n![](rgb/thedoctor.jpg)\n![](rgb/twoface.jpg)\n![](rgb/window.jpg)"}
{"url": "https://github.com/ff6347/duration-and-processing", "owner": "ff6347", "repository_name": "duration-and-processing", "date_all_variable_collection": "2023-09-11", "description": "I had to fiddle with duration after seeing somebody fork it on my github feed", "size": 65288, "stargazers_count": 0, "watchers_count": 0, "language": "Processing", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Do What The F*ck You Want To Public License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Processing", "num_chars": 3644}], "readme": "duration-and-processing\n=======================\n![ani](duration_demo600px.gif)  \nI had to fiddle with duration after seeing somebody fork it on ny github feed. See a quick [screenrecord on vimeo](http://vimeo.com/80712056) \n\n\n1. get the [Duration.app](http://duration.cc) - [Code](https://github.com/YCAMInterlab/Duration)  \n2. get the [procesing osc library](http://www.sojamo.de/libraries/oscP5/)  \n3. get nuts  \n\n##License\n\n    DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE\n    Version 2, December 2004\n    \n     Copyright (C) 2013 Fabian Mor\u00f3n Zirfas aka fabiantheblind\n    \n     Everyone is permitted to copy and distribute verbatim or modified\n     copies of this license document, and changing it is allowed as long\n     as the name is changed.\n    \n    DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE\n    TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\n    \n    0. You just DO WHAT THE FUCK YOU WANT TO.\n\n##Music in Screenrecord:\nB001 by [Monroeville Music Center](http://monroevillemusiccenter.blogspot.com)  \nunder CC Licnese http://creativecommons.org/licenses/by/3.0/\n\n"}
{"url": "https://github.com/ff6347/easing", "owner": "ff6347", "repository_name": "easing", "date_all_variable_collection": "2023-09-11", "description": "Processing sketch exploring Robert Penners easing functions WIP", "size": 70, "stargazers_count": 1, "watchers_count": 1, "language": "Processing", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "BSD 3-Clause \"New\" or \"Revised\" License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Processing", "num_chars": 16287}], "readme": "# easing\n\nProcessing sketch exploring Robert Penners easing functions \n\n## images\n\n### Back easeIn\n![Back.easeIn.png](images/Back.easeIn.png)  \n\n### Back easeInOut\n![Back.easeInOut.png](images/Back.easeInOut.png)  \n\n### Back easeOut\n![Back.easeOut.png](images/Back.easeOut.png)  \n\n### Bounce easeIn\n![Bounce.easeIn.png](images/Bounce.easeIn.png)  \n\n### Bounce easeInOut\n![Bounce.easeInOut.png](images/Bounce.easeInOut.png)  \n\n### Bounce easeOut\n![Bounce.easeOut.png](images/Bounce.easeOut.png)  \n\n### Circ easeIn\n![Circ.easeIn.png](images/Circ.easeIn.png)  \n\n### Circ easeInOut\n![Circ.easeInOut.png](images/Circ.easeInOut.png)  \n\n### Circ easeOut\n![Circ.easeOut.png](images/Circ.easeOut.png)  \n\n### Cubic easeIn\n![Cubic.easeIn.png](images/Cubic.easeIn.png)  \n\n### Cubic easeInOut\n![Cubic.easeInOut.png](images/Cubic.easeInOut.png)  \n\n### Cubic easeOut\n![Cubic.easeOut.png](images/Cubic.easeOut.png)  \n\n### Elastic easeIn\n![Elastic.easeIn.png](images/Elastic.easeIn.png)  \n\n### Elastic easeInOut\n![Elastic.easeInOut.png](images/Elastic.easeInOut.png)  \n\n### Elastic easeOut\n![Elastic.easeOut.png](images/Elastic.easeOut.png)  \n\n### Expo easeIn\n![Expo.easeIn.png](images/Expo.easeIn.png)  \n\n### Expo easeInOut\n![Expo.easeInOut.png](images/Expo.easeInOut.png)  \n\n### Expo easeOut\n![Expo.easeOut.png](images/Expo.easeOut.png)  \n\n### Linear easeIn\n![Linear.easeIn.png](images/Linear.easeIn.png)  \n\n### Linear easeInOut\n![Linear.easeInOut.png](images/Linear.easeInOut.png)  \n\n### Linear easeOut\n![Linear.easeOut.png](images/Linear.easeOut.png)  \n\n### Quad easeIn\n![Quad.easeIn.png](images/Quad.easeIn.png)  \n\n### Quad easeInOut\n![Quad.easeInOut.png](images/Quad.easeInOut.png)  \n\n### Quad easeOut\n![Quad.easeOut.png](images/Quad.easeOut.png)  \n\n### Quart easeIn\n![Quart.easeIn.png](images/Quart.easeIn.png)  \n\n### Quart easeInOut\n![Quart.easeInOut.png](images/Quart.easeInOut.png)  \n\n### Quart easeOut\n![Quart.easeOut.png](images/Quart.easeOut.png)  \n\n### Quint easeIn\n![Quint.easeIn.png](images/Quint.easeIn.png)  \n\n### Quint easeInOut\n![Quint.easeInOut.png](images/Quint.easeInOut.png)  \n\n### Quint easeOut\n![Quint.easeOut.png](images/Quint.easeOut.png)  \n\n### Sine easeIn\n![Sine.easeIn.png](images/Sine.easeIn.png)  \n\n### Sine easeInOut\n![Sine.easeInOut.png](images/Sine.easeInOut.png)  \n\n### Sine easeOut\n![Sine.easeOut.png](images/Sine.easeOut.png)  \n\n\n## LICENSE\n\nCopyright \u00a9 2001 Robert Penner All rights reserved.\n- Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following\nconditions are met:\n\n- Redistributions of source code must retain the above copyright notice,\n    this list of conditions and the following disclaimer.\n- Redistributions in binary form must reproduce the above copyright notice, this list of\n    conditions and the following disclaimer in the documentation and/or\n    other materials provided with the distribution.\n- Neither the name of the author nor the names of contributors may be used to\n    endorse or promote products derived from this software without specific\n    prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS\nAND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES,\nINCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\nMERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN\nNO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\nOR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\nHOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,\nSTRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING\nIN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGE.\n"}
{"url": "https://github.com/ff6347/echo-server", "owner": "ff6347", "repository_name": "echo-server", "date_all_variable_collection": "2023-09-11", "description": null, "size": 33, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "ff6347", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 679}], "readme": "# Echo Server\n\nSimple js script that creates a server that listens on port 8000 and echoes back the message it receives.\n\n## Setup\n\n```bash\nnpm ci\nnode index.js\n```\n\n## Usage\n\n```bash\n# POST\ncurl -X POST -H 'Content-Type: application/json' -d '[\"Hello World\"]' 'http://localhost:8000'\n# or on an different route\ncurl -X POST -H 'Content-Type: application/json' -d '[\"Hello World\"]' 'http://localhost:8000/foo/bah'\n# GET\ncurl 'http://localhost:8000/foo/bah'\n```\n"}
{"url": "https://github.com/FH-Potsdam/.github", "owner": "FH-Potsdam", "repository_name": ".github", "date_all_variable_collection": "2023-09-11", "description": "Welcome to the Interface Design Group at the University of Applied Sciences Potsdam", "size": 2, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "sebastian-meier", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/FH-Potsdam/2014-2015-WiSe-15PP-PW-DIY-Multitouch", "owner": "FH-Potsdam", "repository_name": "2014-2015-WiSe-15PP-PW-DIY-Multitouch", "date_all_variable_collection": "2023-09-11", "description": "DIY (Multi) Touch (less) Human Computer Interaction (Projektwochen)", "size": 52121, "stargazers_count": 4, "watchers_count": 4, "language": "Processing", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 4, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 4, "watchers": 4, "default_branch": "master", "contributors": [{"contributor": "jorditost", "contributions": 30}, {"contributor": "fabiantheblind", "contributions": 4}, {"contributor": "Amerlander", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Processing", "num_chars": 49471}, {"language": "Arduino", "num_chars": 5479}, {"language": "C++", "num_chars": 2509}], "readme": "2014-2015-WiSe-15PP-PW-DIY-Multitouch\n=====================================\n\nDIY (Multi) Touch (less) Human Computer Interaction (Projektwochen)  \n\nAn open-ended exploration of touch, multitouch, computervision- and capacitive systems. In the foreground is an effective but low-cost implementation that can be ported to other projects, no material battle. Depending on the amount of participants one of the technologies mentioned is researched in groups, prototyped and applied. The aim is an exhibition at the end of the project weeks.  \n\n- [incom.org workspace](https://incom.org/workspace/5479)\n\n\n##Timetable:   \n\n__Day 1 || Mo 06.10 LW 126:__  \n\n- Introduction Juri, Jordi, Fabian  \n- Introduction project  \n- Brief and incomplete history of MT  \n- Example MT projects  \n- Form groups\n- Workshop Touch Box  \n- excercise\n\n__Day || 2 - 5 Di 07.10 - Fr 10.10 LW 126:__  \n\n- development and prototyping LW 126\n\n__Day 6 - 10 || Mo 13.10 - Do 16.10 Home & Foyer:__\n\n- development and prototyping home and LW corridor\n\n__Day 10 || Fr. 17.10 Foyer:__\n\n- Exhibition \n\n\n###Software:\n\n#### Processing Libs & Docs\n\n- [Processing Libs Directory](http://processing.org/reference/libraries/)\n- [Processing Video Lib](http://processing.org/reference/libraries/video/index.html)\n- [Processing TUIO Lib](http://prdownloads.sourceforge.net/reactivision/TUIO_Processing-1.4.zip?download)\n- [Camera Input Example](http://www.processing.org/reference/libraries/video/Capture.html)\n\n#### Computer Vision / Blob Detection\n\n- [OpenCV for Processing](https://github.com/atduskgreg/opencv-processing): Processing Computer Vision library and examples. This includes, brightness and contrast operations, image filtering, contour and edges detection, marker detection, background substraction and more CV operations.\n- [Blobscanner](https://github.com/robdanet/blobscanner): Blob detection lib for Processing\n- [flob](http://s373.net/code/flob/): Alternative to OpenCV. For Processing and openFrameworks\n- [BlobDetection](http://www.v3ga.net/processing/BlobDetection/): Blob detection lib for Processing (Old. Last updated Oct. 2012)\n\n#### Software Communication Protocol\n\n- [TUIO](http://tuio.org/)\n\n#### Arduino Libs & Docs  \n\n- [oscuino](http://cnmat.berkeley.edu/oscuino)  \n\n###Hardware:\n\n####Cameras\n\n#####PS3 Eye Camera\n- Inexpensive - 9\u20ac aprox. Check [here](http://www.amazon.de/dp/B000W3YQ1Y/ref=pe_386171_51767411_TE_M3T1_dp_1)\n- High Resolution/Frame Rate - 320x240 resolution 125fps max, 640x480 resolution 75fps\n- Best camera for building optical MT tracking systems because of its amazing camera sensor and ease of modification.\n\nSource: [http://www.peauproductions.com/cameras.html](http://www.peauproductions.com/cameras.html)\n\nWe expirenced some issues using the PSEye3 camera with Processing under Mac OSX. Mountain Lion seems not to work at all.  \n- To use the camera with Mac OSX 10.9.4 you need to use Processing 1.5.1 or 2.0.3 which you can [download here](https://code.google.com/p/processing/downloads/list).  \n- Install [Mac OSX: macam driver](http://webcam-osx.sourceforge.net/)  \n\n- and a [hacky solution](http://forum.processing.org/one/topic/ps3-eyecam-under-osx-10-8.html) for Mountain Lion (did not work yet).  \n- [Windows driver](http://codelaboratories.com/products/eye/driver/)\n\n\n###Useful Links   \nLinks for things.\n\n####Camera Hack: \n\n- [Hack PS3 Eyecam](http://createdigitalmotion.com/2009/08/trick-out-your-ps3-eye-webcam-best-cam-for-vision-augmented-reality/)  \n\n####Physical:\n\n- [Knock Sensor Tutorial (Piezo)](http://www.arduino.cc/en/Tutorial/KnockSensor)  \n- [Knock Tutorial (Piezo)](http://arduino.cc/en/Tutorial/Knock)  \n- [Digitalio Capacitiv Paperclip](https://github.com/fabiantheblind/digitalio/tree/master/capacitive_touch_paperclip)  \n- [Paperclip based on this](http://www.instructables.com/id/Turn-a-pencil-drawing-into-a-capacitive-sensor-for/?ALLSTEPS)\n- [CapacitiveSensor Library (ProjectPage)](https://www.pjrc.com/teensy/td_libs_CapacitiveSensor.html)\n- [CapacitiveSensor Library (Github)](https://github.com/PaulStoffregen/CapacitiveSensor)\n- [CapSense Library Demo Video](https://www.youtube.com/watch?v=BHQPqQ_5ulc)\n\n####Optical (Color Tracking / Blob Detection):\n\n- [Tangible Color Music Instrument (oF)](http://www.creativeapplications.net/sound/tangible-color-music-instrument-openframeworks-sound/)\n- [Prototyp von dem vorheringen Projekt](http://www.ryanraffa.com/parsons/thesis/category/prototypes/5-tangible-player/)\n- [Und die Masterarbeit](http://www.ryanraffa.com/parsons/thesis/category/papers/)\n\n- [Scrapple by Golan Levin](http://www.flong.com/projects/scrapple/)\n\n- [Trackmate (MIT)](http://tangible.media.mit.edu/project/trackmate/) is an inexpensive, do-it-yourself tangible tracking system that allows your computer to recognize tagged objects and their corresponding position, rotation, and color information when placed on a surface. Trackmate sends all object data viaLusidOSC (a protocol layer for unique spatial input devices), allowing any LusidOSC-based application to work with the system.\n\n####Capacitive: \n- [DragDrop \u2013 Ein haptisch interaktives Kinderspeil](http://www.designmadeingermany.de/2013/25478/)\n[Capstones, Zebrawidgets & Lumino (Hasso Plattner Institute Potsdam)](http://www.hpi.uni-potsdam.de/baudisch/projects/lumino.html)\n- [CAPSTONES AND ZEBRAWIDGETS](http://stefaniemueller.org/capstones-and-zebrawidgets/)\n\n- [TOUCH\u00c9 (Disney Research)](http://www.disneyresearch.com/project/touche-touch-and-gesture-sensing-for-the-real-world/)\n- [Capacitive Fingerprinting: User Differentiation Through Capacitive Sensing](http://chrisharrison.net/index.php/Research/CapacitiveFingerprinting)\n\n####Augmented Multitouch \u2013 Sound\n\n- [Augmenting Touch throught acoustic sensing](http://plopesresearch.levelup.webfactional.com/?project=rich-touch-acoustics)\n- [TapSense \u2013 Chris Harrison](http://www.cmu.edu/news/stories/archives/2011/october/oct19_tapsense.html)\n\n####Augmentation \u2013 Misc\n\n- [Chris Harrison - The Rich-Touch Revolution is Coming (opening keynote der TEI'14)](http://www.tei-conf.org/14/program/keynote_harrison.php)\n- [About Chris Harrison](http://www.chrisharrison.net/index.php/Research/Welcome)\n- [WorldKit: Ad Hoc Interactive Applications on Everyday Surfaces](http://chrisharrison.net/index.php/Research/WorldKit)\n\n####Sketch-Interaction (Augmented Drawings / Gesten)\n- [SketchSynth](http://www.creativeapplications.net/openframeworks/sketchsynth-drawable-user-interface-by-billy-keyes/)\n- [Drawn by Zach Liebermann](https://www.youtube.com/watch?v=xwkGC-U8cU4)\n- [Scribbling - Development Prototype #1 Jordi Tost](https://vimeo.com/82286680)\n\n####Misc\n- [Jordi Tost \"Augmented Multitouch\" Pinboard](http://www.pinterest.com/jorditost/augmented-multitouch/)\n\n\n####License\n\nThe code in this repository is available under the MIT License:\n\nCopyright (c)  2014 FH-Potsdam, Juri Wolf, Jordi Tost, Fabian Mor\u00f3n Zirfas  \n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software  without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to  permit persons to whom the Software is furnished to do so, subject to the following conditions:  \n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.  \n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A  PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF  CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  \n\nsee also [http://www.opensource.org/licenses/mit-license.php](http://www.opensource.org/licenses/mit-license.php)  \n\n\n\n"}
{"url": "https://github.com/FH-Potsdam/2014-SoSe-11EG-B-input-output", "owner": "FH-Potsdam", "repository_name": "2014-SoSe-11EG-B-input-output", "date_all_variable_collection": "2023-09-11", "description": "This repo is 4 the course \"Eingabe, Ausgabe. Grundlagen der prozessorientierten Gestaltung\" by Monika Hoinkis & Fabian Mor\u00f3n Zirfas", "size": 347495, "stargazers_count": 4, "watchers_count": 4, "language": "Processing", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 1, "watchers": 4, "default_branch": "master", "contributors": [{"contributor": "IoannisSar", "contributions": 65}, {"contributor": "Ziddal", "contributions": 24}, {"contributor": "timohausmann", "contributions": 23}, {"contributor": "ameliekirchmeyer", "contributions": 10}, {"contributor": "lennerd", "contributions": 8}, {"contributor": "VaSaKos", "contributions": 5}, {"contributor": "fabiantheblind", "contributions": 3}, {"contributor": "jannisfeigl", "contributions": 3}, {"contributor": "natael", "contributions": 2}, {"contributor": "Amerlander", "contributions": 1}, {"contributor": "patricklenz", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Processing", "num_chars": 96114}, {"language": "Java", "num_chars": 25282}, {"language": "Arduino", "num_chars": 18169}, {"language": "C", "num_chars": 1143}], "readme": "2014-SoSe-11EG-B-input-output\n=============================\n\nThis repo is 4 the course \"Eingabe, Ausgabe. Grundlagen der prozessorientierten Gestaltung\" by Monika Hoinkis &amp; Fabian Mor\u00f3n Zirfas  \n\n##contributers\n\n- [ameliekirchmeyer](https://github.com/ameliekirchmeyer) \n- [eliahueneburg](https://github.com/eliahueneburg) \n- [HannaHoffmann](https://github.com/HannaHoffmann) \n- [IoannisSar](https://github.com/IoannisSar) \n- [jannisfeigl](https://github.com/jannisfeigl) \n- [lennerd](https://github.com/lennerd) \n- [natael](https://github.com/natael) \n- [patricklenz](https://github.com/patricklenz) \n- [timohausmann](https://github.com/timohausmann) \n- [trimpd](https://github.com/trimpd) \n- [ww-](https://github.com/ww-) \n- [xiel](https://github.com/xiel) \n- [Ziddal](https://github.com/Ziddal) \n\n\n\n##content\n\n```txt\n    examples  \n    \u251c\u2500\u2500 processing\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 particle_system\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 simple_particle_system\n    \u251c\u2500\u2500 processing.js\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 processing_js_json_reading\n    \u2514\u2500\u2500 shell\n```\n\n\n- excercises  \n    + 01_patternprocedure\n    + 02_tbd\n    + 03_tbd\n\n##Git/Github Training ressources  \n\n[https://help.github.com/articles/what-are-other-good-resources-for-learning-git-and-github](https://help.github.com/articles/what-are-other-good-resources-for-learning-git-and-github)  \n\n[http://training.github.com/kit/](http://training.github.com/kit/)  \n\n##License  \n\nIf not further noticed  \n\nCopyright (c)  2014 by the respective owners\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software  without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to  permit persons to whom the Software is furnished to do so, subject to the following conditions:  \nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.  \nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A  PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF  CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  \n\nsee also http://www.opensource.org/licenses/mit-license.php  \n\n\n"}
{"url": "https://github.com/FH-Potsdam/2014-SoSe-14W4D-IL-Blockseminar", "owner": "FH-Potsdam", "repository_name": "2014-SoSe-14W4D-IL-Blockseminar", "date_all_variable_collection": "2023-09-11", "description": "Repo for teaching collaborative workflows @FH-Potsdam 2014-SoSe-14W4D-IL-Blockseminar", "size": 204, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "basilikumdesign", "contributions": 4}, {"contributor": "jorditost", "contributions": 1}, {"contributor": "fabiantheblind", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "2014-SoSe-14W4D-IL-Blockseminar\n===============================\n\nRepo for teaching collaborative workflows @FH-Potsdam 2014-SoSe-14W4D-IL-Blockseminar\n"}
{"url": "https://github.com/FH-Potsdam/add-users-via-github-api", "owner": "FH-Potsdam", "repository_name": "add-users-via-github-api", "date_all_variable_collection": "2023-09-11", "description": "add users from shell script to team", "size": 124, "stargazers_count": 1, "watchers_count": 1, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 646}], "readme": "add-users-via-github-api\n========================\n\nadd users from shell script\n\n\n\n- get a token like in this guide:\n[https://help.github.com/articles/creating-an-access-token-for-command-line-use](https://help.github.com/articles/creating-an-access-token-for-command-line-use)  \nThis should stay a secret it has read write acces to all your repos.  \n\n- create a team https://github.com/organizations/[YOUR_ORGANIZATION]/teams\n- get the id of the team  \n\n-----------------\n\n    #!/bin/bash\n    yourusername=\"user-name\"\n    token=\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n    response=$(curl -u \"$yourusername:$token\" https://api.github.com/orgs/:org/teams)\n    echo $response\n\n\n- add all users  \n\n-----------------\n\n    #!/bin/bash\n    token=\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n    yourusername=\"user-name\"\n    team=\"123456\"\n    # all the users\n    users=(\"foo\" \"bah\" \"foobah\" )\n    #loop all users\n    #\n    #\n    for i in \"${users[@]}\"\n    do\n       :\n       # do whatever on $i\n       $(curl -i -u \"$yourusername:$token\" -X PUT -d \"\" https://api.github.com/teams/$team/members/$i)\n    done\n\n\n\nCopyright (c)  2013 Fabian \"fabiantheblind\" Mor\u00f3n Zirfas  \nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software  without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to  permit persons to whom the Software is furnished to do so, subject to the following conditions:  \nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.  \nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A  PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF  CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  \n\nsee also http://www.opensource.org/licenses/mit-license.php\n\n"}
{"url": "https://github.com/FH-Potsdam/ar-prototyping", "owner": "FH-Potsdam", "repository_name": "ar-prototyping", "date_all_variable_collection": "2023-09-11", "description": "evaluation of ar prototyping tools", "size": 5514, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 8, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 8, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "sebastian-meier", "contributions": 60}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 6083048}, {"language": "HTML", "num_chars": 9891}], "readme": "# AR-Prototyping\n## AFRAME.js + AR.js\n\nIf you are an experience developer, [Unity](https://unity.com/unity/features/ar) is the recommended development environment for AR and VR. There are good examples and boilerplates to get you [started](https://github.com/Unity-Technologies/arfoundation-samples). This repository is using [AFRAME.js](https://aframe.io/) and [AR.js](https://ar-js-org.github.io/AR.js-Docs/) (and [THREE.js](https://threejs.org/) under the hood). Using only web technologies it is easy to get started, also for beginners and it is extremely easy to deploy (its just a website).\n\n## Deploying Prototypes\n\nIf you are just getting started and want to experiment, I recommend you fork this repo and activate the [GitHub Pages settings](https://pages.github.com/). GitHub will then host all the examples and your code and you can immediately test it on your mobile device.\n\n## A little introduction\n\nThere a different concepts for extending reality (XR) through digital content. XR is the encompassing term describing all approaches. Virtual reality (VR) are applications that seperate reality and the virtual reality completely. While physicial interactions might still happen in the real world. The visual world is completely virtual. Augmented reality (AR) on the other hand, displays digital content on top of the real world. Most of the time the digital content is simply added on top, but in a mixed reality (MR), the real world objects and digital objects are interacting with one another. For example moving something in the real world, also results in an interaction in the digital world. Sometimes MR is also defined by the way you perceive the digital visualisation. While most people use phones and tablets to view AR content, using AR-glasses removes the device-frame and creates a smooth blending between real world and digital content.\n\n![Realities](figures/realities.png)\n\n### Devices\n\n![Cardboard AR](figures/cardboard.jpg)\nSource: [Wikipedia](https://en.wikipedia.org/wiki/Google_Cardboard#/media/File:Google-Cardboard.jpg)\n\nFor this prototyping approach we will simply use modern smartphones or tablets, nothing special required. If you are interested in prototyping VR content, I recommend buying a cardboard VR. Originally produced by [Google](https://arvr.google.com/cardboard/), cardboard VR sets are now available from various distributors for as cheap as 5 euros. Cardboard VR allows you to transform your phone into a VR headset. More sophisticated AR/VR headsets are:\n\n**VR:**\n- [HTC Vive](https://www.vive.com/us/)\n- [Facebook Oculus](https://www.oculus.com/quest-2/)\n- [HP Reverb](https://www.hp.com/us-en/vr/reverb-g2-vr-headset.html)\n- [Valve Index](https://store.steampowered.com/valveindex)\n- [PlayStation VR](https://www.playstation.com/en-us/ps-vr/)\n\n**AR**:\n- [Microsoft Hololens](https://www.microsoft.com/en-us/hololens/buy)\n- [Magic Leap](https://www.magicleap.com/en-us)\n- [Vuzix Blade](https://www.vuzix.com/products/vuzix-blade-smart-glasses-upgraded)\n- [Epson Moverio](https://www.epson.de/products/see-through-mobile-viewer/moverio-bt-40)\n\n## Overview\n\n**Basic**\n- 1. [Basic VR](01_basic_vr/README.md) - [Demo](01_basic_vr/index.html)\n- 2. [Basic AR](02_basic_ar/README.md) - [Demo](02_basic_ar/index.html)\n- 3. [Marker-based AR](03_marker/README.md) - [Demo](03_marker/index.html)\n- 4. [Photo-based AR](04_photo/README.md) - [Demo](04_photo/index.html)\n- 5. [Location-based AR](05_location/README.md) - [Demo](05_location/index.html)\n\n**Advanced**\n- 6. [Dynamic Content](06_dynamic/README.md) - [Demo](06_dynamic/index.html)\n- 7. [Interactions](07_interactions/README.md) - [Demo](07_interactions/index.html)\n- 8. [3D-Manipulation](08_3d/README.md) - [Demo](08_3d/index.html)\n\n\n"}
{"url": "https://github.com/FH-Potsdam/artomaton", "owner": "FH-Potsdam", "repository_name": "artomaton", "date_all_variable_collection": "2023-09-11", "description": "this is just test code. Nothing to see here. Move along", "size": 4, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["event-emitter", "johnny-five", "plotter", "testing"], "languages": [{"language": "JavaScript", "num_chars": 4988}], "readme": "# artomaton\na physical computing project using johnny five, tracking.js, kinect to build something beautiful. Part of the seminar \"Gestalten in Code\" @FH-Potsdam\n"}
{"url": "https://github.com/FH-Potsdam/Basic-Coding-Crash-Course-I", "owner": "FH-Potsdam", "repository_name": "Basic-Coding-Crash-Course-I", "date_all_variable_collection": "2023-09-11", "description": "BC\u00d73 I @ University of Applied Sciences Potsdam (Germany)", "size": 3609, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 4067}, {"language": "HTML", "num_chars": 340}], "readme": "Basic Coding Crash Course I\n===========================\n\nThese are the examples we wrote at the BC\u00d73I @ University of Applied Sciences Potsdam (Germany).  \n\n## Dependencies \n\n- Needs [Nodejs](https://nodejs.org/en/)  \n\n## Further reading  \n\n__The Nature of Code__  \n\n> How can we capture the unpredictable evolutionary and emergent properties of nature in software? How can understanding the mathematical principles behind our physical world help us to create digital worlds? This book focuses on the programming strategies and techniques behind computer simulations of natural systems using Processing.  \n\n\n- [http://natureofcode.com/](http://natureofcode.com/)  \n- [shiffman/The-Nature-of-Code-Examples-p5.js](https://github.com/shiffman/The-Nature-of-Code-Examples-p5.js)\n- [shiffman/The-Nature-of-Code](https://github.com/shiffman/The-Nature-of-Code)  \n\n\n\n__Processing__\n\n> The visual arts are rapidly changing as media moves into the web, mobile devices, and architecture. When designers and artists learn the basics of writing software, they develop a new form of literacy that enables them to create new media for the present, and to imagine future media that are beyond the capacities of current software tools. This book introduces this new literacy by teaching computer programming within the context of the visual arts. It offers a comprehensive reference and text for Processing (www.processing.org), an open-source programming language that can be used by students, artists, designers, architects, researchers, and anyone who wants to program images, animation, and interactivity. Written by Processing\u2019s cofounders, the book offers a definitive reference for students and professionals. Tutorial chapters make up the bulk of the book; advanced professional projects from such domains as animation, performance, and installation are discussed in interviews with their creators.  \n\n- [mitpress.mit.edu/books/processing-0](https://mitpress.mit.edu/books/processing-0)\n\n__Generative Gestaltung__  \n\n>This website completes the book Generative Design. It offers direct access to all processing source code for the software described in the book.  \n>The book Generative Design describes the creation of images by using codes. An image is not created manually, but instead by translating a visual idea into a set of rules and then implementing it in a programming language. Such a program can not only create a single image but also design complete visual worlds when parameters are changed.  \n>We, the authors, want this book to provide a solid foundation for the use of this process. The book section \u201cBasic Principles\u201d illustrates generative techniques in relation to four foundation areas of design: color, shape, typography, and image. The designer\u2019s repertoire is further expanded in the section \u201cComplex Methods\u201d by combining a number of principles on the basis of six larger-scaled examples. In this section you will also find explanations of advanced techniques.\n\n\n- [generative-gestaltung.de](http://www.generative-gestaltung.de/)\n- [github.com/generative-design/Code-Package-p5.js  (WORK IN PROGRESS)](https://github.com/generative-design/Code-Package-p5.js)\n\n__Input/Output (Eingabe/Ausgabe)__\n\n>Fundamentals of process-oriented design.  \n>Design is increasingly dynamic and participatory. Digital, generative and interactive processes can be found in the design of digital media, communication processes and products (in production & use). In the center of the design the focus is planning, anticipating and implementing emergent systems based on natural technological and social processes. In this course the basic skills and possibilities of process-oriented design are analyzed and developed in a number of creative exercises. It is a broad overview of facets, methods and tools, as well as insights into the elementary handicraft and technical procedures and concepts of process-oriented design. An artistic and creative engagement with the corresponding technologies takes place.  \n\n- [interface.fh-potsdam.de/eingabe-ausgabe](https://interface.fh-potsdam.de/eingabe-ausgabe/)  \n- [P5.js examples for the current seminar @ fh-potsdam.github.io/steel-ant-input-output](http://fh-potsdam.github.io/steel-ant-input-output/)  \n\n## License  \n\n\nCopyright 2015 Fabian \"fabiantheblind\" Mor\u00f3n Zirfas & FH-Potsdam\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"}
{"url": "https://github.com/FH-Potsdam/Basic-Coding-Crash-Course-II", "owner": "FH-Potsdam", "repository_name": "Basic-Coding-Crash-Course-II", "date_all_variable_collection": "2023-09-11", "description": "BC\u00d73 II @ University of Applied Sciences Potsdam (Germany)", "size": 3389, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 2284063}, {"language": "HTML", "num_chars": 2062}, {"language": "CSS", "num_chars": 125}], "readme": "Basic Coding Crash Course II\n============================\n\nThese are the examples we wrote at the BC\u00d73II @ University of Applied Sciences Potsdam (Germany).  \n\n## Dependencies \n\n- Needs [Nodejs](https://nodejs.org/en/)  \n\n## Further reading  \n\n__The Nature of Code__  \n\n> How can we capture the unpredictable evolutionary and emergent properties of nature in software? How can understanding the mathematical principles behind our physical world help us to create digital worlds? This book focuses on the programming strategies and techniques behind computer simulations of natural systems using Processing.  \n\n\n- [http://natureofcode.com/](http://natureofcode.com/)  \n- [shiffman/The-Nature-of-Code-Examples-p5.js](https://github.com/shiffman/The-Nature-of-Code-Examples-p5.js)\n- [shiffman/The-Nature-of-Code](https://github.com/shiffman/The-Nature-of-Code)  \n\n\n\n__Processing__\n\n> The visual arts are rapidly changing as media moves into the web, mobile devices, and architecture. When designers and artists learn the basics of writing software, they develop a new form of literacy that enables them to create new media for the present, and to imagine future media that are beyond the capacities of current software tools. This book introduces this new literacy by teaching computer programming within the context of the visual arts. It offers a comprehensive reference and text for Processing (www.processing.org), an open-source programming language that can be used by students, artists, designers, architects, researchers, and anyone who wants to program images, animation, and interactivity. Written by Processing\u2019s cofounders, the book offers a definitive reference for students and professionals. Tutorial chapters make up the bulk of the book; advanced professional projects from such domains as animation, performance, and installation are discussed in interviews with their creators.  \n\n- [mitpress.mit.edu/books/processing-0](https://mitpress.mit.edu/books/processing-0)\n\n__Generative Gestaltung__  \n\n>This website completes the book Generative Design. It offers direct access to all processing source code for the software described in the book.  \n>The book Generative Design describes the creation of images by using codes. An image is not created manually, but instead by translating a visual idea into a set of rules and then implementing it in a programming language. Such a program can not only create a single image but also design complete visual worlds when parameters are changed.  \n>We, the authors, want this book to provide a solid foundation for the use of this process. The book section \u201cBasic Principles\u201d illustrates generative techniques in relation to four foundation areas of design: color, shape, typography, and image. The designer\u2019s repertoire is further expanded in the section \u201cComplex Methods\u201d by combining a number of principles on the basis of six larger-scaled examples. In this section you will also find explanations of advanced techniques.\n\n\n- [generative-gestaltung.de](http://www.generative-gestaltung.de/)\n- [github.com/generative-design/Code-Package-p5.js  (WORK IN PROGRESS)](https://github.com/generative-design/Code-Package-p5.js)\n\n__Input/Output (Eingabe/Ausgabe)__\n\n>Fundamentals of process-oriented design.  \n>Design is increasingly dynamic and participatory. Digital, generative and interactive processes can be found in the design of digital media, communication processes and products (in production & use). In the center of the design the focus is planning, anticipating and implementing emergent systems based on natural technological and social processes. In this course the basic skills and possibilities of process-oriented design are analyzed and developed in a number of creative exercises. It is a broad overview of facets, methods and tools, as well as insights into the elementary handicraft and technical procedures and concepts of process-oriented design. An artistic and creative engagement with the corresponding technologies takes place.  \n\n- [interface.fh-potsdam.de/eingabe-ausgabe](https://interface.fh-potsdam.de/eingabe-ausgabe/)  \n- [P5.js examples for the current seminar @ fh-potsdam.github.io/steel-ant-input-output](http://fh-potsdam.github.io/steel-ant-input-output/)  \n\n## License  \n\n\nCopyright 2015 Fabian \"fabiantheblind\" Mor\u00f3n Zirfas & FH-Potsdam\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE."}
{"url": "https://github.com/FH-Potsdam/BedTimeStories-by-GPT-3", "owner": "FH-Potsdam", "repository_name": "BedTimeStories-by-GPT-3", "date_all_variable_collection": "2023-09-11", "description": null, "size": 14, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "jorditost", "contributions": 3}, {"contributor": "Rahfl", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 2811}, {"language": "CSS", "num_chars": 1415}], "readme": "# BedTimeStories-by-GPT-3"}
{"url": "https://github.com/FH-Potsdam/best-practice-github", "owner": "FH-Potsdam", "repository_name": "best-practice-github", "date_all_variable_collection": "2023-09-11", "description": "Best practices for GitHub", "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "sebastian-meier", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# best-practice-github\nBest practices for GitHub\n"}
{"url": "https://github.com/FH-Potsdam/bit", "owner": "FH-Potsdam", "repository_name": "bit", "date_all_variable_collection": "2023-09-11", "description": null, "size": 3, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 1}, {"contributor": "gitter-badger", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 2471}], "readme": "# bit\n\n[![Gitter](https://badges.gitter.im/FH-Potsdam/bit.svg)](https://gitter.im/FH-Potsdam/bit?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)"}
{"url": "https://github.com/FH-Potsdam/blockseminar-WS1314-14W4D-IL", "owner": "FH-Potsdam", "repository_name": "blockseminar-WS1314-14W4D-IL", "date_all_variable_collection": "2023-09-11", "description": "written for block seminar @FH-Potsdam Werkstattpraxis 14W4D-IL Interface-Labor WS 2013/2014", "size": 44368, "stargazers_count": 3, "watchers_count": 3, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "blockseminar-WS1314-14W4D-IL\n============================\n\n\n###License  \nif not further noticed \n\nCopyright (c)  2014 Fabian \"fabiantheblind\" Mor\u00f3n Zirfas  \nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software  without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to  permit persons to whom the Software is furnished to do so, subject to the following conditions:  \nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.  \nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A  PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF  CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  \n\nsee also http://www.opensource.org/licenses/mit-license.php  \n\n\n#LW 126  \nDas Interfacelabor soll ein Ort zum Arbeiten und Experimentieren sein. Aufgrund der Tatsache, dass dort Hardware im Wert von mehreren Zehntausend Euro zur Verf\u00fcgung steht m\u00fcssen wir jedoch den Zugang beschr\u00e4nken. __Es wird keine freien Zugang geben__. Durch die Teilnahme am Seminar 14W4D-IL erlangt ihr die Berechtigung projektbasiert dort zu Arbeiten. Des weiteren finden unterschiedliche Kurse in LW 126 statt.  \n\nHinzu kommt die Sprechstunde am Dienstag von 10 bis 12:30 und 13:00 bis 16:00 Uhr in LW 126. Da gibt es die M\u00f6glichkeit sich Hilfe zu Soft- und Hardware Projekten zu holen. Andere Termine gibt es nur auf Vereinbarung.  \n\n\n###Umgang mit Hard- und Software  \n- Bitte behandeln Sie Hardware und Software pfleglich.  \n- Bei etwaigen Sch\u00e4den m\u00fcssen wir Ihre Haftpflicht Versicherung hinzuziehen.\n- F\u00fcr den Fall, dass Sie keine Haftpflicht Versicherung\u00a0haben, schliessen Sie bitte eine ab.  \n\n###[Workspace](https://incom.org/workspace/4652)  \n- Bitte werden Sie Mitglied des Workspace f\u00fcr allgemeine Ank\u00fcndigungen und Kommunikation.\n\n###Arbeitspl\u00e4tze  \n- Bitte halten Sie Ihren Arbeitsplatz in Ordnung.  \n- Ger\u00e4te, Bauteile und Werkzeuge kommen nach Gebrauch zur\u00fcck dahin wo sie her kamen.  \n- Verwaiste Projekte und Bauteile kommen nach einmaliger Ank\u00fcndigung im Workspace in den __\"Fundus\"__ und sind zur Verwendung und zum Ausschlachten durch andere freigegeben.  \n- M\u00fcll kommt in den M\u00fclleimern.  \n\n###Computer  \n- Bitte halte Sie die Computer in Ordnung.  \n- Software wird __NUR__ in Absprache mit der Werkstattleitung installiert.  \n- Projekte werden __NUR__ in den daf\u00fcr vorgesehenen Ordnern abgelegt.   \n- K\u00fcmmern Sie sich um die Archivierung Ihrer Software Projekte. Verwaiste Projekte werden nach einmaliger Ank\u00fcndigung im Workspace gel\u00f6scht.  \n\n###Ausleihe  \n- Bitte bringen Sie Geliehenes zum vereinbarten Termin zur\u00fcck. Bei nicht Einhaltung verlieren Sie das Anrecht sich etwas zu leihen.  \n\n###Arbeitssicherheit beim L\u00f6ten und Handwerken  \n\n- Tragen Sie eine Schutzbrille. (L\u00f6tzinn kann spritzen).  \n- Tragen Sie keine Ringe, Halst\u00fccher u.\u00e4..  \n- Tragen Sie festes Schuhwerk.\n- \u00dcberpr\u00fcfen Sie den L\u00f6tkolben auf M\u00e4ngel.  \n- Seien Sie vorsichtig beim Umgang mit dem L\u00f6tkolben.  \n- Benutzen Sie den L\u00f6tkolben nicht zweckentfremdet.  \n- Halten Sie den Schwamm sauber.  \n- Halten Sie die L\u00f6tspitze sauber.  \n- Stecken sie den L\u00f6tkolben immer in die Haltevorrichtung.  \n- Achten sie darauf, dass der L\u00f6tkolben nicht das eigene Kabel verletzt.  \n- Lassen Sie den L\u00f6tkolben nie unbeaufsichtigt.  \n- Trennen Sie den L\u00f6tkolben bei Verlassen des Arbeitsplatzes immer vom Netz.  \n- Halten sie den ausgesteckten, aber noch hei\u00dfen L\u00f6tkolben von brennbaren Stoffen fern.  \n\n##Kein Essen, Trinken und Rauchen in der Werkstatt  \n\nMit freundlichen Gr\u00fc\u00dfen\nFabian Mor\u00f3n Zirfas\n\n\n"}
{"url": "https://github.com/FH-Potsdam/city-vis-website", "owner": "FH-Potsdam", "repository_name": "city-vis-website", "date_all_variable_collection": "2023-09-11", "description": "cityvis.io", "size": 693287, "stargazers_count": 0, "watchers_count": 0, "language": "SCSS", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 3, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 3, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "jessicabounassar", "contributions": 25}, {"contributor": "sebastian-meier", "contributions": 22}, {"contributor": "leooleh", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "SCSS", "num_chars": 56714}, {"language": "JavaScript", "num_chars": 30225}, {"language": "Nunjucks", "num_chars": 27283}, {"language": "HTML", "num_chars": 1344}], "readme": "# CityVis Website\n\n- `npm install`\n- `npm start`\n"}
{"url": "https://github.com/FH-Potsdam/climate-project-collection", "owner": "FH-Potsdam", "repository_name": "climate-project-collection", "date_all_variable_collection": "2023-09-11", "description": "Netlify Forms for collecting Climate Change Communication projects", "size": 16185, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "sebastian-meier", "contributions": 23}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 41361}, {"language": "JavaScript", "num_chars": 1990}], "readme": "# climate-project-collection\nNetlify Forms for collecting Climate Change Communication projects\n"}
{"url": "https://github.com/FH-Potsdam/connecting-bits", "owner": "FH-Potsdam", "repository_name": "connecting-bits", "date_all_variable_collection": "2023-09-11", "description": "A project of the seminar input output", "size": 102165, "stargazers_count": 4, "watchers_count": 4, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 3, "license": "ISC License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 3, "watchers": 4, "default_branch": "master", "contributors": [{"contributor": "nikoripka", "contributions": 79}, {"contributor": "fabiantheblind", "contributions": 9}, {"contributor": "vogelino", "contributions": 7}, {"contributor": "antsteelmule", "contributions": 5}, {"contributor": "miduku", "contributions": 3}, {"contributor": "Ourelius", "contributions": 2}, {"contributor": "gitter-badger", "contributions": 1}, {"contributor": "transl8r", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 46265}], "readme": "\n[![Join the chat at https://gitter.im/FH-Potsdam/connecting-bits](https://badges.gitter.im/FH-Potsdam/connecting-bits.svg)](https://gitter.im/FH-Potsdam/connecting-bits?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge) [![ZenHub] (https://raw.githubusercontent.com/ZenHubIO/support/master/zenhub-badge.png)] (https://zenhub.io) [![Managed with asana](https://raw.githubusercontent.com/FH-Potsdam/connecting-bits/master/documentation/asanabadge.jpg)](https://app.asana.com/-/share?s=80136391129690-GUJvZiI4OufoWMTDhjjkZauXYEhwvhpqUgnTvw22tMr-74348281972886)\n[![Javascript documentation](http://fh-potsdam.github.io/connecting-bits/badge.svg?build=123)](http://fh-potsdam.github.io/connecting-bits/source.html) [![Inline docs](http://inch-ci.org/github/FH-Potsdam/connecting-bits.svg?branch=master&style=shields)](http://inch-ci.org/github/FH-Potsdam/connecting-bits)\n\n# TRANSL8R \u2013 Play the _Chinese whispers_ game with machines\n\n[![the video](images/tranls8r-video2.png)](https://www.vimeo.com/157480156)\n*Watch our video on Vimeo.*\n\n\n## Introduction\nTRANSL8R is a chain of multilingual machines to play the _Chinese whispers_ game with, meant to be shown in an exhibition context.\nIt consists of four boxes. The first box listens to the visitor's message and repeats it out loud. The second box listens to the first one and translates that message into a different language. The third and fourth one each do the same (every box speaks a different language). Finally, the first box translates the message back into the original language. In an ideal case, that message would be the same as the original one, but the little mistakes of the translation engine make for a funny ending, just as in the _Chinese whispers_ game.\n\n\n## Tech specs\n![arduino and sensors](images/hardware-.3.jpg)\n\nThe four boxes are custom-made cubic machines with various mechanical elements and electronics. Each box consists of:\n\n- **An LED:** To indicate that the box is speaking\n- **Two servo motors:** To move the box as it listens and speaks and to give it a living character\n- **An infrared sensor:** To detect the presence of a person standing in front of it and start the audio recording\n- **A microphone:** To record the person's voice\n- **A speaker:** To play back the messages\n- **A Particle Photon:** To control the whole process via Wi-Fi\n\nWe also used:\n- **A Mac mini**: To record, translate and play back the messages\n\n\n## Design\n![final design](images/hardware-.4.jpg)\n\n\nThe base is made of concrete and looks like a thick frame. On top of it there is a structure of medium-density-fibreboard that holds everything together: the photon board, the microphone, the LED, as well as the two servo motors that make the lifting and tilting movements possible. For the cover, we bent a thin aluminium plate to create a five-sided cube.\nThe four boxes are on top of a black, custom-made table, in which the infrared sensor, the speakers, the Mac mini and all the cables are hidden.\n\n\n![arduino and sensors](images/hardware-.1.jpg)\n\n\n## How it works\nIn reality, the boxes don't really \"listen\" to each other as with a microphone; everything is done at once by a computer and played back simultaneously with the movement of the boxes. This is what really happens:\n\n0. The IR sensor is placed under the first box. As soon as someone gets closer than 30cm to the table, the next step is triggered.\n1. The servo motors lift and tilt the first box.\n2. A welcoming messaged is played back by the speaker, asking the visitor to say something.\n3. The microphone records the visitor's message.\n4. The first box tilts back, as it is about to say something. At the same time, the second box lifts and tilts, as if it were about to \"listen\" to its sibling.\n5. The speaker plays back the visitor's message in German. Under the hood, the computer is translating it into the three remaining languages and back to German.\n6. The second box tilts back and the speaker plays back the translation in Spanish. The first box moves back to its original position, while the third box is already in \"listening\" mode.\n7. Now the third box tilts back and the speaker plays back the translation in English. The second box moves back to its original position, while the fourth box is in \"listening\" mode.\n8. The fourth box tilts back and the speaker plays back the translation in Arabic. The third box moves back to its original position, while the first box is in \"listening\" mode.\n9. Finally, the first box tilts back and the speaker plays back the last translation (German). The fourth box moves back to its original position.\n10. The first box moves back, too, ready for the next visitor.\n\n\n## The process\n\n### The base reference\nThis was our third and last project of the semester. Our assignment was to develop and build a system consisting of four different modules. Each module should have a Particle Photon with an Internet connection as well as sensors that would trigger something (like a temperature sensor that would make an LED blink once a certain temperature was reached, for instance). Such an activated module would then send a signal to the next one, which would do something as well, and send a signal to the next one until all four had successfully done 'something'.\nFour groups were formed, each tasked with the creation of one unique module. And that was it. We had to figure out the rest for ourselves.\n\n#### Initial ideas\n![brainstorming](images/group-work-.1.jpg)\n\nAfter hours of brainstorming, we came up with several ideas. Here are some of the more funny and original ones:\n- **The four temperaments:** \"A proto-psychological theory that suggests that there are four fundamental personality types, sanguine (optimistic and social), choleric (short-tempered or irritable), melancholic (analytical and quiet), and phlegmatic (relaxed and peaceful).\" (Wikipedia) Using these personality types, we wanted to question whether it is possible to create machines with a certain temperament.\n- **Black boxes:** The idea was to create a kind of treasure hunt using at least twenty black boxes that looked the same. The visitors would have to find the 'real' four boxes with the leads inside of them.\n- **Moralizer:** A judging robot that would scream whenever someone did something immoral, like lighting a cigarette.\n- **TRANSL8R:** Four boxes that play the Chinese Whispers game (sound familiar?!) translating a message into several languages and then back into the original one.\n\n#### Our final choice\nWe ended up choosing the latter. This led us to restructure the groups, since we needed a consistent design and the same programming for all boxes.\nTwo new groups were formed: _Product design & Mechanics_ and _Hardware & Software_.\n\n\n\n### Product design & Mechanics\nEarly on, the team developed a simple lifting and tilting system.\n\n![mechanics](images/mechanics-.1.jpg)\n![mechanics](images/mechanics-.2.jpg)\n\nCopper and concrete were chosen as external materials as both share an interesting texture and have colours that complement each other well.\n\n![copper and concrete](images/product-design-.8.jpg)\n\nUnfortunately, we realised that copper was heavier than expected, which meant we would need more powerful and considerably costlier servo motors to lift the copper cover. That was not an option, so the lighter (and cheaper!) aluminium it was.\n\n![cutting the aluminium](images/product-design-.5.jpg)\n_Cutting the aluminium_\n\n![glueing the aluminium together](images/product-design-.7.jpg)\n_Glueing the aluminium together_\n\n![concrete](images/product-design-.6.jpg)\n_The concrete in the custom-built molds_\n\n![Building the first prototype](images/product-design-.2.jpg)\n![Building the first prototype](images/product-design-.3.jpg)\n_Building the first prototype_\n\n![Laser-cutting the structure parts](images/product-design-.4.jpg)\n_Laser-cutting the structure parts (medium-density-fibreboard)_\n\n![finishing the table](images/product-design-.10.jpg)\n_Finishing the table_\n\n#### How-to\n\n![finishing the table](images/TRANSL8R-How-to-3.png)\n![finishing the table](images/TRANSL8R-How-to-1.png)\n![finishing the table](images/TRANSL8R-How-to-2.png)\n\nYou can download the original Ai file [here](images/TRANSL8R-How-to.ai).\n\n\n### Hardware & Software\n![the coding team](images/software.jpg)\n\nCheck out the detailed documentation of the [software](https://github.com/FH-Potsdam/connecting-bits/wiki/The-Software) and the [hardware](https://github.com/FH-Potsdam/connecting-bits/wiki/The-Hardware) in the Wiki.\n\n\n## About Us\n![group work](images/group-work-.3.jpg)\n\nWe are students from the [University of Applied Sciences of Potsdam](http://fh-potsdam.de) aka [@fh-potsdam](https://github.com/FH-Potsdam). Our team consists of interface, product, and graphic designers that took part in the course _Input Output \u2013 Introduction to process-oriented design_ by [Fabian Mor\u00f3n Zirfas](https://github.com/fabiantheblind). This project was developed during the last third of the course. To see the other projects we made, visit [this repository](https://interface.fh-potsdam.de/eingabe-ausgabe/2015-2016/).\n\n- [Wolfgang Albrecht](https://github.com/wollemannone)\n- [Marta Carlesso](https://github.com/martakarta)\n- [Julia Freyhoff](https://github.com/antsteelmule)\n- [Paul Klinski](https://github.com/Logetcrea)\n- [Nina Komarova-Zelinskaya](https://github.com/Ninotschka)\n- [Dustin Kummer](https://github.com/miduku)\n- [Bela Kurek](https://github.com/Q-rec)\n- [Andre Nagusch](https://github.com/Ourelius)\n- [Joshua Pacheco](https://github.com/josues)\n- [Laura Pau Bielsa](https://github.com/lpaubielsa)\n- [Nikolas Ripka](https://github.com/nikoripka)\n- [Jo Swarzynska](https://github.com/swjo)\n- [Daria Thies](https://github.com/dariaDunkelbier)\n- [Lucas Vogel](https://github.com/vogelino)\n"}
{"url": "https://github.com/FH-Potsdam/controlling-hue", "owner": "FH-Potsdam", "repository_name": "controlling-hue", "date_all_variable_collection": "2023-09-11", "description": "controlling hue", "size": 9, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1912}, {"language": "HTML", "num_chars": 942}, {"language": "CSS", "num_chars": 743}], "readme": "controlling hue\n===============\n\nThis is boilerplate code for the hue team.\n\n## Usage\n\nDownload and unzip this package [here][download].  \n\nMove with the terminal into the folder.  \n\n    cd ~/Downloads/controlling-hue-master/\n\nInstall the modules\n\n    npm install\n\nRun it \n\n    node index.js\n\nopen [http://localhost:3000][host].  \n\nClick the buttons.  \n\nNow you can add your code in the index.js file to control the hue bulbs.  \n\n\n\n[download]: https://github.com/FH-Potsdam/controlling-hue/archive/master.zip\n[host]: http://localhost:3000"}
{"url": "https://github.com/FH-Potsdam/coursesAPI", "owner": "FH-Potsdam", "repository_name": "coursesAPI", "date_all_variable_collection": "2023-09-11", "description": "A REST API designed for study courses", "size": 68, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 6, "license": "Do What The F*ck You Want To Public License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 6, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "vogelino", "contributions": 70}, {"contributor": "Q-rec", "contributions": 6}, {"contributor": "topada", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 25469}], "readme": "[![Join the chat at https://gitter.im/FH-Potsdam/coursesAPI][gitterBadge]][gitterUrl]\n\n# Courses API\nA REST API designed to create, read, update and delete study courses (CRUD).\n\n## Prerequisites\nTo contribute to the development and to run the courses API, make sure you fulfill the following prerequisites:\n- You have ``node (6.7.0)`` and ``npm (3.10.3)`` installed. (I recommend installing them with [nvm][nvm])\n- You have both ``mongo (3.2.9)^`` and ``mongod (db version v3.2.9^)`` installed.\n\n## Quick start\n\n### Quick start: First setup\nClone the repository locally and move into it.\n```bash\ngit clone https://github.com/FH-Potsdam/coursesAPI.git && cd coursesAPI\n```\nIf you have [nvm][nvm] installed, run:\n```sh\nnvm use\n```\nInstall the node dependencies (npm):\n```sh\nnpm install\n```\n\n### Quick start: Development\nMake sure ``mongod`` is running by executing the following in another terminal session:\n```sh\nmongod\n```\nIf you changed the configuration of mongoDB, adapt the local configuration:\n```sh\nvim config/default.json\n```\nNow, to watch and develop run:\n```sh\nnpm run watch\n```\nTry it (Example using the defaults. Adapt it to your config):\n```sh\ncurl -i -X http://localhost:3000/courses?limit=5\n```\n\n### Quick start: Production\nStart you production mongoDB server:\n```sh\nmyProductionUser@myProductionServer(ssh)$ mongod\n```\nAdapt your production config\n```sh\ncp config/default.json config/production.json\nvim config/production.json # change the config and save\n```\nFinally build and serve in production mode\n```sh\nnpm run build && npm run serve\n```\nTry it (Example using a dummy url. Adapt it to your config):\n```sh\ncurl -i -X http://my-online-api-server.com/courses/?limit=5\n```\n\n## Courses API data\nThe courses data consists of the following resources:\n- :white_check_mark: **A course**: Information about a study course teached in a school at a specific semester.\n- :white_medium_square: **A school**: Information about a school offering courses.\n- :white_check_mark: **A teacher**: Information about a teacher acossiated to courses and schools.\n- :white_check_mark: **A location**: Information about a specific location where one or many courses take place.\n- :white_medium_square: **A relationship**: Information about courses dependencies. I.e. Course B requires students to first graduate the course A.\n\nResources with :white_check_mark: are already implemented and others are to follow.\n\nResources names are consistent through the whole programm. They are used for collections in the MongoDB database, for the mongoose Schemas and in the REST API urls. They are always written in lowercase and in the plural form to avoid inconsistencies and improve intuitiveness.\n\nThis enables us to improve upon existing resources easier and in a generic fashion. In the future, you will just have to add a mongoose Schema with a lowercase plural name, and automatically, an url, a collection and all CRUD actions will be available for this resource.  \n\nTo better understand how a resource is structured, refer to the documentation:\n[Types, Schemas, Structure and Relationships][docDataType] WIP\n\n# Motivation\nThis project has been made as project of the 2 weeks long Workshop \"Creating an open sourced REST API\" given by Julia Freyhoff @antsteelmule and Lucas Vogel @vogelino in the University of Applied Sciences Potsdam.\n\nThis project was done in parallel with two other projects:\n- :octocat: [Data Scraper](https://github.com/FH-Potsdam/fhpCoursesScraper)\nA webscraper extracting information about the courses of the University of Applied Sciences Potsdam to fill the MongoDB database.\n- :octocat: [Viewer (App)](https://github.com/FH-Potsdam/coursesViewer)\nAn html website using the courses API to display all the available courses. This project was used as a demonstration of an API usage with ajax loading.\n\nIf you want to know more about the Project and/or the Workshop, look at our [documentation](https://fhp.incom.org/projekt/7668) (german), or get in touch with us.\n\n## Collaborators\n- [Julia Freyhoff](https://github.com/antsteelmule) \u2014 @antsteelmule\n- [Lucas Vogel](https://github.com/vogelino) \u2014 @vogelino\n- [Jonas K\u00f6pfer](https://github.com/topada) \u2014 @topada\n- [Joseph Ribbe](https://github.com/coderwelsch) \u2014 @coderwelsch\n- [Bela Kurek](https://github.com/q-rec) \u2014 @q-rec\n\n<!--- Links -->\n[gitterBadge]: https://badges.gitter.im/Join%20Chat.svg\n[gitterUrl]:  https://gitter.im/FH-Potsdam/coursesAPI?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge\n[nvm]: https://github.com/creationix/nvm\n[docDataType]: #\n"}
{"url": "https://github.com/FH-Potsdam/coursesViewer", "owner": "FH-Potsdam", "repository_name": "coursesViewer", "date_all_variable_collection": "2023-09-11", "description": "A study courses viewer using the FH-Potsdam/coursesAPI", "size": 6161, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "Do What The F*ck You Want To Public License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "vogelino", "contributions": 16}, {"contributor": "antsteelmule", "contributions": 10}, {"contributor": "Q-rec", "contributions": 5}, {"contributor": "topada", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 1846}, {"language": "JavaScript", "num_chars": 1119}, {"language": "CSS", "num_chars": 252}], "readme": "[![Join the chat at https://gitter.im/FH-Potsdam/coursesAPI][gitterBadge]][gitterUrl]\n\n# Courses Viewer\nAn html website using the [courses API](https://github.com/FH-Potsdam/coursesAPI) to display all the available courses given at the University Of Applied Science Potsdam. This project was used as a demonstration of an API usage with ajax loading.\n\n![A preview of the viewer](README.png)\n\n## Getting started\nClone the repository locally and move into it.\n```bash\ngit clone https://github.com/FH-Potsdam/coursesViewer.git && cd coursesViewer\n```\nAnd open the file `src/index.html` in your favourite browser.\n\n# Motivation\nThis project has been made as project of the 2 weeks long Workshop \"Creating an open sourced REST API\" given by Julia Freyhoff @antsteelmule and Lucas Vogel @vogelino in the University of Applied Sciences Potsdam.\n\nThis project was done in parallel with two other projects:\n- :octocat: [Data Scraper](https://github.com/FH-Potsdam/fhpCoursesScraper)\nA webscraper extracting information about the courses of the University of Applied Sciences Potsdam to fill the MongoDB database.\n- :octocat: [Courses API](https://github.com/FH-Potsdam/coursesAPI)\nA REST API designed to create, read, update and delete study courses (CRUD).\n\nIf you want to know more about the Project and/or the Workshop, look at our [documentation](https://fhp.incom.org/projekt/7668) (german), or get in touch with us.\n\n## Collaborators\n- [Julia Freyhoff](https://github.com/antsteelmule) \u2014 @antsteelmule\n- [Lucas Vogel](https://github.com/vogelino) \u2014 @vogelino\n- [Jonas K\u00f6pfer](https://github.com/topada) \u2014 @topada\n- [Joseph Ribbe](https://github.com/coderwelsch) \u2014 @coderwelsch\n- [Bela Kurek](https://github.com/q-rec) \u2014 @q-rec\n\n<!--- Links -->\n[gitterBadge]: https://badges.gitter.im/Join%20Chat.svg\n[gitterUrl]:  https://gitter.im/FH-Potsdam/coursesAPI?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge\n"}
{"url": "https://github.com/FH-Potsdam/ct-code-examples", "owner": "FH-Potsdam", "repository_name": "ct-code-examples", "date_all_variable_collection": "2023-09-11", "description": "All Coding Sessions from the seminar Creative Technologists - Tracing the City https://fhp.incom.org/workspace/8527 ", "size": 2271, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 11, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 11, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 28}, {"contributor": "dependabot[bot]", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 26828}, {"language": "HTML", "num_chars": 18893}], "readme": "# CT Coding Sessions\n\n[![](./docs/thumbs/colores.png)](./packages/colores) [![](./docs/thumbs/connected-dots.png)](./packages/grid) [![](./docs/thumbs/gridorious.png)](./packages/gridorious) [![](./docs/thumbs/swing.png)](./packages/swing)\n\nThis is a collection repo with all the examples generated during coding sessions in the seminar [Creative Technologists - Tracing the City](https://fhp.incom.org/workspace/8527).\n\nIn the folder `packages` you will find all the session. \n\n\n## Usage\n\nDue to the fact that we have multiple repos we use lerna to bootstrap them all.\n\n\n```bash\ngit clone git@github.com:FH-Potsdam/ct-code-examples.git\ncd ct-code-examples\nnpm install\nnpm run setup\nnpm run serve\n```\n\n## Develop  \n\nWhen all the subfolders should have their dependencies installed using \n`npm run setup` you can cd into it and start the dev server using `npm start`.\n\n"}
{"url": "https://github.com/FH-Potsdam/ct-interactive", "owner": "FH-Potsdam", "repository_name": "ct-interactive", "date_all_variable_collection": "2023-09-11", "description": "assigment for the seminar CT - Tracing the city", "size": 122, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 2, "license": null, "allow_forking": true, "is_template": true, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 6208}, {"language": "HTML", "num_chars": 4463}], "readme": "# Creative Technologist Interactive\n\n## How to\n\n1. Open the whole folder in VSCode\n2. Open a new Terminal session\n3. Run `npm install` **once**\n4. Run `npm run bootstrap` **once**\n5. Run `npm start` **whenever you need a development server**\n6. The assignments are added as `@todo` in the beginning of each `packages/{area,particles}/index.js` file\n7. When done commit and push your results back to GitHub\n8. Describe in the README which problems you've solved\n9. Add images. \ud83d\udc47\n\n## Images\n\n1. Result images need to be located in each packages folder under `images`\n2. Images should be type PNG\n3. Images should be 500 \u00d7 500 Pixels\n4. Each image has to be added to the `images.json` file in the images folder\n5. NO UPPERCASE names\n6. NO whitespaces in names\n7. NO special characters `\u00f6\u00e4\u00fc\u00df?=)(/&%$\u00a7\"!*'#.;:,`\n8. `a-z` and `0-9` and `_-` are okay\n"}
{"url": "https://github.com/FH-Potsdam/ct-keyboardhack", "owner": "FH-Potsdam", "repository_name": "ct-keyboardhack", "date_all_variable_collection": "2023-09-11", "description": "Keyboardhack template for the seminar creative Technologist", "size": 89, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 3, "license": "MIT License", "allow_forking": true, "is_template": true, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 3, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1855}, {"language": "HTML", "num_chars": 1652}], "readme": "# CT Keyboard Hack\n\n> Starter kit for the seminar \"Creative Technologists - Tracing the City\" @ University of Applied Sciences Potsdam (Germany) winter semester 2019/2020 by Fabian Mor\u00f3n Zirfas\n\n## Assignment\n\n1. Hack your keyboard\n2. Create a reaction on keypress\n3. Create a video which shows your Hack\n4. Commit and push to the repo\n\n### Hints\n\n## Usage\n\n1. Open a terminal session in the root of the repository and type `npm install`  and hit return \u21a9 to install all dependencies.\n2. Type `npm start` and hit return \u21a9 to start the reload server.\n3. Start hacking\n4. When you are done and enrolled in the classroom, use the classroom to submit your assignment.\n\n## Contributing\n\nPull requests and stars are always welcome. For bugs and feature requests, [please create an issue](https://github.com/FH-Potsdam/dma/issues)\n\n## Author(s)\n\n**Fabian Mor\u00f3n Zirfas:**\n\n- [github/](https://github.com/fabianmoronzirfas)\n- [twitter/](http://twitter.com/fmoronzirfas)\n\n## License\n\nCopyright \u00a9 2019 [Fabian Mor\u00f3n Zirfas](https://fabianmoronzirfas.me)\nLicensed under the MIT license.\n"}
{"url": "https://github.com/FH-Potsdam/ct-making-things-move", "owner": "FH-Potsdam", "repository_name": "ct-making-things-move", "date_all_variable_collection": "2023-09-11", "description": "Boilerplate/Template for the seminar Creative Technologist - Excercise Making Things Move", "size": 38, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": true, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 27995}, {"language": "JavaScript", "num_chars": 1251}], "readme": "# Creative Technologist - Making Things Move\n\nThis is Boilerplate code for making things move using Johnny Five, Arduino and Node.js.\n\n## Prerequisites\n\n1. Arduino Uno Board + USB AB cable\n2. Something to flash Firmata to the Arduino.\n   - [Arduino IDE](https://www.arduino.cc/en/Main/Software)\n   - or [PlatformIO IDE f\u00fcr VSCode](https://platformio.org/)\n   - or [PlatformIO Core CLI](https://docs.platformio.org/en/latest/installation.html#)\n3. Some components like LEDs or servos\n\n## Setup\n\n### Node.js\n\nIn the root of the repository run `npm install`.  \n\n### Flash the StandardFirmata sketch to the Arduino\n\n*Hint: If you want to use steppers motors you will need a different Firmata Sketch. See the comments in example source for the [johnny-five stepper-driver](http://johnny-five.io/examples/stepper-driver/)*\n\n- Connect your board\n  \n#### With Arduino IDE\n\n- Select the board `Tools > Board > Arduino Uno/ Genuino Uno`\n- Select the USB port `Tools > Port > tty/usb.something` (on Windows `COM1` or another number)\n- Select the StandardFirmata Sketch `File > Examples Firmata > StandardFirmata`\n- Hit upload on the top of the IDE or select `Sketch > Upload`\n\n#### With PlatformIO Core\n\n*Hint: You can use the command `platformio` interchangeably with `pio` both work the same way.*\n\n\n- Open a new Terminal\n- In an empty folder run `platformio init --board uno` to scaffold a new project\n- Edit `platformio.ini` and add the following lines below `[env:uno]`\n\n```ini\nlib_deps =\n  Servo\n  Firmata\n  SoftwareSerial\n```\n\n- Got to [https://github.com/firmata/arduino](https://github.com/firmata/arduino/blob/master/examples/StandardFirmata/StandardFirmata.ino) and copy the content of `examples/StandardFirmata/StandardFirmata.ino` into a new file in the folder called `src/` called `StandardFirmata.ino`\n- Run `platformio run` in your Terminal\n- Watch the output for errors. If there are missing libraries add them to the `lib_deps`\n- With your board connected run `platformio run --target upload`\n\nSee the folder [firmwares/standard-firmata](firmwares/standard-firmata) for an example.\n\n---\n\nIf everything went smooth you should have your board ready.\n\n## Run\n\nWith your board running a firmata sketch and connected to the computer run:\n\n`npm start`\n\n## Troubleshooting\n\n### Board not recognized\n\nIs your board connected and recognized? Did you select the right port in the IDE?\n\nTo test this you should try to upload a simple Blink sketch from the Arduino IDE `File > Examples > 01.Basic > Blink`\n\nSometimes using a different USB port helps.\n\n### PlatformIO does not find the board\n\nTry running `pio upgrade` and `pio update`\nTry running `pio device list` is your board showing up?\nTry running the `pio run --target upload --upload-port` and add the device port from the list to the end.\n"}
{"url": "https://github.com/FH-Potsdam/ct-making-things-move-interactive", "owner": "FH-Potsdam", "repository_name": "ct-making-things-move-interactive", "date_all_variable_collection": "2023-09-11", "description": "Boilerplate for CT seminar", "size": 846, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 3, "license": null, "allow_forking": true, "is_template": true, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 3, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 4310748}, {"language": "C++", "num_chars": 28521}, {"language": "HTML", "num_chars": 545}, {"language": "CSS", "num_chars": 38}], "readme": "# Creative Technologist - Making Things Move interactive\n\nTemplate for the seminar CT.\n\n\n## Setup\n\n- clone it\n- cd into repo\n- npm install\n- connect a servo on pin 10 to the board\n- connect board with StandardFirmata on it to the computer\n- `npm start` (reloads on change)\n- open http://localhost:3000\n- hack on it"}
{"url": "https://github.com/FH-Potsdam/ct-mtm-a-joseph14", "owner": "FH-Potsdam", "repository_name": "ct-mtm-a-joseph14", "date_all_variable_collection": "2023-09-11", "description": "ct-mtm-a-joseph14 created by GitHub Classroom", "size": 45, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 27995}, {"language": "JavaScript", "num_chars": 1251}], "readme": "# Creative Technologist - Making Things Move\n\nThis is Boilerplate code for making things move using Johnny Five, Arduino and Node.js.\n\n## Prerequisites\n\n1. Arduino Uno Board + USB AB cable\n2. Something to flash Firmata to the Arduino.\n   - [Arduino IDE](https://www.arduino.cc/en/Main/Software)\n   - or [PlatformIO IDE f\u00fcr VSCode](https://platformio.org/)\n   - or [PlatformIO Core CLI](https://docs.platformio.org/en/latest/installation.html#)\n3. Some components like LEDs or servos\n\n## Setup\n\n### Node.js\n\nIn the root of the repository run `npm install`.  \n\n### Flash the StandardFirmata sketch to the Arduino\n\n*Hint: If you want to use steppers motors you will need a different Firmata Sketch. See the comments in example source for the [johnny-five stepper-driver](http://johnny-five.io/examples/stepper-driver/)*\n\n- Connect your board\n  \n#### With Arduino IDE\n\n- Select the board `Tools > Board > Arduino Uno/ Genuino Uno`\n- Select the USB port `Tools > Port > tty/usb.something` (on Windows `COM1` or another number)\n- Select the StandardFirmata Sketch `File > Examples Firmata > StandardFirmata`\n- Hit upload on the top of the IDE or select `Sketch > Upload`\n\n#### With PlatformIO Core\n\n*Hint: You can use the command `platformio` interchangeably with `pio` both work the same way.*\n\n\n- Open a new Terminal\n- In an empty folder run `platformio init --board uno` to scaffold a new project\n- Edit `platformio.ini` and add the following lines below `[env:uno]`\n\n```ini\nlib_deps =\n  Servo\n  Firmata\n  SoftwareSerial\n```\n\n- Got to [https://github.com/firmata/arduino](https://github.com/firmata/arduino/blob/master/examples/StandardFirmata/StandardFirmata.ino) and copy the content of `examples/StandardFirmata/StandardFirmata.ino` into a new file in the folder called `src/` called `StandardFirmata.ino`\n- Run `platformio run` in your Terminal\n- Watch the output for errors. If there are missing libraries add them to the `lib_deps`\n- With your board connected run `platformio run --target upload`\n\nSee the folder [firmwares/standard-firmata](firmwares/standard-firmata) for an example.\n\n---\n\nIf everything went smooth you should have your board ready.\n\n## Run\n\nWith your board running a firmata sketch and connected to the computer run:\n\n`npm start`\n\n## Troubleshooting\n\n### Board not recognized\n\nIs your board connected and recognized? Did you select the right port in the IDE?\n\nTo test this you should try to upload a simple Blink sketch from the Arduino IDE `File > Examples > 01.Basic > Blink`\n\nSometimes using a different USB port helps.\n\n### PlatformIO does not find the board\n\nTry running `pio upgrade` and `pio update`\nTry running `pio device list` is your board showing up?\nTry running the `pio run --target upload --upload-port` and add the device port from the list to the end.\n"}
{"url": "https://github.com/FH-Potsdam/ct-mtm-aaengelberg", "owner": "FH-Potsdam", "repository_name": "ct-mtm-aaengelberg", "date_all_variable_collection": "2023-09-11", "description": "ct-mtm-aaengelberg created by GitHub Classroom", "size": 45, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 27995}, {"language": "JavaScript", "num_chars": 1251}], "readme": "# Creative Technologist - Making Things Move\n\nThis is Boilerplate code for making things move using Johnny Five, Arduino and Node.js.\n\n## Prerequisites\n\n1. Arduino Uno Board + USB AB cable\n2. Something to flash Firmata to the Arduino.\n   - [Arduino IDE](https://www.arduino.cc/en/Main/Software)\n   - or [PlatformIO IDE f\u00fcr VSCode](https://platformio.org/)\n   - or [PlatformIO Core CLI](https://docs.platformio.org/en/latest/installation.html#)\n3. Some components like LEDs or servos\n\n## Setup\n\n### Node.js\n\nIn the root of the repository run `npm install`.  \n\n### Flash the StandardFirmata sketch to the Arduino\n\n*Hint: If you want to use steppers motors you will need a different Firmata Sketch. See the comments in example source for the [johnny-five stepper-driver](http://johnny-five.io/examples/stepper-driver/)*\n\n- Connect your board\n  \n#### With Arduino IDE\n\n- Select the board `Tools > Board > Arduino Uno/ Genuino Uno`\n- Select the USB port `Tools > Port > tty/usb.something` (on Windows `COM1` or another number)\n- Select the StandardFirmata Sketch `File > Examples Firmata > StandardFirmata`\n- Hit upload on the top of the IDE or select `Sketch > Upload`\n\n#### With PlatformIO Core\n\n*Hint: You can use the command `platformio` interchangeably with `pio` both work the same way.*\n\n\n- Open a new Terminal\n- In an empty folder run `platformio init --board uno` to scaffold a new project\n- Edit `platformio.ini` and add the following lines below `[env:uno]`\n\n```ini\nlib_deps =\n  Servo\n  Firmata\n  SoftwareSerial\n```\n\n- Got to [https://github.com/firmata/arduino](https://github.com/firmata/arduino/blob/master/examples/StandardFirmata/StandardFirmata.ino) and copy the content of `examples/StandardFirmata/StandardFirmata.ino` into a new file in the folder called `src/` called `StandardFirmata.ino`\n- Run `platformio run` in your Terminal\n- Watch the output for errors. If there are missing libraries add them to the `lib_deps`\n- With your board connected run `platformio run --target upload`\n\nSee the folder [firmwares/standard-firmata](firmwares/standard-firmata) for an example.\n\n---\n\nIf everything went smooth you should have your board ready.\n\n## Run\n\nWith your board running a firmata sketch and connected to the computer run:\n\n`npm start`\n\n## Troubleshooting\n\n### Board not recognized\n\nIs your board connected and recognized? Did you select the right port in the IDE?\n\nTo test this you should try to upload a simple Blink sketch from the Arduino IDE `File > Examples > 01.Basic > Blink`\n\nSometimes using a different USB port helps.\n\n### PlatformIO does not find the board\n\nTry running `pio upgrade` and `pio update`\nTry running `pio device list` is your board showing up?\nTry running the `pio run --target upload --upload-port` and add the device port from the list to the end.\n"}
{"url": "https://github.com/FH-Potsdam/ct-mtm-AgathaCrystal", "owner": "FH-Potsdam", "repository_name": "ct-mtm-AgathaCrystal", "date_all_variable_collection": "2023-09-11", "description": "ct-mtm-AgathaCrystal created by GitHub Classroom", "size": 45, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 27995}, {"language": "JavaScript", "num_chars": 1251}], "readme": "# Creative Technologist - Making Things Move\n\nThis is Boilerplate code for making things move using Johnny Five, Arduino and Node.js.\n\n## Prerequisites\n\n1. Arduino Uno Board + USB AB cable\n2. Something to flash Firmata to the Arduino.\n   - [Arduino IDE](https://www.arduino.cc/en/Main/Software)\n   - or [PlatformIO IDE f\u00fcr VSCode](https://platformio.org/)\n   - or [PlatformIO Core CLI](https://docs.platformio.org/en/latest/installation.html#)\n3. Some components like LEDs or servos\n\n## Setup\n\n### Node.js\n\nIn the root of the repository run `npm install`.  \n\n### Flash the StandardFirmata sketch to the Arduino\n\n*Hint: If you want to use steppers motors you will need a different Firmata Sketch. See the comments in example source for the [johnny-five stepper-driver](http://johnny-five.io/examples/stepper-driver/)*\n\n- Connect your board\n  \n#### With Arduino IDE\n\n- Select the board `Tools > Board > Arduino Uno/ Genuino Uno`\n- Select the USB port `Tools > Port > tty/usb.something` (on Windows `COM1` or another number)\n- Select the StandardFirmata Sketch `File > Examples Firmata > StandardFirmata`\n- Hit upload on the top of the IDE or select `Sketch > Upload`\n\n#### With PlatformIO Core\n\n*Hint: You can use the command `platformio` interchangeably with `pio` both work the same way.*\n\n\n- Open a new Terminal\n- In an empty folder run `platformio init --board uno` to scaffold a new project\n- Edit `platformio.ini` and add the following lines below `[env:uno]`\n\n```ini\nlib_deps =\n  Servo\n  Firmata\n  SoftwareSerial\n```\n\n- Got to [https://github.com/firmata/arduino](https://github.com/firmata/arduino/blob/master/examples/StandardFirmata/StandardFirmata.ino) and copy the content of `examples/StandardFirmata/StandardFirmata.ino` into a new file in the folder called `src/` called `StandardFirmata.ino`\n- Run `platformio run` in your Terminal\n- Watch the output for errors. If there are missing libraries add them to the `lib_deps`\n- With your board connected run `platformio run --target upload`\n\nSee the folder [firmwares/standard-firmata](firmwares/standard-firmata) for an example.\n\n---\n\nIf everything went smooth you should have your board ready.\n\n## Run\n\nWith your board running a firmata sketch and connected to the computer run:\n\n`npm start`\n\n## Troubleshooting\n\n### Board not recognized\n\nIs your board connected and recognized? Did you select the right port in the IDE?\n\nTo test this you should try to upload a simple Blink sketch from the Arduino IDE `File > Examples > 01.Basic > Blink`\n\nSometimes using a different USB port helps.\n\n### PlatformIO does not find the board\n\nTry running `pio upgrade` and `pio update`\nTry running `pio device list` is your board showing up?\nTry running the `pio run --target upload --upload-port` and add the device port from the list to the end.\n"}
{"url": "https://github.com/FH-Potsdam/ct-mtm-ahaahaahaa", "owner": "FH-Potsdam", "repository_name": "ct-mtm-ahaahaahaa", "date_all_variable_collection": "2023-09-11", "description": "ct-mtm-ahaahaahaa created by GitHub Classroom", "size": 45, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 27995}, {"language": "JavaScript", "num_chars": 1251}], "readme": "# Creative Technologist - Making Things Move\n\nThis is Boilerplate code for making things move using Johnny Five, Arduino and Node.js.\n\n## Prerequisites\n\n1. Arduino Uno Board + USB AB cable\n2. Something to flash Firmata to the Arduino.\n   - [Arduino IDE](https://www.arduino.cc/en/Main/Software)\n   - or [PlatformIO IDE f\u00fcr VSCode](https://platformio.org/)\n   - or [PlatformIO Core CLI](https://docs.platformio.org/en/latest/installation.html#)\n3. Some components like LEDs or servos\n\n## Setup\n\n### Node.js\n\nIn the root of the repository run `npm install`.  \n\n### Flash the StandardFirmata sketch to the Arduino\n\n*Hint: If you want to use steppers motors you will need a different Firmata Sketch. See the comments in example source for the [johnny-five stepper-driver](http://johnny-five.io/examples/stepper-driver/)*\n\n- Connect your board\n  \n#### With Arduino IDE\n\n- Select the board `Tools > Board > Arduino Uno/ Genuino Uno`\n- Select the USB port `Tools > Port > tty/usb.something` (on Windows `COM1` or another number)\n- Select the StandardFirmata Sketch `File > Examples Firmata > StandardFirmata`\n- Hit upload on the top of the IDE or select `Sketch > Upload`\n\n#### With PlatformIO Core\n\n*Hint: You can use the command `platformio` interchangeably with `pio` both work the same way.*\n\n\n- Open a new Terminal\n- In an empty folder run `platformio init --board uno` to scaffold a new project\n- Edit `platformio.ini` and add the following lines below `[env:uno]`\n\n```ini\nlib_deps =\n  Servo\n  Firmata\n  SoftwareSerial\n```\n\n- Got to [https://github.com/firmata/arduino](https://github.com/firmata/arduino/blob/master/examples/StandardFirmata/StandardFirmata.ino) and copy the content of `examples/StandardFirmata/StandardFirmata.ino` into a new file in the folder called `src/` called `StandardFirmata.ino`\n- Run `platformio run` in your Terminal\n- Watch the output for errors. If there are missing libraries add them to the `lib_deps`\n- With your board connected run `platformio run --target upload`\n\nSee the folder [firmwares/standard-firmata](firmwares/standard-firmata) for an example.\n\n---\n\nIf everything went smooth you should have your board ready.\n\n## Run\n\nWith your board running a firmata sketch and connected to the computer run:\n\n`npm start`\n\n## Troubleshooting\n\n### Board not recognized\n\nIs your board connected and recognized? Did you select the right port in the IDE?\n\nTo test this you should try to upload a simple Blink sketch from the Arduino IDE `File > Examples > 01.Basic > Blink`\n\nSometimes using a different USB port helps.\n\n### PlatformIO does not find the board\n\nTry running `pio upgrade` and `pio update`\nTry running `pio device list` is your board showing up?\nTry running the `pio run --target upload --upload-port` and add the device port from the list to the end.\n"}
{"url": "https://github.com/FH-Potsdam/ct-mtm-carl-qq", "owner": "FH-Potsdam", "repository_name": "ct-mtm-carl-qq", "date_all_variable_collection": "2023-09-11", "description": "ct-mtm-carl-qq created by GitHub Classroom", "size": 35414, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}, {"contributor": "carl-qq", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 27995}, {"language": "JavaScript", "num_chars": 1251}], "readme": "# Creative Technologist - Making Things Move\n\nThis is Boilerplate code for making things move using Johnny Five, Arduino and Node.js.\n\n## Prerequisites\n\n1. Arduino Uno Board + USB AB cable\n2. Something to flash Firmata to the Arduino.\n   - [Arduino IDE](https://www.arduino.cc/en/Main/Software)\n   - or [PlatformIO IDE f\u00fcr VSCode](https://platformio.org/)\n   - or [PlatformIO Core CLI](https://docs.platformio.org/en/latest/installation.html#)\n3. Some components like LEDs or servos\n\n## Setup\n\n### Node.js\n\nIn the root of the repository run `npm install`.  \n\n### Flash the StandardFirmata sketch to the Arduino\n\n*Hint: If you want to use steppers motors you will need a different Firmata Sketch. See the comments in example source for the [johnny-five stepper-driver](http://johnny-five.io/examples/stepper-driver/)*\n\n- Connect your board\n  \n#### With Arduino IDE\n\n- Select the board `Tools > Board > Arduino Uno/ Genuino Uno`\n- Select the USB port `Tools > Port > tty/usb.something` (on Windows `COM1` or another number)\n- Select the StandardFirmata Sketch `File > Examples Firmata > StandardFirmata`\n- Hit upload on the top of the IDE or select `Sketch > Upload`\n\n#### With PlatformIO Core\n\n*Hint: You can use the command `platformio` interchangeably with `pio` both work the same way.*\n\n\n- Open a new Terminal\n- In an empty folder run `platformio init --board uno` to scaffold a new project\n- Edit `platformio.ini` and add the following lines below `[env:uno]`\n\n```ini\nlib_deps =\n  Servo\n  Firmata\n  SoftwareSerial\n```\n\n- Got to [https://github.com/firmata/arduino](https://github.com/firmata/arduino/blob/master/examples/StandardFirmata/StandardFirmata.ino) and copy the content of `examples/StandardFirmata/StandardFirmata.ino` into a new file in the folder called `src/` called `StandardFirmata.ino`\n- Run `platformio run` in your Terminal\n- Watch the output for errors. If there are missing libraries add them to the `lib_deps`\n- With your board connected run `platformio run --target upload`\n\nSee the folder [firmwares/standard-firmata](firmwares/standard-firmata) for an example.\n\n---\n\nIf everything went smooth you should have your board ready.\n\n## Run\n\nWith your board running a firmata sketch and connected to the computer run:\n\n`npm start`\n\n## Troubleshooting\n\n### Board not recognized\n\nIs your board connected and recognized? Did you select the right port in the IDE?\n\nTo test this you should try to upload a simple Blink sketch from the Arduino IDE `File > Examples > 01.Basic > Blink`\n\nSometimes using a different USB port helps.\n\n### PlatformIO does not find the board\n\nTry running `pio upgrade` and `pio update`\nTry running `pio device list` is your board showing up?\nTry running the `pio run --target upload --upload-port` and add the device port from the list to the end.\n"}
{"url": "https://github.com/FH-Potsdam/ct-mtm-fabianmoronzirfas", "owner": "FH-Potsdam", "repository_name": "ct-mtm-fabianmoronzirfas", "date_all_variable_collection": "2023-09-11", "description": "ct-mtm-fabianmoronzirfas created by GitHub Classroom", "size": 45, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 27995}, {"language": "JavaScript", "num_chars": 1251}], "readme": "# Creative Technologist - Making Things Move\n\nThis is Boilerplate code for making things move using Johnny Five, Arduino and Node.js.\n\n## Prerequisites\n\n1. Arduino Uno Board + USB AB cable\n2. Something to flash Firmata to the Arduino.\n   - [Arduino IDE](https://www.arduino.cc/en/Main/Software)\n   - or [PlatformIO IDE f\u00fcr VSCode](https://platformio.org/)\n   - or [PlatformIO Core CLI](https://docs.platformio.org/en/latest/installation.html#)\n3. Some components like LEDs or servos\n\n## Setup\n\n### Node.js\n\nIn the root of the repository run `npm install`.  \n\n### Flash the StandardFirmata sketch to the Arduino\n\n*Hint: If you want to use steppers motors you will need a different Firmata Sketch. See the comments in example source for the [johnny-five stepper-driver](http://johnny-five.io/examples/stepper-driver/)*\n\n- Connect your board\n  \n#### With Arduino IDE\n\n- Select the board `Tools > Board > Arduino Uno/ Genuino Uno`\n- Select the USB port `Tools > Port > tty/usb.something` (on Windows `COM1` or another number)\n- Select the StandardFirmata Sketch `File > Examples Firmata > StandardFirmata`\n- Hit upload on the top of the IDE or select `Sketch > Upload`\n\n#### With PlatformIO Core\n\n*Hint: You can use the command `platformio` interchangeably with `pio` both work the same way.*\n\n\n- Open a new Terminal\n- In an empty folder run `platformio init --board uno` to scaffold a new project\n- Edit `platformio.ini` and add the following lines below `[env:uno]`\n\n```ini\nlib_deps =\n  Servo\n  Firmata\n  SoftwareSerial\n```\n\n- Got to [https://github.com/firmata/arduino](https://github.com/firmata/arduino/blob/master/examples/StandardFirmata/StandardFirmata.ino) and copy the content of `examples/StandardFirmata/StandardFirmata.ino` into a new file in the folder called `src/` called `StandardFirmata.ino`\n- Run `platformio run` in your Terminal\n- Watch the output for errors. If there are missing libraries add them to the `lib_deps`\n- With your board connected run `platformio run --target upload`\n\nSee the folder [firmwares/standard-firmata](firmwares/standard-firmata) for an example.\n\n---\n\nIf everything went smooth you should have your board ready.\n\n## Run\n\nWith your board running a firmata sketch and connected to the computer run:\n\n`npm start`\n\n## Troubleshooting\n\n### Board not recognized\n\nIs your board connected and recognized? Did you select the right port in the IDE?\n\nTo test this you should try to upload a simple Blink sketch from the Arduino IDE `File > Examples > 01.Basic > Blink`\n\nSometimes using a different USB port helps.\n\n### PlatformIO does not find the board\n\nTry running `pio upgrade` and `pio update`\nTry running `pio device list` is your board showing up?\nTry running the `pio run --target upload --upload-port` and add the device port from the list to the end.\n"}
{"url": "https://github.com/FH-Potsdam/ct-mtm-kochlisa", "owner": "FH-Potsdam", "repository_name": "ct-mtm-kochlisa", "date_all_variable_collection": "2023-09-11", "description": "ct-mtm-kochlisa created by GitHub Classroom", "size": 45, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 27995}, {"language": "JavaScript", "num_chars": 1251}], "readme": "# Creative Technologist - Making Things Move\n\nThis is Boilerplate code for making things move using Johnny Five, Arduino and Node.js.\n\n## Prerequisites\n\n1. Arduino Uno Board + USB AB cable\n2. Something to flash Firmata to the Arduino.\n   - [Arduino IDE](https://www.arduino.cc/en/Main/Software)\n   - or [PlatformIO IDE f\u00fcr VSCode](https://platformio.org/)\n   - or [PlatformIO Core CLI](https://docs.platformio.org/en/latest/installation.html#)\n3. Some components like LEDs or servos\n\n## Setup\n\n### Node.js\n\nIn the root of the repository run `npm install`.  \n\n### Flash the StandardFirmata sketch to the Arduino\n\n*Hint: If you want to use steppers motors you will need a different Firmata Sketch. See the comments in example source for the [johnny-five stepper-driver](http://johnny-five.io/examples/stepper-driver/)*\n\n- Connect your board\n  \n#### With Arduino IDE\n\n- Select the board `Tools > Board > Arduino Uno/ Genuino Uno`\n- Select the USB port `Tools > Port > tty/usb.something` (on Windows `COM1` or another number)\n- Select the StandardFirmata Sketch `File > Examples Firmata > StandardFirmata`\n- Hit upload on the top of the IDE or select `Sketch > Upload`\n\n#### With PlatformIO Core\n\n*Hint: You can use the command `platformio` interchangeably with `pio` both work the same way.*\n\n\n- Open a new Terminal\n- In an empty folder run `platformio init --board uno` to scaffold a new project\n- Edit `platformio.ini` and add the following lines below `[env:uno]`\n\n```ini\nlib_deps =\n  Servo\n  Firmata\n  SoftwareSerial\n```\n\n- Got to [https://github.com/firmata/arduino](https://github.com/firmata/arduino/blob/master/examples/StandardFirmata/StandardFirmata.ino) and copy the content of `examples/StandardFirmata/StandardFirmata.ino` into a new file in the folder called `src/` called `StandardFirmata.ino`\n- Run `platformio run` in your Terminal\n- Watch the output for errors. If there are missing libraries add them to the `lib_deps`\n- With your board connected run `platformio run --target upload`\n\nSee the folder [firmwares/standard-firmata](firmwares/standard-firmata) for an example.\n\n---\n\nIf everything went smooth you should have your board ready.\n\n## Run\n\nWith your board running a firmata sketch and connected to the computer run:\n\n`npm start`\n\n## Troubleshooting\n\n### Board not recognized\n\nIs your board connected and recognized? Did you select the right port in the IDE?\n\nTo test this you should try to upload a simple Blink sketch from the Arduino IDE `File > Examples > 01.Basic > Blink`\n\nSometimes using a different USB port helps.\n\n### PlatformIO does not find the board\n\nTry running `pio upgrade` and `pio update`\nTry running `pio device list` is your board showing up?\nTry running the `pio run --target upload --upload-port` and add the device port from the list to the end.\n"}
{"url": "https://github.com/FH-Potsdam/ct-mtm-The-bastART", "owner": "FH-Potsdam", "repository_name": "ct-mtm-The-bastART", "date_all_variable_collection": "2023-09-11", "description": "ct-mtm-The-bastART created by GitHub Classroom", "size": 47, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}, {"contributor": "thatbastart", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 27995}, {"language": "JavaScript", "num_chars": 6451}], "readme": "# Creative Technologist - Making Things Move\n\nThis is Boilerplate code for making things move using Johnny Five, Arduino and Node.js.\n\n## Prerequisites\n\n1. Arduino Uno Board + USB AB cable\n2. Something to flash Firmata to the Arduino.\n   - [Arduino IDE](https://www.arduino.cc/en/Main/Software)\n   - or [PlatformIO IDE f\u00fcr VSCode](https://platformio.org/)\n   - or [PlatformIO Core CLI](https://docs.platformio.org/en/latest/installation.html#)\n3. Some components like LEDs or servos\n\n## Setup\n\n### Node.js\n\nIn the root of the repository run `npm install`.  \n\n### Flash the StandardFirmata sketch to the Arduino\n\n*Hint: If you want to use steppers motors you will need a different Firmata Sketch. See the comments in example source for the [johnny-five stepper-driver](http://johnny-five.io/examples/stepper-driver/)*\n\n- Connect your board\n  \n#### With Arduino IDE\n\n- Select the board `Tools > Board > Arduino Uno/ Genuino Uno`\n- Select the USB port `Tools > Port > tty/usb.something` (on Windows `COM1` or another number)\n- Select the StandardFirmata Sketch `File > Examples Firmata > StandardFirmata`\n- Hit upload on the top of the IDE or select `Sketch > Upload`\n\n#### With PlatformIO Core\n\n*Hint: You can use the command `platformio` interchangeably with `pio` both work the same way.*\n\n\n- Open a new Terminal\n- In an empty folder run `platformio init --board uno` to scaffold a new project\n- Edit `platformio.ini` and add the following lines below `[env:uno]`\n\n```ini\nlib_deps =\n  Servo\n  Firmata\n  SoftwareSerial\n```\n\n- Got to [https://github.com/firmata/arduino](https://github.com/firmata/arduino/blob/master/examples/StandardFirmata/StandardFirmata.ino) and copy the content of `examples/StandardFirmata/StandardFirmata.ino` into a new file in the folder called `src/` called `StandardFirmata.ino`\n- Run `platformio run` in your Terminal\n- Watch the output for errors. If there are missing libraries add them to the `lib_deps`\n- With your board connected run `platformio run --target upload`\n\nSee the folder [firmwares/standard-firmata](firmwares/standard-firmata) for an example.\n\n---\n\nIf everything went smooth you should have your board ready.\n\n## Run\n\nWith your board running a firmata sketch and connected to the computer run:\n\n`npm start`\n\n## Troubleshooting\n\n### Board not recognized\n\nIs your board connected and recognized? Did you select the right port in the IDE?\n\nTo test this you should try to upload a simple Blink sketch from the Arduino IDE `File > Examples > 01.Basic > Blink`\n\nSometimes using a different USB port helps.\n\n### PlatformIO does not find the board\n\nTry running `pio upgrade` and `pio update`\nTry running `pio device list` is your board showing up?\nTry running the `pio run --target upload --upload-port` and add the device port from the list to the end.\n"}
{"url": "https://github.com/FH-Potsdam/ct-tracing-the-city", "owner": "FH-Potsdam", "repository_name": "ct-tracing-the-city", "date_all_variable_collection": "2023-09-11", "description": "How to for generating GCode through SVG from code", "size": 1976, "stargazers_count": 1, "watchers_count": 1, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 21}, {"contributor": "dependabot[bot]", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Tracing the City\n\n\n<!-- @import \"[TOC]\" {cmd=\"toc\" depthFrom=2 depthTo=6 orderedList=false} -->\n\n<!-- code_chunk_output -->\n\n- [Tracing the City](#tracing-the-city)\n  - [Find Data](#find-data)\n  - [Clean Data](#clean-data)\n    - [MacOS](#macos)\n    - [Windows](#windows)\n    - [Cross Platform](#cross-platform)\n  - [Visualize Data](#visualize-data)\n  - [Generate SVG (Optional)](#generate-svg-optional)\n  - [Generate GCode](#generate-gcode)\n  - [Optimize GCode](#optimize-gcode)\n  - [Check GCode](#check-gcode)\n    - [Trouble with Node version?](#trouble-with-node-version)\n  - [Plot](#plot)\n  - [Iterate](#iterate)\n\n<!-- /code_chunk_output -->\n\n\n## Find Data\n\nThere are lots of data sets out there. The links below are just some examples where you can find some.  \n\n- [www.statistik-berlin-brandenburg.de](https://www.statistik-berlin-brandenburg.de/webapi/jsf/login.xhtml)\n- [data.technologiestiftung-berlin.de](https://data.technologiestiftung-berlin.de/)\n- [geocommons.com](http://geocommons.com/)\n\n\n## Clean Data\n\nWhen you have some data you will have to clean it up. Try to remove all noise and clutter there might be in it to reduce it only to the data you need. These are some tools you can use to work clean them up.\n\n### MacOS\n\n- [Table Tool](https://github.com/jakob/TableTool)\n- \u2026\n  \n### Windows\n\n- [CSVPad](http://www.trustfm.net/software/utilities/CSVpad.php)\n- \u2026\n\n### Cross Platform\n\n- [Tad](https://www.tadviewer.com/)\n- [Google Sheets](https://www.google.com/sheets/about/)\n- [Data Curator](https://github.com/ODIQueensland/data-curator)\n- [Open Office](https://www.openoffice.org/)\n- [Libre Office](https://www.libreoffice.org/)\n\n## Visualize Data\n\nThis is where you have to get into code. To get a grip on what is going on I suggest to start with P5.js. It has a nice and convenient function called `loadTable` [(reference)](https://p5js.org/reference/#/p5/loadTable). Take a look at the [basic data drawing with p5js](examples/basic-data\u2013drawing-with-p5js/README.md) examples in this repository to get a grip on it. If you want to skip P5.js you can try it without an additional library and use Vanilla.js. Take a look at the example [basic data drawing with Vanillajs](examples/basic-data-drawing-with-vanillajs/README.md).\n\nIf you are working with spatial data take a look into [basic spatial data drawing example](examples/basic-data-to-svg-drawing-with-node_js/README.md).  \n\n*If you manage to export SVG directly from p5.js (or Processing) you can skip the next step*.  \n\n## Generate SVG (Optional)\n\nTo generate SVG data we can't use the normal canvas. You will have to translate your P5.js sketch into something that is able to export the data. See the example that ports the \"basic data drawing with p5js\" to [basic data to SVG drawing with Node.js](/examples/basic-data-to-svg-drawing-with-node_js/README.md).  \n\n## Generate GCode\n\n\nTo create GCode from your generated SVG files you will have to run them through our converter tool called [@tsb/svg2gcode-cli](https://github.com/technologiestiftung/svgcode-cli). Just take a look into the example [generate GCode from SVG](examples/generate-gcode-from-svg/README.md).  \n\n## Optimize GCode\n\nNow your freshly generated GCode from the step before might have the [traveling salesman problem](https://en.wikipedia.org/wiki/Travelling_salesman_problem). Check out [xyzbots.com gcode-optimizer](https://xyzbots.com:4000/gcode-optimizer/) or grab the source code for it and run it yourself \ud83d\udc47. \n\n```bash\ngit clone https://github.com/andrewhodel/gcode-optimizer.git \ncd gcode-optimizer\nnpm init -y\nnpm install reload -D\n./node_modules/.bin/reload -p 3000 -b\n```\n\n## Check GCode\n\n*!Note: To install cncjs you will have to run **Node.js <= 10**. Use nvm to install another version. nvm install v10.16.3*\n\nTo see if your GCode can be understood by the CityLAB plotter you should run it through [cncjs](https://cnc.js.org/). See  the example [check gcode](examples/check-gcode/README.md) To be able to connect cncjs and preview your GCode you need an Arduino board running on a USB port. The right solution to do this should be installing [GRBL](https://github.com/gnea/grbl/wiki/Compiling-Grbl) on that board.\n\n(For the lazy ones:) Just flash the sketch below to your board and connect from the connection widget of cncjs to the listed board.\n\n\n```arduino\nvoid setup() {\nSerial.begin(115200);\n}\nvoid loop() {}\n```\n\n### Trouble with Node version?\n\nIn the example [check GCode with Node.js 12](examples/check-gcode-with-node-12/README.md) you can find a hacked setup that allows to run cncjs under Node 12.\n\n## Plot\n\nFinally. You have some working GCode?! **woohoo!\\o/**. Come to the CityLAB and make that thing run.  \n\n## Iterate\n\nIf you reached this point you might be unhappy with your result. Iterate through (some of) the steps and do it all again.\n\n"}
{"url": "https://github.com/FH-Potsdam/cti-a-joseph14", "owner": "FH-Potsdam", "repository_name": "cti-a-joseph14", "date_all_variable_collection": "2023-09-11", "description": "cti-a-joseph14 created by GitHub Classroom", "size": 278, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 6, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 6, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 7054}, {"language": "JavaScript", "num_chars": 6208}], "readme": "# Creative Technologist Interactive\n\n## How to\n\n1. Open the whole folder in VSCode\n2. Open a new Terminal session\n3. Run `npm install` **once**\n4. Run `npm run bootstrap` **once**\n5. Run `npm start` **whenever you need a development server**\n6. The assignments are added as `@todo` in the beginning of each `packages/{area,particles}/index.js` file\n7. When done commit and push your results back to GitHub\n8. Describe in the README which problems you've solved\n9. Add images. \ud83d\udc47\n\n## Images\n\n1. Result images need to be located in each packages folder under `images`\n2. Images should be type PNG\n3. Images should be 500 \u00d7 500 Pixels\n4. Each image has to be added to the `images.json` file in the images folder\n5. NO UPPERCASE names\n6. NO whitespaces in names\n7. NO special characters `\u00f6\u00e4\u00fc\u00df?=)(/&%$\u00a7\"!*'#.;:,`\n8. `a-z` and `0-9` and `_-` are okay\n"}
{"url": "https://github.com/FH-Potsdam/cti-aaengelberg", "owner": "FH-Potsdam", "repository_name": "cti-aaengelberg", "date_all_variable_collection": "2023-09-11", "description": "cti-aaengelberg created by GitHub Classroom", "size": 258, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 5, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 5, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 7054}, {"language": "JavaScript", "num_chars": 6208}], "readme": "# Creative Technologist Interactive\n\n## How to\n\n1. Open the whole folder in VSCode\n2. Open a new Terminal session\n3. Run `npm install` **once**\n4. Run `npm run bootstrap` **once**\n5. Run `npm start` **whenever you need a development server**\n6. The assignments are added as `@todo` in the beginning of each `packages/{area,particles}/index.js` file\n7. When done commit and push your results back to GitHub\n8. Describe in the README which problems you've solved\n9. Add images. \ud83d\udc47\n\n## Images\n\n1. Result images need to be located in each packages folder under `images`\n2. Images should be type PNG\n3. Images should be 500 \u00d7 500 Pixels\n4. Each image has to be added to the `images.json` file in the images folder\n5. NO UPPERCASE names\n6. NO whitespaces in names\n7. NO special characters `\u00f6\u00e4\u00fc\u00df?=)(/&%$\u00a7\"!*'#.;:,`\n8. `a-z` and `0-9` and `_-` are okay\n"}
{"url": "https://github.com/FH-Potsdam/cti-AgathaCrystal", "owner": "FH-Potsdam", "repository_name": "cti-AgathaCrystal", "date_all_variable_collection": "2023-09-11", "description": "cti-AgathaCrystal created by GitHub Classroom", "size": 280, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 6, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 6, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "AgathaCrystal", "contributions": 2}, {"contributor": "ff6347", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 7675}, {"language": "HTML", "num_chars": 7054}], "readme": "# Creative Technologist Interactive\n\n## How to\n\n1. Open the whole folder in VSCode\n2. Open a new Terminal session\n3. Run `npm install` **once**\n4. Run `npm run bootstrap` **once**\n5. Run `npm start` **whenever you need a development server**\n6. The assignments are added as `@todo` in the beginning of each `packages/{area,particles}/index.js` file\n7. When done commit and push your results back to GitHub\n8. Describe in the README which problems you've solved\n9. Add images. \ud83d\udc47\n\n## Images\n\n1. Result images need to be located in each packages folder under `images`\n2. Images should be type PNG\n3. Images should be 500 \u00d7 500 Pixels\n4. Each image has to be added to the `images.json` file in the images folder\n5. NO UPPERCASE names\n6. NO whitespaces in names\n7. NO special characters `\u00f6\u00e4\u00fc\u00df?=)(/&%$\u00a7\"!*'#.;:,`\n8. `a-z` and `0-9` and `_-` are okay\n"}
{"url": "https://github.com/FH-Potsdam/cti-AGlazkova", "owner": "FH-Potsdam", "repository_name": "cti-AGlazkova", "date_all_variable_collection": "2023-09-11", "description": "cti-AGlazkova created by GitHub Classroom", "size": 288, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 6, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 6, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "AGlazkova", "contributions": 12}, {"contributor": "ff6347", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 8218}, {"language": "JavaScript", "num_chars": 7784}], "readme": "# Creative Technologist Interactive\n\n## How to\n\n1. Open the whole folder in VSCode\n2. Open a new Terminal session\n3. Run `npm install` **once**\n4. Run `npm run bootstrap` **once**\n5. Run `npm start` **whenever you need a development server**\n6. The assignments are added as `@todo` in the beginning of each `packages/{area,particles}/index.js` file\n7. When done commit and push your results back to GitHub\n8. Describe in the README which problems you've solved\n9. Add images. \ud83d\udc47\n\n## Images\n\n1. Result images need to be located in each packages folder under `images`\n2. Images should be type PNG\n3. Images should be 500 \u00d7 500 Pixels\n4. Each image has to be added to the `images.json` file in the images folder\n5. NO UPPERCASE names\n6. NO whitespaces in names\n7. NO special characters `\u00f6\u00e4\u00fc\u00df?=)(/&%$\u00a7\"!*'#.;:,`\n8. `a-z` and `0-9` and `_-` are okay\n"}
{"url": "https://github.com/FH-Potsdam/cti-ahaahaahaa", "owner": "FH-Potsdam", "repository_name": "cti-ahaahaahaa", "date_all_variable_collection": "2023-09-11", "description": "cti-ahaahaahaa created by GitHub Classroom", "size": 278, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 6, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 6, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 6208}, {"language": "HTML", "num_chars": 4463}], "readme": "# Creative Technologist Interactive\n\n## How to\n\n1. Open the whole folder in VSCode\n2. Open a new Terminal session\n3. Run `npm install` **once**\n4. Run `npm run bootstrap` **once**\n5. Run `npm start` **whenever you need a development server**\n6. The assignments are added as `@todo` in the beginning of each `packages/{area,particles}/index.js` file\n7. When done commit and push your results back to GitHub\n8. Describe in the README which problems you've solved\n9. Add images. \ud83d\udc47\n\n## Images\n\n1. Result images need to be located in each packages folder under `images`\n2. Images should be type PNG\n3. Images should be 500 \u00d7 500 Pixels\n4. Each image has to be added to the `images.json` file in the images folder\n5. NO UPPERCASE names\n6. NO whitespaces in names\n7. NO special characters `\u00f6\u00e4\u00fc\u00df?=)(/&%$\u00a7\"!*'#.;:,`\n8. `a-z` and `0-9` and `_-` are okay\n"}
{"url": "https://github.com/FH-Potsdam/cti-BabalouBoi", "owner": "FH-Potsdam", "repository_name": "cti-BabalouBoi", "date_all_variable_collection": "2023-09-11", "description": "cti-BabalouBoi created by GitHub Classroom", "size": 277, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 5, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 5, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 6208}, {"language": "HTML", "num_chars": 4463}], "readme": "# Creative Technologist Interactive\n\n## How to\n\n1. Open the whole folder in VSCode\n2. Open a new Terminal session\n3. Run `npm install` **once**\n4. Run `npm run bootstrap` **once**\n5. Run `npm start` **whenever you need a development server**\n6. The assignments are added as `@todo` in the beginning of each `packages/{area,particles}/index.js` file\n7. When done commit and push your results back to GitHub\n8. Describe in the README which problems you've solved\n9. Add images. \ud83d\udc47\n\n## Images\n\n1. Result images need to be located in each packages folder under `images`\n2. Images should be type PNG\n3. Images should be 500 \u00d7 500 Pixels\n4. Each image has to be added to the `images.json` file in the images folder\n5. NO UPPERCASE names\n6. NO whitespaces in names\n7. NO special characters `\u00f6\u00e4\u00fc\u00df?=)(/&%$\u00a7\"!*'#.;:,`\n8. `a-z` and `0-9` and `_-` are okay\n"}
{"url": "https://github.com/FH-Potsdam/cti-carl-qq", "owner": "FH-Potsdam", "repository_name": "cti-carl-qq", "date_all_variable_collection": "2023-09-11", "description": "cti-carl-qq created by GitHub Classroom", "size": 2562, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 5, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 5, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 8259}, {"language": "HTML", "num_chars": 7054}], "readme": "# Creative Technologist Interactive\n\n## How to\n\n1. Open the whole folder in VSCode\n2. Open a new Terminal session\n3. Run `npm install` **once**\n4. Run `npm run bootstrap` **once**\n5. Run `npm start` **whenever you need a development server**\n6. The assignments are added as `@todo` in the beginning of each `packages/{area,particles}/index.js` file\n7. When done commit and push your results back to GitHub\n8. Describe in the README which problems you've solved\n9. Add images. \ud83d\udc47\n\n## Images\n\n1. Result images need to be located in each packages folder under `images`\n2. Images should be type PNG\n3. Images should be 500 \u00d7 500 Pixels\n4. Each image has to be added to the `images.json` file in the images folder\n5. NO UPPERCASE names\n6. NO whitespaces in names\n7. NO special characters `\u00f6\u00e4\u00fc\u00df?=)(/&%$\u00a7\"!*'#.;:,`\n8. `a-z` and `0-9` and `_-` are okay\n"}
{"url": "https://github.com/FH-Potsdam/cti-DanEglau", "owner": "FH-Potsdam", "repository_name": "cti-DanEglau", "date_all_variable_collection": "2023-09-11", "description": "cti-DanEglau created by GitHub Classroom", "size": 278, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 6, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 6, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 6208}, {"language": "HTML", "num_chars": 4463}], "readme": "# Creative Technologist Interactive\n\n## How to\n\n1. Open the whole folder in VSCode\n2. Open a new Terminal session\n3. Run `npm install` **once**\n4. Run `npm run bootstrap` **once**\n5. Run `npm start` **whenever you need a development server**\n6. The assignments are added as `@todo` in the beginning of each `packages/{area,particles}/index.js` file\n7. When done commit and push your results back to GitHub\n8. Describe in the README which problems you've solved\n9. Add images. \ud83d\udc47\n\n## Images\n\n1. Result images need to be located in each packages folder under `images`\n2. Images should be type PNG\n3. Images should be 500 \u00d7 500 Pixels\n4. Each image has to be added to the `images.json` file in the images folder\n5. NO UPPERCASE names\n6. NO whitespaces in names\n7. NO special characters `\u00f6\u00e4\u00fc\u00df?=)(/&%$\u00a7\"!*'#.;:,`\n8. `a-z` and `0-9` and `_-` are okay\n"}
{"url": "https://github.com/FH-Potsdam/cti-dISCOeRG0sUM", "owner": "FH-Potsdam", "repository_name": "cti-dISCOeRG0sUM", "date_all_variable_collection": "2023-09-11", "description": "cti-dISCOeRG0sUM created by GitHub Classroom", "size": 282, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 5, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 5, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Disc0erg0sum", "contributions": 6}, {"contributor": "ff6347", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 7054}, {"language": "JavaScript", "num_chars": 6815}], "readme": "# Creative Technologist Interactive\n\n## How to\n\n1. Open the whole folder in VSCode\n2. Open a new Terminal session\n3. Run `npm install` **once**\n4. Run `npm run bootstrap` **once**\n5. Run `npm start` **whenever you need a development server**\n6. The assignments are added as `@todo` in the beginning of each `packages/{area,particles}/index.js` file\n7. When done commit and push your results back to GitHub\n8. Describe in the README which problems you've solved\n9. Add images. \ud83d\udc47\n\n## Images\n\n1. Result images need to be located in each packages folder under `images`\n2. Images should be type PNG\n3. Images should be 500 \u00d7 500 Pixels\n4. Each image has to be added to the `images.json` file in the images folder\n5. NO UPPERCASE names\n6. NO whitespaces in names\n7. NO special characters `\u00f6\u00e4\u00fc\u00df?=)(/&%$\u00a7\"!*'#.;:,`\n8. `a-z` and `0-9` and `_-` are okay\n"}
{"url": "https://github.com/FH-Potsdam/cti-fabianmoronzirfas", "owner": "FH-Potsdam", "repository_name": "cti-fabianmoronzirfas", "date_all_variable_collection": "2023-09-11", "description": "cti-fabianmoronzirfas created by GitHub Classroom", "size": 285, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 5, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 5, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 8141}, {"language": "HTML", "num_chars": 7054}], "readme": "# Creative Technologist Interactive\n\n## How to\n\n1. Open the whole folder in VSCode\n2. Open a new Terminal session\n3. Run `npm install` **once**\n4. Run `npm run bootstrap` **once**\n5. Run `npm start` **whenever you need a development server**\n6. The assignments are added as `@todo` in the beginning of each `packages/{area,particles}/index.js` file\n7. When done commit and push your results back to GitHub\n8. Describe in the README which problems you've solved\n9. Add images. \ud83d\udc47\n\n## Images\n\n1. Result images need to be located in each packages folder under `images`\n2. Images should be type PNG\n3. Images should be 500 \u00d7 500 Pixels\n4. Each image has to be added to the `images.json` file in the images folder\n5. NO UPPERCASE names\n6. NO whitespaces in names\n7. NO special characters `\u00f6\u00e4\u00fc\u00df?=)(/&%$\u00a7\"!*'#.;:,`\n8. `a-z` and `0-9` and `_-` are okay\n"}
{"url": "https://github.com/FH-Potsdam/cti-fatherhummingbird", "owner": "FH-Potsdam", "repository_name": "cti-fatherhummingbird", "date_all_variable_collection": "2023-09-11", "description": "cti-fatherhummingbird created by GitHub Classroom", "size": 278, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 6, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 6, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 7054}, {"language": "JavaScript", "num_chars": 6208}], "readme": "# Creative Technologist Interactive\n\n## How to\n\n1. Open the whole folder in VSCode\n2. Open a new Terminal session\n3. Run `npm install` **once**\n4. Run `npm run bootstrap` **once**\n5. Run `npm start` **whenever you need a development server**\n6. The assignments are added as `@todo` in the beginning of each `packages/{area,particles}/index.js` file\n7. When done commit and push your results back to GitHub\n8. Describe in the README which problems you've solved\n9. Add images. \ud83d\udc47\n\n## Images\n\n1. Result images need to be located in each packages folder under `images`\n2. Images should be type PNG\n3. Images should be 500 \u00d7 500 Pixels\n4. Each image has to be added to the `images.json` file in the images folder\n5. NO UPPERCASE names\n6. NO whitespaces in names\n7. NO special characters `\u00f6\u00e4\u00fc\u00df?=)(/&%$\u00a7\"!*'#.;:,`\n8. `a-z` and `0-9` and `_-` are okay\n"}
{"url": "https://github.com/FH-Potsdam/cti-kennyloeffler", "owner": "FH-Potsdam", "repository_name": "cti-kennyloeffler", "date_all_variable_collection": "2023-09-11", "description": "cti-kennyloeffler created by GitHub Classroom", "size": 279, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 5, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 5, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 2}, {"contributor": "kennyloeffler", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 7054}, {"language": "JavaScript", "num_chars": 6208}], "readme": "# Creative Technologist Interactive\n\n## How to\n\n1. Open the whole folder in VSCode\n2. Open a new Terminal session\n3. Run `npm install` **once**\n4. Run `npm run bootstrap` **once**\n5. Run `npm start` **whenever you need a development server**\n6. The assignments are added as `@todo` in the beginning of each `packages/{area,particles}/index.js` file\n7. When done commit and push your results back to GitHub\n8. Describe in the README which problems you've solved\n9. Add images. \ud83d\udc47\n\n## Images\n\n1. Result images need to be located in each packages folder under `images`\n2. Images should be type PNG\n3. Images should be 500 \u00d7 500 Pixels\n4. Each image has to be added to the `images.json` file in the images folder\n5. NO UPPERCASE names\n6. NO whitespaces in names\n7. NO special characters `\u00f6\u00e4\u00fc\u00df?=)(/&%$\u00a7\"!*'#.;:,`\n8. `a-z` and `0-9` and `_-` are okay\n"}
{"url": "https://github.com/FH-Potsdam/cti-kochlisa", "owner": "FH-Potsdam", "repository_name": "cti-kochlisa", "date_all_variable_collection": "2023-09-11", "description": "cti-kochlisa created by GitHub Classroom", "size": 278, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 6, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 6, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 7054}, {"language": "JavaScript", "num_chars": 6208}], "readme": "# Creative Technologist Interactive\n\n## How to\n\n1. Open the whole folder in VSCode\n2. Open a new Terminal session\n3. Run `npm install` **once**\n4. Run `npm run bootstrap` **once**\n5. Run `npm start` **whenever you need a development server**\n6. The assignments are added as `@todo` in the beginning of each `packages/{area,particles}/index.js` file\n7. When done commit and push your results back to GitHub\n8. Describe in the README which problems you've solved\n9. Add images. \ud83d\udc47\n\n## Images\n\n1. Result images need to be located in each packages folder under `images`\n2. Images should be type PNG\n3. Images should be 500 \u00d7 500 Pixels\n4. Each image has to be added to the `images.json` file in the images folder\n5. NO UPPERCASE names\n6. NO whitespaces in names\n7. NO special characters `\u00f6\u00e4\u00fc\u00df?=)(/&%$\u00a7\"!*'#.;:,`\n8. `a-z` and `0-9` and `_-` are okay\n"}
{"url": "https://github.com/FH-Potsdam/cti-lisa-lh", "owner": "FH-Potsdam", "repository_name": "cti-lisa-lh", "date_all_variable_collection": "2023-09-11", "description": "cti-lisa-lh created by GitHub Classroom", "size": 278, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 6, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 6, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 6208}, {"language": "HTML", "num_chars": 4463}], "readme": "# Creative Technologist Interactive\n\n## How to\n\n1. Open the whole folder in VSCode\n2. Open a new Terminal session\n3. Run `npm install` **once**\n4. Run `npm run bootstrap` **once**\n5. Run `npm start` **whenever you need a development server**\n6. The assignments are added as `@todo` in the beginning of each `packages/{area,particles}/index.js` file\n7. When done commit and push your results back to GitHub\n8. Describe in the README which problems you've solved\n9. Add images. \ud83d\udc47\n\n## Images\n\n1. Result images need to be located in each packages folder under `images`\n2. Images should be type PNG\n3. Images should be 500 \u00d7 500 Pixels\n4. Each image has to be added to the `images.json` file in the images folder\n5. NO UPPERCASE names\n6. NO whitespaces in names\n7. NO special characters `\u00f6\u00e4\u00fc\u00df?=)(/&%$\u00a7\"!*'#.;:,`\n8. `a-z` and `0-9` and `_-` are okay\n"}
{"url": "https://github.com/FH-Potsdam/cti-milanwulf", "owner": "FH-Potsdam", "repository_name": "cti-milanwulf", "date_all_variable_collection": "2023-09-11", "description": "cti-milanwulf created by GitHub Classroom", "size": 645, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 5, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 5, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 2}, {"contributor": "milanwulf", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 7054}, {"language": "JavaScript", "num_chars": 6531}], "readme": "# Creative Technologist Interactive\n\n## How to\n\n1. Open the whole folder in VSCode\n2. Open a new Terminal session\n3. Run `npm install` **once**\n4. Run `npm run bootstrap` **once**\n5. Run `npm start` **whenever you need a development server**\n6. The assignments are added as `@todo` in the beginning of each `packages/{area,particles}/index.js` file\n7. When done commit and push your results back to GitHub\n8. Describe in the README which problems you've solved\n9. Add images. \ud83d\udc47\n\n## Images\n\n1. Result images need to be located in each packages folder under `images`\n2. Images should be type PNG\n3. Images should be 500 \u00d7 500 Pixels\n4. Each image has to be added to the `images.json` file in the images folder\n5. NO UPPERCASE names\n6. NO whitespaces in names\n7. NO special characters `\u00f6\u00e4\u00fc\u00df?=)(/&%$\u00a7\"!*'#.;:,`\n8. `a-z` and `0-9` and `_-` are okay\n"}
{"url": "https://github.com/FH-Potsdam/cti-SchmittVa", "owner": "FH-Potsdam", "repository_name": "cti-SchmittVa", "date_all_variable_collection": "2023-09-11", "description": "cti-SchmittVa created by GitHub Classroom", "size": 261, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 5, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 5, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 2}, {"contributor": "SchmittVa", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 7054}, {"language": "JavaScript", "num_chars": 6715}], "readme": "# Creative Technologist Interactive\n\n## How to\n\n1. Open the whole folder in VSCode\n2. Open a new Terminal session\n3. Run `npm install` **once**\n4. Run `npm run bootstrap` **once**\n5. Run `npm start` **whenever you need a development server**\n6. The assignments are added as `@todo` in the beginning of each `packages/{area,particles}/index.js` file\n7. When done commit and push your results back to GitHub\n8. Describe in the README which problems you've solved\n9. Add images. \ud83d\udc47\n\n## Images\n\n1. Result images need to be located in each packages folder under `images`\n2. Images should be type PNG\n3. Images should be 500 \u00d7 500 Pixels\n4. Each image has to be added to the `images.json` file in the images folder\n5. NO UPPERCASE names\n6. NO whitespaces in names\n7. NO special characters `\u00f6\u00e4\u00fc\u00df?=)(/&%$\u00a7\"!*'#.;:,`\n8. `a-z` and `0-9` and `_-` are okay\n"}
{"url": "https://github.com/FH-Potsdam/cti-The-bastART", "owner": "FH-Potsdam", "repository_name": "cti-The-bastART", "date_all_variable_collection": "2023-09-11", "description": "cti-The-bastART created by GitHub Classroom", "size": 4975, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 5, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 5, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 3}, {"contributor": "thatbastart", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 12333}, {"language": "HTML", "num_chars": 10098}], "readme": "# Creative Technologist Interactive\n\n## How to\n\n1. Open the whole folder in VSCode\n2. Open a new Terminal session\n3. Run `npm install` **once**\n4. Run `npm run bootstrap` **once**\n5. Run `npm start` **whenever you need a development server**\n6. The assignments are added as `@todo` in the beginning of each `packages/{area,particles}/index.js` file\n7. When done commit and push your results back to GitHub\n8. Describe in the README which problems you've solved\n9. Add images. \ud83d\udc47\n\n## Images\n\n1. Result images need to be located in each packages folder under `images`\n2. Images should be type PNG\n3. Images should be 500 \u00d7 500 Pixels\n4. Each image has to be added to the `images.json` file in the images folder\n5. NO UPPERCASE names\n6. NO whitespaces in names\n7. NO special characters `\u00f6\u00e4\u00fc\u00df?=)(/&%$\u00a7\"!*'#.;:,`\n8. `a-z` and `0-9` and `_-` are okay\n"}
{"url": "https://github.com/FH-Potsdam/ctk-a-joseph14", "owner": "FH-Potsdam", "repository_name": "ctk-a-joseph14", "date_all_variable_collection": "2023-09-11", "description": "ctk-a-joseph14 created by GitHub Classroom", "size": 66, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 2, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1855}, {"language": "HTML", "num_chars": 1652}], "readme": "# CT Keyboard Hack\n\n> Starter kit for the seminar \"Creative Technologists - Tracing the City\" @ University of Applied Sciences Potsdam (Germany) winter semester 2019/2020 by Fabian Mor\u00f3n Zirfas\n\n## Assignment\n\n1. Hack your keyboard\n2. Create a reaction on keypress\n3. Create a video which shows your Hack\n4. Commit and push to the repo\n\n### Hints\n\n## Usage\n\n1. Open a terminal session in the root of the repository and type `npm install`  and hit return \u21a9 to install all dependencies.\n2. Type `npm start` and hit return \u21a9 to start the reload server.\n3. Start hacking\n4. When you are done and enrolled in the classroom, use the classroom to submit your assignment.\n\n## Contributing\n\nPull requests and stars are always welcome. For bugs and feature requests, [please create an issue](https://github.com/FH-Potsdam/dma/issues)\n\n## Author(s)\n\n**Fabian Mor\u00f3n Zirfas:**\n\n- [github/](https://github.com/fabianmoronzirfas)\n- [twitter/](http://twitter.com/fmoronzirfas)\n\n## License\n\nCopyright \u00a9 2019 [Fabian Mor\u00f3n Zirfas](https://fabianmoronzirfas.me)\nLicensed under the MIT license.\n"}
{"url": "https://github.com/FH-Potsdam/ctk-aaengelberg", "owner": "FH-Potsdam", "repository_name": "ctk-aaengelberg", "date_all_variable_collection": "2023-09-11", "description": "ctk-aaengelberg created by GitHub Classroom", "size": 66, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 2, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1855}, {"language": "HTML", "num_chars": 1652}], "readme": "# CT Keyboard Hack\n\n> Starter kit for the seminar \"Creative Technologists - Tracing the City\" @ University of Applied Sciences Potsdam (Germany) winter semester 2019/2020 by Fabian Mor\u00f3n Zirfas\n\n## Assignment\n\n1. Hack your keyboard\n2. Create a reaction on keypress\n3. Create a video which shows your Hack\n4. Commit and push to the repo\n\n### Hints\n\n## Usage\n\n1. Open a terminal session in the root of the repository and type `npm install`  and hit return \u21a9 to install all dependencies.\n2. Type `npm start` and hit return \u21a9 to start the reload server.\n3. Start hacking\n4. When you are done and enrolled in the classroom, use the classroom to submit your assignment.\n\n## Contributing\n\nPull requests and stars are always welcome. For bugs and feature requests, [please create an issue](https://github.com/FH-Potsdam/dma/issues)\n\n## Author(s)\n\n**Fabian Mor\u00f3n Zirfas:**\n\n- [github/](https://github.com/fabianmoronzirfas)\n- [twitter/](http://twitter.com/fmoronzirfas)\n\n## License\n\nCopyright \u00a9 2019 [Fabian Mor\u00f3n Zirfas](https://fabianmoronzirfas.me)\nLicensed under the MIT license.\n"}
{"url": "https://github.com/FH-Potsdam/ctk-AgathaCrystal", "owner": "FH-Potsdam", "repository_name": "ctk-AgathaCrystal", "date_all_variable_collection": "2023-09-11", "description": "ctk-AgathaCrystal created by GitHub Classroom", "size": 68, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 2, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "AgathaCrystal", "contributions": 2}, {"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 3506}, {"language": "HTML", "num_chars": 1750}], "readme": "# CT Keyboard Hack\n\n> Starter kit for the seminar \"Creative Technologists - Tracing the City\" @ University of Applied Sciences Potsdam (Germany) winter semester 2019/2020 by Fabian Mor\u00f3n Zirfas\n\n## Assignment\n\n1. Hack your keyboard\n2. Create a reaction on keypress\n3. Create a video which shows your Hack\n4. Commit and push to the repo\n\n### Hints\n\n## Usage\n\n1. Open a terminal session in the root of the repository and type `npm install`  and hit return \u21a9 to install all dependencies.\n2. Type `npm start` and hit return \u21a9 to start the reload server.\n3. Start hacking\n4. When you are done and enrolled in the classroom, use the classroom to submit your assignment.\n\n## Contributing\n\nPull requests and stars are always welcome. For bugs and feature requests, [please create an issue](https://github.com/FH-Potsdam/dma/issues)\n\n## Author(s)\n\n**Fabian Mor\u00f3n Zirfas:**\n\n- [github/](https://github.com/fabianmoronzirfas)\n- [twitter/](http://twitter.com/fmoronzirfas)\n\n## License\n\nCopyright \u00a9 2019 [Fabian Mor\u00f3n Zirfas](https://fabianmoronzirfas.me)\nLicensed under the MIT license.\n"}
{"url": "https://github.com/FH-Potsdam/ctk-AGlazkova", "owner": "FH-Potsdam", "repository_name": "ctk-AGlazkova", "date_all_variable_collection": "2023-09-11", "description": "ctk-AGlazkova created by GitHub Classroom", "size": 66, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 2, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1855}, {"language": "HTML", "num_chars": 1652}], "readme": "# CT Keyboard Hack\n\n> Starter kit for the seminar \"Creative Technologists - Tracing the City\" @ University of Applied Sciences Potsdam (Germany) winter semester 2019/2020 by Fabian Mor\u00f3n Zirfas\n\n## Assignment\n\n1. Hack your keyboard\n2. Create a reaction on keypress\n3. Create a video which shows your Hack\n4. Commit and push to the repo\n\n### Hints\n\n## Usage\n\n1. Open a terminal session in the root of the repository and type `npm install`  and hit return \u21a9 to install all dependencies.\n2. Type `npm start` and hit return \u21a9 to start the reload server.\n3. Start hacking\n4. When you are done and enrolled in the classroom, use the classroom to submit your assignment.\n\n## Contributing\n\nPull requests and stars are always welcome. For bugs and feature requests, [please create an issue](https://github.com/FH-Potsdam/dma/issues)\n\n## Author(s)\n\n**Fabian Mor\u00f3n Zirfas:**\n\n- [github/](https://github.com/fabianmoronzirfas)\n- [twitter/](http://twitter.com/fmoronzirfas)\n\n## License\n\nCopyright \u00a9 2019 [Fabian Mor\u00f3n Zirfas](https://fabianmoronzirfas.me)\nLicensed under the MIT license.\n"}
{"url": "https://github.com/FH-Potsdam/ctk-ahaahaahaa", "owner": "FH-Potsdam", "repository_name": "ctk-ahaahaahaa", "date_all_variable_collection": "2023-09-11", "description": "ctk-ahaahaahaa created by GitHub Classroom", "size": 66, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 2, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1855}, {"language": "HTML", "num_chars": 1652}], "readme": "# CT Keyboard Hack\n\n> Starter kit for the seminar \"Creative Technologists - Tracing the City\" @ University of Applied Sciences Potsdam (Germany) winter semester 2019/2020 by Fabian Mor\u00f3n Zirfas\n\n## Assignment\n\n1. Hack your keyboard\n2. Create a reaction on keypress\n3. Create a video which shows your Hack\n4. Commit and push to the repo\n\n### Hints\n\n## Usage\n\n1. Open a terminal session in the root of the repository and type `npm install`  and hit return \u21a9 to install all dependencies.\n2. Type `npm start` and hit return \u21a9 to start the reload server.\n3. Start hacking\n4. When you are done and enrolled in the classroom, use the classroom to submit your assignment.\n\n## Contributing\n\nPull requests and stars are always welcome. For bugs and feature requests, [please create an issue](https://github.com/FH-Potsdam/dma/issues)\n\n## Author(s)\n\n**Fabian Mor\u00f3n Zirfas:**\n\n- [github/](https://github.com/fabianmoronzirfas)\n- [twitter/](http://twitter.com/fmoronzirfas)\n\n## License\n\nCopyright \u00a9 2019 [Fabian Mor\u00f3n Zirfas](https://fabianmoronzirfas.me)\nLicensed under the MIT license.\n"}
{"url": "https://github.com/FH-Potsdam/ctk-BabalouBoi", "owner": "FH-Potsdam", "repository_name": "ctk-BabalouBoi", "date_all_variable_collection": "2023-09-11", "description": "ctk-BabalouBoi created by GitHub Classroom", "size": 66, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 2, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1855}, {"language": "HTML", "num_chars": 1652}], "readme": "# CT Keyboard Hack\n\n> Starter kit for the seminar \"Creative Technologists - Tracing the City\" @ University of Applied Sciences Potsdam (Germany) winter semester 2019/2020 by Fabian Mor\u00f3n Zirfas\n\n## Assignment\n\n1. Hack your keyboard\n2. Create a reaction on keypress\n3. Create a video which shows your Hack\n4. Commit and push to the repo\n\n### Hints\n\n## Usage\n\n1. Open a terminal session in the root of the repository and type `npm install`  and hit return \u21a9 to install all dependencies.\n2. Type `npm start` and hit return \u21a9 to start the reload server.\n3. Start hacking\n4. When you are done and enrolled in the classroom, use the classroom to submit your assignment.\n\n## Contributing\n\nPull requests and stars are always welcome. For bugs and feature requests, [please create an issue](https://github.com/FH-Potsdam/dma/issues)\n\n## Author(s)\n\n**Fabian Mor\u00f3n Zirfas:**\n\n- [github/](https://github.com/fabianmoronzirfas)\n- [twitter/](http://twitter.com/fmoronzirfas)\n\n## License\n\nCopyright \u00a9 2019 [Fabian Mor\u00f3n Zirfas](https://fabianmoronzirfas.me)\nLicensed under the MIT license.\n"}
{"url": "https://github.com/FH-Potsdam/ctk-carl-qq", "owner": "FH-Potsdam", "repository_name": "ctk-carl-qq", "date_all_variable_collection": "2023-09-11", "description": "ctk-carl-qq created by GitHub Classroom", "size": 66, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 2, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1855}, {"language": "HTML", "num_chars": 1652}], "readme": "# CT Keyboard Hack\n\n> Starter kit for the seminar \"Creative Technologists - Tracing the City\" @ University of Applied Sciences Potsdam (Germany) winter semester 2019/2020 by Fabian Mor\u00f3n Zirfas\n\n## Assignment\n\n1. Hack your keyboard\n2. Create a reaction on keypress\n3. Create a video which shows your Hack\n4. Commit and push to the repo\n\n### Hints\n\n## Usage\n\n1. Open a terminal session in the root of the repository and type `npm install`  and hit return \u21a9 to install all dependencies.\n2. Type `npm start` and hit return \u21a9 to start the reload server.\n3. Start hacking\n4. When you are done and enrolled in the classroom, use the classroom to submit your assignment.\n\n## Contributing\n\nPull requests and stars are always welcome. For bugs and feature requests, [please create an issue](https://github.com/FH-Potsdam/dma/issues)\n\n## Author(s)\n\n**Fabian Mor\u00f3n Zirfas:**\n\n- [github/](https://github.com/fabianmoronzirfas)\n- [twitter/](http://twitter.com/fmoronzirfas)\n\n## License\n\nCopyright \u00a9 2019 [Fabian Mor\u00f3n Zirfas](https://fabianmoronzirfas.me)\nLicensed under the MIT license.\n"}
{"url": "https://github.com/FH-Potsdam/ctk-dISCOeRG0sUM", "owner": "FH-Potsdam", "repository_name": "ctk-dISCOeRG0sUM", "date_all_variable_collection": "2023-09-11", "description": "ctk-dISCOeRG0sUM created by GitHub Classroom", "size": 45586, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 2, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1855}, {"language": "HTML", "num_chars": 1652}], "readme": "# CT Keyboard Hack\n\n> Starter kit for the seminar \"Creative Technologists - Tracing the City\" @ University of Applied Sciences Potsdam (Germany) winter semester 2019/2020 by Fabian Mor\u00f3n Zirfas\n\n## Assignment\n\n1. Hack your keyboard\n2. Create a reaction on keypress\n3. Create a video which shows your Hack\n4. Commit and push to the repo\n\n### Hints\n\n## Usage\n\n1. Open a terminal session in the root of the repository and type `npm install`  and hit return \u21a9 to install all dependencies.\n2. Type `npm start` and hit return \u21a9 to start the reload server.\n3. Start hacking\n4. When you are done and enrolled in the classroom, use the classroom to submit your assignment.\n\n## Contributing\n\nPull requests and stars are always welcome. For bugs and feature requests, [please create an issue](https://github.com/FH-Potsdam/dma/issues)\n\n## Author(s)\n\n**Fabian Mor\u00f3n Zirfas:**\n\n- [github/](https://github.com/fabianmoronzirfas)\n- [twitter/](http://twitter.com/fmoronzirfas)\n\n## License\n\nCopyright \u00a9 2019 [Fabian Mor\u00f3n Zirfas](https://fabianmoronzirfas.me)\nLicensed under the MIT license.\n"}
{"url": "https://github.com/FH-Potsdam/ctk-fabianmoronzirfas", "owner": "FH-Potsdam", "repository_name": "ctk-fabianmoronzirfas", "date_all_variable_collection": "2023-09-11", "description": "ctk-fabianmoronzirfas created by GitHub Classroom", "size": 66, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 2, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1855}, {"language": "HTML", "num_chars": 1652}], "readme": "# CT Keyboard Hack\n\n> Starter kit for the seminar \"Creative Technologists - Tracing the City\" @ University of Applied Sciences Potsdam (Germany) winter semester 2019/2020 by Fabian Mor\u00f3n Zirfas\n\n## Assignment\n\n1. Hack your keyboard\n2. Create a reaction on keypress\n3. Create a video which shows your Hack\n4. Commit and push to the repo\n\n### Hints\n\n## Usage\n\n1. Open a terminal session in the root of the repository and type `npm install`  and hit return \u21a9 to install all dependencies.\n2. Type `npm start` and hit return \u21a9 to start the reload server.\n3. Start hacking\n4. When you are done and enrolled in the classroom, use the classroom to submit your assignment.\n\n## Contributing\n\nPull requests and stars are always welcome. For bugs and feature requests, [please create an issue](https://github.com/FH-Potsdam/dma/issues)\n\n## Author(s)\n\n**Fabian Mor\u00f3n Zirfas:**\n\n- [github/](https://github.com/fabianmoronzirfas)\n- [twitter/](http://twitter.com/fmoronzirfas)\n\n## License\n\nCopyright \u00a9 2019 [Fabian Mor\u00f3n Zirfas](https://fabianmoronzirfas.me)\nLicensed under the MIT license.\n"}
{"url": "https://github.com/FH-Potsdam/ctk-fatherhummingbird", "owner": "FH-Potsdam", "repository_name": "ctk-fatherhummingbird", "date_all_variable_collection": "2023-09-11", "description": "ctk-fatherhummingbird created by GitHub Classroom", "size": 66, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 2, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1855}, {"language": "HTML", "num_chars": 1652}], "readme": "# CT Keyboard Hack\n\n> Starter kit for the seminar \"Creative Technologists - Tracing the City\" @ University of Applied Sciences Potsdam (Germany) winter semester 2019/2020 by Fabian Mor\u00f3n Zirfas\n\n## Assignment\n\n1. Hack your keyboard\n2. Create a reaction on keypress\n3. Create a video which shows your Hack\n4. Commit and push to the repo\n\n### Hints\n\n## Usage\n\n1. Open a terminal session in the root of the repository and type `npm install`  and hit return \u21a9 to install all dependencies.\n2. Type `npm start` and hit return \u21a9 to start the reload server.\n3. Start hacking\n4. When you are done and enrolled in the classroom, use the classroom to submit your assignment.\n\n## Contributing\n\nPull requests and stars are always welcome. For bugs and feature requests, [please create an issue](https://github.com/FH-Potsdam/dma/issues)\n\n## Author(s)\n\n**Fabian Mor\u00f3n Zirfas:**\n\n- [github/](https://github.com/fabianmoronzirfas)\n- [twitter/](http://twitter.com/fmoronzirfas)\n\n## License\n\nCopyright \u00a9 2019 [Fabian Mor\u00f3n Zirfas](https://fabianmoronzirfas.me)\nLicensed under the MIT license.\n"}
{"url": "https://github.com/FH-Potsdam/ctk-kochlisa", "owner": "FH-Potsdam", "repository_name": "ctk-kochlisa", "date_all_variable_collection": "2023-09-11", "description": "ctk-kochlisa created by GitHub Classroom", "size": 66, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 2, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1855}, {"language": "HTML", "num_chars": 1652}], "readme": "# CT Keyboard Hack\n\n> Starter kit for the seminar \"Creative Technologists - Tracing the City\" @ University of Applied Sciences Potsdam (Germany) winter semester 2019/2020 by Fabian Mor\u00f3n Zirfas\n\n## Assignment\n\n1. Hack your keyboard\n2. Create a reaction on keypress\n3. Create a video which shows your Hack\n4. Commit and push to the repo\n\n### Hints\n\n## Usage\n\n1. Open a terminal session in the root of the repository and type `npm install`  and hit return \u21a9 to install all dependencies.\n2. Type `npm start` and hit return \u21a9 to start the reload server.\n3. Start hacking\n4. When you are done and enrolled in the classroom, use the classroom to submit your assignment.\n\n## Contributing\n\nPull requests and stars are always welcome. For bugs and feature requests, [please create an issue](https://github.com/FH-Potsdam/dma/issues)\n\n## Author(s)\n\n**Fabian Mor\u00f3n Zirfas:**\n\n- [github/](https://github.com/fabianmoronzirfas)\n- [twitter/](http://twitter.com/fmoronzirfas)\n\n## License\n\nCopyright \u00a9 2019 [Fabian Mor\u00f3n Zirfas](https://fabianmoronzirfas.me)\nLicensed under the MIT license.\n"}
{"url": "https://github.com/FH-Potsdam/ctk-milanwulf", "owner": "FH-Potsdam", "repository_name": "ctk-milanwulf", "date_all_variable_collection": "2023-09-11", "description": "ctk-milanwulf created by GitHub Classroom", "size": 25146, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 2, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "milanwulf", "contributions": 3}, {"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1855}, {"language": "HTML", "num_chars": 1652}], "readme": "Video (click on image)\n[![Youtube Video](https://img.youtube.com/vi/ualzgEbyCdE/0.jpg)](https://youtu.be/ualzgEbyCdE)\n\n\nImages: https://github.com/FH-Potsdam/ctk-milanwulf/tree/master/Images\n\n# CT Keyboard Hack\n\n> Starter kit for the seminar \"Creative Technologists - Tracing the City\" @ University of Applied Sciences Potsdam (Germany) winter semester 2019/2020 by Fabian Mor\u00f3n Zirfas\n\n## Assignment\n\n1. Hack your keyboard\n2. Create a reaction on keypress\n3. Create a video which shows your Hack\n4. Commit and push to the repo\n\n### Hints\n\n## Usage\n\n1. Open a terminal session in the root of the repository and type `npm install`  and hit return \u21a9 to install all dependencies.\n2. Type `npm start` and hit return \u21a9 to start the reload server.\n3. Start hacking\n4. When you are done and enrolled in the classroom, use the classroom to submit your assignment.\n\n## Contributing\n\nPull requests and stars are always welcome. For bugs and feature requests, [please create an issue](https://github.com/FH-Potsdam/dma/issues)\n\n## Author(s)\n\n**Fabian Mor\u00f3n Zirfas:**\n\n- [github/](https://github.com/fabianmoronzirfas)\n- [twitter/](http://twitter.com/fmoronzirfas)\n\n## License\n\nCopyright \u00a9 2019 [Fabian Mor\u00f3n Zirfas](https://fabianmoronzirfas.me)\nLicensed under the MIT license.\n"}
{"url": "https://github.com/FH-Potsdam/ctk-SchmittVa", "owner": "FH-Potsdam", "repository_name": "ctk-SchmittVa", "date_all_variable_collection": "2023-09-11", "description": "ctk-SchmittVa created by GitHub Classroom", "size": 66, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 2, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1855}, {"language": "HTML", "num_chars": 1652}], "readme": "# CT Keyboard Hack\n\n> Starter kit for the seminar \"Creative Technologists - Tracing the City\" @ University of Applied Sciences Potsdam (Germany) winter semester 2019/2020 by Fabian Mor\u00f3n Zirfas\n\n## Assignment\n\n1. Hack your keyboard\n2. Create a reaction on keypress\n3. Create a video which shows your Hack\n4. Commit and push to the repo\n\n### Hints\n\n## Usage\n\n1. Open a terminal session in the root of the repository and type `npm install`  and hit return \u21a9 to install all dependencies.\n2. Type `npm start` and hit return \u21a9 to start the reload server.\n3. Start hacking\n4. When you are done and enrolled in the classroom, use the classroom to submit your assignment.\n\n## Contributing\n\nPull requests and stars are always welcome. For bugs and feature requests, [please create an issue](https://github.com/FH-Potsdam/dma/issues)\n\n## Author(s)\n\n**Fabian Mor\u00f3n Zirfas:**\n\n- [github/](https://github.com/fabianmoronzirfas)\n- [twitter/](http://twitter.com/fmoronzirfas)\n\n## License\n\nCopyright \u00a9 2019 [Fabian Mor\u00f3n Zirfas](https://fabianmoronzirfas.me)\nLicensed under the MIT license.\n"}
{"url": "https://github.com/FH-Potsdam/ctk-The-bastART", "owner": "FH-Potsdam", "repository_name": "ctk-The-bastART", "date_all_variable_collection": "2023-09-11", "description": "ctk-The-bastART created by GitHub Classroom", "size": 66, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 2, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1855}, {"language": "HTML", "num_chars": 1652}], "readme": "# CT Keyboard Hack\n\n> Starter kit for the seminar \"Creative Technologists - Tracing the City\" @ University of Applied Sciences Potsdam (Germany) winter semester 2019/2020 by Fabian Mor\u00f3n Zirfas\n\n## Assignment\n\n1. Hack your keyboard\n2. Create a reaction on keypress\n3. Create a video which shows your Hack\n4. Commit and push to the repo\n\n### Hints\n\n## Usage\n\n1. Open a terminal session in the root of the repository and type `npm install`  and hit return \u21a9 to install all dependencies.\n2. Type `npm start` and hit return \u21a9 to start the reload server.\n3. Start hacking\n4. When you are done and enrolled in the classroom, use the classroom to submit your assignment.\n\n## Contributing\n\nPull requests and stars are always welcome. For bugs and feature requests, [please create an issue](https://github.com/FH-Potsdam/dma/issues)\n\n## Author(s)\n\n**Fabian Mor\u00f3n Zirfas:**\n\n- [github/](https://github.com/fabianmoronzirfas)\n- [twitter/](http://twitter.com/fmoronzirfas)\n\n## License\n\nCopyright \u00a9 2019 [Fabian Mor\u00f3n Zirfas](https://fabianmoronzirfas.me)\nLicensed under the MIT license.\n"}
{"url": "https://github.com/FH-Potsdam/dataviz-2013", "owner": "FH-Potsdam", "repository_name": "dataviz-2013", "date_all_variable_collection": "2023-09-11", "description": "Dataviz Challenges 2013 - class material from the interface design programme @ FH Potsdam", "size": 23513, "stargazers_count": 3, "watchers_count": 3, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 4, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 4, "open_issues": 0, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "kennstenicht", "contributions": 46}, {"contributor": "rielc", "contributions": 34}, {"contributor": "mphasize", "contributions": 29}, {"contributor": "smnmrtn", "contributions": 28}, {"contributor": "Nappli", "contributions": 18}, {"contributor": "sebastian-meier", "contributions": 9}, {"contributor": "timpulver", "contributions": 8}, {"contributor": "GeniusSK", "contributions": 5}, {"contributor": "cpietsch", "contributions": 5}, {"contributor": "ahoi", "contributions": 2}, {"contributor": "ggsp", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 7018837}, {"language": "CoffeeScript", "num_chars": 306013}, {"language": "Processing", "num_chars": 44955}, {"language": "PHP", "num_chars": 29290}], "readme": "dataviz-2013\n============\n\nDataviz Challenges 2013 - class material from the interface design programme @ FH Potsdam\n\n### Development\n\n**GitHub**  \n\nClone this Project with git by running:\n```\ngit clone git@github.com:FH-Potsdam/dataviz-2013.git\n```\ncd into git repository \n```\ncd dataviz-2013\n```\n\n**Virtual Server**  \n\nPython  \n```\npython -m SimpleHTTPServer 8000\n```\n[Jekyll](http://jekyllrb.com/) / Github Pages engine  \nInstall description [here](https://github.com/mojombo/jekyll/wiki/install)\n```\njekyll server\n```\n"}
{"url": "https://github.com/FH-Potsdam/digenti-api", "owner": "FH-Potsdam", "repository_name": "digenti-api", "date_all_variable_collection": "2023-09-11", "description": "DIGENTI REST API", "size": 22642, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 11, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 11, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "jorditost", "contributions": 52}, {"contributor": "fabianehmel", "contributions": 22}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 90157}], "readme": "# digenti-api\n\nDIGENTI REST API.\n\n\n## Installation\n\nRun the following command from inside the app directory:\n\n```\nnpm install\n```\n\nThis will install all dependencies.\n\n## Config\n\nYou will need to enter some configuration parameters within a `config.js` file, placed in the main folder.\n\n- Rename `config.sample.js` to `config.js` or create a copy by this name.\n\n\n## Usage\n\n```\nnpm start\n```\n\nAnd check the server in:\n\nor\n\n```\nnode server.js\n```\n\nTest in the browser:\n\n```\nhttp://localhost:61002\n```\n\nIf everything is ok, you should see:\n\n```\n{\"status\":\"success\",\"message\":\"Live long and prosper!\"}\n```\n\n## Setting up the PostGRE / PostGIS Database\n\n- https://redmine.geoway.de/projects/digenti/wiki/Notes\n\n## Setting up your queries\n\n- `api/here.js`: HERE API functions and exports.\n- `api/postgres.js`: Postgres DIGENTI database functions and exports.\n- `api/index.js`: connect the functions to the permalinks.\n\n## HERE REST APIs\n\n- [Routing API Reference](https://developer.here.com/rest-apis/documentation/routing/topics/api-reference.html)\n- [Calculate isoline](https://developer.here.com/rest-apis/documentation/routing/topics/resource-calculate-isoline.html)\n- [Calculate route](https://developer.here.com/rest-apis/documentation/routing/topics/resource-calculate-route.html)\n\n## Dependencies\n\n- [turf.js](https://github.com/Turfjs/turf)\n- [concaveman](https://github.com/mapbox/concaveman)\n- [Express](http://expressjs.com/)\n\n## License\n\nYou may use this code under the terms of the MIT License. See http://en.wikipedia.org/wiki/MIT_License for more information.\n\nIf you make enhancements or changes we would love to hear from you.\n\nCopyright (C) 2017 Jordi Tost, Fabian Ehmel, and contributors\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"}
{"url": "https://github.com/FH-Potsdam/digenti-apps", "owner": "FH-Potsdam", "repository_name": "digenti-apps", "date_all_variable_collection": "2023-09-11", "description": "Open-source web-based tool for area accessibility assessment in the context of disaster management \u2013 based on satellite data and geovisualization.", "size": 11063, "stargazers_count": 1, "watchers_count": 1, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 15, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 15, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "jorditost", "contributions": 145}, {"contributor": "fabianehmel", "contributions": 71}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["accessibility-analysis", "d3-js", "disaster-management", "emergency-response", "geovisualization", "mapbox-gl-js", "remote-sensing"], "languages": [{"language": "HTML", "num_chars": 1258388}, {"language": "JavaScript", "num_chars": 715656}, {"language": "CSS", "num_chars": 75660}, {"language": "SCSS", "num_chars": 9516}], "readme": "# DIGENTI Apps\n\nOpen-source web-based tool for area accessibility assessment in the context of disaster management \u2013 based on satellite data and geovisualization.\n\nThe tool gives an overview of the accessibility of the settlements in the [Area of Interest in Colombia](https://docs.google.com/document/d/15N1pgERY4TUcnvck36jJFi3MvAZuxh8J-mOUpWDt-_w/edit?usp=sharing) using a routing API and remote sensing data.\n\nMoreover, the repository includes a set of snippets and examples, including routing experiments combining a routing API and remote sensing data.\n\n## Accessibility Interface\n\nThe Accessibility Interface is located in `app-access`.\n\nThe interface visualizes for each settlement:\n\n- Accessibility by road (vehicle)\n- Accessibility by path (walk)\n\n*Overview of the accessibility of each settlement in the area:*\n<img width=\"1324\" alt=\"Area accessibility overview\" src=\"https://github.com/FH-Potsdam/digenti-apps/assets/859148/a3c1888d-97e3-4ff5-b827-a7b4095f8646\">\n\n*Reachability of a settlement by road with time isolines:*\n<img width=\"1324\" alt=\"Settlement reachability\" src=\"https://github.com/FH-Potsdam/digenti-apps/assets/859148/ebcceaae-66e4-49a1-a45e-c1bfbf73f287\">\n\nIf a settlement is **not directly accessible** by road:\n\n1. Provide accessibility data to the nearest road:\n    - Distance\n    - Elevation profile\n    - Passable areas (%, polygons)\n    - Walkable areas (%, polygons)\n2. Provide helicopter landing areas (within a given distance from the settlement)\n\n*Data to the settlement's nearest road:*\n<img width=\"1324\" alt=\"Missing settlement reachability\" src=\"https://github.com/FH-Potsdam/digenti-apps/assets/859148/6dbadf05-6ff5-44c5-a57c-228c4fcf6836\">\n\n*Potential helicopter landing sites around a settlement:*\n<img width=\"1324\" alt=\"Potential helicopter landing sites\" src=\"https://github.com/FH-Potsdam/digenti-apps/assets/859148/638af0bf-cf43-4a32-ae99-fb404623cae2\">\n\n*Summary of the remote sensing data-based routing concept:*\n<img width=\"685\" alt=\"DIGENTI_RemoteSensingRouting\" src=\"https://github.com/FH-Potsdam/digenti-apps/assets/859148/ccda1126-f827-4644-840e-dd3da3f23620\">\n\n## Dependencies\n\nThis is the client part of a modular architecture. In order to access the satellite data you'll need to install the following packages:\n\n- [DIGENTI Framework: Libs, commons and utils](https://github.com/FH-Potsdam/digenti-framework)\n- [DIGENTI Server and REST API](https://github.com/FH-Potsdam/digenti-api)\n- [PostGRE / PostGIS Database](https://redmine.geoway.de/projects/digenti/wiki/Notes)\n\n## Docs\n\nFurther information of the project can be found in the following research articles and documentation:\n\n- [Project Documentation](https://github.com/FH-Potsdam/digenti-doc)\n- [Visualization and Interaction with Multiple Devices. A Case Study on Reachability of Remote Areas for Emergency Management \u2013 Jordi Tost & Frank Heidmann, i-com Journal of Interactive Media](https://doi.org/10.1515/icom-2017-0027)\n\n## Data\n\nThe remote sensing data is based on the Tandem-X WorldDEM 10-m resolution digital elevation model (DEM) with complete coverage for the area of interest.\n\n- [Data Wiki](https://docs.google.com/document/d/1rOW-6X6TNkypR-dgxWhZ4W7whIa5dxpPMbqCAW_iMPc/edit)\n- [Data Formats](https://docs.google.com/spreadsheets/d/1igPn_mZqVaId_kqjcNPapB_qUvXkHo37GfP1JvSQrOs/edit?usp=sharing)\n\n## Tools\n\n### Geo tools\n\n- [Mapbox GL JS](https://www.mapbox.com/mapbox-gl-js/)\n- [Turf.js](http://turfjs.org/)\n\n### Routing\n\n- [HERE Routing API](https://developer.here.com/rest-apis/documentation/routing)\n"}
{"url": "https://github.com/FH-Potsdam/digenti-react", "owner": "FH-Potsdam", "repository_name": "digenti-react", "date_all_variable_collection": "2023-09-11", "description": null, "size": 262, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "fabianehmel", "contributions": 2}, {"contributor": "jorditost", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 501}], "readme": "# DIGENTI react playground\n\nThis is a playground and repo for testing purposes with react for DIGENTI.\n\n## Useful Sources\n\n### Informational Posts\n- http://blog.andrewray.me/reactjs-for-stupid-people/\n- https://camjackson.net/post/9-things-every-reactjs-beginner-should-know\n- http://reactjs.de/posts/die-flux-architektur-und-react\n- https://facebook.github.io/react/docs/thinking-in-react.html\n\n### Tutorials\n- https://facebook.github.io/react/docs/tutorial.html\n- http://codepen.io/allanpope/post/build-react-redux-component\n- https://developmentarc.gitbooks.io/react-indepth/content/life_cycle/birth_mounting_indepth.html\n- https://reactjsnews.com/playing-with-react-and-d3\n"}
{"url": "https://github.com/FH-Potsdam/digenti-server", "owner": "FH-Potsdam", "repository_name": "digenti-server", "date_all_variable_collection": "2023-09-11", "description": null, "size": 4682, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "jorditost", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 42769}, {"language": "HTML", "num_chars": 2438}]}
{"url": "https://github.com/FH-Potsdam/digenti-tiles", "owner": "FH-Potsdam", "repository_name": "digenti-tiles", "date_all_variable_collection": "2023-09-11", "description": "DIGENTI Tile Server", "size": 2021, "stargazers_count": 1, "watchers_count": 1, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "jorditost", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 14430}, {"language": "JavaScript", "num_chars": 2012}], "readme": "# digenti-tiles\n\nDIGENTI Tile Server for mbtiles.\n\nMore info soon.\n\n## Installation\n\n1. Rename `config.sample.js` to `config.js` or create a copy with this name, and set your server/tiles configuration.\n2. Execute `npm install` in the Terminal\n3. Download the tiles from [here](https://www.dropbox.com/sh/3oy10e2lkue85k9/AABTNyKFkaFc6kxJ27n54D-Ta?dl=0) and put them in the folder `tiles` inside the project folder.\n"}
{"url": "https://github.com/FH-Potsdam/dma", "owner": "FH-Potsdam", "repository_name": "dma", "date_all_variable_collection": "2023-09-11", "description": "Starter kit for the seminar \"Creative Technologists - Tracing the City\" @ University of Applied Sciences Potsdam (Germany) by Fabian Mor\u00f3n Zirfas", "size": 26, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 1, "license": "MIT License", "allow_forking": true, "is_template": true, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 1165}, {"language": "JavaScript", "num_chars": 466}], "readme": "# Deconstructing Master Artists (dma)\n\n> Starter kit for the seminar \"Creative Technologists - Tracing the City\" @ University of Applied Sciences Potsdam (Germany) winter semester 2019/2020 by Fabian Mor\u00f3n Zirfas\n\n\n## Assignment\n\n1. Find a master artist/group/style\n2. Analyse one or several of her/his/their/its works.\n3. Create an algorithm that generates versions of these works.\n4. Update this README.md with some informations about your Artist(s) and describe your result.\n5. Save three **extraordinary** results as png files and add them to this README.md\n6. Prepare a verbal 2 minute presentation of your project.\n\n### Hints\n\n- Try not to replicate the image in its [phenotype](https://en.wikipedia.org/wiki/Phenotype). Try to define the algorithm behind its [genotype](https://en.wikipedia.org/wiki/Genotype) and create environmental factors.\n- Try not use fixed values. Try to find a rule. e.g. the center of the canvas is `width/2` and `height/2`. This allows to scale your graphic and the center stays the center\n- Try to use [HSB/HSL over RGB](https://p5js.org/reference/#/p5/colorMode) because HSB/HSL is way easier to understand if you want to create rules for harmonic colors. \n\n\n## Inspiration\n\nSome possible artists could be: _(graphic designers) Josef M\u00fcller-Brockmann, Karl Gerstner, Paul Rand, Otl Aicher, Ken Garland, (typographers): Adrian Frutiger, Jan Tschichold,Herbert Bayer, Paul Renner (artists) Aaron Marcus ,Giovanni Pintori,Sol LeWitt, Roy Lichtenstein, Francis Picabia, (styles) Dadaismus, Futurismus, constructivism, (groups) De Stijl: Piet Mondrian, Theo van Doesburg, Vilmos Husz\u00e1r, Bart van der Leck, Gerrit Rietveld (architect), Robert van 't Hoff (architect), Jacobus Oud (architect) Neue Tendenzen: Ivan Picelj Bauhaus: Alfred Arndt, Georg Muche, Gerhard Marcks, Hannes Meyer, Heinrich Beberniss, Johannes Itten, Josef Albers, Laszlo Moholy-Nagy, Lothar Schreyer, Ludwig Mies van der Rohe, Lyonel Feininger, Marcel Breuer, Max Krehan, Oskar Schlemmer, Paul Klee, Walter Gropius, Walter Peterhans, Wassily Kandinsky, Joost Schmidt, Gertrud Grunow\u2026_[^1]\n\nSee the some results of the seminar gestalten-in-code for some inspiration.\n\n- [Deconstructing Master Artists: Marcel Storr](https://interface.fh-potsdam.de/gestalten-in-code/projects/deconstructing-storr/) by <span><a href=\"https://incom.org/profil/7029\">Joshua Pacheco</a></span> and <span><a href=\"http://invitrocolor.com\">Theodor Hillmann</a></span>\n- [Deconstructing master artists: Bart van der Leck \u2013 Mountain view](https://interface.fh-potsdam.de/gestalten-in-code/projects/bart-van-der-leck/) by <span><a href=\"https://github.com/edgalindo\">Edmundo Mejia Galindo</a></span> and <span><a href=\"https://github.com/piixelcat\">Julia Hilt</a></span>\n- And many more [great projects](https://interface.fh-potsdam.de/gestalten-in-code/projects/) from this series\n- And here are even more [code snippets you can learn from](https://interface.fh-potsdam.de/gestalten-in-code/categories/)[^2]\n\n## Usage\n\n1. If you are enrolled the GitHub classroom for the seminar - accept the invite for your first assignment. If not clone the repo by running `git clone git@github.com:FH-Potsdam/dma.git`, [download the source](https://github.com/FH-Potsdam/dma/archive/master.zip) or [use it as a template](https://github.com/FH-Potsdam/dma/generate) from the GitHub interface.\n\n2. Open a terminal session in the root of the repository and type `npm install`  and hit return \u21a9 to install all dependencies.\n\n3. Type `npm start` and hit return \u21a9 to start the reload server.\n\n4. Start deconstructing your master artist.\n\n5. When you are done and enrolled in the classroom, use the classroom to submit your assignment.\n\n## Contributing\n\nPull requests and stars are always welcome. For bugs and feature requests, [please create an issue](https://github.com/FH-Potsdam/dma/issues)\n\n## Author(s)\n\n**Fabian Mor\u00f3n Zirfas:**\n\n- [github/](https://github.com/fabianmoronzirfas)\n- [twitter/](http://twitter.com/fmoronzirfas)\n\n## License\n\nCopyright \u00a9 2019 [Fabian Mor\u00f3n Zirfas](https://fabianmoronzirfas.me)\nLicensed under the MIT license.\n\n[^1]: Please extend this list with some more artists. Also no women here?  \n[^2]: Some of the examples are not written for P5.js but for Basil.js or Processing. Try to port them, ask for help.\n"}
{"url": "https://github.com/FH-Potsdam/docker-node-proof-of-concept", "owner": "FH-Potsdam", "repository_name": "docker-node-proof-of-concept", "date_all_variable_collection": "2023-09-11", "description": "proof of concept on how build a docker container for Node.js apps ", "size": 100, "stargazers_count": 1, "watchers_count": 1, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 193695}, {"language": "Shell", "num_chars": 1505}, {"language": "HTML", "num_chars": 725}, {"language": "CSS", "num_chars": 535}, {"language": "JavaScript", "num_chars": 395}], "readme": "# Docker Node.js Proof of Concept\n\nProof of concept on how build a docker container for Node.js apps.  \nThis is just for learning a bit about docker. There might be \ud83d\udc1c\ud83d\udc1b\ud83d\udc1e\ud83d\udd77\ud83d\udc1d and \ud83d\udc32\ud83d\udc09\ud83c\udc04.  \n\n__Makes use of:__  \n\n[![](http://dockeri.co/image/mhart/alpine-node)](https://hub.docker.com/r/mhart/alpine-node/)  \n\n__License:__  \n\n[![license](https://img.shields.io/github/license/mashape/apistatus.svg?maxAge=2592000)](https://fabiantheblind.mit-license.org/)\n\n----\n\nYou need Docker installed to use this. Luckily there is a App for Windows & macOS. Get it at [docker.com](https://www.docker.com/). You also should install [Kitematic](https://kitematic.com/) for easier acces to your running containers.  \n\n```bash\n# Edit the package.json to reflect your project\n# e.g. change the name of the container and user in \n# scripts \n#\n# start docker app\n# then run:  \ngit clone https://github.com/FH-Potsdam/docker-node-proof-of-concept.git ./docker-poc/\ncd docker-poc/\nnpm run docker:simple\n# to get the ID of the container run\n# docker ps\n# to see the output run\ndocker logs [CONTAINER ID]\n```\n\nopen: [localhost:61428](http://localhost:61428) to see the express app.  \n\nThe above commands:\n\n- build a basic the docker image \n- execute the docker container defined in `Dockerfile`\n\nTo have a smaller container you can bundle all your *.js files into a single one. This can be done by running:  \n\n```bash\nnpm run docker:browserify\n```\n\nit will:\n\n- build the basic image\n- bundle the js files into a single bundle.js file using browserify\n- remove the node_modules folder\n- execute the container defined in `Dockerfile.browserify`\n\nNote: There might be problems with native modules. If so fall back to the simple build.  \n\nto clean up after you run:  \n\n```bash\n# stops all containers\n# removs them\n# removes all images created by these commands\n# npm run docker:browserify\n# npm run docker:simple\nnpm run remove\n```\n\n\nUse this as a boilerplate to build node apps that run on the server.\n\n## Useful Docker commands\n\n```bash\n# list all images\ndocker images\n# list all containers\ndocker ps\n# remove a container\ndocker rm [CONTAINER ID or TAG]\n# reomve an image\ndocker rmi [IMAGE ID OR TAG]\n# stop all running containers\ndocker stop $(docker ps -a -q)\n#\n# see what your app is logging\ndocker logs [CONTAINER ID]\n\n# build from docker file not called Dockerfile\n# -t is the tag -f is the filename\n#\n#  the last argument is the working directory root\ndocker build -t [USER]/[FANCY NAME] -f My-Special-Dockerfile-name ./\n#\n# run a container with some useful settings\n# \n# -p is the port to map first is the actual port second the port the node app uses\n# \n# -e sets some environment variables\n# \n# -m the max memory \n# Memory limit (format: <number>[<unit>]). Number is a positive integer. Unit can be one of b, k, m, or g. Minimum is 4M.\n# \n# --memory-swap\n# Total memory limit (memory + swap, format: <number>[<unit>]). Number is a positive integer. Unit can be one of b, k, m, or g.\n# \n# -d sets detached mode\n# To start a container in detached mode, you use -d=true or just -d option. By design, containers started in detached mode exit when the root process used to run the container exits. A container in detached mode cannot be automatically removed when it stops, this means you cannot use the --rm option with -d option.\n#\ndocker run -p 61428:8080 -u \"app\" -e \"NODE_ENV=production\" -m \"300M\" --memory-swap \"1G\" -d user/fancy-name\n\n# see the package.json scripts how they are used in this project\n```\n\n\n## Recommended Readings\n\n- [Dockerfile reference](https://docs.docker.com/engine/reference/builder/)\n- [Dockerizing a Node.js web app Node.js](https://nodejs.org/en/docs/guides/nodejs-docker-webapp/)\n- [Best practices for writing Dockerfiles](https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/)\n- [Best Practices for Non-root User \u00b7 Issue #48 \u00b7 mhart/alpine-node \u00b7 GitHub](https://github.com/mhart/alpine-node/issues/48)\n- [Getting Started with Docker Scotch](https://scotch.io/tutorials/getting-started-with-docker)\n- [option to not install devDependencies \u00b7 Issue #1434 \u00b7 npm/npm \u00b7 GitHub](https://github.com/npm/npm/issues/1434)\n- [docker-node/BestPractices.md at master \u00b7 nodejs/docker-node \u00b7 GitHub](https://github.com/nodejs/docker-node/blob/master/docs/BestPractices.md)\n- [odino.org ||\u00a0Docker run your Nodejs App in 24mb of an Image](http://odino.org/minimal-docker-run-your-nodejs-app-in-25mb-of-an-image/)\n- [Issues \u00b7 docker/docker-bench-security \u00b7 GitHub](https://github.com/docker/docker-bench-security/issues)\n\n\n__nexe (Not working yet)__\n\n\n- [Docker for Mac: standard_init_linux.go:175: exec user process caused \"exec format error\" \u00b7 Issue #23865 \u00b7 docker/docker \u00b7 GitHub](https://github.com/docker/docker/issues/23865)\n- [deployment - How do I deploy Node.js applications as a single executable file? - Stack Overflow](http://stackoverflow.com/questions/14314038/how-do-i-deploy-node-js-applications-as-a-single-executable-file)\n"}
{"url": "https://github.com/FH-Potsdam/doing-papercraft", "owner": "FH-Potsdam", "repository_name": "doing-papercraft", "date_all_variable_collection": "2023-09-11", "description": "Workshop docs", "size": 295336, "stargazers_count": 2, "watchers_count": 2, "language": "PostScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 1, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 2}, {"contributor": "gitter-badger", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PostScript", "num_chars": 1109859}, {"language": "Ruby", "num_chars": 3051}, {"language": "JavaScript", "num_chars": 1019}], "readme": "doing papercraft\n================\n\n[![Gitter](https://img.shields.io/gitter/room/nwjs/nw.js.svg?style=flat-square)](https://gitter.im/FH-Potsdam/doing-papercraft)  \n\n## Introduction  \n\nThis repository is a write-down for an upcoming workshop @ the University of Applied Sciences Potsdam (Germany). We will explore the minimal basics of the 3D application Blender to create some primitive shapes. These shapes will then be unfolded for laser cutting. It is a walkthrough of some possible workflows. We will focus on using Blender and exporting 3D data from it. If you already know other 3D applications you can skip Blender and move on to the [Unfolding](#unfolding) section. _This is still work in progress, there might be_ \ud83d\udc1b_,_ \ud83d\udc09 _and_ \ud83d\udc7e_._\n\nSee the [docs here](http://fh-potsdam.github.io/doing-papercraft/). Build with [mkdocs](http://www.mkdocs.org/).  \n\n## Contribution & Issues\n\nPlease file any issues [here](https://github.com/FH-Potsdam/doing-papercraft/issues) on GitHub. Contributions and Pull Requests are welcome.  \n\n## Creating gifs\n\nThe gifs in these docs are created by transfomring a screenrecord with ffmpeg to a sequence. This sequence then gets transformed with ImageMagick to a gif. ffmpeg and ImageMagick can be installde using [homebrew](https://brew.sh).  \n\nInstall brew like discribed on their site. Then run:\n\n    brew install ffmpeg --with-fdk-aac --with-ffplay --with-freetype --with-frei0r --with-libass --with-libvo-aacenc --with-libvorbis --with-libvpx --with-opencore-amr --with-openjpeg --with-opus --with-rtmpdump --with-schroedinger --with-speex --with-theora --with-tools\n    brew install imagemagick\n\nYou should be good to go. \n\n    ffmpeg -i blender-ui.mp4 -r 20 -vcodec ppm  -s800x600 seq/out%05d.png\n    convert -layers Optimize seq/out*.png ../images/blender-ui.gif\n\n\nCopyright (c) 2016 Fabian Moron Zirfas & University of Applied Sciences Potsdam (Germany)\n\nPermission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies.  \n\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.  "}
{"url": "https://github.com/FH-Potsdam/doing-projection-mapping", "owner": "FH-Potsdam", "repository_name": "doing-projection-mapping", "date_all_variable_collection": "2023-09-11", "description": "a workshop about projection mapping", "size": 43129, "stargazers_count": 9, "watchers_count": 9, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 3, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "ISC License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 3, "open_issues": 0, "watchers": 9, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "Doing Projection Mapping\n========================\n\n## Introduction  \n\nThis document is a write-down for a workshop by [Fabian Mor\u00f3n Zirfas](https://github.com/fabiantheblind) @ [the University of Applied Sciences Potsdam (Germany)](http://www.fh-potsdam.de/) as part of the seminar [\"Datenobjekte\"](https://incom.org/workspace/6569) (data objects) by [Professor Boris M\u00fcller](https://incom.org/profil/99) (a.k.a [@borism](https://twitter.com/borism) on Twitter). We will explore the basics possibilites we have in the field of projection mapping. _This is still work in progress, there might be_ \ud83d\udc1b_,_ \ud83d\udc09 _and_ \ud83d\udc7e_._  \n\n\n\n## Prerequisites  \n\n- a computer\n- a projector\n- Processing  \n- HeavyM  \n\n!!!note\n    Some of these are optional. Depending on which workflow you are going to use.  \n\n## Source  \n\nThese docs are written using [mkdocs](http://www.mkdocs.org/) using the [readthedocs](https://readthedocs.org/) theme by Fabian Mor\u00f3n Zirfas with \u2665. See the source on [GitHub.](https://github.com/FH-Potsdam/doing-projection-mapping)  \n\n[![Gitter](https://img.shields.io/gitter/room/nwjs/nw.js.svg?style=flat-square)](https://gitter.im/FH-Potsdam/doing-projection-mapping)  \n\n## Creating gifs\n\nThe gifs in these docs are created by transfomring a screenrecord with ffmpeg to a sequence. This sequence then gets transformed with ImageMagick to a gif. ffmpeg and ImageMagick can be installde using [homebrew](https://brew.sh).  \n\nInstall brew like discribed on their site. Then run:\n\n    brew install ffmpeg --with-fdk-aac --with-ffplay --with-freetype --with-frei0r --with-libass --with-libvo-aacenc --with-libvorbis --with-libvpx --with-opencore-amr --with-openjpeg --with-opus --with-rtmpdump --with-schroedinger --with-speex --with-theora --with-tools\n    brew install imagemagick\n\nYou should be good to go. \n\n    ffmpeg -i blender-ui.mp4 -r 20 -vcodec ppm  -s800x600 seq/out%05d.png\n    convert -layers Optimize seq/out*.png ../images/blender-ui.gif"}
{"url": "https://github.com/FH-Potsdam/dome.perimeter", "owner": "FH-Potsdam", "repository_name": "dome.perimeter", "date_all_variable_collection": "2023-09-11", "description": "Fulldome Perimetrie Test Application", "size": 136, "stargazers_count": 2, "watchers_count": 2, "language": "Processing", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Processing", "num_chars": 30064}], "readme": "# dome.perimeter\n\n\n## General Information\nThe dome.perimeter was developed in collaboration with Prof. Klaus Dufke in the summer term 2012.  \n  \nFH-Potsdam, University of Applied Science\n\n  \n**Current Version:**  \n0.1.42 (stable and versioned using [semantic versioning](http://semver.org/))   \n  \n**Tested Platform:**  \nMacOS 10.6+  \nWin ???  \nLinux ???  \n\n**Processing version:**  \n2.0b8  \n\n**Dependencies**  \ncontrolP5 v2.0.4  \n\n**Issues and Bugs**  \nYou can find a list of all known bugs at [GitHub](https://github.com/fh-potsdam/dome.perimeter/issues). Please report if you find an unknown bug.  \n\n\n## Development\n\nClone and build this Project by running:\n\n    git clone https://github.com/fh-potsdam/dome.perimeter.git\n    git submodule init\n    git submodule update\n    cd dome.perimeter\n    make run\n\n\n## Changelog  \nA detailed changelog, intended for programmers.  \n  \n0.1.42  \n- Add and update test xml files.\n- Add Makefile and processing.make submodule\n- Small changes at save image/sequence\n\n0.1.41a  \n- Fixed XML Processing 2.0 changes\n- Create git Repository  \n  \n  \n## Author  \ndome.perimeter is developed by Paul Vollmer  \nCheck out for new release at https://github.com/fh-potsdam/dome.perimeter/  \n  \nMail: paul.vollmer@fh-potsdam.de  \nGithub: http://www.github.com/wrongentertainment  \n\n\n## License \ndome.perimeter is released under the MIT License: http://www.opensource.org/licenses/MIT\n"}
{"url": "https://github.com/FH-Potsdam/easydriver", "owner": "FH-Potsdam", "repository_name": "easydriver", "date_all_variable_collection": "2023-09-11", "description": "Some simple sketches for using the schmalzhaus - easydriver", "size": 120, "stargazers_count": 0, "watchers_count": 0, "language": "Arduino", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Arduino", "num_chars": 4735}], "readme": "easydriver\n==========\n\nSome simple sketches for using the schmalzhaus - easydriver  \n\n##Links\n\nEasy Driver stepper motor driver\n[http://www.schmalzhaus.com/EasyDriver/index.html](http://www.schmalzhaus.com/EasyDriver/index.html)\n\nStepper Motor Quickstart Guide - SparkFun Electronics\n[https://www.sparkfun.com/tutorials/400](https://www.sparkfun.com/tutorials/400)\n\nEasy Driver stepper motor driver\n[http://www.schmalzhaus.com/EasyDriver/index.html](http://www.schmalzhaus.com/EasyDriver/index.html)\n\n\n##License\n\nCopyright (c) 2015 FH-Potsdam & Fabian \"fabiantheblind\" Mor\u00f3n Zirfas\n\nPermission is hereby granted, free of charge, to any person obtaining a\ncopy of this software and associated documentation files (the \"Software\"),\nto deal in the Software without restriction, including without limitation\nthe rights to use, copy, modify, merge, publish, distribute, sublicense,\nand/or sell copies of the Software, and to permit persons to whom the\nSoftware is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\nDEALINGS IN THE SOFTWARE.\n\n"}
{"url": "https://github.com/FH-Potsdam/eingabe-ausgabe", "owner": "FH-Potsdam", "repository_name": "eingabe-ausgabe", "date_all_variable_collection": "2023-09-11", "description": "a microsite for the seminar Eingabe/Ausgabe in 2014/2015 - 2015 - 2015/2016", "size": 206424, "stargazers_count": 2, "watchers_count": 2, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 3}, {"contributor": "PDXIII", "contributions": 2}, {"contributor": "Wetterprophet", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 34042}, {"language": "CSS", "num_chars": 15925}, {"language": "JavaScript", "num_chars": 4212}, {"language": "Ruby", "num_chars": 697}, {"language": "Shell", "num_chars": 163}], "readme": "Input Output (Eingabe Ausgabe)\n=============================\n\nFundamentals of process-oriented design.\nDesign is increasingly dynamic and participatory. Digital, generative and interactive processes can be found in the design of digital media, communication processes and products (in production & use). In the center of the design the focus is planning, anticipating and implementing emergent systems based on natural technological and social processes. In this course the basic skills and possibilities of process-oriented design are analyzed and developed in a number of creative exercises. It is a broad overview of facets, methods and tools, as well as insights into the elementary handicraft and technical procedures and concepts of process-oriented design. An artistic and creative engagement with the corresponding technologies takes place.\n\nThe exercises represent a cross-section of the following topics:\n\nGenerative Design. Analog and digital using the Processing platform\nPhysical Computing. Using the Arduino & Raspberry Pi platforms\nDigital culture. Possibilities of the Web and use of web technologies\nParticipatory design. Participation and user-generated content.\nBio design. Designing with living organisms.\nA Seminar by Mey Lean Konemann, Lisa Charlotte Rost, Cedirc Kiefer, Jonas Loh, Benedikt Gro\u00df and Fabian Mor\u00f3n Zirfas from the wintersemster 2014/2015 till summersemester 2015/2016 at the Interface Design Department of the University of Applied Sciences Potsdam (Germany) based on works by Monika Hoinkis.\n\n### What is in here?  \n\nThis is the source for the jekyll powerd site. See [https://interface.fh-potsdam.de/eingabe-ausgabe](https://interface.fh-potsdam.de/eingabe-ausgabe/) for all the results.  \n\n### Chat with us\n\n[![Gitter](https://img.shields.io/gitter/room/nwjs/nw.js.svg?maxAge=2592000?style=flat-square)](https://gitter.im/FH-Potsdam/eingabe-ausgabe)  \n\n##License  \n\nThe MIT License (MIT)\nCopyright \u00a9 2014 - 2016 FH-Potsdam & Fabian Mor\u00f3n Zirfas\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \u201cSoftware\u201d), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:  \n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.  \n\nTHE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.  \n"}
{"url": "https://github.com/FH-Potsdam/eovis", "owner": "FH-Potsdam", "repository_name": "eovis", "date_all_variable_collection": "2023-09-11", "description": "Visualization of the Natural Hazards listed by the NASA Earth Observatory in 2015", "size": 3004, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 3, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 3, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "jorditost", "contributions": 21}, {"contributor": "petestern", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 294773}, {"language": "HTML", "num_chars": 88650}, {"language": "CSS", "num_chars": 27387}], "readme": "# EOVIS\n\nVisualization of the Natural Hazards listed by the [NASA's Earth Observatory](http://earthobservatory.nasa.gov/NaturalHazards/) in 2015.\n\n## Sources\n\n- [NASA's EONET](http://eonet.sci.gsfc.nasa.gov/): Natural Hazards\n- [USGS Earthquakes](http://earthquake.usgs.gov/earthquakes/eqinthenews/2015/): Earthquakes\n\n## Prepare data\n\n- Clean file with `scraper/clean.js`. To export the file as GeoJSON use `scraper/cleanGeoJSON.js` instead.\n- Load social media `scraper/social.js`, or load social media and automatically add analytics `scraper/social-analytics.js`.\n\n## EONET\n\n### Data format (JSON)\n\n```\n{\n\t\"id\": \"EONET_56\",\n\t\"title\": \"Fuego Volcano, Guatemala\",\n    \"description\": \"During a 30-hour period during 30 June-1 July, activity at Fuego was at a high level, characterized by explosions, high-temperature pyroclastic flows, and ashfall. Ash plumes and explosions have continued into the fall.\",\n\t\"link\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/events/EONET_56\",\n\t\"categories\": [\n\t\t{\n\t\t\t\"id\": 12,\n\t\t\t\"title\": \"Volcanoes\"\n\t\t}\n\t],\n\t\"sources\": [\n\t\t{\n\t\t\t\"id\": \"SIVolcano\",\n\t\t\t\"url\": \"http://volcano.si.edu/volcano.cfm?vn=342090\"\n\t\t}\n\n\t],\n\t\"geometries\": [\n\t\t{\n\t\t\t\"date\": \"2015-06-30T00:00:00Z\",\n\t\t\t\"type\": \"Polygon\",\n\t\t\t\"coordinates\": [[ [-90.91110229492188, 14.442392240227267], [-90.91110229492188, 14.501434647062004], [-90.84945678710938, 14.501434647062004], [-90.84945678710938, 14.442392240227267], [-90.91110229492188, 14.442392240227267] ]]\n\t\t}\n\n\t]\n}\n```\n\n### Categories\n\n```\n{\n\t\"title\": \"EONET Event Categories\",\n\t\"description\": \"List of all the available event categories in the EONET system\",\n\t\"link\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/categories\",\n\t\"categories\": [\n\t\t{\n\t\t\t\"id\": 6,\n\t\t\t\"title\": \"Drought\",\n\t\t\t\"link\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/categories/6\",\n\t\t\t\"description\": \"Long lasting absence of precipitation affecting agriculture and livestock, and the overall availability of food and water.\",\n\t\t\t\"layers\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/layers/6\"\n\t\t},\n\t\t{\n\t\t\t\"id\": 7,\n\t\t\t\"title\": \"Dust and Haze\",\n\t\t\t\"link\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/categories/7\",\n\t\t\t\"description\": \"Related to dust storms, air pollution and other non-volcanic aerosols. Volcano-related plumes shall be included with the originating eruption event.\",\n\t\t\t\"layers\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/layers/7\"\n\t\t},\n\t\t{\n\t\t\t\"id\": 16,\n\t\t\t\"title\": \"Earthquakes\",\n\t\t\t\"link\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/categories/16\",\n\t\t\t\"description\": \"Related to all manner of shaking and displacement. Certain aftermath of earthquakes may also be found under landslides and floods.\",\n\t\t\t\"layers\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/layers/16\"\n\t\t},\n\t\t{\n\t\t\t\"id\": 9,\n\t\t\t\"title\": \"Floods\",\n\t\t\t\"link\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/categories/9\",\n\t\t\t\"description\": \"Related to aspects of actual flooding--e.g., inundation, water extending beyond river and lake extents.\",\n\t\t\t\"layers\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/layers/9\"\n\t\t},\n\t\t{\n\t\t\t\"id\": 14,\n\t\t\t\"title\": \"Landslides\",\n\t\t\t\"link\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/categories/14\",\n\t\t\t\"description\": \"Related to landslides and variations thereof: mudslides, avalanche.\",\n\t\t\t\"layers\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/layers/14\"\n\t\t},\n\t\t{\n\t\t\t\"id\": 19,\n\t\t\t\"title\": \"Manmade\",\n\t\t\t\"link\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/categories/19\",\n\t\t\t\"description\": \"Events that have been human-induced and are extreme in their extent.\",\n\t\t\t\"layers\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/layers/19\"\n\t\t},\n\t\t{\n\t\t\t\"id\": 15,\n\t\t\t\"title\": \"Sea and Lake Ice\",\n\t\t\t\"link\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/categories/15\",\n\t\t\t\"description\": \"Related to all ice that resides on oceans and lakes, including sea and lake ice (permanent and seasonal) and icebergs.\",\n\t\t\t\"layers\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/layers/15\"\n\t\t},\n\t\t{\n\t\t\t\"id\": 10,\n\t\t\t\"title\": \"Severe Storms\",\n\t\t\t\"link\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/categories/10\",\n\t\t\t\"description\": \"Related to the atmospheric aspect of storms (hurricanes, cyclones, tornadoes, etc.). Results of storms may be included under floods, landslides, etc.\",\n\t\t\t\"layers\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/layers/10\"\n\t\t},\n\t\t{\n\t\t\t\"id\": 17,\n\t\t\t\"title\": \"Snow\",\n\t\t\t\"link\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/categories/17\",\n\t\t\t\"description\": \"Related to snow events, particularly extreme/anomalous snowfall in either timing or extent/depth.\",\n\t\t\t\"layers\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/layers/17\"\n\t\t},\n\t\t{\n\t\t\t\"id\": 18,\n\t\t\t\"title\": \"Temperature Extremes\",\n\t\t\t\"link\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/categories/18\",\n\t\t\t\"description\": \"Related to anomalous land temperatures, either heat or cold.\",\n\t\t\t\"layers\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/layers/18\"\n\t\t},\n\t\t{\n\t\t\t\"id\": 12,\n\t\t\t\"title\": \"Volcanoes\",\n\t\t\t\"link\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/categories/12\",\n\t\t\t\"description\": \"Related to both the physical effects of an eruption (rock, ash, lava) and the atmospheric (ash and gas plumes). \",\n\t\t\t\"layers\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/layers/12\"\n\t\t},\n\t\t{\n\t\t\t\"id\": 13,\n\t\t\t\"title\": \"Water Color\",\n\t\t\t\"link\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/categories/13\",\n\t\t\t\"description\": \"Related to events that alter the appearance of water: phytoplankton, red tide, algae, sediment, whiting, etc.\",\n\t\t\t\"layers\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/layers/13\"\n\t\t},\n\t\t{\n\t\t\t\"id\": 8,\n\t\t\t\"title\": \"Wildfires\",\n\t\t\t\"link\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/categories/8\",\n\t\t\t\"description\": \"Wildfires includes all nature of fire, including forest and plains fires, as well as urban and industrial fire events. Fires may be naturally caused or manmade.\",\n\t\t\t\"layers\": \"http://eonet.sci.gsfc.nasa.gov/api/v2.1/layers/8\"\n\t\t}\n\t]\n}\n```\n"}
{"url": "https://github.com/FH-Potsdam/fh-potsdam.github.com", "owner": "FH-Potsdam", "repository_name": "fh-potsdam.github.com", "date_all_variable_collection": "2023-09-11", "description": "Index of public and open source projects created at the University of Applied Sciences in Potsdam, Germany", "size": 616, "stargazers_count": 3, "watchers_count": 3, "language": "CSS", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 8, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 8, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 5}, {"contributor": "dependabot[bot]", "contributions": 4}, {"contributor": "fabiantheblind", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "CSS", "num_chars": 9859}, {"language": "HTML", "num_chars": 4328}, {"language": "Ruby", "num_chars": 73}], "readme": "# fh-potsdam.github.com\n\nFor usage check out the [jekyll](http://jekyllrb.com/) and [GitHub Pages](https://pages.github.com/) docs.\n\n\n"}
{"url": "https://github.com/FH-Potsdam/fhpCoursesScraper", "owner": "FH-Potsdam", "repository_name": "fhpCoursesScraper", "date_all_variable_collection": "2023-09-11", "description": "A scrapper for extracting courses information of the University of Applied Science Potsdam", "size": 46, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 3, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 3, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "vogelino", "contributions": 24}, {"contributor": "topada", "contributions": 14}, {"contributor": "Coderwelsch", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 13264}], "readme": "[![Join the chat at https://gitter.im/FH-Potsdam/coursesAPI][gitterBadge]][gitterUrl]\n\n# FHP Design Courses Scraper  \nThis node.js scrapper made with [Nightmare.js](https://github.com/segmentio/nightmare) is designed to extract informations about the design courses given in the University of Applied Science Potsdam as well as the teachers of the school. More precisely, it focuses on scrapping the [online course catalog][vorlesungsverzeichnis FHP] of the design faculty and the [page listing the people involved in the school][people list FHP].\n\n## Prerequisites\nTo contribute to the development and to run the courses API, make sure you have `node (6.7.0)` and `npm 3.10.3` installed.\n\n## Quick Start\n\n```bash\n# clone this repository\ngit clone https://github.com/FH-Potsdam/fhpCoursesScraper.git\n\n# install node dependencies\nnpm install\n\n# start the courses scraper\nnpm start\n```\n\n## What it scrapes\nThe script will save two timestamped json files in the **`results`** folder with all courses from\n\n- http://www.fh-potsdam.de/studieren/design/studium/vorlesungsverzeichnis/1-studienabschnitt-ba-design/\n- http://www.fh-potsdam.de/studieren/design/studium/vorlesungsverzeichnis/2-studienabschnitt-ba-design/\n- http://www.fh-potsdam.de/studieren/design/studium/vorlesungsverzeichnis/ma-design/\n\n...and all teachers from:\n\n- https://www.fh-potsdam.de/studieren/design/personen/\n\n\n# Motivation\nThis project has been made as project of the 2 weeks long Workshop \"Creating an open sourced REST API\" given by Julia Freyhoff @antsteelmule and Lucas Vogel @vogelino in the University of Applied Sciences Potsdam.\n\nThis project was done in parallel with two other projects:\n- :octocat: [Courses API](https://github.com/FH-Potsdam/coursesAPI)\nA REST API designed to create, read, update and delete study courses (CRUD).\n- :octocat: [Viewer (App)](https://github.com/FH-Potsdam/coursesViewer)\nAn html website using the courses API to display all the available courses. This project was used as a demonstration of an API usage with ajax loading.\n\nIf you want to know more about the Project and/or the Workshop, look at our [documentation](https://fhp.incom.org/projekt/7668) (german), or get in touch with us.\n\n## Collaborators\n- [Julia Freyhoff](https://github.com/antsteelmule) \u2014 @antsteelmule\n- [Lucas Vogel](https://github.com/vogelino) \u2014 @vogelino\n- [Jonas K\u00f6pfer](https://github.com/topada) \u2014 @topada\n- [Joseph Ribbe](https://github.com/coderwelsch) \u2014 @coderwelsch\n- [Bela Kurek](https://github.com/q-rec) \u2014 @q-rec\n\n<!--- Links -->\n[gitterBadge]: https://badges.gitter.im/Join%20Chat.svg\n[gitterUrl]:  https://gitter.im/FH-Potsdam/coursesAPI?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge\n\n[vorlesungsverzeichnis FHP]: https://www.fh-potsdam.de/studieren/design/studium/vorlesungsverzeichnis\n[people list FHP]: https://www.fh-potsdam.de/studieren/design/personen\n"}
{"url": "https://github.com/FH-Potsdam/FHP_VPN_Startscript", "owner": "FH-Potsdam", "repository_name": "FHP_VPN_Startscript", "date_all_variable_collection": "2023-09-11", "description": "Script to simplify VPN usage on campus @vicegold", "size": 172, "stargazers_count": 3, "watchers_count": 3, "language": "AppleScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "vicegold", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "AppleScript", "num_chars": 2009}], "readme": "# FHP_VPN_Startscript #\n\nScript to simplify VPN usage on campus\n\nPretty simple and rough code, hacked together at a first start with apple script.\n\nBenutzung:\n\nWichtig: Aktviere \"Start VPN when AnyConnect is started\" in AnyConnect und schalte das Script unter OSX Settings -> Sicherheit -> Bedienungshilfen  frei.\n\n1. Starte das Script\n2. Einmalige Passworteingabe\n3. let the magic happen ;)\n\n\n## Automatisierung: ##\n(funktioniert nur wenn man gerade im WLAN der der FHP ist.)\n\nBen\u00f6tigt: http://www.controlplaneapp.com/ \n1. Starte das Programm\n2. lege in den Einstellungen 2 Umgebungen an\n3. Nenne eine **FH Potsdam** und die andere **Unterwegs** oder \u00e4hnliches\n4. Gehe in den Reiter **Evidenzquellen** und hake dort **Nearby WiFi Network** und **Sleep/Wake Event** an\n5. Lege eine neue **Nearby WiFi Network** -> **WiFi SSID** Regel im Reiter Regeln an, und w\u00e4hle dort das WLAN der FHP aus und stelle die Wahrscheinlichkeit auf 100%. Dann w\u00e4hle bei Umgebung **FH Potsdam** aus.\n6. Erstelle eine weitere Regel im Modus **Sleep/Wake Event**. W\u00e4hle im Dialog Sleep, eine Wahrscheinlichkeit von 100% und Umgebung **Unterwegs**.\n7. Gehe nun in den Reiter Aktionen und lege eine neue **Aktion** an. (Application Actions -> Open File or Application). Dann w\u00e4hle das **FHP VPN Startscript** im File Dialog aus.\n8. W\u00e4hle bei der Aktion unter Umgebung **FH Potsdam**\n9. Fertig. Das Script startet jetzt automatisch sobald ihr euch auf dem Campus der FHP befindet. (Auch nach zuklappen des Laptops wird das Sript automatisch gestartet. Wobei es sein kann dass das teilweise nicht funktioniert. Sollte aber mit der n\u00e4chsten Version richtig funktionieren)\n\nPS: Man sollte evtl. die Benachritigungen von ControlPlane ausschalten, sonst wird man permanent mit Hinweisen bombardiert.\n"}
{"url": "https://github.com/FH-Potsdam/fiducial-detection", "owner": "FH-Potsdam", "repository_name": "fiducial-detection", "date_all_variable_collection": "2023-09-11", "description": null, "size": 10, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "sebastian-meier", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 7927}, {"language": "HTML", "num_chars": 2938}], "readme": "# fiducial-detection"}
{"url": "https://github.com/FH-Potsdam/flipdot", "owner": "FH-Potsdam", "repository_name": "flipdot", "date_all_variable_collection": "2023-09-11", "description": "playing with flipdots", "size": 42023, "stargazers_count": 3, "watchers_count": 3, "language": "Arduino", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Arduino", "num_chars": 3764}], "readme": "flipdot\n=======\n\nplaying with flipdots\n\n\n[flipdot 30 series gif ani](images/flipdot-640-360.gif)  \n![](flipdot/flipdot_bb.png)  \nYou can run the series 30 just by hocking them up to the arduino directly.\n\n\n[flipdot h brdige giv ani](images/flipdot_hbridge.gif)  \n![](flipdot_by_hbridge/flipdot_by_hbridge_bb.png)  \nThe 36 & 54 series needs a higher voltage. Hock 'em up with a h-bridge.  \n\n\n##License\nCopyright 2014 Fabian \"fabiantheblind\" Mor\u00f3n Zirfas\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n"}
{"url": "https://github.com/FH-Potsdam/ForschungsFenster-Logger", "owner": "FH-Potsdam", "repository_name": "ForschungsFenster-Logger", "date_all_variable_collection": "2023-09-11", "description": "Logger utility functions for the \"Forschungsfenster\" software components.", "size": 234, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 3467}], "readme": "# ForschungsFenster-Logger\n\n\nLogger utility functions for the \"ForschungsFenster\" software components.\n\nBunyan was used as the logger module.\n\n\n## Installation\n\nAdd the following line to your `package.json` dependencies.\n\n    \"Forschungsfenster-Logger\": \"https://github.com/FH-Potsdam/ForschungsFenster-Logger/archive/v0.2.0.tar.gz\"\n"}
{"url": "https://github.com/FH-Potsdam/FullDome_", "owner": "FH-Potsdam", "repository_name": "FullDome_", "date_all_variable_collection": "2023-09-11", "description": "Tools & Examples", "size": 1536, "stargazers_count": 1, "watchers_count": 1, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "marctiedemann", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 143928}]}
{"url": "https://github.com/FH-Potsdam/generator-ctp5", "owner": "FH-Potsdam", "repository_name": "generator-ctp5", "date_all_variable_collection": "2023-09-11", "description": null, "size": 408, "stargazers_count": 2, "watchers_count": 2, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "ff6347", "contributions": 10}, {"contributor": "dependabot[bot]", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 4251}, {"language": "HTML", "num_chars": 2838}], "readme": "# ctp5 generator\n\nplugged from https://github.com/pflannery/p5-yeoman-generator/"}
{"url": "https://github.com/FH-Potsdam/getting-a-grade-for-steel-ant-io", "owner": "FH-Potsdam", "repository_name": "getting-a-grade-for-steel-ant-io", "date_all_variable_collection": "2023-09-11", "description": "A check list for creating the documentation for the seminar Input/Output - basics of process oriented design (\"Eingabe/Ausgabe. Grundlagen der prozessorientierten Gestaltung\").", "size": 614, "stargazers_count": 3, "watchers_count": 3, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "ISC License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 4}, {"contributor": "gitter-badger", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "Getting a grade for \"Input/Output Fundamentals of Process-Oriented Design\"\n=========================================================================\n\n[![Join the chat at https://gitter.im/FH-Potsdam/getting-a-grade-for-steel-ant-io](https://badges.gitter.im/FH-Potsdam/getting-a-grade-for-steel-ant-io.svg)](https://gitter.im/FH-Potsdam/getting-a-grade-for-steel-ant-io?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\n\nA check list for creating the documentation for the seminar Input/Output - basics of process oriented design (\"Eingabe/Ausgabe. Grundlagen der prozessorientierten Gestaltung\").  \n\n### The thirteen commandments for getting a grade     \n\n1. The repositories should have a meaningful name. Don't call them \"Eingabe_Ausgabe_Projekt1\" or I start puking. Also don't use \"_\"  and UPPERCASE in the names. Give your project a nice short name. You are designers come up with some ideas.   \n2. The image names should all be lower case, short and unique. The thumbnail (64 \u00d7 64 px) images have the same name as the large (500 \u00d7 500 px) images but with the extension \"thumb-\". E.g. \"myimage.png\" has the thumbnail \"myimage-thumb.png\".  \n3. The beauty shot(s) are representative images for your project. All in 1920 \u00d7 1080 px.  \n4. You need to add a license to each repository. [\"Choosing an OSS license doesn't need to be scary - ChooseALicense.com\"](http://choosealicense.com/)  \n5. You need to write comments into your source code.  \n6. Your source code works or you need to have directions in your README.md how to install all dependencies and run your code.  \n7. If you created a poster for the ISS project you need to provide your InDesign or Photoshop files as well.  \n8. Your README.md is valid Markdown syntax. You can learn that [here](http://www.remarq.io/articles/five-minutes-to-markdown-mastery/)  \n9. Add your data to this repository. Your data.json has to be valid JSON. you can validate it [here](http://jsonlint.com/)\n10. Your documentation and README.mds should be written in English\n11. your documentation and README.mds should allow the reader to reproduce your project (if it is source code) or at least (in case of the posters for the ISS project) fully understand what the gist is. This means you need to describe also the process of aggregating your data. All scraping steps and so on.  \n12. Don't forget the microsite.  \n13. Your deadline is the first of April. No joke.  \n\nThis repository contains examples for all the files you need to provide.  \n\n- __Example-README.md__ (contains some examples on Markdown and what sections a README.md could have)\n- __code__ The code folder should contain all your source code\n- __data.json__ is the layout for your infos that will be part of the website\n- __images__ The images folder contains examples for the images ignore the anim.gif and the canvas.png they are just for the Example-README.md  \n\n\n## Each of you should deliver   \n\n### for the project algorithm\n\n- [ ] GitHub repository with microsite  \n- [ ] README.md for that repo  \n- [ ] image Beauty Shot(s) (1920 \u00d7 1080 PNG-24)  \n- [ ] image for algorithm (500 \u00d7 500 PNG-24)\n- [ ] image thumbnail for algorithm (64 \u00d7 64 PNG-24)\n- [ ] source code (working with comments)  \n- [ ] License for your code  \n\n\n------\n\n### for the project ISS\n\n- [ ] GitHub repository with microsite  \n- [ ] README.md for that repo  \n- [ ] image Beauty Shot(s) (1920 \u00d7 1080 PNG-24)  \n- [ ] image for ISS (500 \u00d7 500 PNG-24)\n- [ ] image thumbnail for ISS (64 \u00d7 64 PNG-24)  \n- [ ] source code (working with comments)  \n- [ ] License for your code  \n\n------\n\n### for the website  \n\n[This will be the home for all the data ](https://interface.fh-potsdam.de/eingabe-ausgabe/2015-2016/)\n\n- [ ] GitHub repository with your data   \n- [ ] data.json filled and valid ([Validate JSON here](http://jsonlint.com/)) and added to [this repository](https://github.com/FH-Potsdam/steel-ant-io-data.json)  \n- [ ] all the 500 \u00d7 500 images and their thumbnails  \n\n\n-----\n\n\n# All of you together should deliver\n\n##for project connecting bits  \n\n- [ ] GitHub repository with microsite  \n- [ ] Video that shows how the project works  \n- [ ] Documentation of process and result and code  \n- [ ] image Beauty Shot(s) (1920 \u00d7 1080 PNG-24)  \n- [ ] image connecting bits (500 \u00d7 500 PNG-24)  \n- [ ] image thumbnail for connecting bits (64 \u00d7 64 PNG-24)  \n- [ ] source code (working with comments)  \n- [ ] License for your code  \n\n\n\n\n\n"}
{"url": "https://github.com/FH-Potsdam/github-setup-tools", "owner": "FH-Potsdam", "repository_name": "github-setup-tools", "date_all_variable_collection": "2023-09-11", "description": "some small tools for setting up github repositories.", "size": 196, "stargazers_count": 1, "watchers_count": 1, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 3550}, {"language": "JavaScript", "num_chars": 2965}], "readme": "#github setup tools\n\nSome tools for setting up github for organizations, managing teams, getting infos and so on.\n\n##prerequisites Mac OSX  \n\ninstall tools via [homebrew](http://brew.sh)  \n\n    brew install imagemagick\n    brew install ghi\n    brew install node\n    brew install jq\n\n##Content  \n\n####deprecated (nothing to see here move along)\n####init (bash - creates a set of folders from a list and adds README.md and a image)\n####issues (bash - create issues from a list needs \"ghi\" works in a repo)\n####organization (nodejs - orga reading)  \nneeds nodejs. Install dependencies using npm (node package manager) by running\n\n    # install dependencies\n    npm install\n    # now run via\n    node index.js\n    # watch the console output\n\n####team (bash - add users to a team)\n\n\n##Authentification  \nget an auth token like in [this guide](https://help.github.com/articles/creating-an-access-token-for-command-line-use)\n__Warning!__ this should stay a secret. It has read write acces to all your repos.\n\n\n##Environment Variables  \nFor easy auth code storage you can use [EnvPane](https://github.com/hschmidt/EnvPane). These variables can then be accessed in scripts and applications. \n\n__In NodeJs:__  \n\n    console.log(process.env.ENV_VARIABLE) // ENV_VARIABLE is the name of the variable \n\n__In Shell Scripts:__  \n\n    echo $ENV_VARIABLE  \n\n\n##Misc Infos  \n\nIf you want to create a repository without assigning all admins of the organization to it do it like this.  \n\n- Create the repo in your own account  \n- go to settings > Danger Zone\u2122 > Transfer\n- Transfer the ownership to the organization\n\n\n\n##License  \n\nCopyright (c)  2013 Fabian \"fabiantheblind\" Mor\u00f3n Zirfas  \nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software  without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to  permit persons to whom the Software is furnished to do so, subject to the following conditions:  \nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.  \nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A  PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF  CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  \n\nsee also http://www.opensource.org/licenses/mit-license.php\n\n\n"}
{"url": "https://github.com/FH-Potsdam/google-sheets-page-generator", "owner": "FH-Potsdam", "repository_name": "google-sheets-page-generator", "date_all_variable_collection": "2023-09-11", "description": "Generate static pages from google sheets. Specifically to present thematic inquiries, as lists and detail pages.", "size": 1157, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "sebastian-meier", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 279017}, {"language": "HTML", "num_chars": 160682}, {"language": "SCSS", "num_chars": 81408}, {"language": "Svelte", "num_chars": 2553}, {"language": "CSS", "num_chars": 2043}, {"language": "TypeScript", "num_chars": 481}], "readme": "# google-sheets-page-generator\nGenerate static pages from google sheets. Specifically to present thematic inquiries, as lists and detail pages.\n\nCurrently it is not possible to access images using the new \"Insert Image in cell\" Feature through the API (see `generator/index.js` and `generator/google.js`). The easiest workaround for now is to download the spreadsheet as an HTML-Site. After that use the `generator/html.js` script to extract the data and images."}
{"url": "https://github.com/FH-Potsdam/hello-processing-py-cv-world", "owner": "FH-Potsdam", "repository_name": "hello-processing-py-cv-world", "date_all_variable_collection": "2023-09-11", "description": "Some simple sketches for learning processing and openCV", "size": 9132, "stargazers_count": 2, "watchers_count": 2, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 15486}, {"language": "JavaScript", "num_chars": 1040}], "readme": "hello processing py cv world\n============================\n\nSome simple sketches for learning processing and openCV\n\n\n##background_subtraction\n![](images/background_subtraction.png)  \nHow to use background subtraction  \n\n------------\n\n##brightness_tracking\n![](images/brightness_tracking.png)  \nlook for the brightest point int the video  \n\n\n------------\n\n##color_tracking\n![](images/color_tracking.png)  \nlook for ta specific color in the video !Not working that well right now!  \n\n------------\n\n##contour_tracking\n![](images/contour_tracking.png)  \nSimple sketch that tracks some spots in a video  \n\n------------\n\n##empty_example\n![](images/empty_example.png)  \nSimple empty example  \n\n------------\n##filtering_and_display\n![](images/filtering_and_display.png)  \nSimple empty sketch  \n\n------------\n\n##find_lines\n![](images/find_lines.png)  \nSimple sketch that looks for lines in a video  \n\n------------\n\n##using_saturation_channel\n![](images/using_saturation_channel.png)  \nSimple sketch that uses the saturation channel  \n\n##License  \n\nCopyright (c) 2015 Fabian Moron Zirfas & FH-Potsdam  \n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software  without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to  permit persons to whom the Software is furnished to do so, subject to the following conditions:  \nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.  \nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A  PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF  CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  \n\nsee also http://www.opensource.org/licenses/mit-license.php\n\n"}
{"url": "https://github.com/FH-Potsdam/hello-processing-py-world", "owner": "FH-Potsdam", "repository_name": "hello-processing-py-world", "date_all_variable_collection": "2023-09-11", "description": "Some sketches created @FH-Potsdam for showing processing.py", "size": 636, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "fabiantheblind", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 10177}, {"language": "Processing", "num_chars": 676}], "readme": "# hello-processing-py-world\n\nSome sketches created @FH-Potsdam 2015.04.15 for showing some processing.py  \n\n##hsb_mode\n\nShows how to use the `colorMode(HSB)` and draw `rect()` in a `for` loop. Makes use of `size()`\nand `noStroke()`\n\n##lines_from_side_to_side  \n\nDraws `line()` in two `for` loops. Once from top to bottom. Once from left to right. Also makes use of `strokeWeight()`\n\n##load_svg  \n\nUses `list` (in Processing it would be an `Array`) to store file names. Selects `random()` items from that list and draws them in `def draw():`. Also uses `noStroke()`, `frameRate()`, `fill()`, `rect()`, `int()`, `random()`, `len()`, `loadShape()` and `shape()` \n\n##simple_function  \n\nShows how to use def `setup():`, `def draw():` and how to declare own functions. Makes use of`beginShape()`, `endShape()` `vertex()` and `ellipse()`\n\n##simple_loop_with_list  \n\nShows how to store values in a two dimensional `list` and how to access them. Makes use of `for` loops, `len()`, `list.append()`, `random()`, `int()` and `ellipse()`\n\n##draw_triangle\n\n![](images/draw_triangle.png)  \n\n##pvectors  \n\n![](images/pvectors.png)  \n\n\n\nCopyright (c) 2015 Fabian Moron Zirfas & FH-Potsdam\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:  \n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.  \n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  \n\n"}
{"url": "https://github.com/FH-Potsdam/hid-hack-utils", "owner": "FH-Potsdam", "repository_name": "hid-hack-utils", "date_all_variable_collection": "2023-09-11", "description": "simple processing sketches to help with Human Interaction Device hacking. ", "size": 2, "stargazers_count": 1, "watchers_count": 1, "language": "Processing", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Processing", "num_chars": 3473}], "readme": "# hid-hack-utils\nsimple processing sketches to help with Human Interaction Device hacking. \n"}
{"url": "https://github.com/FH-Potsdam/Homo-Effectus", "owner": "FH-Potsdam", "repository_name": "Homo-Effectus", "date_all_variable_collection": "2023-09-11", "description": "Homo Effectus", "size": 179, "stargazers_count": 1, "watchers_count": 1, "language": "Processing", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "Flave", "contributions": 6}, {"contributor": "fabiantheblind", "contributions": 2}, {"contributor": "casparkirsch", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Processing", "num_chars": 22169}], "readme": "# Homo Effectus\n\n[Video of the installation in action](https://vimeo.com/113909158)\n\n## E\n\nThe Goal of the Course titled DIY (Multi) Touch (less) Human Computer Interaction was to develop a Musical Interface which could be controled with gestures like a director of an orchestra directs various instruments and voices. In hopes that we would develop a more expressive interface than regular knobs, sliders and buttons we thought of different gestures and interactions. These ranged from simple right-left-movements to more complex gestures with multiple step movements. After that we tried out different technologies to track body movements. After a few experiments with different Markertechnologies we concluded that within the timelimit the most reliable and simple technology to develop a functional interface would be color detection.\nUsing simply colored gloves to track movements is of course way more rudimentary and limiting than for example Microsoft's Kinect. It is far more difficult to recognize complex gestures. But we agreed that for our purpose tracking x- and y-position as well as being able to calculate speed and distance between hands would suffice.\nOn the way from the analog gloves to manipulating digital music, the information has to pass three steps:\n\n1. On the technology side we use a webcam to capture the environment. The image we get from the cam is then being processed by a...well Processing Sketch. The Processing Sketch recognizes different colors as individual Blobs, assigns Ids to every one of them and tracks them to be able to conceive a movement over multiple frames. At the same time the sketch gets the x- and y-position as well as the speed of the individual blobs and sends corresponding OSC signals.\n\n2. The OSC Signals are then received and converted to MIDI Signals by an Application called Osculator.\n\n3. The MIDI signals can then be intercepted and used by any audiosoftware. We used Ableton Live to assign the different MIDI messages to different parameters of different effects. This closes the loop of manipulating audio effects using simple handgestures.\n\nIn addition to this we also used the received data from the first Processing sketch to drive a second Processing Sktech which draws patterns which react to the hand movements as well as the music produced by them.\n\nThe final product is of course just a prototype. Nevertheless while using it one gets a good impression of the possibilities of gesture based controls.\n\n## D\n\nUnser Ziel des Kurses mit dem Titel DIY (Multi) Touch (less) Human Computer Interaction war es ein Musik Interface zu entwickeln, welches \u2014 \u00e4hnlich wie ein Dirigent ein Orchester dirigiert \u2014 mit Gesten gesteuert werden kann. In der Hoffnung und mit dem Ziel ein expressiveres Interface als Drehkn\u00f6pfe zu entwickeln haben wir uns verschiedene Gesten und Interaktionsm\u00f6glichkeiten \u00fcberlegt. Diese reichten von simplen rechts-links-Armbewegungen bis zu komplexeren Gesten bei welchen mehrere Bewegungsabl\u00e4ufe involviert waren. Daraufhin haben wir uns mit verschiedenen Technologien zum tracking von K\u00f6rperteilen auseinandergesetzt. Nach einigen Experimenten mit verschiedenen Markertechnologien wie z.B. Fiduci Marker sind wir zum Schluss gekommen, dass das Tracking von Farben die einfachste und verl\u00e4sslichste M\u00f6glichkeit ist in kurzer Zeit ein funktionales Interface zu entwickeln. Als Eingabemedium haben wir uns darauf geeinigt farbige Handschuhe zu verwenden. Nat\u00fcrlich ist es mit einer derart rudiment\u00e4ren Technik schwierig komplexe Gesten zu erkennen wie dies z.B. mit Microsofts Kinect m\u00f6glich w\u00e4re. Die Parameter x- und y-Koordinate, Geschwindigkeit sowie Distanz der H\u00e4nde zueinander reichten uns aber f\u00fcr unseren Prototypen aus.\nBis die mit Handschuhen produzierten analogen Daten als Digitale Input Signale in einer Musiksoftware ankommen m\u00fcssen sie 3 Schritte durchlaufen:\n\nAls Eingabetechnologie verwenden wir eine Webcam, deren Bild von einem Processing Sketch ausgewertet wird. Der Processing Sketch erkennt verschiedene Farben als einzelne Blobs, vergibt diesen eine ID und trackt sie um einen einzelnen Blob \u00fcber mehrere Frames verfolgen zu k\u00f6nnen. Gleichzeitig wertet er die x- und y- position sowie die Geschwindigkeit der einzelnen Blobs aus und versendet OSC Signale welche mit den gefundenen Daten angereichert werden.\n2. Die OSC Signale werden von einer Applikation namens Osculator in MIDI Signale umgewandelt und weitergeleitet.\n\n3. MIDI Signale werden von vielen Audioprogrammen erkannt und k\u00f6nnen da weiterverwendet werden. Wir haben f\u00fcr die Weiterverarbeitung Ableton Live verwendet. Damit k\u00f6nnen wir die empfangenen MIDI Signale beliebigen Effekten zuweisen und so durch einfache Handbewegungen Musik steuern.\nAls Zusatz haben wir die empfangenen Daten ebenfalls verwendet um in einem weiteren Processing Sketch eine Animation mit simplen geometrischen Formen zu generieren.\nDas Endprodukt ist nat\u00fcrlich nur ein einfacher Prototyp und zeigt nur Ansatzweise auf was m\u00f6glich ist. Dennoch bekommt man bereits mit dieser simplen Implementierung ein gutes Gef\u00fchl f\u00fcr die gestenbasierten Steuerung.\n\n\nCopyright (c) 2014 Caspar Kirsch, Fabian Dinklage, Flavio Gortana  \nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:  \nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.  \nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  \n\nsee also [http://www.opensource.org/licenses/mit-license.php](http://www.opensource.org/licenses/mit-license.php)\n"}
{"url": "https://github.com/flxw/adventofcode", "owner": "flxw", "repository_name": "adventofcode", "date_all_variable_collection": "2023-09-11", "description": null, "size": 57, "stargazers_count": 0, "watchers_count": 0, "language": "Go", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "flxw", "contributions": 13}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Go", "num_chars": 13837}, {"language": "Python", "num_chars": 4572}, {"language": "Rust", "num_chars": 4001}]}
{"url": "https://github.com/flxw/apcpp16", "owner": "flxw", "repository_name": "apcpp16", "date_all_variable_collection": "2023-09-11", "description": "Repository for lecture materials of Advanced Programming in C++ in winter term 16/17 at HPI", "size": 4718, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 22}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 5739888}, {"language": "CMake", "num_chars": 763}, {"language": "C", "num_chars": 536}, {"language": "QMake", "num_chars": 240}, {"language": "Objective-C", "num_chars": 112}]}
{"url": "https://github.com/flxw/aroundhere", "owner": "flxw", "repository_name": "aroundhere", "date_all_variable_collection": "2023-09-11", "description": "Get to know Berlins monuments around you!", "size": 2664, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 105}, {"contributor": "PetrykowskiM", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 49297}, {"language": "CSS", "num_chars": 11490}, {"language": "Python", "num_chars": 5504}, {"language": "HTML", "num_chars": 1911}], "readme": "#  Installation\n\nRequired are:\n *  `npm`, the node.js package manager\n * `bower`, the frontend package manager (install via `npm install -g bower`)\n * mongodb\n\nFollow these steps to get the application up and running\n\n* Open a terminal\n* Clone the repo, as usual with `git clone github.com/flxw/aroundhere && cd aroundhere`\n* Install frontend and backend dependencies: `npm install && bower install`\n* Start the database (this command will block your shell): `mkdir db && mongod --dbpath db`\n* Inflate the database dump and import it: `tar xvJf dump.tar.xz && mongorestore dump`\n* Run the application via `node app.js`\n"}
{"url": "https://github.com/flxw/bachelor-thesis", "owner": "flxw", "repository_name": "bachelor-thesis", "date_all_variable_collection": "2023-09-11", "description": "My bachelor thesis about selecting job candidates based on their Github profile code contributions and matching them to job descriptions", "size": 972, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 28}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 94259}, {"language": "Shell", "num_chars": 160}]}
{"url": "https://github.com/flxw/badass-group", "owner": "flxw", "repository_name": "badass-group", "date_all_variable_collection": "2023-09-11", "description": null, "size": 146113, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 452}, {"contributor": "tengallonheadNS", "contributions": 246}, {"contributor": "bluehyunah", "contributions": 101}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 181879}], "readme": "### Assignment Report Group 36\n\n## Group members\n\n# Ece Caliskan, Matrikel-Nr. 592 264, E-Mail: ececaliskan@live.com\n# Felix Stefan Wolff, Matrikel-Nr. 765 508 (Universit\u00e4t Potsdam), E-Mail: felix.stefan.wolff@gmail.com\n# Hyunah Jung, Matrikel-Nr. 591 621, E-Mail: bluehyunah@gmail.com\n# Nicolai Sprenger, Matrikel-Nr. 578 540, E-Mail: sprengernicolai@gmail.com\n\n## Directory structure\n\nFor execution of all scripts, the working directory needs to be the project root!\n\nThe directory is organized according to the structure of our written report in addition to some auxiliary folders (helpers, individual_submissions, old)\n\n`base_modeling/` code for model construction with mlr \n\n`data/` for CSVs, results, raw as well as preprocessed, used in the report\n\n`feature_engineering/` code related to feature engineering\n\n`models/` for binary, saved models which can be loaded for inferring predictions\n\n`post_processing/` additional results exclusively used for pst-processing\n\n`stacking/` code for different stacking models we compared\n\n## Thank you for a great course!\n\n### END\n\n\n\n"}
{"url": "https://github.com/flxw/blogviz", "owner": "flxw", "repository_name": "blogviz", "date_all_variable_collection": "2023-09-11", "description": "BlogIntelligence Insights - Chrome extension for displaying supplementary information about indexed pages", "size": 1036, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 4, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 4, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 59}, {"contributor": "ThomasGoerttler", "contributions": 33}, {"contributor": "DomHey", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 494066}, {"language": "CSS", "num_chars": 4459}, {"language": "HTML", "num_chars": 3418}]}
{"url": "https://github.com/flxw/bs1", "owner": "flxw", "repository_name": "bs1", "date_all_variable_collection": "2023-09-11", "description": "Repository for the collaborative groupwork with adi64 (adrian.holfter.de) to solve the tasks for the lecture 'Operating Systems I'", "size": 4635, "stargazers_count": 1, "watchers_count": 1, "language": "C", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "adi64", "contributions": 38}, {"contributor": "WGierke", "contributions": 2}, {"contributor": "flxw", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C", "num_chars": 37094}, {"language": "HTML", "num_chars": 6728}, {"language": "Makefile", "num_chars": 779}, {"language": "Objective-C", "num_chars": 466}]}
{"url": "https://github.com/flxw/cluster-computing-up", "owner": "flxw", "repository_name": "cluster-computing-up", "date_all_variable_collection": "2023-09-11", "description": "Repository for exercises in SS2017 lecture on Cluster Computing at University of Potsdam", "size": 2989, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 29}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 226628}, {"language": "C", "num_chars": 58657}, {"language": "Makefile", "num_chars": 8400}, {"language": "Python", "num_chars": 7828}, {"language": "Shell", "num_chars": 6944}, {"language": "CMake", "num_chars": 1128}, {"language": "C++", "num_chars": 936}]}
{"url": "https://github.com/flxw/code-repository-mining", "owner": "flxw", "repository_name": "code-repository-mining", "date_all_variable_collection": "2023-09-11", "description": null, "size": 6101, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 109}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 15281}, {"language": "PLpgSQL", "num_chars": 385}], "readme": "# Introduction\nThis repository contains the code for the application presented at [flxw.de/code-repository-mining](http://flxw.de/code-repository-mining).\nIt is a Python 3 client-server application. Please follow the subsections below to setup the individual parts:\n\nThe directory contents are as follows:\n1. `client` contains the code that runs client-side\n2. `server` contains the code running server-side, providing an API\n3. `data`   contains the scripts needed for creating the necessary tables and views\n4. `docs`   contains several the project website, several artifacts and raw Jupyter notebooks\n\n\n## Client setup\n1. Change directories to the `client/` folder and install the dependencies:\n```\npip install -r requirements.txt\n```\n\nThen, simply scan your system for vulnerable packages via: `./checksystem.py`. Currently, only apt and pacman\npackage managers are supported, which translates to most Debian or Arch based Linux distributions.\nTo simulate the results that this application could potentially give, run `./checksystem.py --test`.\nIt will show results for openssl package affected by Heartbleed.\n\n## Server setup\nThis setup assumes the GHtorrent database dump at the HPI chair for software architecture.\nFurthermore a mongoDB instance needs to be running and you need to have access to it.\nThe data procurement and setup is time-consuming:\n\n1. Change directories to `data/`\n2. Copy the `config.py.smpl` to `config.py` and edit it so it works for your installation\n2. Copy `config.py` to `server/`as well\n3. Run `create-cve-search-view.sql`.  Wait for completion.\n4. Install `scrapy` via `pip install scrapy`\n5. Download [my TweetScraper fork](https://github.com/flxw/TweetScraper)\n6. Configure the TweetScraper via its `settings.py` to reflect your PostgreSQL settings and have the TweetScraper use it\n7. Run `./crawl-cve-tweets-from-github-subset` *from inside* the TweetScraper project directory. You can go ahead with the next step while the crawler is doing its thing.\n8. Download and setup [cve-search](https://github.com/cve-search/cve-search). Wait for completion here.\n9. Run `mine-cve-search-into-postgres.py`. Wait for completion.\n11. Run `create-reference-url-extraction-view.sql`, `create-tweet-extracted-views.sql`, `create-cwe-nist-reference-ranking.sql` and `create-twitter-user-ranking.sql`. In that order.\n\nThe API server setup is straightforward and can be summarized in three commands:\n```\ncd server\npip install -r requirements.txt\nhug -f api.py\n```\n"}
{"url": "https://github.com/flxw/codingmasters2013", "owner": "flxw", "repository_name": "codingmasters2013", "date_all_variable_collection": "2023-09-11", "description": null, "size": 888, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 3970}, {"language": "C++", "num_chars": 2455}]}
{"url": "https://github.com/flxw/committed-to-code", "owner": "flxw", "repository_name": "committed-to-code", "date_all_variable_collection": "2023-09-11", "description": "A commit generator to fill the GitHub activity timeline :D", "size": 102, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 16}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 8596}], "readme": "![](docs/effect.gif)\n\n# Committed to code\n\n> Activity on the timeline is an important indicator for recruiters\n\nI think this is funny and that it can be bypassed easily.\nThinking about a pet project anyway, I started this ``committed-to-code``,\nalso to get back into Java.\nUse this generator to generate a series of commits which will immediately fill your activity timeline\nand make you appear a lot more active.\n\n## Installation\nTo install, simply clone the repository,\nand have maven do the job of downloading dependencies\nand compiling the JAR file.\n```shell script\n$ git clone https://github.com/flxw/committed-to-code\n$ cd committed-to-code\n$ mvn package\n```\n\n### Setup\nAdapt `application.ini` to your needs.\nAn exemplary configuration might look like this\n```ini\n[GENERAL]\nREPODIRECTORY=testrepo\nSTARTDATE=2019-03-07\nENDDATE=2019-11-10\nBREAK_DAYS=120\n\n[USER]\nNAME=John Doe\nEMAIL=j.doe@doemail.com\n\n[FREQUENCY]\nLOWER=1\nUPPER=5\n```\n\n## Usage\nAfter compiling the JAR file and setting the configuration options,\nsimply execute the program like this:\n```shell script\n$ java -jar committed-to-code-1.0.jar -c <your-configuration-file>\n```"}
{"url": "https://github.com/flxw/dbs2", "owner": "flxw", "repository_name": "dbs2", "date_all_variable_collection": "2023-09-11", "description": "Solutions for the exercises from the database systems 2 lecture at HPI", "size": 2120, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "PetrykowskiM", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 33703}]}
{"url": "https://github.com/flxw/desktop-photos", "owner": "flxw", "repository_name": "desktop-photos", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1684, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 30, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 30, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 77}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 21321}, {"language": "TypeScript", "num_chars": 13323}, {"language": "HTML", "num_chars": 1310}, {"language": "JavaScript", "num_chars": 1018}, {"language": "CSS", "num_chars": 879}]}
{"url": "https://github.com/flxw/developium", "owner": "flxw", "repository_name": "developium", "date_all_variable_collection": "2023-09-11", "description": "A mobile-first, lightweight Ghost theme for presenting oneself as developer and blogger", "size": 428, "stargazers_count": 0, "watchers_count": 0, "language": "CSS", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 14}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "CSS", "num_chars": 4274}, {"language": "Handlebars", "num_chars": 2341}, {"language": "JavaScript", "num_chars": 1706}], "readme": "# developium\nA mobile-first, lightweight Ghost theme for presenting oneself as developer and blogger\n\n![](sc.png)\n\n1. Download the [latest release](https://github.com/flxw/developium/releases/latest)\n2. Unzip it into `ghost/content/themes`\n3. Open your blog administration panel and select the `developium` theme\n4. Tweak to suit your needs\n"}
{"url": "https://github.com/flxw/dictionary-compressor-rs", "owner": "flxw", "repository_name": "dictionary-compressor-rs", "date_all_variable_collection": "2023-09-11", "description": null, "size": 16, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "flxw", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 41680}, {"language": "Rust", "num_chars": 1302}]}
{"url": "https://github.com/flxw/domainconverter", "owner": "flxw", "repository_name": "domainconverter", "date_all_variable_collection": "2023-09-11", "description": null, "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 950}]}
{"url": "https://github.com/flxw/dotfiles", "owner": "flxw", "repository_name": "dotfiles", "date_all_variable_collection": "2023-09-11", "description": null, "size": 105, "stargazers_count": 0, "watchers_count": 0, "language": "Vim Script", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 24}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Vim Script", "num_chars": 1553}, {"language": "Shell", "num_chars": 632}], "readme": "# How to use\nThis is a buffet of configuration - choose whatever you like,\nthen symlink it to the appropriate location, e.g.\n\n```bash\n$ ln -s \"$PWD/dotfiles/.zshrc\" \"$HOME/.zshrc\"\n```\n\n# Colors\n* https://github.com/herrbischoff/iterm2-gruvbox\n"}
{"url": "https://github.com/flxw/flighttrack", "owner": "flxw", "repository_name": "flighttrack", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1408, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 8, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 8, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 88}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 34626}, {"language": "HTML", "num_chars": 15268}, {"language": "CSS", "num_chars": 3902}], "readme": "# angular-seed \u2014 the seed for AngularJS apps\n\nThis project is an application skeleton for a typical [AngularJS](http://angularjs.org/) web app.\nYou can use it to quickly bootstrap your angular webapp projects and dev environment for these\nprojects.\n\nThe seed contains a sample AngularJS application and is preconfigured to install the Angular\nframework and a bunch of development and testing tools for instant web development gratification.\n\nThe seed app doesn't do much, just shows how to wire two controllers and views together.\n\n\n## Getting Started\n\nTo get you started you can simply clone the angular-seed repository and install the dependencies:\n\n### Prerequisites\n\nYou need git to clone the angular-seed repository. You can get git from\n[http://git-scm.com/](http://git-scm.com/).\n\nWe also use a number of node.js tools to initialize and test angular-seed. You must have node.js and\nits package manager (npm) installed.  You can get them from [http://nodejs.org/](http://nodejs.org/).\n\n### Clone angular-seed\n\nClone the angular-seed repository using [git][git]:\n\n```\ngit clone https://github.com/angular/angular-seed.git\ncd angular-seed\n```\n\nIf you just want to start a new project without the angular-seed commit history then you can do:\n\n```bash\ngit clone --depth=1 https://github.com/angular/angular-seed.git <your-project-name>\n```\n\nThe `depth=1` tells git to only pull down one commit worth of historical data.\n\n### Install Dependencies\n\nWe have two kinds of dependencies in this project: tools and angular framework code.  The tools help\nus manage and test the application.\n\n* We get the tools we depend upon via `npm`, the [node package manager][npm].\n* We get the angular code via `bower`, a [client-side code package manager][bower].\n\nWe have preconfigured `npm` to automatically run `bower` so we can simply do:\n\n```\nnpm install\n```\n\nBehind the scenes this will also call `bower install`.  You should find that you have two new\nfolders in your project.\n\n* `node_modules` - contains the npm packages for the tools we need\n* `app/bower_components` - contains the angular framework files\n\n*Note that the `bower_components` folder would normally be installed in the root folder but\nangular-seed changes this location through the `.bowerrc` file.  Putting it in the app folder makes\nit easier to serve the files by a webserver.*\n\n### Run the Application\n\nWe have preconfigured the project with a simple development web server.  The simplest way to start\nthis server is:\n\n```\nnpm start\n```\n\nNow browse to the app at `http://localhost:8000/app/index.html`.\n\n\n\n## Directory Layout\n\n```\napp/                    --> all of the source files for the application\n  app.css               --> default stylesheet\n  components/           --> all app specific modules\n    version/              --> version related components\n      version.js                 --> version module declaration and basic \"version\" value service\n      version_test.js            --> \"version\" value service tests\n      version-directive.js       --> custom directive that returns the current app version\n      version-directive_test.js  --> version directive tests\n      interpolate-filter.js      --> custom interpolation filter\n      interpolate-filter_test.js --> interpolate filter tests\n  view1/                --> the view1 view template and logic\n    view1.html            --> the partial template\n    view1.js              --> the controller logic\n    view1_test.js         --> tests of the controller\n  view2/                --> the view2 view template and logic\n    view2.html            --> the partial template\n    view2.js              --> the controller logic\n    view2_test.js         --> tests of the controller\n  app.js                --> main application module\n  index.html            --> app layout file (the main html template file of the app)\n  index-async.html      --> just like index.html, but loads js files asynchronously\nkarma.conf.js         --> config file for running unit tests with Karma\ne2e-tests/            --> end-to-end tests\n  protractor-conf.js    --> Protractor config file\n  scenarios.js          --> end-to-end scenarios to be run by Protractor\n```\n\n## Testing\n\nThere are two kinds of tests in the angular-seed application: Unit tests and End to End tests.\n\n### Running Unit Tests\n\nThe angular-seed app comes preconfigured with unit tests. These are written in\n[Jasmine][jasmine], which we run with the [Karma Test Runner][karma]. We provide a Karma\nconfiguration file to run them.\n\n* the configuration is found at `karma.conf.js`\n* the unit tests are found next to the code they are testing and are named as `..._test.js`.\n\nThe easiest way to run the unit tests is to use the supplied npm script:\n\n```\nnpm test\n```\n\nThis script will start the Karma test runner to execute the unit tests. Moreover, Karma will sit and\nwatch the source and test files for changes and then re-run the tests whenever any of them change.\nThis is the recommended strategy; if your unit tests are being run every time you save a file then\nyou receive instant feedback on any changes that break the expected code functionality.\n\nYou can also ask Karma to do a single run of the tests and then exit.  This is useful if you want to\ncheck that a particular version of the code is operating as expected.  The project contains a\npredefined script to do this:\n\n```\nnpm run test-single-run\n```\n\n\n### End to end testing\n\nThe angular-seed app comes with end-to-end tests, again written in [Jasmine][jasmine]. These tests\nare run with the [Protractor][protractor] End-to-End test runner.  It uses native events and has\nspecial features for Angular applications.\n\n* the configuration is found at `e2e-tests/protractor-conf.js`\n* the end-to-end tests are found in `e2e-tests/scenarios.js`\n\nProtractor simulates interaction with our web app and verifies that the application responds\ncorrectly. Therefore, our web server needs to be serving up the application, so that Protractor\ncan interact with it.\n\n```\nnpm start\n```\n\nIn addition, since Protractor is built upon WebDriver we need to install this.  The angular-seed\nproject comes with a predefined script to do this:\n\n```\nnpm run update-webdriver\n```\n\nThis will download and install the latest version of the stand-alone WebDriver tool.\n\nOnce you have ensured that the development web server hosting our application is up and running\nand WebDriver is updated, you can run the end-to-end tests using the supplied npm script:\n\n```\nnpm run protractor\n```\n\nThis script will execute the end-to-end tests against the application being hosted on the\ndevelopment server.\n\n\n## Updating Angular\n\nPreviously we recommended that you merge in changes to angular-seed into your own fork of the project.\nNow that the angular framework library code and tools are acquired through package managers (npm and\nbower) you can use these tools instead to update the dependencies.\n\nYou can update the tool dependencies by running:\n\n```\nnpm update\n```\n\nThis will find the latest versions that match the version ranges specified in the `package.json` file.\n\nYou can update the Angular dependencies by running:\n\n```\nbower update\n```\n\nThis will find the latest versions that match the version ranges specified in the `bower.json` file.\n\n\n## Loading Angular Asynchronously\n\nThe angular-seed project supports loading the framework and application scripts asynchronously.  The\nspecial `index-async.html` is designed to support this style of loading.  For it to work you must\ninject a piece of Angular JavaScript into the HTML page.  The project has a predefined script to help\ndo this.\n\n```\nnpm run update-index-async\n```\n\nThis will copy the contents of the `angular-loader.js` library file into the `index-async.html` page.\nYou can run this every time you update the version of Angular that you are using.\n\n\n## Serving the Application Files\n\nWhile angular is client-side-only technology and it's possible to create angular webapps that\ndon't require a backend server at all, we recommend serving the project files using a local\nwebserver during development to avoid issues with security restrictions (sandbox) in browsers. The\nsandbox implementation varies between browsers, but quite often prevents things like cookies, xhr,\netc to function properly when an html page is opened via `file://` scheme instead of `http://`.\n\n\n### Running the App during Development\n\nThe angular-seed project comes preconfigured with a local development webserver.  It is a node.js\ntool called [http-server][http-server].  You can start this webserver with `npm start` but you may choose to\ninstall the tool globally:\n\n```\nsudo npm install -g http-server\n```\n\nThen you can start your own development web server to serve static files from a folder by\nrunning:\n\n```\nhttp-server -a localhost -p 8000\n```\n\nAlternatively, you can choose to configure your own webserver, such as apache or nginx. Just\nconfigure your server to serve the files under the `app/` directory.\n\n\n### Running the App in Production\n\nThis really depends on how complex your app is and the overall infrastructure of your system, but\nthe general rule is that all you need in production are all the files under the `app/` directory.\nEverything else should be omitted.\n\nAngular apps are really just a bunch of static html, css and js files that just need to be hosted\nsomewhere they can be accessed by browsers.\n\nIf your Angular app is talking to the backend server via xhr or other means, you need to figure\nout what is the best way to host the static files to comply with the same origin policy if\napplicable. Usually this is done by hosting the files by the backend server or through\nreverse-proxying the backend server(s) and webserver(s).\n\n\n## Continuous Integration\n\n### Travis CI\n\n[Travis CI][travis] is a continuous integration service, which can monitor GitHub for new commits\nto your repository and execute scripts such as building the app or running tests. The angular-seed\nproject contains a Travis configuration file, `.travis.yml`, which will cause Travis to run your\ntests when you push to GitHub.\n\nYou will need to enable the integration between Travis and GitHub. See the Travis website for more\ninstruction on how to do this.\n\n### CloudBees\n\nCloudBees have provided a CI/deployment setup:\n\n<a href=\"https://grandcentral.cloudbees.com/?CB_clickstart=https://raw.github.com/CloudBees-community/angular-js-clickstart/master/clickstart.json\">\n<img src=\"https://d3ko533tu1ozfq.cloudfront.net/clickstart/deployInstantly.png\"/></a>\n\nIf you run this, you will get a cloned version of this repo to start working on in a private git repo,\nalong with a CI service (in Jenkins) hosted that will run unit and end to end tests in both Firefox and Chrome.\n\n\n## Contact\n\nFor more information on AngularJS please check out http://angularjs.org/\n\n[git]: http://git-scm.com/\n[bower]: http://bower.io\n[npm]: https://www.npmjs.org/\n[node]: http://nodejs.org\n[protractor]: https://github.com/angular/protractor\n[jasmine]: http://jasmine.github.io\n[karma]: http://karma-runner.github.io\n[travis]: https://travis-ci.org/\n[http-server]: https://github.com/nodeapps/http-server\n"}
{"url": "https://github.com/flxw/folienizer", "owner": "flxw", "repository_name": "folienizer", "date_all_variable_collection": "2023-09-11", "description": "A PDF viewer that also allows you to comment, designed for paying attention during a lecture ;)", "size": 184, "stargazers_count": 1, "watchers_count": 1, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 9, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 9, "watchers": 1, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 64912}, {"language": "IDL", "num_chars": 864}, {"language": "C", "num_chars": 209}]}
{"url": "https://github.com/flxw/getsome", "owner": "flxw", "repository_name": "getsome", "date_all_variable_collection": "2023-09-11", "description": null, "size": 144, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 3218}], "readme": "# getsome!\ngetsome is a small, HTTP-Server that only supports GET-Requests.\nIt features the following:\n    * threading (one thread per request)\n    * 404/400 Error Codes\n    * 404.html - Support\n    * port-independant routing (pass the desired port as argument)\n"}
{"url": "https://github.com/flxw/hello-github-actions", "owner": "flxw", "repository_name": "hello-github-actions", "date_all_variable_collection": "2023-09-11", "description": null, "size": 6, "stargazers_count": 0, "watchers_count": 0, "language": "Dockerfile", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 6}, {"contributor": "hectorsector", "contributions": 1}, {"contributor": "githubteacher", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Dockerfile", "num_chars": 113}, {"language": "Shell", "num_chars": 65}], "readme": "## Welcome to \"Hello World\" with GitHub Actions\n\nThis course will walk you through writing your first action and using it with a workflow file. \n\n**Ready to get started? Navigate to the first issue.**"}
{"url": "https://github.com/flxw/hirebot", "owner": "flxw", "repository_name": "hirebot", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1248, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 83}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 36770}, {"language": "HTML", "num_chars": 22616}, {"language": "CSS", "num_chars": 397}], "readme": "# Integration into N2O\nTo make use of the already existent N2O application prototype, it is necessary to adapt the database schema of posts to contain candidates. Crawlers that gathered account-related data from job sites and forums would need to be created. The datasets from the different social networks would then need to be linked to give a complete picture to the HR manager.\nThe working principle of inboxing and forwarding posts can stay, it will also work with employees. Specific employees may be forwarded to HR people of other divisions. In short:\n\n - Adapt database schema from posts to candidates\n - Create social network crawlers\n - Link data from different social networks\n\n\n# Rerunning analysis\n```SQL\nDELETE FROM statistics;\nUPDATE repositories SET last_analyzed_commit = NULL;\n```\n\n```bash\nnode analyzer.js\n```\n"}
{"url": "https://github.com/flxw/icalgen", "owner": "flxw", "repository_name": "icalgen", "date_all_variable_collection": "2023-09-11", "description": "A small ical-file generation web service built for a seminar at HPI", "size": 108, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1282}]}
{"url": "https://github.com/flxw/master-thesis-code", "owner": "flxw", "repository_name": "master-thesis-code", "date_all_variable_collection": "2023-09-11", "description": "The code for my thesis about sequence prediction on business processes ", "size": 61864, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 193}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 722321}, {"language": "Python", "num_chars": 53123}, {"language": "Dockerfile", "num_chars": 919}, {"language": "Shell", "num_chars": 510}], "readme": "# master-thesis-code\n\nconda environment setup\n\npip install -r requirements.txt\n\njupyter labextension install @jupyter-widgets/jupyterlab-manager\n"}
{"url": "https://github.com/flxw/master-thesis-latex", "owner": "flxw", "repository_name": "master-thesis-latex", "date_all_variable_collection": "2023-09-11", "description": "My master thesis about sequence prediction on business processes", "size": 93461, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 153}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 265177}, {"language": "Shell", "num_chars": 415}]}
{"url": "https://github.com/flxw/nitro4ppm", "owner": "flxw", "repository_name": "nitro4ppm", "date_all_variable_collection": "2023-09-11", "description": "A simple framework for facilitating the training of sequence prediction models with different batch construction strategies", "size": 14, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 33838}, {"language": "Shell", "num_chars": 510}], "readme": "# Introduction\r\nThis framework can assist you in training a Keras model for sequence prediction.\r\nIt provides a training infrastructure that logs training information, checkpoints models, and offers early stopping.\r\nThe infrastructure ties together implementations of two abstract classes.\r\nThe `model_runner` framework will detect each implementation automatically and list it when calling `model_runner -h`.\r\n\r\n# Installation\r\nInstall the required packages via `pip install -r requirements.txt`or via any other package manager you use for Python.\r\n\r\n# Adding a custom network\r\nInherit from `AbstractBuilder` and place the file into `builders/`.\r\nThis class file should contains at least two method:\r\n\r\n```python\r\nprepare_datasets(path_to_original_data, target_variable)\r\n```\r\nThe method reads in sequential training and validation data from a source of your choosing.\r\nIt returns a four-tupel with X and Y values for both training and validation sets.\r\nAt this point, the return data is a simple array of samples, not divided into batches.\r\nThe exact contents of the return values are described in the abstract class' docstring of the method.\r\n\r\n```python\r\nconstruct_model(n_train_cols, n_target_cols, learn_windows=False)\r\n```\r\nA method which constructs the Keras model. Pretty straightforward.\r\n\r\nAdditionally, the variable `n_epochs` can be defined so that the training scripts knows a maximum number of epochs\r\n\r\n# Adding a custom batching strategy\r\nInherit from `AbstractBatcher` and place the file into `batchers/`.\r\nThis class file only needs to implement a single method:\r\n\r\n```python\r\nformat_datasets(model_formatted_data_fn, datapath, target_variable)\r\n```\r\nThe method takes a function pointer, path to the raw data, and the column name of the target variable.\r\nAll parameters and return values are documented in the docstring of the abstract class.\r\nThe point of the function is to format the input data into batches which can be fed into the network, i.e. that honor the requirement of samples containing the same number of timesteps.\r\n\r\n# Example\r\nThe frontend could be invoked with a command like the following\r\n```bash\r\nmodel_runner.py evermann grouped --gpu=5 ../logs/bpic2011\r\n```\r\n\r\nThis runs the `EvermannBuilder` implementation with the `GroupedBatcher` batching strategy.\r\nThe grouped batcher creates batches of samples with the same number of timesteps.\r\n"}
{"url": "https://github.com/flxw/nsc-tools", "owner": "flxw", "repository_name": "nsc-tools", "date_all_variable_collection": "2023-09-11", "description": "Tools that allow you to have a self-updating network-shared pacman cache", "size": 188, "stargazers_count": 0, "watchers_count": 0, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 3664}], "readme": "## Intro\nIf you use ArchLinux on several machines in your home network,\nyou'll often download the same packages several times for different machines\nwhen doing a system update.\n\nWouldn't it be nice to have a central shared cache that always gives\nyou the newest packages without downloading any unneeded stuff?\nIf you own a device that can serve files over the network and is always\nonline, this project might be interesting for you.\n\n## What capabilites do the nsc-tools provide?\nThe network device will serve packages through a read-only samba/NFS-share.\nIt will maintain package lists for each registered machine and will pull\nupdates if available.\n\nOn the client-side, three capabilities are provided:\n* removing packages\n* installing packages\n* updating the system\n\nIf installing a package, the client will connect to the server using SSH\nand initiate the package download on the server. If finished, the connection\nis terminated and the shared cache is mounted. Then, the package is installed and\nthe cache is unmounted. Thus, you have a local package database and can still run\nsystem updates if the network cache is down.\n\nIf removing a package, the client connects to the server and\nremoves the entry for the specific package from its package list.\nThat does not mean, that if you e.g. uninstall git, the other machines will not \nreceive updates for git anymore. Each machine has its own package list on the server\nto avoid that. Only if all systems don't use a specific package, it is not downloaded.\n\nIf updating a client, the share will simply be mounted and the updates will be installed.\nNote that all these operations depend on the sync database of the server to provide\nconsistency. If your local sync database is more up to date than the servers,\nan installation procedure would fail.\n"}
{"url": "https://github.com/flxw/numimon", "owner": "flxw", "repository_name": "numimon", "date_all_variable_collection": "2023-09-11", "description": "Monitor a programs memory consumption across NUMA nodes along its execution", "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 2485}]}
{"url": "https://github.com/flxw/physioplan", "owner": "flxw", "repository_name": "physioplan", "date_all_variable_collection": "2023-09-11", "description": null, "size": 140700, "stargazers_count": 0, "watchers_count": 0, "language": "TypeScript", "has_issues": false, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 46}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TypeScript", "num_chars": 23018}, {"language": "HTML", "num_chars": 2588}, {"language": "JavaScript", "num_chars": 1840}, {"language": "Stylus", "num_chars": 234}], "readme": "# PhysioplanAngular\n\nThis project was generated with [Angular CLI](https://github.com/angular/angular-cli) version 8.3.7.\n\n## Development server\n\nRun `ng serve` for a dev server. Navigate to `http://localhost:4200/`. The app will automatically reload if you change any of the source files.\n\n## Code scaffolding\n\nRun `ng generate component component-name` to generate a new component. You can also use `ng generate directive|pipe|service|class|guard|interface|enum|module`.\n\n## Build\n\nRun `ng build` to build the project. The build artifacts will be stored in the `dist/` directory. Use the `--prod` flag for a production build.\n\n## Running unit tests\n\nRun `ng test` to execute the unit tests via [Karma](https://karma-runner.github.io).\n\n## Running end-to-end tests\n\nRun `ng e2e` to execute the end-to-end tests via [Protractor](http://www.protractortest.org/).\n\n## Further help\n\nTo get more help on the Angular CLI use `ng help` or go check out the [Angular CLI README](https://github.com/angular/angular-cli/blob/master/README.md).\n"}
{"url": "https://github.com/flxw/playwithpgasus", "owner": "flxw", "repository_name": "playwithpgasus", "date_all_variable_collection": "2023-09-11", "description": null, "size": 4, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 5830}, {"language": "CMake", "num_chars": 566}]}
{"url": "https://github.com/flxw/pois-praktikum", "owner": "flxw", "repository_name": "pois-praktikum", "date_all_variable_collection": "2023-09-11", "description": null, "size": 112, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 441}], "readme": "# Preparing for deployment\n1.  Right-click the project name in the Eclipse package explorer and click *Create deployment artifacts*\n2.  Right-click your classes and export them as JARs to a directory of your choice\n\n# Deploying\n1.  Stop Apache Tomcat\n2.  Copy the JARS into **$TOMCAT-HOME/webapps/acticiti-explorer/WEB-INF/lib**\n3.  Start Apache Tomcat\n4.  Login to http://localhost:8080/activiti-explorer and click *Manage*\n5.  There, click *Deployments* and *Upload New*\n6.  In the file selection pop-up, choose the **.bar** file from your projects */deployment* subfolder\n"}
{"url": "https://github.com/flxw/PracticeOnPower", "owner": "flxw", "repository_name": "PracticeOnPower", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1904, "stargazers_count": 0, "watchers_count": 0, "language": "C", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "MrSerth", "contributions": 16}, {"contributor": "flxw", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C", "num_chars": 17988}, {"language": "Makefile", "num_chars": 2116}]}
{"url": "https://github.com/flxw/premiumprojekt", "owner": "flxw", "repository_name": "premiumprojekt", "date_all_variable_collection": "2023-09-11", "description": null, "size": 68474, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 3, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 3, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 12}, {"contributor": "rshkv", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 10635}, {"language": "JavaScript", "num_chars": 6229}, {"language": "Python", "num_chars": 2925}, {"language": "CSS", "num_chars": 99}]}
{"url": "https://github.com/flxw/ptuebungen", "owner": "flxw", "repository_name": "ptuebungen", "date_all_variable_collection": "2023-09-11", "description": null, "size": 740, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "mr-flannery", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 134300}, {"language": "C", "num_chars": 34801}, {"language": "Shell", "num_chars": 1861}, {"language": "JavaScript", "num_chars": 559}, {"language": "Perl", "num_chars": 488}, {"language": "C++", "num_chars": 149}]}
{"url": "https://github.com/flxw/qt-vs-node-mp3-streaming", "owner": "flxw", "repository_name": "qt-vs-node-mp3-streaming", "date_all_variable_collection": "2023-09-11", "description": "Node.js vs Qt/C++ playing a SoundCloud 128k MP3 stream", "size": 120, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 3755}, {"language": "JavaScript", "num_chars": 1028}, {"language": "IDL", "num_chars": 373}], "readme": "Pitching node.js versus a Qt/C++ implementation for decoding and playing a SoundCloud 128k MP3 stream.\nRead more [on my blog](flxw.de/2014/03/pitching-qmediaplayer-against-node.js.html).\n"}
{"url": "https://github.com/flxw/qtagsort", "owner": "flxw", "repository_name": "qtagsort", "date_all_variable_collection": "2023-09-11", "description": "Sort your music files via tags!", "size": 264, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 3, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 3, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 50088}, {"language": "Prolog", "num_chars": 1052}, {"language": "C", "num_chars": 182}]}
{"url": "https://github.com/flxw/rekor-monitor", "owner": "flxw", "repository_name": "rekor-monitor", "date_all_variable_collection": "2023-09-11", "description": "A Rekor crawler and monitor", "size": 7836, "stargazers_count": 1, "watchers_count": 1, "language": "Go", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 2, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 2, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 37}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["grafana", "rekor", "sigstore"], "languages": [{"language": "Go", "num_chars": 6382}, {"language": "HCL", "num_chars": 4598}, {"language": "Dockerfile", "num_chars": 225}], "readme": "# A Rekor monitor\nThis project hosts the code and deployment configuration for [rekor-monitor.flxw.de](https://rekor-monitor.flxw.de).\nIt is my attempt to mine some analytics data on how Rekor, Sigstore's transparency log, is used and who are the main users.\nFurthermore, I hope to evolve it into a monitoring system for Rekor, where users can be notified of suspicious signatures made in their name.\n\n## Local Deployment\n\nYou can run this project locally in a containerized fashion using the following commands:\n\n```bash\ngit clone github.com/flxw/rekor-monitor\ncd rekor-monitor/local\ndocker-compose up\n```\n\nThis will build the Rekor crawler image and container, and start it along with the PostgreSQL and Grafana containers.\n## Acknowledgements\n\n - [Sigstore](https://sigstore.dev)\n - [Rekor](https://github.com/sigstore/rekor)\n "}
{"url": "https://github.com/flxw/rekor-monitor-view-refresher", "owner": "flxw", "repository_name": "rekor-monitor-view-refresher", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": "Go", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Go", "num_chars": 355}]}
{"url": "https://github.com/flxw/REMAPSEM", "owner": "flxw", "repository_name": "REMAPSEM", "date_all_variable_collection": "2023-09-11", "description": null, "size": 49, "stargazers_count": 0, "watchers_count": 0, "language": "C", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 38}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C", "num_chars": 40290}, {"language": "Fortran", "num_chars": 14864}, {"language": "Shell", "num_chars": 1418}, {"language": "CMake", "num_chars": 925}, {"language": "Makefile", "num_chars": 903}]}
{"url": "https://github.com/flxw/rusty-json-completeness-checker", "owner": "flxw", "repository_name": "rusty-json-completeness-checker", "date_all_variable_collection": "2023-09-11", "description": null, "size": 4, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 2308}], "readme": "I retired this project after finding that serde already implements this feature:\nhttps://serde.rs/container-attrs.html#deny_unknown_fields.\n\nHappy coding!\n\n<del>\n# A JSON completeness checker for Rust\n\nThis project is a personal playground for coming up with a solution for the following problem:\n* A client is developed against an API, possibly a third-party one\n* The API changes - and more data is added\n* Without an update to the API, data gets discarded and the client will never know that the API has changed\n\nTypically the APIs speak JSON, and an object mapper is used, like `serde-json`.\nThis create already protects against the first case, of having a class that takes in more data than is provided by the API.\nHowever, there is no alerting when the case above happens.\n\nI aspire to turn this code into a plugin, if only for the sake of learning.\n</del>\n"}
{"url": "https://github.com/flxw/rusty-ls", "owner": "flxw", "repository_name": "rusty-ls", "date_all_variable_collection": "2023-09-11", "description": null, "size": 8, "stargazers_count": 1, "watchers_count": 1, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "flxw", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 4915}]}
{"url": "https://github.com/flxw/scnrcpt", "owner": "flxw", "repository_name": "scnrcpt", "date_all_variable_collection": "2023-09-11", "description": null, "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/flxw/scplay", "owner": "flxw", "repository_name": "scplay", "date_all_variable_collection": "2023-09-11", "description": "A SoundCloud player for your desktop!", "size": 812, "stargazers_count": 1, "watchers_count": 1, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 9, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 9, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 141545}, {"language": "C", "num_chars": 2008}, {"language": "IDL", "num_chars": 1161}], "readme": "![](https://github.com/flxw/scplay/blob/master/images/playing2.png)\n\n# Running it\nWindows Users will find builds attached to the releases above.\nThose with another OS will need to build it themselves\n\n``` bash\ngit clone http://github.com/flxw/scplay /tmp/scplay\ncd /tmp/folienizer\nqmake\nmake\n```\n\n# Usage\nI tried to make scplay as easy to use as possible. When firing it up for the first time, you are asked for your\npermalink profile ID, which you can extract from the permalink to you profile. My profile ID would be:\n\n*http:// soundcloud.com/<span style=\"color:#f00\">fe-lix-62</span>*\n\nFrom there on, simply double-click your songs inside the list to play them. The application\nwill hide itself once you click elsewhere on the screen. To bring it back up, click on the icon in the systray.\n\n![Initial scplay screen](https://github.com/flxw/scplay/blob/master/images/initial.png)\n\n## Version\nTo find out your version number, right-click the icon in your systray. Always be sure to make use of the latest one ;)\n\n![finding out your version-number](https://github.com/flxw/scplay/blob/master/images/finding-version-number.png)\n\n## Endorsement\nAt the moment of writing, I am not affiliated with or endorsed by SoundCloud.\nI just put up their logo so that you do not forget that SoundCloud does the heavy lifting here."}
{"url": "https://github.com/flxw/sigstore-local-setup", "owner": "flxw", "repository_name": "sigstore-local-setup", "date_all_variable_collection": "2023-09-11", "description": "Configuration files for [TBD]", "size": 2, "stargazers_count": 1, "watchers_count": 1, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/flxw/sublime-packages", "owner": "flxw", "repository_name": "sublime-packages", "date_all_variable_collection": "2023-09-11", "description": null, "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/flxw/tagwalker", "owner": "flxw", "repository_name": "tagwalker", "date_all_variable_collection": "2023-09-11", "description": "Sort or rename music files using information contained in their tags. Also check for specific tag contents.", "size": 148, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 20930}], "readme": "Disabandoned. See qtagsort for a project that continues the tagwalker idea.\n"}
{"url": "https://github.com/flxw/test-pr-action-repo", "owner": "flxw", "repository_name": "test-pr-action-repo", "date_all_variable_collection": "2023-09-11", "description": null, "size": 2, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flxw", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/flxw/tgrep", "owner": "flxw", "repository_name": "tgrep", "date_all_variable_collection": "2023-09-11", "description": "grep your music files' tags", "size": 144, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 10410}, {"language": "C", "num_chars": 507}], "readme": "If you want to find files inside your huge collection of files\nreasonably fast, **tgrep** may be worth the try.\n\nFor example, after trying out to sort software by tags, lots of albums\nthat were mixed up out of several songs, I wanted these songs to be in a single\ndirectory again.\n\nBy using tgrep, that was done in a matter of seconds:\n\n    $ mkdir Hypermix\n    $ tgrep -Ro -r 'Hypermix' . | xargs -d '\\n' -I '{}' mv '{}' Hypermix/\n"}
{"url": "https://github.com/flying-bear/2018-course-poster", "owner": "flying-bear", "repository_name": "2018-course-poster", "date_all_variable_collection": "2023-09-11", "description": "Poster for my 2018 course paper", "size": 4536, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flying-bear", "contributions": 18}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 2209328}, {"language": "TeX", "num_chars": 67049}]}
{"url": "https://github.com/flying-bear/2019_hse_data_analysis", "owner": "flying-bear", "repository_name": "2019_hse_data_analysis", "date_all_variable_collection": "2023-09-11", "description": "HSE data analysys for linguists", "size": 160, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flying-bear", "contributions": 15}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 1093}], "readme": "# 2019_hse_data_analysis\nHSE data analysys for linguists\n\n[link to the course lectures](https://agricolamz.github.io/2019_data_analysis_for_linguists/)\n\n[link to the course repository](https://github.com/agricolamz/2019_data_analysis_for_linguists)\n"}
{"url": "https://github.com/flying-bear/Academic-Writing", "owner": "flying-bear", "repository_name": "Academic-Writing", "date_all_variable_collection": "2023-09-11", "description": "My attempts to make my laptop do all the boring chores", "size": 254, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flying-bear", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 4742}]}
{"url": "https://github.com/flying-bear/ANLP-project", "owner": "flying-bear", "repository_name": "ANLP-project", "date_all_variable_collection": "2023-09-11", "description": null, "size": 477, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "flying-bear", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 738949}], "readme": "# ANLP-project\nby Galina Ryazanskaya, 811155\n\nThis is the final project ANLP. All the code for the project is included in the Jupiter Notebook. \nThe initial plan for the project included using [deepPavlovEval](https://github.com/deepmipt/deepPavlovEval#datasets-and-tasks), but it turned out to be out of maintenence. Additionally, I intended to do this project with a partner, who dropped out, and I fell severely ill. Thus, I decided to only implement the Semantic textual similarity task as the evaluation mode. The vast majority of the project was finguring out the configuration of packaging versions that would work together, but even this turned out to be very challenging, not working stably.\n"}
{"url": "https://github.com/flying-bear/ANLPotsdam", "owner": "flying-bear", "repository_name": "ANLPotsdam", "date_all_variable_collection": "2023-09-11", "description": null, "size": 5968, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flying-bear", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 1590019}]}
{"url": "https://github.com/flying-bear/AutoT", "owner": "flying-bear", "repository_name": "AutoT", "date_all_variable_collection": "2023-09-11", "description": "HSE course", "size": 51570, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flying-bear", "contributions": 19}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 1258951}], "readme": "# AutoT\n[HSE course](https://github.com/sjut/HSE-Compling)\n"}
{"url": "https://github.com/flying-bear/databases", "owner": "flying-bear", "repository_name": "databases", "date_all_variable_collection": "2023-09-11", "description": "HSE Data Bases Course", "size": 96296, "stargazers_count": 0, "watchers_count": 0, "language": "TSQL", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flying-bear", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TSQL", "num_chars": 18686263}, {"language": "Jupyter Notebook", "num_chars": 2412583}], "readme": "# databases\nHSE Data Bases Course\n"}
{"url": "https://github.com/flying-bear/FLA", "owner": "flying-bear", "repository_name": "FLA", "date_all_variable_collection": "2023-09-11", "description": "code for parsing CHILDES corpus", "size": 15167, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flying-bear", "contributions": 29}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 41760}, {"language": "Python", "num_chars": 12223}], "readme": "# FLA\ncode for parsing [CHILDES](https://childes.talkbank.org/access/) corpus\n"}
{"url": "https://github.com/flying-bear/HSE_programming", "owner": "flying-bear", "repository_name": "HSE_programming", "date_all_variable_collection": "2023-09-11", "description": "homeworks and classworks", "size": 68699, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "flying-bear", "contributions": 63}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 211181}, {"language": "Python", "num_chars": 71253}, {"language": "HTML", "num_chars": 22179}]}
{"url": "https://github.com/flying-bear/infosearch", "owner": "flying-bear", "repository_name": "infosearch", "date_all_variable_collection": "2023-09-11", "description": "HSE course", "size": 31042, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flying-bear", "contributions": 62}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 232891}, {"language": "Python", "num_chars": 38390}, {"language": "HTML", "num_chars": 4745}], "readme": "# infosearch HSE course "}
{"url": "https://github.com/flying-bear/kompluxternaya", "owner": "flying-bear", "repository_name": "kompluxternaya", "date_all_variable_collection": "2023-09-11", "description": null, "size": 4137, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flying-bear", "contributions": 39}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 3407836}]}
{"url": "https://github.com/flying-bear/modeling_schizo", "owner": "flying-bear", "repository_name": "modeling_schizo", "date_all_variable_collection": "2023-09-11", "description": "Trying to apply methods of automatic discourse analysis to my data", "size": 135622, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flying-bear", "contributions": 66}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 8660880}, {"language": "R", "num_chars": 22464}, {"language": "Python", "num_chars": 1420}, {"language": "Batchfile", "num_chars": 101}], "readme": "# modeling_schizo\r\nTrying to apply methods of automatic discourse analysis to my data\r\n"}
{"url": "https://github.com/flying-bear/practice", "owner": "flying-bear", "repository_name": "practice", "date_all_variable_collection": "2023-09-11", "description": null, "size": 4322, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flying-bear", "contributions": 14}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 22535}], "readme": "# practice\n\nThis repo is dedicated to my summer practice on automatic evaluation of morphological splitting and tagging for [lowresource language evaluation competition](https://lowresource-lang-eval.github.io/index.html)"}
{"url": "https://github.com/flying-bear/Proofreading", "owner": "flying-bear", "repository_name": "Proofreading", "date_all_variable_collection": "2023-09-11", "description": null, "size": 204, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "flying-bear", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 73614}], "readme": "# Proofreading\n"}
{"url": "https://github.com/flying-bear/R_2018", "owner": "flying-bear", "repository_name": "R_2018", "date_all_variable_collection": "2023-09-11", "description": "The R course materials", "size": 26935, "stargazers_count": 1, "watchers_count": 1, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "flying-bear", "contributions": 21}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 57771}], "readme": "# R_2018\nThe R course materials\n\nwhere to get dfs: https://github.com/agricolamz/r_on_line_course_data\n\nour course site: https://agricolamz.github.io/2018_data_analysis_for_linguists/index.html\n\nour course repo: https://github.com/agricolamz/2018_data_analysis_for_linguists\n"}
{"url": "https://github.com/flying-bear/Style-Transfer", "owner": "flying-bear", "repository_name": "Style-Transfer", "date_all_variable_collection": "2023-09-11", "description": "Final Project for Machine Learning II Course at the University of Potsdam", "size": 103773, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "flying-bear", "contributions": 16}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 9442432}], "readme": "# Style-Transfer\nFinal Project for Machine Learning II Course at the University of Potsdam\n\nThe project description can be found [here](https://github.com/flying-bear/Style-Transfer/blob/main/FinalProject.ipynb).\n\nThe project components include:\n* [AutoEncoder (code)](https://github.com/flying-bear/Style-Transfer/blob/main/AE.ipynb)\n* [AdaIN (code)](https://github.com/flying-bear/Style-Transfer/blob/main/AdaIN.ipynb) - [(Huang & Belongie, 2017)](https://arxiv.org/pdf/1703.06868.pdf) Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization \n* [ArtGAN (code)](https://github.com/flying-bear/Style-Transfer/blob/main/ArtGAN_best.ipynb) - [(Sanakoyeu et al., 2018)](https://arxiv.org/pdf/1807.10201.pdf) A Style-Aware Content Loss for Real-time HD Style Transfer \n"}
{"url": "https://github.com/flying-bear/thesis", "owner": "flying-bear", "repository_name": "thesis", "date_all_variable_collection": "2023-09-11", "description": "Automated Assessment of Discourse Coherence in Schizophrenia and Schizoaffective Disorder", "size": 64116, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flying-bear", "contributions": 14}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 3769256}, {"language": "R", "num_chars": 6807}, {"language": "Batchfile", "num_chars": 99}], "readme": "# Thesis: Automated Assessment of Discourse Coherence in Schizophrenia and Schizoaffective Disorder\nThis repository contains code and data for thesis paper.\n\n### Abstract:\nDisorganized, or incoherent, speech is one of the key criteria for diagnosing schizophrenia . However, there is still a lack of an objective method of measuring speech coherence. Automated discourse analysis is a possible solution to this problem. I analyzed discourse coherence in a set of spoken narratives by people with schizophrenia or schizoaffective disorder (n = 21) and by neurotypical speakers of Russian (n = 20). All narratives were [automatically rated for local and global coherence, using vector semantics methods](https://github.com/flying-bear/thesis/tree/master/coherence). The discourse coherence was compared to psychiatric judgment as well as to [the automatically measured performance on a verbal fluency task](https://github.com/flying-bear/thesis/tree/master/verbal%20fluency). People with higher psychosis symptoms showed lower coherence scores. Lower discourse coherence was also found to be associated with worse performance on verbal fluency task.\n"}
{"url": "https://github.com/flying-bear/verbal_fluency", "owner": "flying-bear", "repository_name": "verbal_fluency", "date_all_variable_collection": "2023-09-11", "description": "comparing performance of different word embeddings for researching verbal fluency task in russian", "size": 11674, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "flying-bear", "contributions": 17}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 1832678}, {"language": "TeX", "num_chars": 25786}, {"language": "Python", "num_chars": 12483}, {"language": "R", "num_chars": 5539}, {"language": "Makefile", "num_chars": 532}]}
{"url": "https://github.com/FMalerba/LIBS-Spectra-Classification", "owner": "FMalerba", "repository_name": "LIBS-Spectra-Classification", "date_all_variable_collection": "2023-09-11", "description": null, "size": 36158, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "FMalerba", "contributions": 24}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 762229}, {"language": "Python", "num_chars": 82544}], "readme": "# LIBS-Spectra-Classification\n\nThis is the code for part of a project I worked on which was concerned with classifying rocks based on 1D-spectra. The dataset (not included in the repo) is composed of _Measurement Points_ (MP) made up of an 8x8 grid of _shots_ where each shot is one such 1D-spectrum. Each shot appears as in the figure below and two experiments were conducted.\n![Spectrum](1D_spectra.png)\nThe first one generated more data using an online dataset provided by the National Institute of Standards and Technology (NIST) and used an autoencoder in an attempt to denoise the real data. In this case each single shot was taken as a single stand-alone sample. The second experiment used the entire MP as input to the model and applied pooling to improve performance.\n"}
{"url": "https://github.com/FMalerba/skbuild_test", "owner": "FMalerba", "repository_name": "skbuild_test", "date_all_variable_collection": "2023-09-11", "description": null, "size": 4, "stargazers_count": 0, "watchers_count": 0, "language": "CMake", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "FMalerba", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "CMake", "num_chars": 343}, {"language": "Python", "num_chars": 264}]}
{"url": "https://github.com/FMalerba/tunable-agents-MORL", "owner": "FMalerba", "repository_name": "tunable-agents-MORL", "date_all_variable_collection": "2023-09-11", "description": null, "size": 363, "stargazers_count": 3, "watchers_count": 3, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 3, "default_branch": "main", "contributors": [{"contributor": "FMalerba", "contributions": 335}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 112534}, {"language": "Jupyter Notebook", "num_chars": 21824}], "readme": "# Introduction\nThis repository contains the code necessary to train, evaluate and display results for tunable agents in a Multi-Objective Deep Reinforcement Learning scenario. The environment implemented is the Multi-Objective Gathering environment described in [this](https://ala2019.vub.ac.be/papers/ALA2019_paper_12.pdf) paper. The original code repository was [forked](https://github.com/FMalerba/gym-mo) and slightly modified to improve code readability, adapt the classes to interface with this repository's code and change some undesiderable behaviour.\n\nThe key difference between the `GatheringWrapper` environment implemented in this repo and the one implemented in the original paper is that here we are interested in agents trained to have non-linear utility functions. \n\n# Setup\nTo start, clone the repository with its submodule using the command\n```\ngit clone --recurse-submodules https://github.com/FMalerba/tunable-agents-MORL\n```\n\nInstall the requirements listed in the `requirements.txt` file and then run the commmand \n```\npip install .\n```\n\nFrom both `tunable-agents-MORL/` and  `tunable-agents-MORL/tunable_agents/environments/gathering_env/gym-mo/` \n\nThis will install the package containing all the environments and required code to run `train_agent.py`, the evaluation scripts and the code in the jupyter notebooks.\n\n# Training an agent\n\nThis repository makes extensive use of [Gin Config](https://github.com/google/gin-config) in order to set all the parameters that are needed for the execution of code. Gin Config works by passing configuration files that set all the parameters to be used by functions and classes decorated with `@gin.configurable`. The files are passed to the scripts using the `--gin_files` flag and they are stored under the `configs` folder. To pass multiple files one can simply invoke the `--gin_files` flag multiple times feeding different paths for every configuration file. More information on Gin Config can be found at the project's repository.\n\n\nIn general, `train_agent.py` will expect a `--root_dir` to tell it where to store the trained model and the results for the rewards. Three `--gin_files` flags will also be needed; one to specify the training process, one to sepecify the model to be used and one to specify the environment and utility functions to be used. Additionally the `--gin_bindings` flag can be passed to set a certain parameter (or change it from the value set in the configuration files); this is usually used to assign unique names to different runs of a same experiment. A typical training command will thus look something like this:\n```\npython tunable-agents-MORL/train_agent.py \\\n--root_dir='experiments_results' \\\n--gin_files=\"tunable-agents-MORL/configs/replication.gin\" \\\n--gin_files=\"tunable-agents-MORL/configs/qnets/64_64_model.gin\" \\\n--gin_files=\"tunable-agents-MORL/configs/envs/replication_env.gin\" \\\n--gin_bindings=\"train_eval.training_id='replication-1'\"\n```\n\n\n\n\n"}
{"url": "https://github.com/fosler/PLCC", "owner": "fosler", "repository_name": "PLCC", "date_all_variable_collection": "2023-09-11", "description": null, "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "fosler", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# PLCC from plcc.pithon.net.\n"}
{"url": "https://github.com/fpottbaecker/cp-template", "owner": "fpottbaecker", "repository_name": "cp-template", "date_all_variable_collection": "2023-09-11", "description": "Competitive Programming CMake template", "size": 35, "stargazers_count": 3, "watchers_count": 3, "language": "CMake", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "fpottbaecker", "contributions": 28}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "CMake", "num_chars": 6426}, {"language": "Shell", "num_chars": 1582}, {"language": "C++", "num_chars": 630}], "readme": "# Competitive Programming Template\n\nThis is a mostly platform independent template, most scripts are written for CMake, which is required as build system.\n\n## Usage\n\n1. Change project name in root `CMakeLists.txt`\n2. Run CMake, e.g. via `cmake -B cmake-build-debug .` (automatically done by CLion)\n3. Run `contests/add_contest NAME`\n4. Then, either\n    * Download `samples-TASK.zip` files to `contests/NAME` and run `contest/NAME/load_tasks`, or\n    * Run `contest/NAME/add_task TASK`\n5. Write code (this is the important part)\n6. Run `ctest` in the tasks cmake binary directory (`cmake-build-debug/contests/NAME/TASK` if configured according to step 2) to test it\n\n## Features\n\n### Contest and task management\n\n* `contests/add_contest NAME` to create a new contest `NAME`.\n  > This invokes `scripts/add_contest.cmake` to create a contest folder, using `templates/contest.cmake` and `templates/contest/*`.\n* `contests/NAME/add_task TASK` to create a new task `TASK` in contest `NAME`.\n  > This invokes `scripts/add_task.cmake` to create a task folder, using `templates/task.cmake`, `templates/template.cpp` and `templates/task/*`.\n* `contests/NAME/load_tasks` creates a task for each `samples-TASK.zip` in contest `NAME` and adds the samples contained in the zip file.\n  > This invokes `scripts/load_tasks.cmake`, which uses `scripts/add_task.cmake` to create task folders.\n* `contests/NAME/TASK/add_sample NAME` creates a sample for the given task (both `NAME.in` and `NAME.out`).\n  > This is just a bash script, but rather simple, so it should be easily portable.\n\n### Automatic testing of all samples\n\nRun `ctest` in the cmake build directory corresponding to a task (in CLion: `cmake-build-TYPE/contests/NAME/TASK`) to run all samples. Add `--output-on-failure` for more detail (e.g. solution diff). Add `-j 8` and/or `--progress` if you feel like it.\n\nEach time `cmake` is run (the project is reloaded), `ctest` tests are generated.\nEach task receives a build test (as testing is performed via a script, the test runner does not have to be built).\nFor each `SAMPLE` of the task, a test is created which runs the task executable with `SAMPLE.in` as input and compares the output with `SAMPLE.out`.\nThe test fails if:\n\n* the execution does not finish within 5 seconds (configurable in `config.cmake`)\n* the executable exits with a non-zero exit code (usually a run error, error output is printed to console if using `--output-on-failure`)\n* the output does not match the desired output (wrong answer, diff output is printed to console if using `--output-on-failure`)\n\nProgram output is saved to `SAMPLE.result`, diff output (if any) is saved to `SAMPLE.result.diff`, error output (if any) is saved to `SAMPLE.result.err`.\nThe sample tests are skipped if the build fails.\n\n> There are two test runner scripts, `perform_test.sh` for UNIX and `perform_test.cmake` for other platforms. `perform_test.sh` terminates itself with `SIGSEGV` to make `ctest` output `Exception` instead of `Failed` to allow for a quick distinction between run errors and wrong answers. `perform_test.cmake` does not have this capability, so both run errors and wrong answers are reported as `Failed`.\n>\n> `perform_test.cmake` uses `diff` to compare outputs, this might need to be changed based on the setup.\n>\n> `perform_test.sh` uses `diff`, `head` and `wc` (although the latter two are not strictly required).\n\n## Installing and Updating\n\nThe simplest way to install this is to clone this repository.\nThen you can add this repository as upstream remote (`git remote add upstream REPO_URL`) and change the `origin` to your repository.\n\nIf `upstream` is set up, you can `git pull upstream master` to update to the latest version.\nThe template is structured such that, if at all possible, new features also apply to existing tasks.\n\nIf you already have an existing repository, you can add this repository to its history:\n1. (optional) rename/move files you know will conflict\n2. `git remote add upstream REPO_URL`.\n3. `git pull --allow-unrelated-histories upstream master`.\n   This is most certain to result in conflicts, especially in `CMakeLists.txt`.\n   Mostly you can just pick the remote files in case of conflict, unless you know that you do not.\n   If you feel daring, you can specify `-s recursive -X theirs` to automatically pick remote files during merge.\n4. Incorporate your existing files by creating the appropriate contests and tasks and copying the respective source files.\n\n\n"}
{"url": "https://github.com/fpottbaecker/foundryvtt-how-to-be-a-hero", "owner": "fpottbaecker", "repository_name": "foundryvtt-how-to-be-a-hero", "date_all_variable_collection": "2023-09-11", "description": "Foundry VTT implementation for the How to be a Hero system (https://howtobeahero.de)", "size": 2, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "fpottbaecker", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["foundryvtt"], "languages": [], "readme": "# foundryvtt-how-to-be-a-hero"}
{"url": "https://github.com/fpottbaecker/homebrew-misc", "owner": "fpottbaecker", "repository_name": "homebrew-misc", "date_all_variable_collection": "2023-09-11", "description": "Some miscellaneous stuff that is not good enough for homebrew-core", "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Pottiman Misc\n\n## How do I install these formulae?\n`brew install pottiman/misc/<formula>`\n\nOr `brew tap pottiman/misc` and then `brew install <formula>`.\n\nOr install via URL (which will not receive updates):\n\n```\nbrew install https://raw.githubusercontent.com/pottiman/homebrew-misc/master/Formula/<formula>.rb\n```\n\n## Documentation\n`brew help`, `man brew` or check [Homebrew's documentation](https://docs.brew.sh).\n"}
{"url": "https://github.com/fpottbaecker/st-data-gen", "owner": "fpottbaecker", "repository_name": "st-data-gen", "date_all_variable_collection": "2023-09-11", "description": "Data generation utilities for spatial trascriptomics (especially scanpy).", "size": 1411, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "fpottbaecker", "contributions": 44}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["spatial-transcriptomics", "transcriptomics"], "languages": [{"language": "Jupyter Notebook", "num_chars": 1277506}, {"language": "Python", "num_chars": 289963}], "readme": "\n# Spatial Transcriptomics Deconvolution Data Matching\n\nThis repository contains the data generation, deconvolution, and data matching tools for spatial transcriptomics described in my Master's thesis.\n\n\nHere is a short example of how to use these tools.\n```python\nfrom scstmatch.data import SingleCellDataset, SpatialTranscriptomicsDataset\nfrom scstmatch.generation import SC2STGenerator\nfrom scstmatch.deconvolution import IntegralDeconvolver, GreedySelector\nfrom scstmatch.deconvolution.evaluation import evaluate_jsd\nfrom scstmatch.matching import SpotNMatch\n\n# Load a SC dataset and set the known cell type column\nsc = SingleCellDataset.read(\"single-cell-data.h5ad\")\nsc.cell_type_column = \"CELLTYPE\"\n\n# Load a real ST dataset and generate a synthetic one\nreal_st = SpatialTranscriptomicsDataset.read(\"spatial-data.h5ad\")\nsynthetic_sc = SC2STGenerator(sc).generate()\n\n# Deconvolve using the greedy selector and evaluate the JSD\ntype_mixtures = IntegralDeconvolver(sc, GreedySelector()).deconvolve(synthetic_sc)\nspot_jsd = evaluate_jsd(synthetic_sc, type_mixtures)\n\n# Get per spot matching scores\nscores = SpotNMatch(sc).match(real_st)\n```\n\n\n## Setup\n\nTo install the dependencies, setup a virtual environment and install the `requirements.txt`:\n```bash\npython -m venv .venv\nsource .venv/bin/active\npip install -r requirements.txt\n```\n\nDepending on your setup, you might need to add the project directory to your `PYTHONPATH`.\n\nTo download the source dataset ([HCA](https://www.heartcellatlas.org)) and generate the variants, use `data/formula.py`:\n```bash\ncd data\n# This might take a while.\npython formula.py\ncd ..\n```\n\n## Project Structure\n\n### SCSTMatch Library\n\nThe primary libraries for single-cell and spatial transcriptomics data handling are located in `scstmatch`.\nThese are structured into four main components:\n* `data` handles dataset management and utility functions\n* `generation` handles fully and partially synthetic dataset generation functions\n* `deconvolution` implements the integral deconvolution approach described in the thesis\n* `matching` implements the SpotNMatch Algorithm\n\n\n### Data\n\nThe `data` folder contains the definitions for the reference datasets and a script to generate them.\nThis is used by different scripts for the evaluation of this thesis.\n\n### Thesis Content\n\nThe `thesis` folder contains notebooks and scripts to generate figures and tables for the thesis.\nThis includes [AntiSplodge](https://github.com/HealthML/AntiSplodge) training and score/deconvolution correlation.\n\n### Scripts\n\nThe `scripts` folder contains utility scripts and older evaluation methods.\nThis also includes CLI frontends of the data generators: `cell_types.py`, `single_cell.py`, `spatial_transcriptomics.py`, `st_from_sc.py`.\n"}
{"url": "https://github.com/frcroth/advent-of-code-2020", "owner": "frcroth", "repository_name": "advent-of-code-2020", "date_all_variable_collection": "2023-09-11", "description": "Personal Advent of code 2020 solutions.", "size": 125, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "frcroth", "contributions": 34}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["advent-of-code", "advent-of-code-2020"], "languages": [{"language": "Python", "num_chars": 59268}], "readme": "# Advent of Code 2020\n\nHere I collect my solutions for [advent of code 2020](https://adventofcode.com/2020/).\n\nAll challenges have been solved, but performance is not always what I'd like.\n"}
{"url": "https://github.com/frcroth/advent-of-code-2021", "owner": "frcroth", "repository_name": "advent-of-code-2021", "date_all_variable_collection": "2023-09-11", "description": "My Advent of code 2021 solutions. \ud83d\udc20", "size": 118, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "frcroth", "contributions": 29}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["advent-of-code", "advent-of-code-2021"], "languages": [{"language": "Rust", "num_chars": 122129}], "readme": "# Advent of Code 2021\n\nHere I collected my solutions for [advent of code 2021](https://adventofcode.com/2021/).\n\nUntil the 12th, I finished them each on the same day. Afterwards, other things got in the way. I returned to the challenges months later and completed them all.\n\nAfter I used Python in the [last year](https://github.com/frcroth/advent-of-code-2020), this time I used Rust exclusively, despite not having a lot of experience with that language.\n"}
{"url": "https://github.com/frcroth/BRIEFly", "owner": "frcroth", "repository_name": "BRIEFly", "date_all_variable_collection": "2023-09-11", "description": null, "size": 137, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Niwo1403", "contributions": 1}, {"contributor": "frcroth", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 18445}], "readme": "# BRIEFly"}
{"url": "https://github.com/frcroth/elections", "owner": "frcroth", "repository_name": "elections", "date_all_variable_collection": "2023-09-11", "description": "Simulate elections.", "size": 829, "stargazers_count": 2, "watchers_count": 2, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 4, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 4, "watchers": 2, "default_branch": "main", "contributors": [{"contributor": "frcroth", "contributions": 60}, {"contributor": "dependabot[bot]", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["elections", "simulate-elections", "voting"], "languages": [{"language": "JavaScript", "num_chars": 63531}, {"language": "HTML", "num_chars": 7589}, {"language": "CSS", "num_chars": 985}], "readme": "# elections\n[![Language grade: JavaScript](https://img.shields.io/lgtm/grade/javascript/g/frcroth/elections.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/frcroth/elections/context:javascript)  \nThis tool allows you to simulate elections. Place candidates and voters on a political coordinate system, and compare different voting systems to get different results.\n\n![](doc/Screenshot_20210126.png)\n\n[Try it](https://frcroth.github.io/elections/)\n\n### Mechanisms\n\nCurrently implemented voting mechanisms for a single seat:\n- [First past the post](https://en.wikipedia.org/wiki/First-past-the-post_voting)\n- [Instant runoff](https://en.wikipedia.org/wiki/Instant-runoff_voting)\n- [Borda count](https://en.wikipedia.org/wiki/Borda_count)\n- [Bucklin voting](https://en.wikipedia.org/wiki/Bucklin_voting#Voting_process)\n- [Condorcet method](https://en.wikipedia.org/wiki/Condorcet_method)\n- [Approval voting](https://en.wikipedia.org/wiki/Approval_voting)  \n\nFor multiple seats:\n- [Sainte-Lagu\u00eb method](https://en.wikipedia.org/wiki/Webster/Sainte-Lagu%C3%AB_method) \n- [Largest Remainder method](https://en.wikipedia.org/wiki/Largest_remainder_method) with different quotas\n- [D'Hondt method](https://en.wikipedia.org/wiki/D%27Hondt_method)\n- [Huntington-Hill method](https://en.wikipedia.org/wiki/Huntington%E2%80%93Hill_method)\n- Individual candidates\n### Usage\n\nAdd voters by clicking into the coordinate system. Add candidates by clicking into the coordinate system and setting the appropriate draw mode.  \nParty names are just for flavor and do not have any real political meaning or valuation.  \nSelect a Voting mechanism and look at the results.\n\n### Deployment\n\nAll Javascript is client side so no special server is required. Just clone the repository and open index.html in a browser. Tested in Mozilla Firefox 84.\n"}
{"url": "https://github.com/frcroth/frcroth", "owner": "frcroth", "repository_name": "frcroth", "date_all_variable_collection": "2023-09-11", "description": null, "size": 2, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "frcroth", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "### Hi there \ud83d\udc4b\n\nI'm a student at [HPI](https://hpi.de/en/index.html). I'm interested in Software Engineering, Systems programming and Cybersecurity, among other things. Find further information on my [Website](https://frcroth.de).\n\n![frcroth's GitHub stats](https://raw.githubusercontent.com/frcroth/github-stats/master/generated/overview.svg)\n![language stats](https://raw.githubusercontent.com/frcroth/github-stats/master/generated/languages.svg)\n<!--\n**frcroth/frcroth** is a \u2728 _special_ \u2728 repository because its `README.md` (this file) appears on your GitHub profile.\n\nHere are some ideas to get you started:\n\n- \ud83d\udd2d I\u2019m currently working on ...\n- \ud83c\udf31 I\u2019m currently learning ...\n- \ud83d\udc6f I\u2019m looking to collaborate on ...\n- \ud83e\udd14 I\u2019m looking for help with ...\n- \ud83d\udcac Ask me about ...\n- \ud83d\udceb How to reach me: ...\n- \ud83d\ude04 Pronouns: ...\n- \u26a1 Fun fact: ...\n-->\n"}
{"url": "https://github.com/frcroth/github-stats", "owner": "frcroth", "repository_name": "github-stats", "date_all_variable_collection": "2023-09-11", "description": null, "size": 463, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "frcroth", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 21507}], "readme": "# [GitHub Stats Visualization](https://github.com/jstrieb/github-stats)\n\n<a href=\"https://github.com/jstrieb/github-stats\">\n\n![](https://github.com/jstrieb/github-stats/blob/master/generated/overview.svg)\n![](https://github.com/jstrieb/github-stats/blob/master/generated/languages.svg)\n\n</a>\n\nGenerate visualizations of GitHub user and repository statistics using GitHub\nActions.\n\nThis project is currently a work-in-progress; there will always be more\ninteresting stats to display.\n\n## Background\n\nWhen someone views a profile on GitHub, it is often because they are curious\nabout a user's open source projects and contributions. Unfortunately, that\nuser's stars, forks, and pinned repositories do not necessarily reflect the\ncontributions they make to private repositories. The data likewise does not\npresent a complete picture of the user's total contributions beyond the current\nyear.\n\nThis project aims to collect a variety of profile and repository statistics\nusing the GitHub API. It then generates images that can be displayed in\nrepository READMEs, or in a user's [Profile\nREADME](https://docs.github.com/en/github/setting-up-and-managing-your-github-profile/managing-your-profile-readme).\n\nSince the project runs on GitHub Actions, no server is required to regularly\nregenerate the images with updated statistics. Likewise, since the user runs\nthe analysis code themselves via GitHub Actions, they can use their GitHub\naccess token to collect statistics on private repositories that an external\nservice would be unable to access.\n\n## Disclaimer\n\nIf the project is used with an access token that has sufficient permissions to\nread private repositories, it may leak details about those repositories in\nerror messages. For example, the `aiohttp` library\u2014used for asynchronous API\nrequests\u2014may include the requested URL in exceptions, which can leak the name\nof private repositories. If there is an exception caused by `aiohttp`, this\nexception will be viewable in the Actions tab of the repository fork, and\nanyone may be able to see the name of one or more private repositories.\n\nDue to some issues with the GitHub statistics API, there are some situations\nwhere it returns inaccurate results. Specifically, the repository view count\nstatistics and total lines of code modified are probably somewhat inaccurate.\nUnexpectedly, these values will become more accurate over time as GitHub\ncaches statistics for your repositories. Additionally, repositories that were\nlast contributed to more than a year ago may not be included in the statistics\ndue to limitations in the results returned by the API.\n\nFor more information on inaccuracies, see issue\n[#2](https://github.com/jstrieb/github-stats/issues/2),\n[#3](https://github.com/jstrieb/github-stats/issues/3), and\n[#13](https://github.com/jstrieb/github-stats/issues/13).\n\n# Installation\n\n<!-- TODO: Add details and screenshots -->\n\n1. Create a personal access token (not the default GitHub Actions token) using\n   the instructions\n   [here](https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token).\n   Personal access token must have permissions: `read:user` and `repo`. Copy\n   the access token when it is generated \u2013 if you lose it, you will have to\n   regenerate the token.\n2. Click [here](https://github.com/jstrieb/github-stats/generate) to create a\n   copy of this repository. Note: this is not the same as forking a copy\n   because it copies everything fresh, without the huge commit history. \n3. If this is the README of your fork, click [this\n   link](../../settings/secrets/actions) to go to the \"Secrets\" page.\n   Otherwise, go to the \"Settings\" tab of the newly-created repository and go\n   to the \"Secrets\" page (bottom left).\n4. Create a new secret with the name `ACCESS_TOKEN` and paste the copied\n   personal access token as the value.\n5. It is possible to change the type of statistics reported.\n   - To ignore certain repos, add them (in owner/name format e.g.,\n     `jstrieb/github-stats`) separated by commas to a new secret\u2014created as\n     before\u2014called `EXCLUDED`.\n   - To ignore certain languages, add them (separated by commas) to a new\n     secret called `EXCLUDED_LANGS`.\n   - To show statistics only for \"owned\" repositories and not forks with\n     contributions, add an environment variable (under the `env` header in the\n     [main\n     workflow](https://github.com/jstrieb/github-stats/blob/master/.github/workflows/main.yml))\n     called `EXCLUDE_FORKED_REPOS` with a value of `true`.\n6. Go to the [Actions\n   Page](../../actions?query=workflow%3A\"Generate+Stats+Images\") and press \"Run\n   Workflow\" on the right side of the screen to generate images for the first\n   time. The images will be periodically generated every hour, but they can be\n   manually regenerated by manually running the workflow.\n7. Check out the images that have been created in the [`generated`](generated)\n   folder.\n8. Link back to this repository so that others can generate their own\n   statistics images.\n9. Star this repo if you like it!\n\n\n# Related Projects\n\n- Inspired by a desire to improve upon\n  [anuraghazra/github-readme-stats](https://github.com/anuraghazra/github-readme-stats)\n- Makes use of [GitHub Octicons](https://primer.style/octicons/) to precisely\n  match the GitHub UI\n"}
{"url": "https://github.com/frcroth/hpi_gamejam2020_2colors", "owner": "frcroth", "repository_name": "hpi_gamejam2020_2colors", "date_all_variable_collection": "2023-09-11", "description": null, "size": 31089, "stargazers_count": 0, "watchers_count": 0, "language": "GDScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 12, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 12, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "frcroth", "contributions": 76}, {"contributor": "oleschl", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["hpigamejam", "hpigamejam07"], "languages": [{"language": "GDScript", "num_chars": 8169}, {"language": "GAP", "num_chars": 4728}], "readme": "# JOFT - HPI GameJam 2020 - Two Colors\n\nThe game works as follows:\n  * Two players play **against** each other on one local machine.\n  * The concept is a simple Last-Man-Standing game, with some nice twists :)\n  * One player is **red**, the other one **blue**.\n  * There is a playfield, that consists of square fields, each red or blue.\n  * Every beat of the playing music, the field colors are changing to the opposite.\n  * Once a player is on a field that does not fit its color, the player dies.\n  * There are several powerups a player can collect, to get closer to killing the other player.\n\n# Controls\n\nPlayer 1: *WASD*\nPlayer 2: *\u2190\u2191\u2192\u2193*\n\n# Colors\n\n**Red:** #910b07\n\n**Blue:** #075c91\n"}
{"url": "https://github.com/frcroth/line-planner", "owner": "frcroth", "repository_name": "line-planner", "date_all_variable_collection": "2023-09-11", "description": "Plan train lines on a map. Just for fun.", "size": 1114, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "frcroth", "contributions": 35}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 27766}, {"language": "HTML", "num_chars": 4998}, {"language": "CSS", "num_chars": 895}], "readme": "# line-planner\n[![Language grade: JavaScript](https://img.shields.io/lgtm/grade/javascript/g/frcroth/line-planner.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/frcroth/line-planner/context:javascript)\n\nLine planner is a simple website that allows the planning of train lines (e.g. subway lines) on a map.\n\n[Try it!](https://frcroth.github.io/line-planner/)  \n\n![](doc/Screenshot_20210314_155624.png)\n\n### Features\n- Create and edit lines on an open street map\n- Create \"U-Bahn\" or \"S-Bahn\" lines\n- Import and export created lines\n- Automatically name stations via reverse geocode\n- Everything is undo and redoable\n"}
{"url": "https://github.com/frcroth/murder-game-bot", "owner": "frcroth", "repository_name": "murder-game-bot", "date_all_variable_collection": "2023-09-11", "description": "A Telegram bot for playing  \"M\u00f6rderspiel\" - murder game", "size": 8, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "frcroth", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 14276}], "readme": "# murder-game-bot\nA Telegram bot for playing  \"M\u00f6rderspiel\" - murder game\n\n\nThe game is for a group of people in a physical environment, and can be used to get to know each other. Every participating player is a murderer with the goal to kill a specific target, another player. How this happens depends on your specific game rules, but it usually involves physically handing over an item to the target. \nThis bot aims to improve the game experience by making sheets of paper with names written on obsolete.\n\nAs a player some useful commands may be:\n/kill Notify the bot that you killed your target. This has to be confirmed by the target by pressing\n/dead.\nYou can see your target at any point with /target. \n"}
{"url": "https://github.com/frcroth/qinoq-commit-analysis", "owner": "frcroth", "repository_name": "qinoq-commit-analysis", "date_all_variable_collection": "2023-09-11", "description": null, "size": 64, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": false, "has_downloads": true, "has_wiki": false, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "frcroth", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 7247}, {"language": "HTML", "num_chars": 2233}, {"language": "CSS", "num_chars": 764}], "readme": "# Qinoq commit data analysis\n\nSome data extracted from a list of commits in the [qinoq](http://github.com/hpi-swa-lab/qinoq) project and displayed on a web page.\n\nView the page at <https://frcroth.github.io/qinoq-commit-analysis/>.\n"}
{"url": "https://github.com/frcroth/sierpinski-random", "owner": "frcroth", "repository_name": "sierpinski-random", "date_all_variable_collection": "2023-09-11", "description": "Draw a Sierpi\u0144ski triangle with random numbers. Uses python and turtle.", "size": 21, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "frcroth", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["chaos-game", "experiments"], "languages": [{"language": "Python", "num_chars": 919}], "readme": " \n# Drawing a Sierpi\u0144ski triangle with random numbers\n\nThis is a small script from my school days, which draws a [Sierpi\u0144ski triangle](https://en.wikipedia.org/wiki/Sierpi%C5%84ski_triangle) using random numbers.\n\n![](screenshot.png)\n\nThis is a well known example of a [chaos game](https://en.wikipedia.org/wiki/Chaos_game). Using turtle, it produces a Sierpi\u0144ski triangle, which is a nice looking fractal.\n\nThis script (without some enhancements) was created at a course at the [\"Mathematische Sch\u00fclergesellschaft Leonhard Euler\"](http://didaktik.mathematik.hu-berlin.de/de/schule/msg-schuelergesellschaft) some years ago.\n\n### Troubleshooting\n\nTo get it to work, I had to do some searching.\nThese links may help you.\n- On installing turtle: [ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.](https://www.programmersought.com/article/6960452148/)\n- [ImportError: libtk8.6.so: cannot open shared object file: No such file or directory](https://stackoverflow.com/questions/48504746/importerror-libtk8-6-so-cannot-open-shared-object-file-no-such-file-or-direct)\n"}
{"url": "https://github.com/frcroth/swing-snake", "owner": "frcroth", "repository_name": "swing-snake", "date_all_variable_collection": "2023-09-11", "description": "A basic Snake game.", "size": 8, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "frcroth", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["archive", "snake"], "languages": [{"language": "Java", "num_chars": 6591}], "readme": "# Swing Snake\n\nA very basic snake game made with awt and swing.\n\nIt was initially created in October 2017. I created this repo and made some improvements in November 2020.\n\n![A screenshot](Screenshot.png)\n\nTested only on Windows."}
{"url": "https://github.com/frcroth/zahlenmaschine", "owner": "frcroth", "repository_name": "zahlenmaschine", "date_all_variable_collection": "2023-09-11", "description": "Virtual machine for custom assembly in Browser.", "size": 301, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "frcroth", "contributions": 33}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 435251}, {"language": "CSS", "num_chars": 11903}, {"language": "HTML", "num_chars": 3637}], "readme": "# Zahlenmaschine\n\n![](doc/screenshot.png)\n\n[Try it!](https://frcroth.de/zahlenmaschine/)\n\n## User documentation\n\nThe documentation for usage can be found [here](doc/general.md), possible operations are listed [here](doc/operations.md).\n\n## Deployment\n\nAll Javascript is client side, so you can simply clone the repository and open index.html in the browser. With newer browser this is not possible because of security rules on loading files and modules, so you might need to start a local server, for example with:\n\n```python -m http.server```\n\nYou can find a deployed version [here](https://frcroth.de/zahlenmaschine/).\n"}
{"url": "https://github.com/freenerd/ask-imogen", "owner": "freenerd", "repository_name": "ask-imogen", "date_all_variable_collection": "2023-09-11", "description": "Midem Hack Day Project", "size": 1052, "stargazers_count": 4, "watchers_count": 4, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 4, "default_branch": "master", "contributors": [{"contributor": "katharina", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 27273}, {"language": "Ruby", "num_chars": 23044}], "readme": "Music Hack Day Hack at Midem Cannes 2011\n"}
{"url": "https://github.com/freenerd/boulevardofbrokenlinks", "owner": "freenerd", "repository_name": "boulevardofbrokenlinks", "date_all_variable_collection": "2023-09-11", "description": "Notify on broken links", "size": 428, "stargazers_count": 2, "watchers_count": 2, "language": "Go", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "freenerd", "contributions": 19}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Go", "num_chars": 337028}], "readme": "# Boulevard Of Broken Links\n## What?\n\nFetch a URL, parse all hyperlinks from the returned HTML and check each hyperlinks status. Collect all broken links (http status >= 400) and send an email to owner about it. Triggered via webhook.\n\nExample email:\n\n```\nhttp://freenerd.de/: 404 http://www.freenerd.de/hackhpi/\nhttp://freenerd.de/: 503 http://takesquestions.com/\nhttp://freenerd.de/: 403 http://bcn.musichackday.org/2012/\n```\n\n## Installation\n\n* Install `go`\n* `go get github.com/freenerd/boulevardofbrokenlinks`\n\n## Tests\n\n```\ncd \"$GOPATH/src/github.com/freenerd/boulevardofbrokenlinks\"\ngo test\n```\n\n## Run\n\n```\ncd \"$GOPATH/src/github.com/freenerd/boulevardofbrokenlinks\"\ngo install\nCHECK_URL=\"http://www.freenerd.de\" boulevardofbrokenlinks\ncurl \"localhost:8080/trigger\"\n```\n\nEmails will only be sent, if sendgrid environment is configured. Otherwise output to STDOUT.\n\n## Deploy on heroku\n\n```\nheroku apps:create -b https://github.com/kr/heroku-buildpack-go.git\nheroku addons:add sendgrid:starter\nheroku config:set EMAIL_RECIPIENT=recipient@example.com\nheroku config:set CHECK_URL=http://www.freenerd.de\ngit push heroku master\n```\n\nThe scans are triggered via a webhook. To e.g. set it up with a github repo, go to your repo settings -> webhooks and enter the url `herokuapp-url/trigger` where you find out `herokuapp-url` via `heroku info | grep \"Web URL\"`.\n\n## TODO\n\n* Test suite\n* Split web.go into more modules\n* Better inline documentation\n* Homepage\n* Connect with Github (because this is only supposed to be for jekyll blogs)\n* Token for github callback (or better: automatic setup after connection)\n* WaitGroups to figure out, when a site has been fully crawled\n* Do some buffering, if people deploy often, they should only get an email every X minutes\n* unsubscribe link in the emails\n\n## Caveats\n\n- Since everything is in memory, a deploy kills currently ongoing scans\n\n## Why the name?\n\n```\n  I walk a lonely URL\n  The only one that I have ever known\n  Don't know where it goes\n  But it's only me and I walk alone\n```\n\nhttps://www.youtube.com/watch?v=tijW_SrCoxs\n"}
{"url": "https://github.com/freenerd/daily-sample-set", "owner": "freenerd", "repository_name": "daily-sample-set", "date_all_variable_collection": "2023-09-11", "description": "Pull latest CC tracks from SoundCloud, find bars with Echonest, Upload samples again", "size": 92, "stargazers_count": 2, "watchers_count": 2, "language": "Ruby", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Ruby", "num_chars": 6252}], "readme": "= Introduction\nThis is a hack from {link Music Hack Day London 2010}[http://wiki.musichackday.org/index.php?title=Daily_Sample_Set].\n\nIt pulls the hottest downloadable uncompressed cc-licensed tracks from SoundCloud, analyses them with EchoNest, slices them on a bar basis with Sox and uploads the slices again to SoundCloud.\n\nThis hack is similar to the {link SoundEchoCloudNest}[http://github.com/hannestyden/SoundEchoCloudNest] hack by Hannes and uses the EchoNest API wrapper fork by him.\n\n= Usage\n\n* Install the SoundCloud Ruby API Wrapper http://github.com/soundcloud/ruby-api-wrapper\n* Install Sox http://sox.sourceforge.net/\n* Install wget http://www.gnu.org/software/wget/\n* Install the Echonest API wrapper fork by Hannes http://github.com/hannestyden/ruby-echonest/\n\n* Register for an Echonest API Key http://developer.echonest.com/docs/v4/\n* Register for a SoundCloud API Application http://soundcloud.com/developers\n* Get an SoundCloud Access Token | you can use this script for that http://github.com/jwagener/sc-shell/blob/master/soundcloud-authorized.rb\n* Put all these information in /setup.rb which should then have\n ECHONEST_API_KEY\n SC_CONSUMER_KEY\n SC_CONSUMER_SECRET\n SC_ACCESS_TOKEN\n SC_ACCESS_TOKEN_SECRET\n\n* Create the folders /originals and /samples\n* Run with # ruby dailysampleset.rb"}
{"url": "https://github.com/freenerd/downloud", "owner": "freenerd", "repository_name": "downloud", "date_all_variable_collection": "2023-09-11", "description": "Private link to a label's release | users can download music after they listened to stream and left name/email/feedback", "size": 196, "stargazers_count": 1, "watchers_count": 1, "language": "Ruby", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "freenerd", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Ruby", "num_chars": 2052}, {"language": "JavaScript", "num_chars": 257}], "readme": "Downloud\n========\n\n# What?\n\nIt's like http://www.fatdrop.co.uk/ but simpler. You setup your own instance with music releases. Each release has it's own page with embedded soundcloud players. When users leave their name, email address and a comment they can download a file (usually the full release). This is usually used by labels to send promotional copies to DJs. Have a look at a demo deployment here http://downloud.heroku.com/odd001josht\n\n# Installation\n\nIn order to set this up you will have to deploy your own instance of the Sinatra app on Heroku. If you can't figure out what this means you should either use Fatdrop or drop me a mail at downloud@freenerd.de\n\n### install rvm and ruby\n\n```\ncurl -L get.rvm.io | bash -s stable\nsource ~/.rvm/scripts/rvm\nrvm install 1.9.2\n```\n\n### checkout and initialize the repo\n\n```\ngit clone git@github.com:freenerd/downloud.git\ncd downloud\necho 'rvm ruby-1.9.2@downloud --create' > .rvmrc\ncd ../downloud\ngem install bundler\nbundle install\n```\n\n### run\n\n```\nrackup\n```\n\nif you want to develop locally shotgun might be your friend\n\n```\ngem install shotgun\nshotgun\n```\n\n### Pre-deploy\n\n * Get an account at http://www.heroku.com\n * Install the heroku toolbelt https://toolbelt.heroku.com/\n\n### Deploy\n\n```\ncd downloud\nheroku login\nheroku create --stack cedar\nheroku addons:add sendgrid:starter\ngit push heroku master\n```\n\n# Configuration\n\nDownloud has no database. All releases and assets are 'in code' and must be commited to the code base in order to be pushed to Heroku.\n\n## First-run conf\n\nOpen ```downloud.rb``` and change the defaults.\n\n * ```email_to``` if no other email specified in the release the feedback will be sent to this address\n * ```email_from``` feedback email will be sent from this address\n * ```banner``` if no other banner is specified for the release this one is used. The banner is in ```/public/img/banners/default.png```. Please make sure that the banner is 300px by 300px\n\n## Putting in a new release\n\nOpen ```releases.yml``` and copy/paste/change one of the releases there\n\n  * the `key of the release` is at the same time is the permalink that the release will be reachable at. Please only use lower case ascii characters and numbers\n  * in ```tracks``` are the tracks that will be available for streaming. Put in the URLs. If your tracks are private, put in the secret URLs with the secret token in the end (like /s-1273)\n  * ```download``` is the URL to the file that will be downloadable once feedback is submitted. You can put in a public link to a file on Dropbox for example\n  * ```email``` the email the feedback will be sent to. If no email specified the default email will be used\n\nIf you want to put in a different banner for the release, go to ```/public/img/banners/{the release name}.png```. The release name is the key of your release as you put in in in ```releases.yml```. Please make sure that the banner is 300px by 300px\n\nCommit everything:\n\n```\ngit add public\ngit commit -a\n```\n\nDeploy:\n\n```\ngit push heroku master\n```\n\nDone, go check in your browser\n\n# Limitations\n\nThis app can be deployed for free on Heroku, but with the free plan you will only be able to receive 200 feedback emails a day. Also the link to the download is not secured in any way. People will be able to share the download link you specified.\n\n# License\n\nCopyright (c) 2012 Johan Uhle\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"}
{"url": "https://github.com/freenerd/ec2-spot-market-analyzer", "owner": "freenerd", "repository_name": "ec2-spot-market-analyzer", "date_all_variable_collection": "2023-09-11", "description": "Locally queries the AWS spot market API for analysis", "size": 2, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "freenerd", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 3681}], "readme": "### EC2 Spot Market Analyzer\n\n__NOTE: Does not work for longer time spans due to aggressive rate limiting of AWS__\n\nQueries the AWS spot market API for local analysis via csv or to derive stats from (how often would i be priced out with my set price). This is a __work in progress__ and doesn't work well.\n\n#### Install\n\n```\ngit clone ...\nnpm install\n```\n\n#### Run\n\n```\nnode index.js\n```\n\n#### Usage\n\n```\nUsage: index.js <command> [options]\n\nCommands:\n  csv    Output csv results to use in spreadsheets\n  stats  Output statistics\n\nOptions:\n  --regions         comma-separated list of AWS regions                [default:\n  \"us-east-1,us-west-2,us-west-1,eu-west-1,eu-central-1,ap-northeast-1,ap-southe\n                                                ast-1,ap-southeast-2,sa-east-1\"]\n  --instance-types  comma-separated list of AWS EC2 instances to look for\n                                             [default: \"r3.8xlarge,m4.10xlarge\"]\n  --max-price       on stats, calculate percentage of time max-price could get a\n                    spot instance\n  --hours           hours back to look at, min 1, max 90 * 24 = 2160\n                                                           [number] [default: 1]\n```\n"}
{"url": "https://github.com/freenerd/elevatorsaga", "owner": "freenerd", "repository_name": "elevatorsaga", "date_all_variable_collection": "2023-09-11", "description": "Trying a solution for http://elevatorsaga.com/", "size": 126, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "leaVael", "contributions": 7}, {"contributor": "freenerd", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 7877}]}
{"url": "https://github.com/freenerd/expensive-lyrics-display", "owner": "freenerd", "repository_name": "expensive-lyrics-display", "date_all_variable_collection": "2023-09-11", "description": "Using many Novation Launchpads as a display for lyrics", "size": 140, "stargazers_count": 5, "watchers_count": 5, "language": "Ruby", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 5, "default_branch": "master", "contributors": [{"contributor": "freenerd", "contributions": 16}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Ruby", "num_chars": 4449}], "readme": "# Expensive LED Scrolling Strip\n\n## What?\nThis is a script that shows lyrics on several Novation Launchpad S. It uses the built-in scrolling functionality of the launchpad, but delays and offsets the messages to show them scrolling over many pads. To enable offset to make the text start in the middle of the display, we patched the Launchpad firmware.\n\nThe software was developed by @freenerd at Music Hack Day Barcelona 2013 with lots of help of Ross from Novation, who wrote the firmware patch. Also the synced lyrics came from MusixMatch.\n\nA video demonstration can be seen here:\nhttps://www.youtube.com/watch?v=AcOoXeCA_-8\n\nAlso for reference, the project lives here:\nhttps://github.com/freenerd/expensive-lyrics-display\n\n## Requirements\n\n  * 1-16 Novation Launchpad S (original Launchpad will not work, since it has no text scroll)\n  * Ruby 1.9.3\n  * Portmidi\n\n## Installation & Setup\n  Install portmidi. If you are on a Mac and have Homebrew, do `brew install portmidi`.\n\n  To install all the dependent gems, use bundler with `bundle install`.\n\n  Connect all the Launchpads you have (i hope it's many!) to your computer.\n  \n  We use a patched Launchpad S firmware to make the text not start at the beginning, but in the middle of the display. If you don't want to patch your Launchpads, comment out the offset line in the `marque` of expensive_led.rb.\n\n  To patch the firmware, Novation wrote about it here https://focusritedevelopmentteam.wordpress.com/2013/06/10/novation-is-coming-to-sonard/ and the Firmware is in this repository as a file with the name `Launchpad_S_expensive_led_firmware.syx`. The new firmware only adds the new offset CC code to the text scroll command.\n\n  Every Launchpad needs a unique sequential device id. To do this, while connecting each Launchpad hold down the session, user1, user2 and mixer buttons. You can then choose the ID of the Launchpad via the top yellow buttons, with 1 in the top left corner and 16 in the bottom right.\n\n  Next: run it!\n\n## Run\n  To run, you obviously need text to be displayed, together with timing information. You can either fill them by hand in the `TextScrollerInput.load_lyrics_test` method or load a file via the `TextScrollerInput.load_lyrics_file` method. As an example for a file, look at the `daftpunk_harder.json` which has the first lines of the lyrics, as also shown in the demo video.\n\n  You can also use the websockets, as explained below.\n\n  If you want to have music played along the lyrics, uncomment the lines at the bottom of the file. This will only work on Mac, since it uses the afplay tool. You have to provide the audio file yourself.\n\n  Once setup run `ruby expensive_led.rb`\n\n## More explanation\nThis only works with the Launchpad S, since the original Launchpad 1 doesn't have a built-in text scrolling functionality.\n\nThe text scrolling is well-explained in the Novation Launchpad S Programmers manual. Check it here:\n\nhttp://global.novationmusic.com/support/product-downloads?product=Launchpad+S\nhttps://d19ulaff0trnck.cloudfront.net/sites/default/files/novation/downloads/4700/launchpad-s-prm.pdf\n\nWe patched the firmware. You can also use it unpatched, but then the lyrics always start to scroll from the first launchpad with no text visible when each lyric line starts.\n\n## Websocket support\nWe also implented websocket support on the basis of SocketIO. You can enable it by uncommenting some code on the bottom of the file. The client respnds to events of 'linechanged' with the structure `{\"lyrics\": \"Your line to display\"}`.\n"}
{"url": "https://github.com/freenerd/extract-epubinfo", "owner": "freenerd", "repository_name": "extract-epubinfo", "date_all_variable_collection": "2023-09-11", "description": "Batch extract metadata and covers from .epubs", "size": 96, "stargazers_count": 1, "watchers_count": 1, "language": "Ruby", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "freenerd", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Ruby", "num_chars": 2075}], "readme": "## Description\n\nExtract-epubinfo bulk extracts metadata and cover images from .epubs into a .csv file and image files.\n\n## Dependencies\n\n* Ruby 1.9.2\n* [epubinfo gem](https://github.com/chdorner/epubinfo/)\n\n## Installation\n\n* gem install epubinfo\n\n## Usage\n\n* Put your .epub files into the ./epubs directory\n* Run `ruby extract.rb`\n* Retrieve output from ./output/{timestamp}\n\n## Copyright\n\nCopyright (c) 2012 Johan Uhle. See LICENSE.txt for further details."}
{"url": "https://github.com/freenerd/findmypi", "owner": "freenerd", "repository_name": "findmypi", "date_all_variable_collection": "2023-09-11", "description": "Send the local ip address of your Raspberry Pi via email", "size": 112, "stargazers_count": 2, "watchers_count": 2, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "freenerd", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 2241}], "readme": "findmypi\n========\n\nSend the local ip address of your Raspberry Pi via email\n\n# Background\n\nWhen you connect your Raspberry Pi to a network with DHCP, it is sometimes hard to find out the IP of the Pi. Ways to solve this include:\n\n  * Connect a screen/keyboard and look up via 'ifconfig'\n  * Look at the DHCP IP assignment table of the router\n  * Set a static IP at the Pi\n  * Tunnel the Pi through another computer\n  * Try out all possible IPs\n  * Have the Pi tell you it's IP ...\n\nThis script here is the last solution. On boot it will look if the Pi has an IP and send it to you via mail. Boom, you are in!\n\nThe repository lives at http://github.com/freenerd/findmypi\n\n# Installation\n\nClone the repository\n\n  ```bash\n  cd ~\n  git clone git://github.com/freenerd/findmypi.git\n  cd findmypi\n  ```\n\nCopy and change the settings file\n\n  ```bash\n  cp settings_example.py settings.py\n  nano settings.py\n  ```\n\nYou can enter your own smtp server. The default is using Gmail.\n\nPlease note that your email password will be in the settings in plain text. If your RaspberryPi gets stolen, the attacker might gain access to your whole email account. The safest way is to create a dedicated email account. If you use Gmail, you can also use an 'application specific password'.\n\nOnce this is done, check if it works locally:\n\n  ```bash\n  python findmypi.py\n\n  # check your email inbox for the email\n  ```\n\nYou will probably want to have this script be executed on startup\n\n  ```bash\n  sudo nano /etc/rc.local\n\n  # add to the bottom just before 'exit 0'\n  python /home/pi/findmypi/findmypi.py &\n  ```\n\nRestart your Pi and wait for the email\n\n# Attribution\n\nThe code was initially created by Alex on http://raspi.tv/tag/locate-your-missing-raspberry-pi\nBig ups for the work!\nI only forked and extended it ...\n"}
{"url": "https://github.com/freenerd/flickr-uploader", "owner": "freenerd", "repository_name": "flickr-uploader", "date_all_variable_collection": "2023-09-11", "description": "Upload all files of a directory to a flickr photoset. Resume if upload stalls ...", "size": 14, "stargazers_count": 22, "watchers_count": 22, "language": "Ruby", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 6, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 6, "open_issues": 0, "watchers": 22, "default_branch": "master", "contributors": [{"contributor": "freenerd", "contributions": 13}, {"contributor": "dohliam", "contributions": 1}, {"contributor": "beemaster", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Ruby", "num_chars": 10620}], "readme": "# flickr-uploader\n## What?\n\nThis script helps you to upload a lot of pictures to Flickr. If the upload fails, you can resume at the last uploaded picture. Also if you uploaded something wrong, you can delete whole photosets including all photos in it.\n\n## Installation\n\nIt's a ruby script. I used ruby 2.0 for development, but it should also run with ruby 1.9.x. Packet management is done via bundler.\n\n```\n  git clone https://github.com/freenerd/flickr-uploader.git\n  cd flickr-uploader\n\n  gem install bundler\n  bundle install\n```\n\n## Usage\n### Examples\n\n```\nruby flickr-uploader.rb --help\nruby flickr-uploader.rb --upload \"/Users/johan/Pictures/vacation\" --photoset-name \"Vacation 2013\"\nruby flickr-uploader.rb --delete-photoset 1234567890123\n```\n\n### Authentication\n\nTo access your Flickr account, you need to be authenticated. This happens either when you first use the tool, or you can prompt the authentication flow via `ruby flickr-uploader.rb --connect`. You will need to open a URL in your browser and then copy/paste the shown number back into the terminal.\n\nIf you want to connect a new account, just start the connect flow again with the above-mentioned command.\n\n### Uploading all files in a directory\n\nflickr-uploader assumes that you want to upload all files (photos and videos) within one directory. Please make sure that no other files are present in the directory.\n\nStart the upload via `ruby flickr-uploader.rb --upload DIRECTORY`. Use the absolute path to the directory. If you specify a photoset name via `--photoset-name NAME` all uploaded items will be added to that newly-created photoset. By default, all photos are uploaded privately. You can upload items publicly via the `-p` switch.\n\n### Deleting all items in a photoset\n\nTo delete all items in a photoset, use `ruby flickr-uploader.rb --delete-photoset PHOTOSET_ID`. To get the photoset_id, either go to the photoset on Flickr and copy the id from the URL, or list all your photosets via `ruby flickr-uploader.rb --list-photosets`.\n\n### Dry mode\n\nIf you run any command with the `-d` switch, it will still show the output but no actions will actually happen.\n\n### What if something goes wrong during the upload?\n\nIf there is an error during the upload of a file, the script will just try again. But you can also quit the script via `CTRL-C`. If so, you can just restart the script with the same commands as before and the script will continue from where it left off. All progress (read: all uploaded photos) is saved to `log.yml`. If something is fishy, delete the `log.yml` file and start the upload again from the beginning.\n\n## Contributing\nFork away. I'm happy to accept pull requests, there is a lot of stuff to be added.\n"}
{"url": "https://github.com/freenerd/go-import-extractor", "owner": "freenerd", "repository_name": "go-import-extractor", "date_all_variable_collection": "2023-09-11", "description": "Extracts a list of imported packages from either a go file or a go package", "size": 100, "stargazers_count": 1, "watchers_count": 1, "language": "Go", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "freenerd", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Go", "num_chars": 4098}], "readme": "# go-import-extractor\n\ngo-import-extractor helps to analyze go programs. It extracts a list of imported packages from either a .go file or a go package. On a go package, it may recursively analyze the imported packages.\n\n## Install\n\n    go get github.com/freenerd/go-import-extractor\n\n## Use\n\nFor basic usage give the absolute go source file path as first argument. In this example, we analyze the code of this package:\n\n    go-import-extractor $GOPATH/src/github.com/freenerd/go-import-extractor/main.go\n\nThe output goes to STDOUT and is formated as xml. It looks like this:\n\n```xml\n<imports>\n  <import>fmt</import>\n  <import>github.com/freenerd/go-import-extractor/extractor</import>\n</imports>\n```\n\nTo analyze a whole package, call like this:\n\n    go-import-extractor -p github.com/freenerd/go-import-extractor\n\nOutput can be filtered by specific suspect package calls (TODO: make customizable)\n\n    go-import-extractor -p github.com/freenerd/go-import-extractor -s\n\n## Output formats\n\nXML only at the moment\n\n## Limitations\n\n- does not expose package renames, but only uses the original package import name\n"}
{"url": "https://github.com/freenerd/honeypot", "owner": "freenerd", "repository_name": "honeypot", "date_all_variable_collection": "2023-09-11", "description": null, "size": 3424, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "freenerd", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "honeypot\n========\n\nThis hosts a static website.  \nSee it at http://freenerd.github.io/honeypot/  \nSee `gh-pages` branch for code.\n"}
{"url": "https://github.com/freenerd/hubdrawer", "owner": "freenerd", "repository_name": "hubdrawer", "date_all_variable_collection": "2023-09-11", "description": "hubdrawer", "size": 176, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "BSD 2-Clause \"Simplified\" License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "larsxschneider", "contributions": 2}, {"contributor": "freenerd", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 52483}, {"language": "Shell", "num_chars": 307}], "readme": "hubDrawer\n=========\n\nChrome extensions to TODO\n\nGet the app from the [Chrome Web Store](https://chrome.google.com/webstore/ TODO)\n\n![Screenshot](chrome-github-magic/raw/master/screenshot.png))\n\n\n## Usage\n\nTODO\n\n## Contact\n\nJohan Uhle (@freenerd)\nLars Schneider (@kit3bus)\n\n\n## License / 3rd Party Components\n\nhubDrawer is available under the BSD license. See the LICENSE file for more info.\n\n[jQuery](http://jquery.org/license/)\n\n"}
{"url": "https://github.com/freenerd/i-am-sitting-in-a-codec", "owner": "freenerd", "repository_name": "i-am-sitting-in-a-codec", "date_all_variable_collection": "2023-09-11", "description": null, "size": 35540, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "freenerd", "contributions": 10}, {"contributor": "Kalli", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 1282}, {"language": "CSS", "num_chars": 348}, {"language": "JavaScript", "num_chars": 239}], "readme": "# What?\n\nRead the [index.html](https://github.com/freenerd/i-am-sitting-in-a-codec/blob/master/templates/index.html) or check the deployed version at http://bit.ly/sitting-in-a-codec for the description.\n\nMade by Karl and Johan at Music Hack Day Barcelona 2014.\n\n# Installation\n\nInstall [FFmpeg](https://ffmpeg.org/)\n\nGet Flask to run\n\nhttp://flask.pocoo.org/docs/installation/\n\nWe recommend:\n\n```\nvirtualenv venv\n. venv/bin/activate\n\npip install -r requirements.txt\n```\n\n# Run\n\nEasy local\n\n```bash\n// activate virtualenv\n. venv/bin/activate\n\n// run\npython web.py\n```\n\nOr with gunicorn\n\n```\n// activate virtualenv\n. venv/bin/activate\n\nvenv/bin/gunicorn -b 0.0.0.0:80 -w 4 web:app\n```\n"}
{"url": "https://github.com/freenerd/import-call-extractor", "owner": "freenerd", "repository_name": "import-call-extractor", "date_all_variable_collection": "2023-09-11", "description": "For a go source file, show list of calls to imported packages", "size": 172, "stargazers_count": 1, "watchers_count": 1, "language": "Go", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "freenerd", "contributions": 15}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Go", "num_chars": 8227}], "readme": "# import-call-extractor\n\nimport-call-extractor is a program to analyze go programs. It extracts calls made to imported packages. It can work either on a single go source file or a go package. On a go package, it will also recursively analyze the imported packages.\n\n## Install\n\n    go get github.com/freenerd/import-call-extractor\n\n## Use\n\nFor basic usage give the absolute go source file path as first argument. In this example, we analyze the code of this package:\n\n    import-call-extractor $GOPATH/src/github.com/freenerd/import-call-extractor/main.go\n\nThe output goes to STDOUT and is formated as yaml. It looks like this:\n\n```yaml\nflag:\n  Parse:\n    - /Users/johan/Code/go/src/github.com/freenerd/import-call-extractor/main.go:87:3\n  Args:\n    - /Users/johan/Code/go/src/github.com/freenerd/import-call-extractor/main.go:88:10\nfmt:\n  Printf:\n    - /Users/johan/Code/go/src/github.com/freenerd/import-call-extractor/main.go:108:3\n    - /Users/johan/Code/go/src/github.com/freenerd/import-call-extractor/main.go:111:4\n    - /Users/johan/Code/go/src/github.com/freenerd/import-call-extractor/main.go:114:5\n```\n\nTo analyze a whole package, call like this:\n\n    import-call-extractor -p github.com/freenerd/import-call-extractor\n\nOutput can be filtered by specific suspect package calls (TODO: make customizable)\n\n    import-call-extractor -p github.com/freenerd/import-call-extractor -s\n\n## Limitations\n\n- It is assumed that all calls are made on the object with the package name string split after last \"/\". This is a casual convention and not how go imports are actually implemented. Therefore anything exported publicly by a package, that is not within the packages name, will not be detected.\n  - This will be detected: `import \"flag\"; ...; flag.Parse()`\n  - This will not be detected: `import \"flag\"; ...; flags := NewFlagSet(...)`\n- In package mode, if a package is imported several times, it will be analyzed each time, resulting in duplicate call occurences\n- Calls made in a `var` block will not be detected\n- Overriding objects will not be respected\n  - `import \"fmt\"; ...; fmt := \"anything\";`\n\n## Todo\n\n- How are package renames handled?\n- Handle all publicl exports by a package\n- Regarding finding network connections: Also within the stdlib, try to traceback network connections to `net.Dial`\n\n"}
{"url": "https://github.com/freenerd/InstaSample", "owner": "freenerd", "repository_name": "InstaSample", "date_all_variable_collection": "2023-09-11", "description": null, "size": 14964, "stargazers_count": 6, "watchers_count": 6, "language": "Ruby", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 6, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Ruby", "num_chars": 4763}], "readme": "A hack by Johan Uhle at Music Hack Day New York 2011\n\nFor more info on this hack, see the wiki page of the Music Hack Day:\nhttp://wiki.musichackday.org/index.php?title=InstaSamples\n\n\n== Used stuff ==\n * Mac OS X 10.6.\n * Ruby 1.9.2\n * Gems\n  * Bundler\n  * SoundCloud\n  * osc-ruby\n * OSCulator\n * Ableton Live\n * Soundflower\n\n== Installation/Usage ==\n  * Create a settings.rb and enter your SoundCloud Client Credentials and your AccessToken\n  * Start Ableton Live, OSCulator, SoundFlower\n  * Make sure, that SoundFlower 2CH is active.\n  * Set SoundFlower 2CH as standard Output in Mac OS X.\n  * Make sure, that SoundFlower is Input on the track in Ableton you want to record to\n  * Make sure, that Ableton has correct MIDI mapping (maybe remap with the help with the help of OSCulator)\n    * OSC/abletonlive/record (CC100/Channel10) on \"Play next scene\"\n    * OSC/abletonlive/stop (CC100/Channel11) on \"\n  * Make sure, that track you record to in Ableton is armed for record, record on Scene Launch is on, Scene highlight is on first scene you want to record on\n  * Make sure, that the folder /temp exists and is writable\n\n== More Stuff ==\nTo get the Audio into Ableton Live, I use SoundFlower. There is probably a nicer way, to get it Files into Live directly (AppleScript? Max4Live?).\n\nI did not found a good gem to do MIDI output in Ruby, so I used osc-ruby and OSCulator to send MIDI to Ableton Live.\n\nChanging the SoundCloud query is pretty easy and can alter totally, how this works.\n\n\n\n"}
{"url": "https://github.com/freenerd/learning-graph-algorithms", "owner": "freenerd", "repository_name": "learning-graph-algorithms", "date_all_variable_collection": "2023-09-11", "description": "learning by doing: implementing graph algorithms", "size": 665, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "freenerd", "contributions": 19}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 2504052}, {"language": "HTML", "num_chars": 267}], "readme": "learning graph algorithms\n\n----\n\nI wanted to implement some graph algorithms to learn more about how they work. Here we are. Each algorithm has their own directory.\n"}
{"url": "https://github.com/freenerd/masters-thesis", "owner": "freenerd", "repository_name": "masters-thesis", "date_all_variable_collection": "2023-09-11", "description": "The Latex source of my Master's Thesis http://freenerd.de/masters-thesis/", "size": 1868, "stargazers_count": 4, "watchers_count": 4, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 4, "default_branch": "master", "contributors": [{"contributor": "freenerd", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 2900793}], "readme": "# What?\n\nMy master thesis in latex. Based on a template from [Peter Tr\u00f6ger](http://www.troeger.eu/teaching).\n\nRead a blog post about the thesis on http://freenerd.de/masters-thesis/\n\n# How to build\n\nWith pdflatex. With MacTex: `texdist \"pdflatex master_thesis.tex\"`. And there is probably some bibtex magic involved, but who understands that anyways?\n\n# License\n\nThis work is licensed under a [Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License](https://creativecommons.org/licenses/by-nc-nd/4.0/).\n"}
{"url": "https://github.com/freenerd/mccabe-cyclomatic", "owner": "freenerd", "repository_name": "mccabe-cyclomatic", "date_all_variable_collection": "2023-09-11", "description": "Calculates Thomas McCabe's cyclomatic complexity for a go file or package", "size": 152, "stargazers_count": 12, "watchers_count": 12, "language": "Go", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 12, "default_branch": "master", "contributors": [{"contributor": "freenerd", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Go", "num_chars": 4267}], "readme": "**Note** This tool is likely doing it wrong. Check out [this conversation](https://groups.google.com/forum/#!topic/golang-nuts/8SB9H1D34qk) on the goloang-nuts mailinglist and checkout [gocyclo](https://github.com/fzipp/gocyclo).\n\n# mccabe-cyclomatic\n\nCalculates Thomas McCabe's cyclomatic complexity for a go file or package\n\n## Install\n\n    go get github.com/freenerd/mccabe-cyclomatic\n\n## Usage\n\nTo get the cyclomatic complexity of a file:\n\n```\n  $ mccabe-cyclomatic -f ./example/example.go\n  7\n```\n\nTo get the cyclomatic complexity of a package:\n\n```\n  $ mccabe-cyclomatic -p github.com/freenerd/mccabe-cyclomatic\n  5\n```\n\nThe output is the cyclomatic complexity number.\n\n## Calculation\n\n`complexity = number of code execution branch statements + 1`\n\nThe file to be analyzed is loaded with [go/parser ParseFile](http://golang.org/pkg/go/parser/#ParseFile) and subsequentially walked with a [go/ast Visitor](http://golang.org/pkg/go/ast/#Visitor). Depending on which ast node types are encountered, the complexity count is increased.\n\n[Effective Go](http://golang.org/doc/effective_go.html#control-structures) describes the following code execution branch statements:\n\n- if\n- for\n- switch\n- select\n\nThese can be mapped to certain [Go ast node types](http://golang.org/pkg/go/ast/):\n\n- **if** is of [IfStmt](http://golang.org/pkg/go/ast/#IfStmt) type. An *else if* is of [IfStmt](http://golang.org/pkg/go/ast/#IfStmt) type as well. An *else* clause does not add cyclomatic complexity.\n- **for** is either of [ForStmt](http://golang.org/pkg/go/ast/#ForStmt) type or of [RangeStmt](http://golang.org/pkg/go/ast/#RangeStmt) type.\n- **switch** might either be an expression switch or a type switch. In both cases, the number of code execution branches to be executed is determined by the number of case statements [CaseClause](http://golang.org/pkg/go/ast/#CaseClause). Therefore, we only count each [CaseClause](http://golang.org/pkg/go/ast/#CaseClause). *default* clauses do not add to cyclomatic complexity.\n- **select** is similar to *switch*, in that its code execution branches are determined by the number of case statements, but of type [CommClause](http://golang.org/pkg/go/ast/#CommClause). *default* clauses do not add to cyclomatic complexity.\n\nWe end up with the list of the following ast node types, that determine a new code execution branch:\n\n- [IfStmt](http://golang.org/pkg/go/ast/#IfStmt)\n- [ForStmt](http://golang.org/pkg/go/ast/#ForStmt)\n- [RangeStmt](http://golang.org/pkg/go/ast/#RangeStmt)\n- [CaseClause](http://golang.org/pkg/go/ast/#CaseClause)\n- [CommClause](http://golang.org/pkg/go/ast/#CommClause)\n\nWhen any of these node types is encounterd, the complexity score is increased by 1.\n\nApart from the ones just listed, the go language specification includes more [control execution statements]((http://golang.org/ref/spec#Statements). These have not been recognized here: it is assumed that they do not add additional cyclomatic complexity, since they do not add a new code execution branch.\n\n## Limitations\n\n- complexity numbers are only returned for whole packages or files, but not for individual functions.\n- the package algorithm is not recursive, it will not recognize sub-packages.\n\n## References\n\nhttp://www.literateprogramming.com/mccabe.pdf\nA Complexity Measure, by Thomas J McCabe. 1976\n\nhttp://www.win.tue.nl/~aserebre/2IS55/2010-2011/10.pdf\n\nhttps://en.wikipedia.org/wiki/Cyclomatic_complexity\n\nhttps://github.com/philbooth/escomplex\n"}
{"url": "https://github.com/freenerd/passport-flattr", "owner": "freenerd", "repository_name": "passport-flattr", "date_all_variable_collection": "2023-09-11", "description": "A passport strategy for Flattr", "size": 134, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 2748}]}
{"url": "https://github.com/freenerd/potty-mouth-bands", "owner": "freenerd", "repository_name": "potty-mouth-bands", "date_all_variable_collection": "2023-09-11", "description": null, "size": 148, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "por", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 5928}]}
{"url": "https://github.com/freenerd/rhok-world-map", "owner": "freenerd", "repository_name": "rhok-world-map", "date_all_variable_collection": "2023-09-11", "description": "RHOK World Map", "size": 116, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "freenerd", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 34926}], "readme": "RHOK World Map\n========\n\n# What?\n\nSee all past and future RHOKs on a world map. A demo is deployed at http://rhokmap.meteor.com/ and the code is available at http://www.github.com/freenerd/rhokmap\n\n# How?\n\nThe RHOK website's RSS feed of events is pulled, locations are extracted from the XML, passed to the client for geocoding against the Google Geocoding API, pushed back to the server, stored in a database and served on a Google Map.\n\n# Why?\n\nBecause it is fun to see where on the world RHOKs are happening. Also I really wanted to play around with Meteor ;)\n\n# Stuff\n\nThis was built during RHOK Berlin June 2012. Version 0.3.6 of Meteor was used, so expect this to break in the future.\n\n# License\n\nCopyright (c) 2012 Johan Uhle\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"}
{"url": "https://github.com/freenerd/songaday", "owner": "freenerd", "repository_name": "songaday", "date_all_variable_collection": "2023-09-11", "description": "Music Hack Day Bologna 2013 project. Please disregard.", "size": 512, "stargazers_count": 0, "watchers_count": 0, "language": "Ruby", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "freenerd", "contributions": 17}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Ruby", "num_chars": 40405}, {"language": "CSS", "num_chars": 1539}, {"language": "CoffeeScript", "num_chars": 1220}, {"language": "JavaScript", "num_chars": 727}], "readme": "== README\n\nThis README would normally document whatever steps are necessary to get the\napplication up and running.\n\nThings you may want to cover:\n\n* Ruby version\n\n* System dependencies\n\n* Configuration\n\n* Database creation\n\n* Database initialization\n\n* How to run the test suite\n\n* Services (job queues, cache servers, search engines, etc.)\n\n* Deployment instructions\n\n* ...\n\n\nPlease feel free to use a different markup language if you do not plan to run\n<tt>rake doc:app</tt>.\n"}
{"url": "https://github.com/freenerd/soundcloud-api-wadl", "owner": "freenerd", "repository_name": "soundcloud-api-wadl", "date_all_variable_collection": "2023-09-11", "description": "Description of the SoundCloud API in wadl xml", "size": 108, "stargazers_count": 2, "watchers_count": 2, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "earth2marsh", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/freenerd/SoundCloud-Map", "owner": "freenerd", "repository_name": "SoundCloud-Map", "date_all_variable_collection": "2023-09-11", "description": "SoundCloud Map displays the latest music uploaded to SoundCloud on a Google Maps map", "size": 1232, "stargazers_count": 28, "watchers_count": 28, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 10, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 22, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 10, "open_issues": 22, "watchers": 28, "default_branch": "master", "contributors": [{"contributor": "freenerd", "contributions": 35}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 93301}, {"language": "Python", "num_chars": 58447}], "readme": "SoundCloud Map displays the latest music uploaded to SoundCloud on a Google Maps map. It features track playback, genre-based filtering and an easy-to-use user interface. It has been implemented by using Python on Google App Engine. The front-end uses jQuery as well as the SoundCloud Javascript Player and Soundmanager 2.\n\nThe application has been created by Johan Uhle in the summer term 2009 at Hasso Plattner Institute in Potsdam / Germany. It has been further developed by Johan Uhle, Eric Wahlforss and Katharina Birkenbach during and after the Music Hackday in Berlin autumn 2009.\n\nA live version of SoundCloud Map can be found under the name TracksOnAMap here\nhttp://www.tracksonamap.com\nhttp://www.twitter.com/tracksonamap\n\nA paper about an early version of the app, it's functionality and possible extensions has been released here\nhttp://www.freenerd.de/soundcloudmap-paper/\n\nThe source code has been released on Github here\nhttp://github.com/freenerd/SoundCloud-Map/\n\nYou are welcome to use, install, fork or do whatever you like. Reference to me is always a nice thing :)\n\nJohan Uhle\nhttp://www.freenerd.de\nhttp://www.twitter.com/freenerd\n\nEric Wahlforss\nhttp://eric.wahlforss.com\nhttp://www.twitter.com/ericw\n\nKatharina Birkenbach\nhttp://the-daily-mess.de  \nhttp://www.twitter.com/kapony\n\nInstallation:\n\n1.) Open a new app on Google App Engine\n2.) Get a Google Maps Key for that app url \n3.) Create a file settings_private.py and set the variable GOOGLE_MAPS_API_KEY\n4.) Upload to App Engine and let the magic happen\n\nNote: Before any marker are displayed on the map the database cache has to be updated via the cron job. This may take some time depending on the traffic at the SoundCloud server so best is you get yourself something to eat and come back in 20 minutes. Check the logs at your App Engine Admin Dashboard to see, how the backend update is doing. If you are running in the development server, you have to call the cron job by yourself via http://localhost:8080/backend-update. Afterwards go to the Admin Console and run all the tasks queued in the default queue. "}
{"url": "https://github.com/freenerd/soundcloud-social", "owner": "freenerd", "repository_name": "soundcloud-social", "date_all_variable_collection": "2023-09-11", "description": "Listen to a track on SoundCloud together with others", "size": 626, "stargazers_count": 9, "watchers_count": 9, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 9, "default_branch": "master", "contributors": [{"contributor": "roelven", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 48693}, {"language": "Ruby", "num_chars": 16790}], "readme": "SoundCloud Social\n\nPlay tracks from soundcloud collaboratively and chat about them. Heavily inspired by http://www.youtubesocial.com\nThe track is started synchronously. All participants always hear the same position of the song. Everyone can chat with each other while the track plays.\n\nThis hack was build by Johan after an idea by Nils at the Music Hack Day Barcelona 2010.\n\nUsed technology:\nSoundCloud Javascript Widget Player\nRails 3\nSocky\n\nHow to install:\nMake sure you have Ruby 1.9.2 running. Install all gems with \"bundle install\".\n\nHow to run:\n1) Make sure that config.yml and config/socky_hosts.yml point to your server (if in development then localhost)\n2) start rails with 'rails server'\n3) start socky websockets server with 'socky -c config.yml'\n"}
{"url": "https://github.com/freenerd/teletask-cli", "owner": "freenerd", "repository_name": "teletask-cli", "date_all_variable_collection": "2023-09-11", "description": "Some command-line tools for the TeleTask service of the HPI Potsdam university", "size": 151, "stargazers_count": 9, "watchers_count": 9, "language": "Ruby", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 9, "default_branch": "master", "contributors": [{"contributor": "freenerd", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Ruby", "num_chars": 4850}], "readme": "# Teletask-cli\n## What?\n\nMy university, the Hasso-Plattner-Institute in Potsdam/Germany, has an extensive online repository of recorded lecture videos at http://tele-task.de/. Sadly the website is not an engineering highlight. Thus most people just want to fetch the video assets and consume them in other ways. Boom, this script should help you.\n\n## Installation\n\nIt's a ruby script. I used ruby 2.0 for development, but it should also run with ruby 1.9.x. Packet management is done via bundler.\n\n```\n  gem install bundler\n  bundle install\n```\n\nTo download videos you need the `wget` tool. It usually ships with your OS, otherwise you can use your favorite packet management tool to download it, e.g. via `brew install wget` or `apt-get install wget`.\n\n## Features\n\nAs input you always need to provide a feed url. You can obtain the url from Teletask on the lecture page on the right top corner. It's not the rss-logo (`Lecture-Feed of Series`) but the iTunes-y cube next to it (`Feed of Series`).\n\n### Feed to XSPF\n  `ruby teletask-cli.rb --xspf http://tele-task.de/feeds/series/946/`\n  `ruby teletask-cli.rb -x http://tele-task.de/feeds/series/946/`\n\n  XSPF is a playlist format that can be read by many popular media players, e.g. VLC. It also accepts urls, thus you can stream right away.\n\n  The cli option `--xspf` accepts a url to a series-feed on Teletask. The generated `output.xspf` links directly to the .mp4 assets on the Teletask servers. You should be able to drag-and-drop the xspf playlist into your favorite player and stream the videos directly.\n\n### Download videos\n  `ruby teletask-cli.rb --download http://tele-task.de/feeds/series/946/`\n  `ruby teletask-cli.rb -d http://tele-task.de/feeds/series/946/`\n\n  You can download all .mp4 video assets by using the `-x` cli option with the feed url. The files will be saved with the original file names in the folder you executed the script in. Downloading happens via `wget`.\n\n## Contributing\nFork away. I'm happy to accept pull requests, there is a lot of stuff to be added.\n\n"}
{"url": "https://github.com/freenerd/versioning-saas-paper", "owner": "freenerd", "repository_name": "versioning-saas-paper", "date_all_variable_collection": "2023-09-11", "description": "Paper for the HPI master's course \"Software-as-a-Service and Multi-tenancy\" 2013", "size": 1324, "stargazers_count": 1, "watchers_count": 1, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "freenerd", "contributions": 50}, {"contributor": "mschneider", "contributions": 21}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "Dear LLNCS user,\n\nThe files in this directory belong to the LaTeX2e package for\nLecture Notes in Computer Science (LNCS) of Springer-Verlag.\n\nIt consists of the following files:\n\n  readme.txt         this file\n\n  history.txt        the version history of the package\n\n  llncs.cls          the LaTeX2e document class\n\n  llncs.dem          the sample input file\n\n  llncs.doc          the documentation of the class (LaTeX source)\n  llncsdoc.pdf       the documentation of the class (PDF version)\n  llncsdoc.sty       the modification of the class for the documentation\n  llncs.ind          an external (faked) author index file\n  subjidx.ind        subject index demo from the Springer book package\n  llncs.dvi          the resultig DVI file (remember to use binary transfer!)\n\n  sprmindx.sty       supplementary style file for MakeIndex\n                     (usage: makeindex -s sprmindx.sty <yourfile.idx>)\n\n  splncs.bst         old BibTeX style for use with llncs.cls\n\n  splncs_srt.bst     ditto with aphabetic sorting\n\n  splncs03.bst       current LNCS BibTeX style with aphabetic sorting\n\n  aliascnt.sty       part of the Oberdiek bundle; allows more control over\n                     the counters associated to any numbered item\n  remreset.sty       by David Carlisle\n"}
{"url": "https://github.com/freenerd/wadl-library", "owner": "freenerd", "repository_name": "wadl-library", "date_all_variable_collection": "2023-09-11", "description": "Collection of WADL (Web Application Description Language) representations for APIs, extended for Apigee.", "size": 617, "stargazers_count": 1, "watchers_count": 1, "language": null, "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "earth2marsh", "contributions": 31}, {"contributor": "mager", "contributions": 12}, {"contributor": "umbrae", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "For more info, see the project wiki at http://wiki.github.com/apigee/wadl-library/\n"}
{"url": "https://github.com/fsr-de/1327", "owner": "fsr-de", "repository_name": "1327", "date_all_variable_collection": "2023-09-11", "description": "CMS for a student representatives website", "size": 6063, "stargazers_count": 20, "watchers_count": 20, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 31, "mirror_url": null, "archived": true, "disabled": false, "open_issues_count": 93, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 31, "open_issues": 93, "watchers": 20, "default_branch": "master", "contributors": [{"contributor": "janno42", "contributions": 327}, {"contributor": "Bartzi", "contributions": 315}, {"contributor": "invliD", "contributions": 170}, {"contributor": "Nef10", "contributions": 133}, {"contributor": "karyon", "contributions": 49}, {"contributor": "hendraet", "contributions": 42}, {"contributor": "jeriox", "contributions": 37}, {"contributor": "LoadingByte", "contributions": 11}, {"contributor": "kaifabian", "contributions": 8}, {"contributor": "Paula-Kli", "contributions": 7}, {"contributor": "T4rikA", "contributions": 6}, {"contributor": "SilvanVerhoeven", "contributions": 5}, {"contributor": "felixrindt", "contributions": 5}, {"contributor": "PFischbeck", "contributions": 4}, {"contributor": "cmfcmf", "contributions": 3}, {"contributor": "felixauringer", "contributions": 3}, {"contributor": "dependabot[bot]", "contributions": 2}, {"contributor": "tzwenn", "contributions": 2}, {"contributor": "julkw", "contributions": 1}, {"contributor": "MerlindlH", "contributions": 1}, {"contributor": "frcroth", "contributions": 1}, {"contributor": "gritfessel", "contributions": 1}, {"contributor": "l--f", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 429616}, {"language": "HTML", "num_chars": 124954}, {"language": "SCSS", "num_chars": 47204}, {"language": "JavaScript", "num_chars": 14685}, {"language": "Shell", "num_chars": 1676}], "readme": "1327\n====\n\n**THIS PROJECT IS DEPRECATED! No security updates, bugfixes or support will be provided. For the successor of myhpi.de, head to the [new project](https://github.com/fsr-de/myHPI).**\n\nA student representatives website.\n\n## Development\n\nYou need to download the source code of 1327 to contribute:\n\n```bash\ngit clone https://github.com/fsr-de/1327.git\n```\n\nFreshly created code needs to be tested - besides our use of unit tests, linting and continous integration, it is possible to run the application in a non-production environment using *Vagrant* or a *Virtual Environment*.\n\n1327 requires `Python 3.6` or higher.\n\n### Vagrant\n\nYou can simply set up an execution environment using `vagrant`:\n\n```bash\nvagrant up\n```\n\nThis will set up a virtual machine and run it. Running this for the first time might take a while.\n\nTo connect to it and start the application do:\n\n```bash\nvagrant ssh\n# This will take you inside the virtual machine\n./manage.py run\n```\n\nAt that point you created a vagrant box, running a [PostgreSQL](https://www.postgresql.org/) database server, [Apache](https://httpd.apache.org/) web server and the [Django](https://www.djangoproject.com/) application. The contents are available on the default port `8000`, which allows you to access the website at `http://localhost:8000`.\n\nTo login with your local user instead of the default OpenID login, you have to visit `http://localhost:8000/login?local_login=1`\n\n### Virtual Environment\n\nAnother way of executing this django application is the use of a virtual python environment. This way bypasses the needs for a virtual machine and simplifies the life with multiple python versions installed.\n\nBefore creating a virtual environment, make sure to use `Python 3.6` or higher:\n\n```bash\npython --version\n# example output\nPython 3.6.0\n```\n\nNow you can create a virtual environment with that python version:\n\n```bash\npython -m venv env\nsource env/bin/activate\npip install -r requirements-dev.txt\npython manage.py migrate\npython manage.py createsuperuser --username=admin\npython manage.py run\n```\n\nAfter you're done with these steps, you'll need to install all static dependencies\nvia [Yarn](https://yarnpkg.com/lang/en/).\n1. Install Yarn\n2. go into the directory `static`\n3. run the command `yarn`\n\n#### Troubleshooting\n\n| Error         | Solution    |\n| ------------- |-------------|\n| `Fatal error: Python.h: No such file or directory`      | Are you on a Debian system (e.g. Ubuntu)? Debian doesn't install development tools by default. Since some of the 1327 dependencies need to be compiled, we need those. You need to install them in your system, e.g. for Python 3.6 via `sudo apt-get install python3.6-dev`, and then recreate the virtual environment.\n\n## Deployment\n\nFor deploying on a single machine 1327 you'll need to install all requirements from `requirements.txt`, and you can follow these [instructions](https://github.com/fsr-itse/1327/wiki/Deployment), for setting up a webserver and starting all scripts using a Process Control System, if you like.\nYou'll also need to setup yarn, as indicated in the last section.\n\n## License\n\nThe software is licensed under the terms of the [MIT license](LICENSE). Please note that non-MIT-licensed contents might be part of this repository.\n"}
{"url": "https://github.com/fsr-de/docs", "owner": "fsr-de", "repository_name": "docs", "date_all_variable_collection": "2023-09-11", "description": "Dokumente der Fachschaft Digital Engineering an der Universit\u00e4t Potsdam", "size": 89, "stargazers_count": 22, "watchers_count": 22, "language": null, "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 10, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 10, "open_issues": 0, "watchers": 22, "default_branch": "master", "contributors": [{"contributor": "janno42", "contributions": 39}, {"contributor": "domoritz", "contributions": 8}, {"contributor": "Nef10", "contributions": 4}, {"contributor": "karyon", "contributions": 3}, {"contributor": "felixrindt", "contributions": 2}, {"contributor": "tzwenn", "contributions": 2}, {"contributor": "BenBals", "contributions": 1}, {"contributor": "Mupico", "contributions": 1}, {"contributor": "MarcelGarus", "contributions": 1}, {"contributor": "MerlindlH", "contributions": 1}, {"contributor": "SilvanVerhoeven", "contributions": 1}, {"contributor": "frcroth", "contributions": 1}, {"contributor": "phSch08", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "## Dokumente der Fachschaft Digital Engineering an der Universit\u00e4t Potsdam\n***Documents of the Digital Engineering Student Body at the University of Potsdam***\n\n- Fachschaft Digital Engineering / *Digital Engineering Student Body*\n    - [Satzung](https://github.com/fsr-de/docs/blob/master/satzung.md) / [*Statutes*](https://github.com/fsr-de/docs/blob/master/statutes.md)\n    - [Wahlordnung](https://github.com/fsr-de/docs/blob/master/wahlordnung.md) / [*Electoral Code*](https://github.com/fsr-de/docs/blob/master/electoral_code.md)\n    - [Gesch\u00e4ftsordnung Vollversammlung](https://github.com/fsr-de/docs/blob/master/geschaeftsordnung-vollversammlung.md) / [*Rules of Procedure General Meeting*](https://github.com/fsr-de/docs/blob/master/rules_of_procedure-general_meeting.md)\n- Fachschaftsrat Digital Engineering / *Digital Engineering Student Representative Group*\n    - [Gesch\u00e4ftsordnung](https://github.com/fsr-de/docs/blob/master/geschaeftsordnung-fachschaftsrat.md) / [*Rules of Procedure*](https://github.com/fsr-de/docs/blob/master/rules_of_procedure-student_representative_group.md)\n\n-----\n\n**\u00c4nderungen**\n\nPull Requests f\u00fcr redaktionelle \u00c4nderungen und Korrekturen sind herzlich willkommen. Wenn du inhaltliche \u00c4nderungen machen m\u00f6chtest, reiche sie bitte beim Fachschaftsrat ein.\n\n- Redaktionelle \u00c4nderungen sind mit `[nicht inhaltlich]` in der Commit Message zu kennzeichnen.\n- F\u00fcr Zeilenenden ist der Unix-Style zu nutzen.\n- Alle Dateien sind UTF-8 encoded.\n\n\n***Changes***\n\n*Pull requests for editorial changes and corrections are welcome. If you want to make substantive changes, please send them to the Student Representative Group.*\n\n- *Editorial changes must be marked with `[nicht inhaltlich]` in the commit message.*\n- *Use Unix style line endings.*\n- *All files must be UTF-8 encoded.*\n"}
{"url": "https://github.com/fsr-de/fsr-deployment", "owner": "fsr-de", "repository_name": "fsr-deployment", "date_all_variable_collection": "2023-09-11", "description": "Configuration files for the FSR infrastructure deployment", "size": 37, "stargazers_count": 0, "watchers_count": 0, "language": "Dockerfile", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "lukasrad02", "contributions": 43}, {"contributor": "jeriox", "contributions": 4}, {"contributor": "fsr-admin", "contributions": 2}, {"contributor": "frcroth", "contributions": 2}, {"contributor": "phSch08", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Dockerfile", "num_chars": 1170}, {"language": "Shell", "num_chars": 695}]}
{"url": "https://github.com/fsr-de/myHPI", "owner": "fsr-de", "repository_name": "myHPI", "date_all_variable_collection": "2023-09-11", "description": "Django/Wagtail page serving myhpi.de", "size": 1054, "stargazers_count": 8, "watchers_count": 8, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 8, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 63, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 8, "open_issues": 63, "watchers": 8, "default_branch": "main", "contributors": [{"contributor": "frcroth", "contributions": 94}, {"contributor": "dependabot[bot]", "contributions": 92}, {"contributor": "SilvanVerhoeven", "contributions": 36}, {"contributor": "jeriox", "contributions": 36}, {"contributor": "Paula-Kli", "contributions": 23}, {"contributor": "DrEGZo", "contributions": 18}, {"contributor": "ksturtzkopf", "contributions": 9}, {"contributor": "T4rikA", "contributions": 9}, {"contributor": "lukasrad02", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["django", "python", "wagtail", "wagtail-cms"], "languages": [{"language": "Python", "num_chars": 123665}, {"language": "HTML", "num_chars": 33306}, {"language": "JavaScript", "num_chars": 23366}, {"language": "SCSS", "num_chars": 10789}, {"language": "Dockerfile", "num_chars": 516}, {"language": "CSS", "num_chars": 177}, {"language": "Shell", "num_chars": 155}], "readme": "# myHPI\n\n[![tests](https://github.com/fsr-de/myHPI/actions/workflows/tests.yml/badge.svg)](https://github.com/fsr-de/myHPI/actions/workflows/tests.yml)\n[![Coverage Status](https://coveralls.io/repos/github/fsr-de/myHPI/badge.svg?branch=main)](https://coveralls.io/github/fsr-de/myHPI?branch=main)\n\nThis tool is used to manage the student representative website at https://myhpi.de. It is a CMS based on Wagtail/Django and adds several functionalities like polls.\n\n## Development setup\n\nTo set up a development version on your local machine, you need to execute the following steps:\n\n1. Check out repository and cd to it\n1. Set up a virtualenv for the project with Python >=3.8 and activate it\n1. Install poetry (if not already installed): `curl -sSL https://install.python-poetry.org/ | python -`\n1. Install dependencies with `poetry install`\n1. Install bootstrap with `python install-bootstrap.py`\n1. Create env file by copying the `.env.example` file to `.env`, e.g. `cp .env.example .env` (Notice that for some functionality like OIDC some settings must be changed)\n1. Migrate the database with `python manage.py migrate`\n1. Compile translations with `python manage.py compilemessages` (does not work on Windows, recommended to skip this step or see [docs](https://docs.djangoproject.com/en/4.0/topics/i18n/translation/#gettext-on-windows))\n1. Create a local superuser with `python manage.py createsuperuser`\n1. Start the development server with `python manage.py runserver`\n1. Open your web browser, visit `http://localhost:8000/admin` and log in with the user you just created\n\n### Tests\n\nTest the code with `python manage.py test myhpi.tests`.\n\n### Code style\n\nWe recommend installing a pre-commit hook with `pre-commit install`. That will (look at `.pre-commit-config.yaml`) before every commit\n\n-   run `autoflake` with a couple of flags to remove unused imports,\n-   run `isort .` to sort imports,\n-   run `black .` to format the code. You can also check out the [IDE integration](https://github.com/psf/black#editor-integration)\n\nIf you want to do that manually, run `pre-commit run --all-files`. Next to that, we also run `pylint myhpi` to check for semantic issues in the code.\n\n## Tips\n\n- To create translations, run `django-admin makemessages -l de` in the myhpi directory.\n\n### Reset database\n\n1. Delete `db.sqlite3`\n2. Conduct development setup steps 7+\n"}
{"url": "https://github.com/georgt99/Lamanizer", "owner": "georgt99", "repository_name": "Lamanizer", "date_all_variable_collection": "2023-09-11", "description": "Optimizing Linkages by encapsulating rigid components", "size": 40, "stargazers_count": 0, "watchers_count": 0, "language": "C#", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "georgt99", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C#", "num_chars": 10954}], "readme": "# Lamanizer\n Optimizing Linkages by encapsulating rigid components\n"}
{"url": "https://github.com/georgt99/SymboLinkage", "owner": "georgt99", "repository_name": "SymboLinkage", "date_all_variable_collection": "2023-09-11", "description": "Simulating 3D-linkages in Unity using symbolic kinematics", "size": 2851, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "georgt99", "contributions": 37}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 4986104}, {"language": "C", "num_chars": 66661}, {"language": "C#", "num_chars": 33770}, {"language": "CMake", "num_chars": 1444}, {"language": "Starlark", "num_chars": 730}]}
{"url": "https://github.com/geveh/GLOFdetection", "owner": "geveh", "repository_name": "GLOFdetection", "date_all_variable_collection": "2023-09-11", "description": "Scripts and input data to detect GLOFs from Landsat images and DEMs", "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "geveh", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# GLOFdetection\nScripts and input data to detect GLOFs from Landsat images and DEMs\n\n\n### References\nVeh, G., Korup, O., Roessner, S., and Walz, A.: Detecting Himalayan glacial lake outburst floods from Landsat time series, Remote Sens. Environ., 207, 84\u201397, https://doi.org/10.1016/j.rse.2017.12.025, 2018.\n\nVeh, G., Korup, O., Specht, S., Roessner, S., and Walz, A.: Unchanged frequency of moraine-dammed glacial lake outburst floods in the Himalaya, Nat. Clim. Change, 2000, 1\u20135, https://doi.org/10.1038/s41558-019-0437-5, 2019.\n"}
{"url": "https://github.com/geveh/GLOFhazard", "owner": "geveh", "repository_name": "GLOFhazard", "date_all_variable_collection": "2023-09-11", "description": "This repository contains the source codes to estimate GLOF peak discharges from the Himalayan lake-size distribtution, and to estimate return periods of GLOF volumes and peak discharges in the entire Himalayas and seven subregions.", "size": 67, "stargazers_count": 1, "watchers_count": 1, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "geveh", "contributions": 20}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 84126}, {"language": "Stan", "num_chars": 2338}], "readme": "# GLOFhazard\n\nThis repository contains the source codes to estimate GLOF peak discharges from the Himalayan lake-size distribution, \nand to estimate return periods of GLOF volumes and peak discharges in the entire Himalayas and seven subregions.\nA mandatory prerequisite to run the scripts is to install R (https://www.r-project.org/) and \nRStudio (https://rstudio.com) on your machine. The comments within the scripts provide further details on model dependencies\nand usage of functions. \n\n\n## Scripts\n\n### bayes_lm_piecewise_regression_stan.R\n\nBayesian piecewise regression model to learn peak discharge Qp from eta, the product of flood volume and the breach rate. Written in R.\n\n### lm_piecewise_const.stan\n\nThis model calls a script to learn the posterior distributions of the model parameters, written in STAN.\n\n### R_Script_lake_area_vs_max_depth.R\n\nRobust regression model to estimate the maximum depth of Himalayan glacier lakes from glacier lake area.\n\n### R_Script_Hazard_from_GLOFs_PNAS_supp.R\n\nScript to estimate regional GLOF hazard from empirical GLOF rates and predicted GLOF volumes and discharges. Contains all commands to reproduce the figures from the associated manuscript.\n\n### HDIofMCMC.R\n\nParts of our codes are based on the HDI function from Kruschke, J. K. (2014). Doing Bayesian Data Analysis: \nA Tutorial with R, JAGS, and Stan. 2nd Edition. Academic Press / Elsevier. We redistribute this function for ease of use, though the original function can be found here: https://sites.google.com/site/doingbayesiandataanalysis/software-installation\n\n\n## Input data\n\n... can be found here: https://doi.org/10.5281/zenodo.3523213\n\n\n## References\n\nVeh, G., Korup, O., & Walz, A. (2020). Hazard from Himalayan glacier lake outburst floods. Proceedings of the National Academy of Sciences, 117(2), 907-912.\n\n## Contact\n\nGeorg Veh\n\nWorking group on natural hazards\n\nUniversity of Potsdam\n\ngeorg.veh@uni-potsdam.de\n\nhttps://www.uni-potsdam.de/de/umwelt/forschung/ag-naturgefahren.html\n"}
{"url": "https://github.com/geveh/GLOFsusceptibility", "owner": "geveh", "repository_name": "GLOFsusceptibility", "date_all_variable_collection": "2023-09-11", "description": "Repository to model the susceptibility of Himalayan glaciers to sudden outburst floods.", "size": 1007, "stargazers_count": 1, "watchers_count": 1, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "geveh", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# GLOFsusceptibility\n\nThis repository contains the source code, as well as the two needed data sets to run it, to estimate susceptibility of Hindu-Kush Karakoram Himalaya (HKKH) glacier lakes to GLOFs in the past four decades. The code describes four Bayesian multi-level logistic regression models, in which we encode and test the possible influences of glacier lake area and its dynamics, catchment area, regional glacier-mass balances, and monsoonality on a given lake's GLOF history. The script, which is deposited as a commented Rmarkdown-file, has to be run in R (https://www.r-project.org/) and RStudio (https://rstudio.com). Data compiled in the two data sets are freely available from: \n\n- Shuttle Radar Topography Mission (SRTM) from the US Geological Survey (https://www.earthexplorer.usgs.gov) \n- CHELSA Bioclim data set (https://chelsa-climate.org/bioclim/): Karger, D. N., Conrad, O., B\u00f6hner, J., Kawohl, T., Kreft, H., Soria-Auza, R. W., Zimmermann, N. E., Linder, H. P. and Kessler, M.: Climatologies at high resolution for the earth\u2019s land surface areas, Sci. Data, 4, 1\u201320, doi:10.1038/sdata.2017.122, 2017. \n- regional glacier-mass balances: Brun, F., Berthier, E., Wagnon, P., K\u00e4\u00e4b, A. and Treichler, D.: A spatially resolved estimate of High Mountain Asia glacier mass balances from 2000 to 2016, Nat. Geosci., 10(9), 668\u2013673, doi:10.1038/ngeo2999, 2017.\n- glacier lake inventories: Maharjan, S. B., Mool, P. K., Lizong, W., Xiao, G., Shrestha, F., Shrestha, R. B., Khanal, N. R., Bajracharya, S. R., Joshi, S., Shai, S. and Baral, P.: The Status of Glacial Lakes in the Hindu Kush Himalaya, Kathmandu., 2018.\nWang, X., Guo, X., Yang, C., Liu, Q., Wei, J., Zhang, Y., Liu, S., Zhang, Y., Jiang, Z. and Tang, Z.: Glacial lake inventory of High Mountain Asia (1990\u20132018) derived from Landsat images, Earth Syst. Sci. Data Discuss., (January), 1\u201323, doi:10.5194/essd-2019-212, 2020.\n- GLOF inventories: Veh, G., Korup, O., Specht, S., Roessner, S. and Walz, A.: Unchanged frequency of moraine-dammed glacial lake outburst floods in the Himalaya, Nat. Clim. Chang., 2000, 1\u20135, doi:10.1038/s41558-019-0437-5, 2019.\n\n\n## BMR_GLOFs_HKKH.Rmd\n\nCommented script written in R describing the setup, output, and predictive oerformance of four Bayesian multi-level logistic regression models which encode the potential influence of topographical, glaciological, and monsoonal drivers on GLOF susceptibility of HKKH lakes in the past four decades.\n\n## GLOF_HKH_Sep2020_2.csv\n\nThis data set has to be loaded into the script included in BMR_GLOFs_HKKH.Rmd. It contains 25 lake characteristics for an inventory of 3390 glacier lakes in the HKKH. \n\n## GLOFDataAll_Dates_GLIMS.txt\n\nThis data set has to be loaded into the script included in BMR_GLOFs_HKKH.Rmd. This file contains 107 characteristics for an inventory of 3390 glacier lakes in the HKKH\n\n## References\n\nFischer, M., Korup, O., Veh, G., and A. Walz: Controls of outburst of Himalayan moraine-dammed lakes. The Cryosphere (submitted).\n\n## Contact\n\nMelanie Fischer\nDFG research training group NatRiskChange\nUniversity of Potsdam\nmelaniefischer@uni-potsdam.de\n"}
{"url": "https://github.com/geveh/IceDamFailures", "owner": "geveh", "repository_name": "IceDamFailures", "date_all_variable_collection": "2023-09-11", "description": null, "size": 146, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "geveh", "contributions": 48}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 176950}, {"language": "Python", "num_chars": 2260}], "readme": "# Code for *\"Less extreme and earlier outbursts of ice-dammed lakes since 1900\"*\n\n## Overview\n\n**This repository contains six scripts to estimate trends in the volume (*V*<sub>0</sub>), peak discharge (*Q*<sub>p</sub>), timing (day of year *doy*), and source elevation (*Z*) of ice-dam failures on regional and local (i.e. lake-) level. In addition, we investigate the consequences of melting glacier dams on the magnitudes of GLOFs.**\n\n- [01_preprocessing.R](#01_lake_area_volumer)\n- [02_trends_in_Qp_and_V0.R](#02_trends_in_qp_and_v0r)\n- [03_trends_in_doy.R](#03_trends_in_doyr)\n- [04_glacier_volumes_and_ice_loss.R](#04_glacier_volumes_and_ice_lossr)\n- [05_trends_in_Z.R](#05_trends_in_zr)\n- [06_magnitudes_vs_elev_change.R](#06_magnitudes_vs_elev_changer)\n- [summary_stats_veh_revision.py](#summary_stats_veh_revisionpy)\n\nThe codes are written in the statistical programming language **R** (https://www.r-project.org/), Version 4.2.0, and called within\nthe Graphical User Interface **RStudio** (https://rstudio.com) under a Microsoft Windows 10 operating system. \nPlease install both **R and RStudio** on your machine to successfully run the codes and produce figures and R data objects.\n\nThe R codes depend on a number of packages, listed at the beginning of all scripts. Please install those packages before running the scripts. \nThe comments within the scripts provide further details on model dependencies and usage of functions. \n\nEach script will call one or more input data object(s), which are available via ***Zenodo***.  \nWe also use freely available digital elevation models (DEMs), glaciological data (glacier outlines, estimates of ice thickness and mass loss), and lake outlines. Please download the data from the web sources provided in the scripts.  \nPlease put all input files into the same folder, and change the folder used in the script to your folder structure. The scripts can be executed one after the other, with the user generating output that is used as input for the next script.\nThe scripts (and parts thereof) can also be run independent of each other using the input files (in most cases *.RDS* files) from Zenodo.\nEach script will produce output in form of a figure (displayed in the associate manuscript and Extended Data figures) or R-objects.\n\n## Scripts\n\n### 01_preprocessing.R\n\n**Script to preprocess a raw OpenOffice table of reported glacier lake outburst floods.**\n\n*Mandatory input data*: \n- \"Global_GLOF_database_2022_05_30.ods\" (table with all reported GLOFs. Compiliation as of May 30, 2022)\n- CRU TS V4.05 temperature data\n\n\n*Main outputs*: \n- \"all_glofs_tibble.RDS\" (R-object of all reported GLOFs in the global GLOF database)\n- \"all_glofs_V0_tibble.RDS\" (R-object of all GLOFs that have reported values of *V*<sub>0</sub>)\n- \"all_glofs_qp_tibble.RDS\" (R-object of all GLOFs that have reported values of *Q*<sub>p</sub>)\n- \"glof_reporting.pdf\" (Multi-panel histogram of reported values of all reported GLOFs, reported values of Qp, and reported values of V0 from ice-dammed lakes) \n- \"temp_doy_histogram.pdf\" (histogram that both shows the number of reported GLOFs and the mean air temperature in a given month)\n\n---\n\n### 02_trends_in_Qp_and_V0.R\n\n**Script to fit quantile regression models (50th and 90th percentile) of peak discharges *Q*<sub>p</sub> and volumes *V*<sub>0</sub> versus time \nfrom ice-dam failures in six mountain ranges.**\n\n*Mandatory input data*: \n- \"all_glofs_V0_tibble.RDS\" (R-object of all GLOFs that have reported values of *V*<sub>0</sub>)\n- \"all_glofs_qp_tibble.RDS\" (R-object of all GLOFs that have reported values of *Q*<sub>p</sub>)\n\n*Main outputs*: \n- \"qp_models.RDS\" (R-object with regional quantile regression models of *Q*<sub>p</sub> versus time for the 50th and 90th for 4 time periods)\n- \"V0_models.RDS\" (R-object with regional quantile regression models of *V*<sub>0</sub> versus time for the 50th and 90th for 4 time periods)\n- \"fig2.pdf\" (PDF figure containing the regional posterior slopes for *Q*<sub>p</sub> and *V*<sub>0</sub> for two different time periods)\n- \"all_pooled_mods.pdf\" (PDF figure containing the pooled trendes of *Q*<sub>p</sub> and *V*<sub>0</sub> for two different time periods)\n- \"qp_model_median_local.RDS\"  (R-object with local quantile regression models of median *Q*<sub>p</sub> versus time)\n- \"Qp_local.pdf\" (PDF figure showing temporal trends of median *Q*<sub>p</sub> for individual glacier lakes) \n- \"V0_model_median_local.RDS\"  (R-object with regional quantile regression models of median *V*<sub>0</sub> versus time)\n- \"V0_local.pdf\" (PDF figure showing temporal trends of median *V*<sub>0</sub> for individual glacier lakes) \n- \"local_posterior_trends.pdf\" (PDF figure showing posterior distributions of the trends in local *Q*<sub>p</sub> and V*<sub>0</sub>)\n\n---\n\n### 03_trends_in_doy.R\n\n**Script to estimate trends in the annual timing (*doy*, i.e. day in a given year) of ice-dam failures on regional and local scale.**\n\n*Mandatory input data*: \n- \"all_glofs_tibble.RDS\" (R-object with a preprocessed table of all reported GLOFs)\n\n*Output*: \n- \"doy_trends_per_region.RDS\" (R-object with regression models of *doy* versus time for all dated GLOFs in the six regions)\n- \"doy_change.pdf\" (Plot of the temporal trends in *doy* for each region, including the posterior differences in *doy* between 2021 and 1900)\n- \"doy_trends_per_glacier.RDS\"  (R-object with regression models of *doy* versus time for lakes with repeat GLOFs)\n- \"doy_local.pdf\" (Plot of local changes in *doy* versus time)\n- \"post_trend_doy_per_lake.pdf\"  (Plot of local  posterior differences in *doy* for each lake)\n\n---\n\n### 04_glacier_volumes_and_ice_loss.R\n\n**Script to obtain the total volumes of glaciers and their volume loss between 2000 and 2019 in 100-m elevation bins.**\n\n*Mandatory input data (Data sources from external repositories are provided in the script)*: \n- Folder \"Region_extents\" (Contains the ESRI shapefile *Extent_pol.shp* to display the extent of the study regions)\n- Glacier outlines from the Randolph Glacier Inventory (RGI)\n- Glacier surface DEMs from Farinotti et al. (2019)\n- Glacier volume DEMs from Farinotti et al. (2019)\n- Glacier elevation change data from Hugonnet et al. (2021)\n\n*Output*: \n- \"Regional_glacier_and_melt_volumes.rds\" (R-object containing the total volume of glacier volume and volume change between 2000 and 2019 in 100-m elevation bins)\n\n---\n\n### 05_trends_in_Z.R\n\n**Script to estimate regional trends in the source elevation (*Z*) of ice-dammed failures.**\n\n*Mandatory input data*: \n- Digital Elevation models from ALOS World 3D - 30m (AW3D30)\n- Files from the \"GDL_database\" (We created a merged lake inventory in ESRI shapefile format from regional lake databases. This lake database is available upon request)   \n- \"Regional_glacier_and_melt_volumes.rds\" (R-object containing the total volume of glacier volume and volume change between 2000 and 2019 in 100-m elevation bins)\n\n*Major outputs*: \n- \"gdl_database_centroid.RDS\" (R-object of glacier lake centroids in the six study regions)\n- \"glofs_ice_with_z.RDS\" (R-object of first reported GLOF from a given lake and its elevation)\n- \"Z_trends_per_region.RDS\" (R-object with a hierarchical regression models of *Z* versus time for dated GLOFs in the six regions between 1900 and 2021)\n- \"elev_trend.pdf\" (Plot of the change in GLOF source elevation for six regions between 1900 and 2021, including the posterior regression slope)\n- \"Lake_GLOF_elevation.pdf\" / \"Lake_GLOF_elevation.png\" (Plot of the elevation distribution of historic burst ice-dammed lakes and present-day ice-dammed lakes for six regions between 1900 and 2021)\n\n---\n\n### 06_magnitudes_vs_elev_change.R\n\n**Script to estimate local trends of  V<sub>0</sub> and  Q<sub>p</sub> with elevation change of the glacier dam.**\n\n*Mandatory input data*: \n\n- Folder \"dh_pergla_cut\" (Tables of cumulative elevation change (in m) for glaciers with repeat GLOFs between 2000 and 2019)\n- \"all_glofs_tibble.RDS\" (R-object with a preprocessed table of all reported GLOFs)\n- \"all_glofs_V0_tibble.RDS\" (Table of lakes with repeat GLOFs and reported V<sub>0</sub>)\n- \"all_glofs_qp_tibble.RDS\" (Table of lakes with repeat GLOFs and reported Q<sub>p</sub>)\n- Folder \"Region_extents\" (Contains the ESRI shapefile *Extent_pol.shp* to display the extent of the study regions)\n\n*Output*: \n\n- \"local_Qp_vs_dhdt_model.RDS\" (R-Object containing a hierarchical model of local changes in Q<sub>p</sub> versus glacier elevation change)\n- \"local_V0_vs_dhdt_model.RDS\" (R-Object containing a hierarchical model of local changes in V<sub>0</sub> versus glacier elevation change)\n- \"map_and_trends.pdf\" (Map of lakes with repeat GLOFs between 2000 and 2019; local trends of V<sub>0</sub> and Q<sub>p</sub> with cumulative changes in glacier dam elevation)\n- \"dam_thinning_rats.shp\" (ESRI shapefile showing mean annual elevation change of glacier dams with repeat outbursts between 2000 and 2019)\n- \"elev_change_per_glacier.pdf\" / \"elev_change_per_glacier.png\" (Plot of cumulative elevation change for each glacier that produced repeated GLOFs between 2000 and 2019)\n\n---\n\n### summary_stats_veh_revision.py\n\n**Script by Romain Hugonnet to obtain elevation changes from glacier dams. Please contact Romain Hugonnet, if you have further questions.**\n\n\n## Input data\n\nPlease visit the repository on Zenodo to obtain the input files.\n\n\n## References\n\nGeorg Veh, Natalie L\u00fctzow, Jenny Tamm, Lisa V. Luna, Romain Hugonnet, Kristin Vogel, Marten Geertsema, John J Clague, and Oliver Korup: *Less extreme and earlier outbursts from ice-dammed lakes since 1900*. Nature, 614, 701\u2013707, https://doi.org/10.1038/s41586-022-05642-9.\n\n## See also\n\nhttp://glofs.geoecology.uni-potsdam.de\n\n## Contact\n\n**Georg Veh**  \nPostdoctoral researcher in the research group on natural hazards  \nInstitute of Environmental Sciences and Geography  \nUniversity of Potsdam  \ngeorg.veh@uni-potsdam.de  \nhttps://www.uni-potsdam.de/de/umwelt/forschung/ag-naturgefahren.html\n"}
{"url": "https://github.com/geveh/LakeAndGLOFdetection", "owner": "geveh", "repository_name": "LakeAndGLOFdetection", "date_all_variable_collection": "2023-09-11", "description": "This repository contains codes to detect glacier lakes and glacier lake outburst floods (GLOFs) from Landsat time series", "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/geveh/MGEW23_WS2018_19", "owner": "geveh", "repository_name": "MGEW23_WS2018_19", "date_all_variable_collection": "2023-09-11", "description": "This is a repository containing instructions, scripts and homework from the lecture \"Basics of Quantifying Natural Hazards\", Geosciences, University of Potsdam. ", "size": 2733, "stargazers_count": 2, "watchers_count": 2, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 5, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 2, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 5, "open_issues": 2, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "geveh", "contributions": 29}, {"contributor": "niygoooo", "contributions": 15}, {"contributor": "andreabhh", "contributions": 10}, {"contributor": "rebamb", "contributions": 9}, {"contributor": "lbergi", "contributions": 8}, {"contributor": "1stJohnDoe", "contributions": 6}, {"contributor": "MelFi7", "contributions": 6}, {"contributor": "JMKII", "contributions": 5}, {"contributor": "saspo", "contributions": 3}, {"contributor": "NoraKrebs", "contributions": 2}, {"contributor": "gluedtke", "contributions": 2}, {"contributor": "MartinaR5", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 18605417}, {"language": "R", "num_chars": 4346}], "readme": "# MGEW23_WS2018_19\n\nThis is a repository containing instructions, scripts and homework from the lecture \"Basics of Quantifying Natural Hazards\", Geosciences, University of Potsdam.\nPlease upload all your documents here. If you have any questions, please contact the maintainer of this repository:\ngeorg.veh@uni-potsdam.de\n"}
{"url": "https://github.com/geveh/ReportingBias", "owner": "geveh", "repository_name": "ReportingBias", "date_all_variable_collection": "2023-09-11", "description": "Scripts for estimating historic trends in GLOF occurrences and potential biases in reporting", "size": 584, "stargazers_count": 1, "watchers_count": 1, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "geveh", "contributions": 38}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["andes", "atmospheric-warming", "bias", "climate-change", "european-alps", "glacier-lake-outburst-floods", "glofs", "high-mountain-asia", "himalaya", "inventory", "natural-hazards", "pacific-nw", "r", "reporting", "scandinavia", "temperature", "trends"], "languages": [{"language": "R", "num_chars": 85918}], "readme": "# ReportingBias\n\nThis repository contains two scripts, one that preprocesses a raw data table of reported GLOFs ([preprocessing.R](#preprocessingr)), and a second one ([assessing_bias.R](#assessing_biasr)) that  \n- estimates temporal and regional trends in reported GLOFs; \n- estimates GLOF trends from the predictors 'annual air temperatures' and 'research activity'; and\n- hind- and forecasts annual GLOF counts, based on these two predictors.\n\nThe codes are written in the statistical programming language **R** (https://www.r-project.org/) and run\nfrom the Graphical User Interface **RStudio** (https://rstudio.com) under a Microsoft Windows 10 operating system. \nTo successfully run the codes, please install both **R and RStudio** on your machine.\n\nThe R codes also depend on a number of packages, listed at the beginning of both scripts. \nPlease install those before running the codes. \nThe comments within the scripts provide further details on model dependencies and usage of functions. \n\n\n## Scripts\n\n### preprocessing.R\n\nPreparation script to obtain annual statistics of\n\n- GLOF counts by dam type;\n- glaciological research activity;\n- temperature; and\n- precipitation\n\nfrom the original Open-Office spreadsheet 'Global_GLOF_database_2021_06_09.ods', available at this page (see a detailed description in the section on [Input data](#global_glof_database_2021_06_09ods)).\nThe script produces the R-Data object *regional_glof_stats.rds*, which is already available on this page.\n\n### assessing_bias.R\n\nMain script to \n\n- find change points in time series of reported GLOFs, air temperatures, and glacier surveys;\n- estimate trends in GLOF reporting for each study region and dam type;\n- predict annual GLOF counts from air temperatures and the number of glacier surveys;\n- to hind- and forecast the number of GLOFs before and after the global break in GLOF reporting.\n- reproduce all figures in the manuscript.\n\n\n\n\n## Input data\n\n### Global_GLOF_database_2021_06_09.ods\n\nOpen-Office spreadsheet as of 09 June 2021 with seven sheets named after the regions, for which we obtained historical GLOF occurrences. \nEach sheet has 32 columns containing the attributes that we were able to collect for each GLOF. Empty cells mean 'No Data'. \nThe first row is the column name, followed by two rows with further description of the content and the data structure.\nThe content of the columns 'Major_RGI_Region', 'Mountain_range_Region', 'Glacier',\t'RGI_Glacier_Id', and\t'RGI_Glacier_Area' is from the\nRandolph Glacier Inventory, V6.0 (https://www.glims.org/RGI/rgi60_dl.html).\n\n\n### Region_extents.zip\n\nExtents of study regions in a WGS 84 / World Mercator projection\n\n\n### regional_glof_stats.rds\n\nR-Data object (a list with 8 entries) containing regional annual statistics of GLOF occurrences, temperatures, and research activity.\nDescription of the column names:\n- 'year': Year;\n- 'freq': Total number of reported GLOFs per year, including GLOFs from volcanic eruptions;\n- 'moraine': Number of moraine-dam failures per year;\n- 'ice': Number of ice-dam failures per year;\n- 'other': Number of GLOFs from other (bedrock, water pockets, supraglacial) or unknown sources;\n- 'volc': Number of GLOFs from subglacial lakes beneath ice-covered volcanoes;\n- 'mb_meas': Annual number of glacier surveys measuring in-situ mass balances from the WGMS database;\n- 'front_meas': Annual number of glacier surveys measuring in-situ front variations;\n- 'dch_meas': Annual number of glacier surveys measuring geodetic mass balances (includes also remote sensing studies);\n- 'all_meas': Annual sum of mb_meas, front_meas, and dch_meas;\n- 'mb_and_front': Annual sum of mb_meas and front_meas;\n- 'region': Name of the study region;\n- 'year_scale': Standardised years (zero mean and unit standard deviation);\n- 'temp_mean': Mean annual air temperature extracted from the CRU TS 4.05 dataset from all lakes that produced at least one GLOF in a given region;\n- 'temp_q25': 25th percentile of annual air temperatures in a given region;\n- 'temp_q75': 75th percentile of annual air temperatures in a given region;\n- 'pre_sum': total amount of precipitation in a given region.\n\n\n\n## References\n\nVeh, G., L\u00fctzow, N., Kharlamova; V., Petrakov, D., Hugonnet, R. & Korup, O.: *Trends, breaks, and biases in the frequency of reported glacier lake outburst floods. Earth's Future* (accepted)\n\n## See also\n\nhttp://glofs.geoecology.uni-potsdam.de\n\n## Contact\n\nGeorg Veh\n\nWorking group on natural hazards\n\nUniversity of Potsdam\n\ngeorg.veh@uni-potsdam.de\n\nhttps://www.uni-potsdam.de/de/umwelt/forschung/ag-naturgefahren.html\n"}
{"url": "https://github.com/geveh/ShadowsOnGlaciers", "owner": "geveh", "repository_name": "ShadowsOnGlaciers", "date_all_variable_collection": "2023-09-11", "description": "This repository provides R code to estimate elevation changes in shaded areas of glaciers", "size": 16, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "geveh", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 34137}], "readme": "# ShadowsOnGlaciers\nThis repository provides an R script to estimate elevation changes in shaded areas of glaciers.\n\nThe input data to run the script are on Zenodo (https://zenodo.org/record/8268976) under \"data_for_R_script.zip\". \n\nThe user needs to change the path to the files in the script to successfully run the script using the input data.\n\n## References\n\nPfau, M., Veh, G., and W. Schwanghart. Cast shadows reveal changes in glacier surface elevation. The Cryosphere, tc-2022-194 (accepted)\n\n## Contact\n\nGeorg Veh\n\nWorking group on natural hazards\n\nUniversity of Potsdam\n\ngeorg.veh@uni-potsdam.de\n\nhttps://www.uni-potsdam.de/de/umwelt/forschung/ag-naturgefahren.html\n"}
{"url": "https://github.com/goldencm/AOC", "owner": "goldencm", "repository_name": "AOC", "date_all_variable_collection": "2023-09-11", "description": "advent of code", "size": 87, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "goldencm", "contributions": 22}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 29218}, {"language": "Python", "num_chars": 12658}]}
{"url": "https://github.com/goldencm/blanc-os", "owner": "goldencm", "repository_name": "blanc-os", "date_all_variable_collection": "2023-09-11", "description": null, "size": 186, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "goldencm", "contributions": 47}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 123939}, {"language": "Assembly", "num_chars": 1471}, {"language": "Dockerfile", "num_chars": 1141}, {"language": "Shell", "num_chars": 666}]}
{"url": "https://github.com/goldencm/CardGameSuite", "owner": "goldencm", "repository_name": "CardGameSuite", "date_all_variable_collection": "2023-09-11", "description": "Rust practice with a game of GoFish", "size": 32827, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "goldencm", "contributions": 23}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 10709}], "readme": "# Card Game Suite\nThis suit of card games is built to test out the Rust programming language.\n\n\n## TODO:\n\n### DEBUG\n1.  Fix the GoFish AI to choose the correct card in a non repetative fashion\n\n### Implement\n1. Add poker the suite: \n    * Chips?\n    * Poker hand analyzer \n    * AI\n    * Multi over LAN\n\n2. GUI?\n\n### Document\n1. cards-lib\n2. GoFish"}
{"url": "https://github.com/goldencm/init.ubuntu", "owner": "goldencm", "repository_name": "init.ubuntu", "date_all_variable_collection": "2023-09-11", "description": null, "size": 3567, "stargazers_count": 0, "watchers_count": 0, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "goldencm", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 2609}], "readme": "### Goldencm's ubuntu init.sh\nThis build script has only been tested so far on WSL2 and may\nor may not be compatible with another linux distro\n\n### Requirements\n\n# Warning\nThis script by default will attempt to install a neovim config (mine by\ndefault) in the /etc/xdg/nvim directory. This will install the neovim config\nsystem wide. If that is your desired behavior then your neovim config requires\na sysinit.vim initialization file\n\n### Installed Apps\n\n1. Rustup\n2. Neovim\n3. Gcc\n4. Github Cli (for git authentication)\n5. Ripgrep\n\n\n### Change Log\n\n"}
{"url": "https://github.com/goldencm/portfolio-website", "owner": "goldencm", "repository_name": "portfolio-website", "date_all_variable_collection": "2023-09-11", "description": null, "size": 3336, "stargazers_count": 0, "watchers_count": 0, "language": "TypeScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "goldencm", "contributions": 26}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TypeScript", "num_chars": 16151}, {"language": "HTML", "num_chars": 4111}, {"language": "CSS", "num_chars": 3170}, {"language": "JavaScript", "num_chars": 1429}], "readme": "# PersonalWeb \n[![Deploy to Firebase Hosting on merge](https://github.com/goldencm/portfolio-website/actions/workflows/firebase-hosting-merge.yml/badge.svg?branch=main)](https://github.com/goldencm/portfolio-website/actions/workflows/firebase-hosting-merge.yml)\n\nThis project was generated with [Angular CLI](https://github.com/angular/angular-cli) version 12.2.7.\n\n## Development server\n\nRun `ng serve` for a dev server. Navigate to `http://localhost:4200/`. The app will automatically reload if you change any of the source files.\n\n## Code scaffolding\n\nRun `ng generate component component-name` to generate a new component. You can also use `ng generate directive|pipe|service|class|guard|interface|enum|module`.\n\n## Build\n\nRun `ng build` to build the project. The build artifacts will be stored in the `dist/` directory.\n\n## Running unit tests\n\nRun `ng test` to execute the unit tests via [Karma](https://karma-runner.github.io).\n\n## Running end-to-end tests\n\nRun `ng e2e` to execute the end-to-end tests via a platform of your choice. To use this command, you need to first add a package that implements end-to-end testing capabilities.\n\n## Further help\n\nTo get more help on the Angular CLI use `ng help` or go check out the [Angular CLI Overview and Command Reference](https://angular.io/cli) page.\n"}
{"url": "https://github.com/goldencm/resume", "owner": "goldencm", "repository_name": "resume", "date_all_variable_collection": "2023-09-11", "description": null, "size": 919, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "goldencm", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/goldencm/rust-RSA", "owner": "goldencm", "repository_name": "rust-RSA", "date_all_variable_collection": "2023-09-11", "description": null, "size": 196, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "goldencm", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 2439}, {"language": "Python", "num_chars": 1623}]}
{"url": "https://github.com/goldencm/rust-TypeSpeed", "owner": "goldencm", "repository_name": "rust-TypeSpeed", "date_all_variable_collection": "2023-09-11", "description": null, "size": 3243, "stargazers_count": 0, "watchers_count": 0, "language": "Rust", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "goldencm", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Rust", "num_chars": 15225}]}
{"url": "https://github.com/goldencm/student-survey-webapp", "owner": "goldencm", "repository_name": "student-survey-webapp", "date_all_variable_collection": "2023-09-11", "description": "A django based web application made for the Software Engineering course at SUNY Potsdam", "size": 21, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "goldencm", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 8029}, {"language": "Dockerfile", "num_chars": 131}], "readme": "# student-survey-webapp\nA django based web application made for the Software Engineering course at SUNY Potsdam\n[Check it out!](https://student-survey-webapp.herokuapp.com/)\n<!-- TABLE OF CONTENTS -->\n<details open=\"open\">\n  <summary><h2 style=\"display: inline-block\">Table of Contents</h2></summary>\n  <ol>\n    <li>\n      <a href=\"#about-the-project\">About The Project</a>\n      <ul>\n        <li><a href=\"#built-with\">Built With</a></li>\n      </ul>\n    </li>\n    <li>\n      <a href=\"#getting-started\">Getting Started</a>\n      <ul>\n        <li><a href=\"#prerequisites\">Prerequisites</a></li>\n        <li><a href=\"#installation\">Installation</a></li>\n      </ul>\n    </li>\n    <li><a href=\"#usage\">Usage</a></li>\n    <li><a href=\"#roadmap\">Roadmap</a></li>\n    <li><a href=\"#contributing\">Contributing</a></li>\n    <li><a href=\"#license\">License</a></li>\n    <li><a href=\"#contact\">Contact</a></li>\n    <li><a href=\"#acknowledgements\">Acknowledgements</a></li>\n  </ol>\n</details>\n\n\n \n<!-- ABOUT THE PROJECT -->\n## About The Project\n  This project is designed to be used as a student survey for the dean of SUNY Potsdam. The project is implemented under a team of seven for the CIS 356 course. MongoDB was chosen for its cloud capabilities to reduce overhead of passing around the database files between developers to reduce redundency. The web app is hosted at [https://student-survey-webapp.herokuapp.com/](https://student-survey-webapp.herokuapp.com/) in order to view the most recent configured branch without having to build on a local machine.\n\n### Built With\n\n* [Django](https://www.djangoproject.com/)\n* [Docker](https://www.docker.com/)\n* [MongoDB](https://www.mongodb.com/)\n\n\n\n<!-- GETTING STARTED -->\n## Getting Started\n\nTo get a local copy up and running follow these simple steps.\n\n### Prerequisites\n\n* docker/docker-compose\n* python\n\n### Installation\n\n1. Clone the repo\n   ```sh\n   git clone https://github.com/goldencm/student-survey-webapp.git\n   ```\n2. Run docker-compose build\n\n3. Use the run.py for command arguements. Check out the Docs for the run.py file\n\n\n<!-- USAGE EXAMPLES -->\n## Usage\n\nTODO: Use this space to show useful examples of how a project can be used. Additional screenshots, code examples and demos work well in this space. You may also link to more resources.\n\n\n\n<!-- ROADMAP -->\n## Roadmap\n\nSee the [open issues](https://github.com/goldencm/student-survey-webapp/issues) for a list of proposed features (and known issues).\n\n\n\n<!-- CONTRIBUTING -->\n## Contributing\n\nContributions are what make the open source community such an amazing place to be learn, inspire, and create.\n\n1. Fork the Project\n2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)\n3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)\n4. Push to the Branch (`git push origin feature/AmazingFeature`)\n5. Open a Pull Request\n\n\n\n<!-- LICENSE -->\n## License\n\nNone as of yet\n\n\n\n<!-- CONTACT -->\n## Contact\n\n\nProject Link: [https://github.com/goldencm/student-survey-webapp/](https://github.com/goldencm/student-survey-webapp/)\nEmail: [goldencm203@potsdam.edu](goldencm203@potsdam.edu)\n\n\n<!-- ACKNOWLEDGEMENTS -->\n## Acknowledgements\n\n* []()\n* []()\n* []()\n\n\n\n\n\n<!-- MARKDOWN LINKS & IMAGES -->\n<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->\n[contributors-shield]: https://img.shields.io/github/contributors/github_username/repo.svg?style=for-the-badge\n[contributors-url]: https://github.com/github_username/repo/graphs/contributors\n[forks-shield]: https://img.shields.io/github/forks/github_username/repo.svg?style=for-the-badge\n[forks-url]: https://github.com/github_username/repo/network/members\n[stars-shield]: https://img.shields.io/github/stars/github_username/repo.svg?style=for-the-badge\n[stars-url]: https://github.com/github_username/repo/stargazers\n[issues-shield]: https://img.shields.io/github/issues/github_username/repo.svg?style=for-the-badge\n[issues-url]: https://github.com/github_username/repo/issues\n[license-shield]: https://img.shields.io/github/license/github_username/repo.svg?style=for-the-badge\n[license-url]: https://github.com/github_username/repo/blob/master/LICENSE.txt\n[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&logo=linkedin&colorB=555\n[linkedin-url]: https://linkedin.com/in/github_username\n"}
{"url": "https://github.com/GregwiseNoah/Advanced-Computational-Astrophysics", "owner": "GregwiseNoah", "repository_name": "Advanced-Computational-Astrophysics", "date_all_variable_collection": "2023-09-11", "description": "Exercises submitted for the course Advanced Computational Physics at the University of Potsdam", "size": 53664, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "GregwiseNoah", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 4596722}, {"language": "TeX", "num_chars": 13543}, {"language": "Python", "num_chars": 12961}], "readme": "# Advanced-Computational-astrophysics\nExercises submitted for the course Advanced Computational Physics at the University of Potsdam\n"}
{"url": "https://github.com/GregwiseNoah/FreeCodeCamp", "owner": "GregwiseNoah", "repository_name": "FreeCodeCamp", "date_all_variable_collection": "2023-09-11", "description": null, "size": 82190, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "GregwiseNoah", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 53521127}, {"language": "C", "num_chars": 704043}, {"language": "Cython", "num_chars": 464895}, {"language": "Jupyter Notebook", "num_chars": 215572}, {"language": "C++", "num_chars": 145470}, {"language": "PowerShell", "num_chars": 27099}, {"language": "Nu", "num_chars": 10101}, {"language": "Shell", "num_chars": 9276}, {"language": "Nix", "num_chars": 1839}, {"language": "Fortran", "num_chars": 1359}]}
{"url": "https://github.com/GregwiseNoah/GregwiseNoah", "owner": "GregwiseNoah", "repository_name": "GregwiseNoah", "date_all_variable_collection": "2023-09-11", "description": "Config files for my GitHub profile.", "size": 3040, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "GregwiseNoah", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["config", "github-config"], "languages": [], "readme": "Hello there <br>\n![obi wan popping up on screen](/assets/obi.gif \"General Kenobi\")\n\n\nLights sabers and deflector shields at maxiumum,\n# GregwiseNoah\n"}
{"url": "https://github.com/GregwiseNoah/link", "owner": "GregwiseNoah", "repository_name": "link", "date_all_variable_collection": "2023-09-11", "description": null, "size": 715, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "GregwiseNoah", "contributions": 13}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 1194}, {"language": "CSS", "num_chars": 294}], "readme": "# link"}
{"url": "https://github.com/grpranto/Aider---Web-Application", "owner": "grpranto", "repository_name": "Aider---Web-Application", "date_all_variable_collection": "2023-09-11", "description": "A platform where both of the faculties and student communicate with each other and get some features. A faculty can take online attendance and add courses. Student can also see their attendance marks, joined their desired courses by putting the enrollment key. ", "size": 32, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "grpranto", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 199996}, {"language": "CSS", "num_chars": 23487}, {"language": "HTML", "num_chars": 4442}]}
{"url": "https://github.com/grpranto/ANTLR-Project-Student-Information-", "owner": "grpranto", "repository_name": "ANTLR-Project-Student-Information-", "date_all_variable_collection": "2023-09-11", "description": "A string like \u201cMd. Golam Rasul (2016-1-60-080) (Rampura, Dhaka) (01622925060)\u201d can be covered with this grammar. And a successful parse tree will be generated with the indication name, id (year, semester, dept_code and roll), address, phone_number.", "size": 24, "stargazers_count": 0, "watchers_count": 0, "language": "ANTLR", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "grpranto", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["antlr4-grammar"], "languages": [{"language": "ANTLR", "num_chars": 587}]}
{"url": "https://github.com/grpranto/Confusion-Matrix-Calculator", "owner": "grpranto", "repository_name": "Confusion-Matrix-Calculator", "date_all_variable_collection": "2023-09-11", "description": "This desktop application returns the following important measurements - Accuracy, precision, sensitivity, specificity, F1-score smoothly!!", "size": 812, "stargazers_count": 0, "watchers_count": 0, "language": "C#", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "grpranto", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C#", "num_chars": 9967}]}
{"url": "https://github.com/grpranto/CPP", "owner": "grpranto", "repository_name": "CPP", "date_all_variable_collection": "2023-09-11", "description": "Algorithms, Data Structure", "size": 22, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "grpranto", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 23250}]}
{"url": "https://github.com/grpranto/Hospital-Management", "owner": "grpranto", "repository_name": "Hospital-Management", "date_all_variable_collection": "2023-09-11", "description": "A desktop app where admin can log in and entry the patients admission record. Nunit testing is included in this application.", "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/grpranto/Internet-Notifier-Desktop-Application", "owner": "grpranto", "repository_name": "Internet-Notifier-Desktop-Application", "date_all_variable_collection": "2023-09-11", "description": "A simple notifier desktop application which reminds you when the internet is up by beeping sound. It has been developed with the help of QT framework.", "size": 43, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "grpranto", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["cpp", "desktop-application", "qtcreator"], "languages": [{"language": "C++", "num_chars": 2136}, {"language": "QMake", "num_chars": 1429}]}
{"url": "https://github.com/grpranto/Kuzushiji-Classification-Deep-Learning", "owner": "grpranto", "repository_name": "Kuzushiji-Classification-Deep-Learning", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1493, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "grpranto", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 2417867}, {"language": "Python", "num_chars": 26993}], "readme": "# Kanji Classification\n\nThis is the practical part of a project that took place as part of the Deep Learning course at the Hasso Plattner Institute under the supervision of Prof. Dr. Lippert.<br />\nThe goal of this lecture was to train a model with the data of [Kuzushiji characters](https://www.kaggle.com/datasets/anokas/kuzushiji). After training, we should use the model for transfer learning on the [Chinese MNIST dataset](https://www.kaggle.com/datasets/gpreda/chinese-mnist). We were also advised to try alternatives to CNNs.\n\n## Requirements\n\n- Python 3.7 or higher\n\nFor the following requirements you could run ```pip -r requirements.txt``` (or something similar):\n- argparse\n- datetime\n- keras\n- matplotlib\n- numpy\n- os\n- pandas\n- PIL\n- sklearn\n- time\n\n## How to use\n\nUse -h/--help to show all possible arguments for the main.py.\n\nYou can run the main.py with different (optional) arguments:<br />\n-b/--balancing: Can be True or False and indicates whether the data should be balanced or not (default is True).<br />\n-bs/--batch_size: Can be an integer which indicates the batch size for training and testing (default is 128).<br />\n-c/--csv_file: Can be a (relational) path to a CSV file which is necessary for data loading for the Chinese MNIST dataset (default is an empty string).<br />\n-d/--data: Can be a (relational) path to a directory that contains the dataset to train the model. The directory should have the structure of subdirectories (named with the labels of the dataset) which contain the respective images (default is an empty string).<br />\n-e/--epochs: Can be an integer which indicates the number of training epochs (default is 50).<br />\n-g/--use_grayscale: Can be True or False and indicates whether grayscale images (8 bit images) will be used for transfer learning on a pretrained model that was trained on rgb images (24 bit images) (default is False).<br />\n-l/--label: Can be a string (without quotes) to add an individual label for the saved files (default is an empty string).<br />\n-ln/--load_from_npz: Can be True or False and indicates whether the data should be loaded from npz files (only with -np/--npz_paths argument to load from the passed paths) (default is False).<br />\n-lr/--learning_rate: Can be a float which indicates the learning rate (default is 0.0001).<br />\n-mp/--model_path: Can be a (relational) path to a local pretrained model to load it for transfer learning.<br />\n-np/--npz_paths: Can be a list of four (relational) paths to the npz files that contains the train images, train labels, test images and test labels (only with -ln True). For an example command see below (default is an empty list).<br />\n-pm/--pretrained_model: Can be resnet50 or vgg16 for selecting a pretrained model (ResNet50 or VGG16) for transfer learning.<br />\n-rs/--resize_shape: Can be two numbers which indicate the shape (width and height) of images to be resized (e.g., use \\'-rs 224 224\\' for the shape (224,224)) (default is (64,64)).<br />\n-sn/--save_to_npz: Can be True or False and indicates whether the loaded data should be saved as npz files (default is True).<br />\n-us/--upsampling_size: Can be an integer which indicates the upsampling size (default is 25).\n\n**HINT: Because of the defaults of the most arguments make sure that you pass the correct values.**\n\nExample commands:\n- You can run the following command if you have downloaded and extracted the [Kuzushiji dataset](https://www.kaggle.com/datasets/anokas/kuzushiji) and want to use the default values (here with the label \\'kanji\\'):<br />\n```python main.py -d path/to/archive/kkanji/kkanji2 -l kanji```\n\n- If you have downloaded and extracted the [Chinese MNIST dataset](https://www.kaggle.com/datasets/gpreda/chinese-mnist) and want to use the ResNet50 model for transfer learning, use the following command in your CLI (here with the label \\'pretrained_resnet\\'):<br />\n```python main.py -d path/to/chinese-MNIST/data/data -c path/to/chinese-MNIST/chinese_mnist.csv -pm resnet50 -l pretrained_resnet -b False -rs 224 224 -g True```<br />\n**HINT: Please be sure that you use -g True for pretrained models as ResNet50 and VGG16 because of the channels of the used images for training these models.**\n\n- If you have run the main.py once and the saving of the data as npz files was successful, you can load the data from these npz files to save time (here with the label \\'loaded_from_npz\\'):<br />\n```python main.py -ln True -np path/to/train_images.npz path/to/train_labels.npz path/to/test_images.npz path/to/test_labels.npz -l loaded_from_npz```\n\n- If you have a local pretrained model that you want to use for transfer learning with  [Chinese MNIST dataset](https://www.kaggle.com/datasets/gpreda/chinese-mnist) you can use the following command in your CLI (with no balancing):<br />\n```python main.py -d path/to/chinese-MNIST/data/data -c path/to/chinese-MNIST/chinese_mnist.csv -mp path/to/pretrained_model.h5 -l pretrained_model -b False```\n\n## Model files\n\nThe used and trained models can be found [here](https://drive.google.com/drive/folders/1EqbCbd32bO3biHrdts9aO1wVDTHMXmib?usp=sharing).\n\n## Dataset Links\n\nKuzushiji-49, Kuzushiji-MNIST, Kuzushiji-Kanji Datasets: https://www.kaggle.com/datasets/anokas/kuzushiji\n\nChinese-MNIST: https://www.kaggle.com/datasets/gpreda/chinese-mnist\n\n## Notes Regarding Demo File:\n\nWe made three demo files to represent our work with different datasets.\n\n1) demo.ipynb  --Represents main demo file where we worked with Kuzushiji-Kanji and Chinese-MNIST datasets along with transfer learning\n\n2) demo_kuzushiji_mnist_classification.ipynb  --Where we worked with Kuzushiji-MNIST dataset\n\n3) demo_kuzushiji_49_classification.ipynb  --Where we worked with Kuzushiji-49 dataset\n"}
{"url": "https://github.com/grpranto/Laser-Detection-Machine-Learning", "owner": "grpranto", "repository_name": "Laser-Detection-Machine-Learning", "date_all_variable_collection": "2023-09-11", "description": null, "size": 918, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "grpranto", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 4354650}], "readme": "# Laser-Detection-Machine-Learning\n\n<a name=\"readme-top\"></a>\n<p float=\"left\">\n  <img src=\"https://img.shields.io/badge/Python-FFD43B?style=for-the-badge&logo=python&logoColor=blue\">\n  <img src=\"https://img.shields.io/badge/Jupyter-F37626.svg?&style=for-the-badge&logo=Jupyter&logoColor=white\">\n  <img src=\"https://img.shields.io/badge/Pandas-2C2D72?style=for-the-badge&logo=pandas&logoColor=white\">\n  <img src=\"https://img.shields.io/badge/Numpy-777BB4?style=for-the-badge&logo=numpy&logoColor=white\">\n  <img src=\"https://img.shields.io/badge/scikit_learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white\">\n  \n</p>\n\n<!-- ABOUT THE PROJECT -->\n### About The Project\nThis machine learning project is a part of my Master's course `Machine Learning` to classify faulty and non-faulty lasers correctly.\n\n### Problem Statement\nFor the purpose of quality assurance, a manufacturer of medical lasers wants to introduce a system which recognizes defective products. For the lasers produced, a constant lightoutput with a frequency as constant as possible is desired. Certain fluctuations are accep-table; Lasers in which the power fluctuates to an intolerable extent should be sorted out.For this purpose, the intensity of each laser is measured for one minute \u2013 one measurement per second.\n\n### Implementation\n\n* four classifiers: `Decision Tree`, `Random Forest`, `SVM(Support Vector Machine)`, `KNN(KNN (K Nearest Neighbor)`\n* evaluation/permormance metrics: `accuracy`, `recall`, `precision`, `f1-score`, `confusion matrix`, `AUC`, `ROC curve`\n* dataset: `laser.mat`\n\n### justify model's robustness\nFollowing this steps to justify all model's robustness:\n* Model training using default parameters\n* Generating confusion matrix, classification report and ROC curve\n* Applying GridSearchCv for finding best parameters\n* Model training using best parameters\n* Generating confusion matrix, classification report and ROC curve for comparing with the default parameters\n\n### Conclusion\nAmong 4 models, We did not get any improvement after hyper-parameter tuning on the two following models:\n* SVM (98%)\n* K-Nearest Neighbor (95%)\n\nOn the other hand, Following two models showed a massive improvement after hyper-parameter tuning:\n* Decision Tree (from 83% to 93%)\n* Random Forest (from 98% to 100%)\n\nSo, Random Forest is outperforming all other models.\n\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n"}
{"url": "https://github.com/grpranto/Medical-Store-Management", "owner": "grpranto", "repository_name": "Medical-Store-Management", "date_all_variable_collection": "2023-09-11", "description": "Medical store management project using data structure. ", "size": 3, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "grpranto", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["data-structures"], "languages": [{"language": "C++", "num_chars": 7206}]}
{"url": "https://github.com/grpranto/ML-GUI-software-fault-detection", "owner": "grpranto", "repository_name": "ML-GUI-software-fault-detection", "date_all_variable_collection": "2023-09-11", "description": null, "size": 3473, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "grpranto", "contributions": 13}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 57698}], "readme": "<a name=\"readme-top\"></a>\n<p float=\"left\">\n  <img src=\"https://img.shields.io/badge/Python-FFD43B?style=for-the-badge&logo=python&logoColor=blue\">\n  <img src=\"https://img.shields.io/badge/Pandas-2C2D72?style=for-the-badge&logo=pandas&logoColor=white\">\n  <img src=\"https://img.shields.io/badge/Numpy-777BB4?style=for-the-badge&logo=numpy&logoColor=white\">\n  <img src=\"https://img.shields.io/badge/scikit_learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white\">\n  <img src=\"https://img.shields.io/badge/Qt-41CD52?style=for-the-badge&logo=qt&logoColor=white\">\n</p>\n\n<!-- ABOUT THE PROJECT -->\n### About The Project\nThis machine learning project is a part of my Bachelor thesis and [publication](https://link.springer.com/chapter/10.1007/978-3-030-33709-4_5) with the goal of checking the effect of feature selection methods in software fault detection. The GUI saved a lot of time during our research as it is capable of generating any combinations of results\n\nThe GUI consists of: \n* five classifiers: `Decision Tree`, `Random Forest`, `Na\u00efve Bayes`, `Logistic Regression`, `Neural Network`\n* five feature selection techniques: `Information Gain`, `Relief`, `Chi-Square`, `Chi-square Test of Independence`, `Feature Importance`\n* five datasets: NASA\u2019s benchmark publicly available datasets\n\nResult includes: `accuracy`, `confusion matrix`, `AUC`, `ROC curve`\n\n[![ML-GUI-SoftwareFaultDetection](https://github.com/grpranto/ML-GUI-software-fault-detection/blob/main/screenshots/interface1.PNG?raw=true)](abcd)\n\nThe GUI can be used in multiple ways. We can choose any of the classifiers without feature selection and check the result. We can also choose classifiers along with feature selection technique. For example, at fist step, we can only take the `Logistic Regression` as classifier and see the result. At second step, we can take the `Logistic Regression` as classifier along with the feature selection technique `Information gain` and produce the result. After comparing the results, we can easily reach to a conclusion if there is any effect of the feature selection technique in software fault detection.\n\n\n### What is the advantage? \nTotal combinations possible = 5 classifiers * 5 feature selection techniques * 5 datasets = 125\n\nJust select any combination from the GUI and get the desired result :)\n\n* Compare the result of `classifier alone` vs `classifer with feature selection technique`\n* User Friendly\n* Save a lot of time\n* Don't have to maintain different python/jupyter notebook files for different combinations\n\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n### Appendix (More Screenshots of the tool):\n#### Dataset Overview\n![ML-GUI-SoftwareFaultDetection](https://github.com/grpranto/ML-GUI-software-fault-detection/blob/main/screenshots/interface2.PNG?raw=true) \n\n![ML-GUI-SoftwareFaultDetection](https://github.com/grpranto/ML-GUI-software-fault-detection/blob/main/screenshots/interface3.PNG?raw=true)\n\n#### Result of an arbitrary combination(`Logistic Regression` along with `Information gain`)\n![ML-GUI-SoftwareFaultDetection](https://github.com/grpranto/ML-GUI-software-fault-detection/blob/main/screenshots/interface4.PNG?raw=true) \n\n![ML-GUI-SoftwareFaultDetection](https://github.com/grpranto/ML-GUI-software-fault-detection/blob/main/screenshots/interface5.PNG?raw=true)\n\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n<!--https://github.com/alexandresanlim/Badges4-README.md-Profile-->\n"}
{"url": "https://github.com/grpranto/Online-shoppers-purchasing-intention-ML", "owner": "grpranto", "repository_name": "Online-shoppers-purchasing-intention-ML", "date_all_variable_collection": "2023-09-11", "description": "Predict the purchasing intention of online shoppers using Decision Tree, Naive Bayes classifier, Random Forrest, Support Vector Machine algorithms.", "size": 311, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "grpranto", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 108880}], "readme": "<a name=\"readme-top\"></a>\n<p float=\"left\">\n  <img src=\"https://img.shields.io/badge/Python-FFD43B?style=for-the-badge&logo=python&logoColor=blue\">\n  <img src=\"https://img.shields.io/badge/Jupyter-F37626.svg?&style=for-the-badge&logo=Jupyter&logoColor=white\">\n  <img src=\"https://img.shields.io/badge/Pandas-2C2D72?style=for-the-badge&logo=pandas&logoColor=white\">\n  <img src=\"https://img.shields.io/badge/Numpy-777BB4?style=for-the-badge&logo=numpy&logoColor=white\">\n  <img src=\"https://img.shields.io/badge/scikit_learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white\">\n</p>\n\n<!-- ABOUT THE PROJECT -->\n### About The Project\nA machine Learning project which was a part of my Bachelor course `Data Mining` to predict the purchasing intention of online shoppers. Classical machine learning classifiers have been applied on [online shoppers purchasing intention kaggle dataset](https://www.kaggle.com/datasets/imakash3011/online-shoppers-purchasing-intention-dataset) that consists of feature vectors belonging to 12,330 sessions. The dataset was formed so that each session would belong to a different user in a 1-year period to avoid any tendency to a specific campaign, special day, user profile, or period. Later it was preprocessed where categorical data has been converted into numerical data using one-hot encoding. It increased the number of attributes in the dataset. 70% of the data have been taken for training purposes and the rest of the data have been used for testing. Among 4 classifiers, `Random Forest` performed better than other classifiers.\n\nIt consists of: \n* four classifiers: `Decision Tree`, `Random Forest`, `Na\u00efve Bayes`, `SVM`\n* evaluation/permormance metrics: `Accuracy`, `TPR`, `FPR`, `AUC`, `Recall`, `Precision`\n\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n\n\n"}
{"url": "https://github.com/grpranto/Smart-Car-Parking-System", "owner": "grpranto", "repository_name": "Smart-Car-Parking-System", "date_all_variable_collection": "2023-09-11", "description": "Arduino based Smart Car Parking System", "size": 373, "stargazers_count": 0, "watchers_count": 0, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "grpranto", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["arduino", "arduino-uno", "ir-sensor", "rfid-rc522"], "languages": [{"language": "C++", "num_chars": 3404}]}
{"url": "https://github.com/grpranto/solving-real-world-dataset-SQL-Python", "owner": "grpranto", "repository_name": "solving-real-world-dataset-SQL-Python", "date_all_variable_collection": "2023-09-11", "description": null, "size": 329, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "grpranto", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 61147}], "readme": "# Solving real world dataset with SQL and Python\n<a name=\"readme-top\"></a>\n<p float=\"left\">\n  <img src=\"https://img.shields.io/badge/Python-FFD43B?style=for-the-badge&logo=python&logoColor=blue\">\n  <img src=\"https://img.shields.io/badge/SQL-005C84?style=for-the-badge&logo=sqlite&logoColor=white\">\n  <img src=\"https://img.shields.io/badge/Jupyter-F37626.svg?&style=for-the-badge&logo=Jupyter&logoColor=white\">\n  <img src=\"https://img.shields.io/badge/Pandas-2C2D72?style=for-the-badge&logo=pandas&logoColor=white\">\n  <img src=\"https://img.shields.io/badge/SQLite-07405E?style=for-the-badge&logo=sqlite&logoColor=white\">\n</p>\n\n<!-- ABOUT THE PROJECT -->\n### About The Project\nThis project was a part the course [Databases and SQL for Data Science with Python](https://www.coursera.org/learn/sql-data-science) where my tasks were to solve a real world dataset provided by the Chicago Data Portal. My job was to analyze the census, crime, and school data for a given neighborhood or district.\n\nDatasets used: \n* [Chicago Census Data](https://data.cityofchicago.org/Health-Human-Services/Census-Data-Selected-socioeconomic-indicators-in-C/kn9c-c2s2?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDB0201ENSkillsNetwork22-2023-01-01)\n* [Chicago Public Schools](https://data.cityofchicago.org/Education/Chicago-Public-Schools-Progress-Report-Cards-2011-/9xs2-f89t?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDB0201ENSkillsNetwork22-2023-01-01)\n* [Chicago Crimes](https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-Present/ijzp-q8t2?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDB0201ENSkillsNetwork22-2023-01-01)\n\nExecuted the appropriate SQL queries to answer each of the following problems:\n* Problem 1: Find the total number of crimes recorded in the CRIME table.\n* Problem 2: List community areas with per capita income less than 11000.\n* Problem 3: List all case numbers for crimes involving minors?\n* Problem 4: List all kidnapping crimes involving a child?(children are not considered minors for the purposes of crime analysis)\n* Problem 5: What kind of crimes were recorded at schools?\n* Problem 6: List the average safety score for all types of schools.\n* Problem 7: List 5 community areas with highest % of households below poverty line.\n* Problem 8: Which community area(number) is most crime prone?\n* Problem 9: Use a sub-query to find the name of the community area with highest hardship index.\n* Problem 10: Use a sub-query to determine the Community Area Name with most number of crimes?\n\n<p align=\"right\">(<a href=\"#readme-top\">back to top</a>)</p>\n"}
{"url": "https://github.com/grpranto/Track-Covid-19", "owner": "grpranto", "repository_name": "Track-Covid-19", "date_all_variable_collection": "2023-09-11", "description": "COVID-19 Coronavirus statistics in real time.", "size": 6, "stargazers_count": 0, "watchers_count": 0, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "grpranto", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["api"], "languages": [{"language": "PHP", "num_chars": 20334}]}
{"url": "https://github.com/grpranto/woocommerce_wordpress", "owner": "grpranto", "repository_name": "woocommerce_wordpress", "date_all_variable_collection": "2023-09-11", "description": null, "size": 54933, "stargazers_count": 0, "watchers_count": 0, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "grpranto", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 41229799}, {"language": "JavaScript", "num_chars": 15394072}, {"language": "CSS", "num_chars": 4380071}, {"language": "SCSS", "num_chars": 927228}, {"language": "Hack", "num_chars": 24996}, {"language": "HTML", "num_chars": 52}], "readme": "<h2>WordPress WooCommerce Website</h2>\n<br>\n<h3>Some screenshots</h3>\n<br>\n<p><b>1. Header Section</b></p>\n<img src=\"screenshots/header.JPG\">\n<br>\n<p><b>2. Featured Categories Section</b></p>\n<img src=\"screenshots/featured_categories.JPG\">\n<br>\n<p><b>3. Top Interesting Section<b></p>\n<img src=\"screenshots/top_interesting.JPG\">\n<br>\n<p><b>4. Products filtering by color and size</b></p>\n<img src=\"screenshots/products filtering.JPG\">\n<br>\n<p><b>5. Order Tracking Section</b></p>\n<img src=\"screenshots/order_tracking.JPG\">\n<br>\n<p><b>6. Cart Section</b></p>\n<img src=\"screenshots/cart_section.JPG\">\n<br>\n<p><b>7. Place Order Section</b></p>\n<img src=\"screenshots/Place_order.JPG\">\n<br>\n<p><b>8. Footer Section</b></p>\n<img src=\"screenshots/footer.JPG\">\n<br>\n<p><b>9. Woocommerce Dashboard Section</b></p>\n<img src=\"screenshots/woocommerce_dashboard.JPG\">\n<br>\n\n\n"}
{"url": "https://github.com/gue-ros/AnaGuerraRosbach", "owner": "gue-ros", "repository_name": "AnaGuerraRosbach", "date_all_variable_collection": "2023-09-11", "description": "Config files for my GitHub profile.", "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["config", "github-config"], "languages": []}
{"url": "https://github.com/gue-ros/Classification_Memes", "owner": "gue-ros", "repository_name": "Classification_Memes", "date_all_variable_collection": "2023-09-11", "description": "Mains task: classify memes as misogynous or not misogynous.", "size": 20, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "gue-ros", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 35285}], "readme": "# memes_final\nMains task: classify memes as misogynous or not misogynous.\n\nIn this project we will do task 5: Multimedia Automatic Misogyny Identification (MAMI), subtask A.\n\nThe purpose of this task is to identify if a meme should be considered misogynous or nor misogynous.\n\nTo be able to acces the data it is necessary to put all the files (training, test, trial) from the MAMI data set on a file in google drive named 'data_memes'.\n\nOpen (https://docs.google.com/forms/d/e/1FAIpQLSe3yJ6ggV0WlPpupN8Hy51F4zmulq_HgdC8rHU1ptZMnqUhjA/viewform) formular to request the data from the SemEval2022 organizators.\n"}
{"url": "https://github.com/gue-ros/DeepLearning_LanguageIdentification", "owner": "gue-ros", "repository_name": "DeepLearning_LanguageIdentification", "date_all_variable_collection": "2023-09-11", "description": "Language Identification using Recurrent Architectures. Based on original code by Hande Celikkanat & Miikka Silfverberg", "size": 80, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "gue-ros", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 14488}], "readme": "# DeepLearning_LanguageIdentification\n\nCourse Deep Learning Potsdam University.\n\nLanguage Identification using Recurrent Architectures. \n\nBased on original code by Hande Celikkanat &amp; Miikka Silfverberg\n"}
{"url": "https://github.com/gue-ros/DeepLearning_SentimentClassification", "owner": "gue-ros", "repository_name": "DeepLearning_SentimentClassification", "date_all_variable_collection": "2023-09-11", "description": "DeepLearnig course", "size": 9237, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "gue-ros", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 18645}], "readme": "# DeepLearning_SentimentClassification\nDeepLearnig course\n\n1st assignment Deep Learning course Potsdam University.\n\nSentiment Classification on a Feed-Forward Neural Network using Pretrained Embeddings.\n\n\nOriginal code by Hande Celikkanat & Miikka Silfverberg. Minor modifications by Sharid Lo\u00e1iciga.\n"}
{"url": "https://github.com/gue-ros/Natural_Language_Inference", "owner": "gue-ros", "repository_name": "Natural_Language_Inference", "date_all_variable_collection": "2023-09-11", "description": null, "size": 10710, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 21562}]}
{"url": "https://github.com/gwastro-2019/problem-set-1", "owner": "gwastro-2019", "repository_name": "problem-set-1", "date_all_variable_collection": "2023-09-11", "description": "Problem set 1 for the Gravitational Wave Astrophysics lecture, summer term 2019 at Potsdam University, Germany", "size": 12, "stargazers_count": 3, "watchers_count": 3, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 8, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 7, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 8, "open_issues": 7, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "nilsvu", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 81349}], "readme": "[Gravitational Wave Astrophysics lecture](https://git.aei.mpg.de/hpfeiffer/GWAstro2019) | Summer Term 2019 | Potsdam University\n\n# Problem Set 1\n\nThis repository contains the programming exercises for the [Problem Set 1](https://git.aei.mpg.de/hpfeiffer/GWAstro2019/blob/master/ProblemSets/ProblemSet1.pdf).\n"}
{"url": "https://github.com/gwastro-2019/problem-set-2", "owner": "gwastro-2019", "repository_name": "problem-set-2", "date_all_variable_collection": "2023-09-11", "description": "Problem set 2 for the Gravitational Wave Astrophysics lecture, summer term 2019 at Potsdam University, Germany", "size": 26, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 7, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 4, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 7, "open_issues": 4, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "nilsvu", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 130333}], "readme": "[Gravitational Wave Astrophysics lecture](https://git.aei.mpg.de/hpfeiffer/GWAstro2019) | Summer Term 2019 | Potsdam University\n\n# Problem Set 2\n\nThis repository contains the programming exercises for the [Problem Set 2](https://git.aei.mpg.de/hpfeiffer/GWAstro2019/blob/master/ProblemSets/ProblemSet2.pdf).\n"}
{"url": "https://github.com/gwastro-2019/problem-set-6", "owner": "gwastro-2019", "repository_name": "problem-set-6", "date_all_variable_collection": "2023-09-11", "description": "Problem set 6 for the Gravitational Wave Astrophysics lecture, summer term 2019 at Potsdam University, Germany", "size": 760, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 3, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 3, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "nilsvu", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 21523}], "readme": "[Gravitational Wave Astrophysics lecture](https://git.aei.mpg.de/hpfeiffer/GWAstro2019) | Summer Term 2019 | Potsdam University\n\n# Problem Set 6\n\nThis repository contains the programming exercises for the [Problem Set 6](https://git.aei.mpg.de/hpfeiffer/GWAstro2019/blob/master/ProblemSets/ProblemSet6.pdf).\n"}
{"url": "https://github.com/gwastro-2019/problem-set-7", "owner": "gwastro-2019", "repository_name": "problem-set-7", "date_all_variable_collection": "2023-09-11", "description": "Problem set 7 for the Gravitational Wave Astrophysics lecture, summer term 2019 at Potsdam University, Germany", "size": 15, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "nilsvu", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 11494}], "readme": "[Gravitational Wave Astrophysics lecture](https://git.aei.mpg.de/hpfeiffer/GWAstro2019) | Summer Term 2019 | Potsdam University\n\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/gwastro-2019/problem-set-7/master?filepath=analyse-ligo-data.ipynb)\n\n# Problem Set 7\n\nThis repository contains the programming exercises for the [Problem Set 7](https://git.aei.mpg.de/hpfeiffer/GWAstro2019/blob/master/ProblemSets/ProblemSet7.pdf).\n\nTo avoid having to install additional Python packages on your computer, you can launch the notebook interactively using the mybinder.org service:\n\n- [Launch notebook interactively](https://mybinder.org/v2/gh/gwastro-2019/problem-set-7/master?filepath=analyse-ligo-data.ipynb)\n\nThis exercise is adapted from the LSC Open Data Workshop tutorials by Alexander Nitz (https://github.com/gw-odw/odw-2018/tree/master/pycbc).\n"}
{"url": "https://github.com/hackpotsdam/hackpotsdam2017", "owner": "hackpotsdam", "repository_name": "hackpotsdam2017", "date_all_variable_collection": "2023-09-11", "description": "The homepage for a 24 hour held at semi-annually at SUNY Potsdam & Clarkson University.", "size": 46428, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 40, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 40, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "JessePeplinski", "contributions": 226}, {"contributor": "EsmeraldaQuintana", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["acm", "clarkson-university", "cosi", "hackathon", "innovation", "potsdam-acm", "suny-potsdam"], "languages": [{"language": "HTML", "num_chars": 512880}, {"language": "CSS", "num_chars": 95652}, {"language": "JavaScript", "num_chars": 70091}], "readme": "# hackpotsdam\nThe homepage for a 24 hour held at semi-annually at SUNY Potsdam &amp; Clarkson University.\n\n## Getting Started\n1. Clone the repo with `git clone https://github.com/PotsdamACM/hackpotsdam.git`\n2. Done!\n\n## Developing Using Source Files (optional, you don't have to do this)\n\nTo use the source files, you will need to have npm installed globally along with Gulp.js. To start:\n* Run `npm install` in the root directory\n* Run `gulp dev` and edit the files as needed\n\nIf you need to update the plugins included with this template, simply run the following tasks:\n* First run `npm update` to update the dependencies\n* Then run `gulp copy` to copy the new versions to their proper destinations"}
{"url": "https://github.com/hallerp/atmt_2022", "owner": "hallerp", "repository_name": "atmt_2022", "date_all_variable_collection": "2023-09-11", "description": "Materials for the first assignment of \"Advanced Techniques of Machine Translation\" @UZH (Autumn 2022).", "size": 30050, "stargazers_count": 1, "watchers_count": 1, "language": "SystemVerilog", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 14, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 14, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "hallerp", "contributions": 15}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "SystemVerilog", "num_chars": 2249083}, {"language": "Frege", "num_chars": 117369}, {"language": "Python", "num_chars": 72601}, {"language": "Perl", "num_chars": 42029}, {"language": "Forth", "num_chars": 40726}, {"language": "Shell", "num_chars": 7851}], "readme": "# atmt code base\nMaterials for \"Advanced Techniques of Machine Translation\".\nPlease refer to the assignment sheet for instructions on how to use the toolkit.\n\nThe toolkit is based on [this implementation](https://github.com/demelin/nmt_toolkit).\n\n# Environment Setup\n\n### conda\n\n```\n# ensure that you have conda (or miniconda) installed (https://conda.io/projects/conda/en/latest/user-guide/install/index.html) and that it is activated\n\n# create clean environment\nconda create --name atmt36 python=3.6\n\n# activate the environment\nconda activate atmt36\n\n# intall required packages\npip install torch==1.6.0 numpy tqdm sacrebleu\n```\n\n### virtualenv\n\n```\n# ensure that you have python 3.6 downloaded and installed (https://www.python.org/downloads/)\n\n# install virtualenv\npip install virtualenv\n\n# create a virtual environment named \"atmt36\"\nvirtualenv --python=python3 atmt36\n\n# launch the newly created environment\natmt36/bin/activate\n\n# intall required packages\npip install torch==1.6.0 numpy tqdm sacrebleu\n```\n\n<!-- # Data Preprocessing\n\n```\n# normalise, tokenize and truecase data\nbash scripts/extract_splits.sh ../infopankki_raw data/en-sv/infopankki/raw\n\n# binarize data for model training\nbash scripts/run_preprocessing.sh data/en-sv/infopankki/raw/\n``` -->\n\n# Training a model\n\n```\npython train.py \\\n    --data path/to/prepared/data \\\n    --source-lang en \\\n    --target-lang sv \\\n    --save-dir path/to/model/checkpoints \\\n    --train-on-tiny # for testing purposes only\n```\n\nNotes:\n- `path/to/prepared/data` and `path/to/model/checkpoints`\n  are placholders, not true paths. Replace these arguments with the correct paths\n  for your system.\n- only use `--train-on-tiny` for testing. This will train a\ndummy model on the `tiny_train` split.\n- add the `--cuda` flag if you want to train on a GPU, e.g. using Google Colab\n\n# Evaluating a trained model\n\nRun inference on test set\n```\npython translate.py \\\n    --data path/to/prepared/data \\\n    --dicts path/to/prepared/data \\\n    --checkpoint-path path/to/model/checkpoint/file/for/loading \\\n    --output path/to/output/file/model/translations\n```\n\nPostprocess model translations\n```\nbash scripts/postprocess.sh path/to/output/file/model/translations path/to/postprocessed/model/translations/file en\n```\n\nScore with SacreBLEU\n```\ncat path/to/postprocessed/model/translations/file | sacrebleu path/to/raw/target/test/file\n```\n\n# Assignments\n\nAssignments must be submitted on OLAT by 14:00 on their respective\ndue dates.\n\n"}
{"url": "https://github.com/hallerp/dyslexia-seqmod", "owner": "hallerp", "repository_name": "dyslexia-seqmod", "date_all_variable_collection": "2023-09-11", "description": null, "size": 34, "stargazers_count": 4, "watchers_count": 4, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 4, "default_branch": "master", "contributors": [{"contributor": "hallerp", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 74242}], "readme": "Eye-tracking based classification of Mandarin Chinese readers with and without dyslexia using neural sequence models\n====================================================================================================================\n[![paper](https://img.shields.io/static/v1?label=paper&message=download%20link&color=brightgreen)](https://arxiv.org/abs/2210.09819)\n\nThis repository contains the sequence and baseline models used in Eye-tracking based classification of Mandarin Chinese readers with and without dyslexia using neural sequence models.\n\n## Using the models\n\nCreate a conda environment with\n```bash\n$ conda env create -f environment.yml\n```\nThen activate the environment and install your appropriate version of [PyTorch](https://pytorch.org/get-started/locally/).\n```bash\n$ conda install -y pytorch torchvision cudatoolkit=11.1 -c pytorch\n$ # conda install pytorch torchvision cpuonly -c pytorch\n$ pip install datasets transformers\n```\n\n## Citation\n\nPatrick Haller, Andreas S\u00e4uberli, Sarah Kiener, Jinger Pan, Ming Yan, and Lena J\u00e4ger. 2022. Eye-tracking based classification of Mandarin Chinese readers with and without dyslexia using neural sequence models. In Proceedings of the Workshop on Text Simplification, Accessibility, and Readability (TSAR-2022), pages 111\u2013118, Abu Dhabi, United Arab Emirates (Virtual). Association for Computational Linguistics.\n"}
{"url": "https://github.com/hallerp/stroop-simon-german", "owner": "hallerp", "repository_name": "stroop-simon-german", "date_all_variable_collection": "2023-09-11", "description": "PsychoPy implementations of Simon and Stroop task in German", "size": 26, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hallerp", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 96467}], "readme": "Simon and Stroop task in German\n====================================================================================================================\n\nThis repository contains German versions of the Simon and Stroop task, implemented in PsychoPy. \n\n## Run the experiments\n\nTo run the experiments, execute\n```bash\n$ python CognControl_lastrun.py\n```"}
{"url": "https://github.com/hannesharnisch/BeautifulSwiftUI", "owner": "hannesharnisch", "repository_name": "BeautifulSwiftUI", "date_all_variable_collection": "2023-09-11", "description": null, "size": 15, "stargazers_count": 0, "watchers_count": 0, "language": "Swift", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "hannesharnisch", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Swift", "num_chars": 21701}], "readme": "# BeautifulSwiftUI"}
{"url": "https://github.com/hannesharnisch/dotfiles", "owner": "hannesharnisch", "repository_name": "dotfiles", "date_all_variable_collection": "2023-09-11", "description": null, "size": 42, "stargazers_count": 2, "watchers_count": 2, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "main", "contributors": [{"contributor": "hannesharnisch", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 56353}, {"language": "Vim Script", "num_chars": 49796}, {"language": "GDB", "num_chars": 29}], "readme": "# Hannes' dotfiles\n\n## Installation\n\n### Using Git and the bootstrap script\n\nYou can clone the repository wherever you want. (I like to keep it in `~/Projects/dotfiles`, with `~/dotfiles` as a symlink.) The bootstrapper script will pull in the latest version and copy the files to your home folder.\n\n```bash\ngit clone https://github.com/hannesharnisch/dotfiles.git && cd dotfiles && source bootstrap.sh\n```\n\nTo update, `cd` into your local `dotfiles` repository and then:\n\n```bash \nbash bootstrap.sh\n```\n\nAlternatively, to update while avoiding the confirmation prompt:\n\n```bash\nset -- -f; source bootstrap.sh\n```\n\n### Git-free install\n\nTo install these dotfiles without Git:\n\n```bash\ncd; mkdir dotfiles; cd dotfiles; curl -#L https://github.com/hannesharnisch/dotfiles/tarball/main | tar -xzv --strip-components 1; ./bootstrap.sh; rm -rf ~/dotfiles;\n```\n\nTo update later on, just run that command again.\n\n### Add custom commands without creating a new fork\n\nIf `~/.extra` exists, it will be sourced along with the other files. You can use this to add a few custom commands without the need to fork this entire repository, or to add commands you don\u2019t want to commit to a public repository.\n\nMy `~/.extra` looks something like this:\n\n```bash\n# Git credentials\n# Not in the repository, to prevent people from accidentally committing under my name\nGIT_AUTHOR_NAME=\"Hannes Harnisch\"\nGIT_COMMITTER_NAME=\"$GIT_AUTHOR_NAME\"\ngit config --global user.name \"$GIT_AUTHOR_NAME\"\nGIT_AUTHOR_EMAIL=\"haharnisch@uni-potsdam.de\"\nGIT_COMMITTER_EMAIL=\"$GIT_AUTHOR_EMAIL\"\ngit config --global user.email \"$GIT_AUTHOR_EMAIL\"\n```\n\nYou could also use `~/.extra` to override settings, functions and aliases from my dotfiles repository. It\u2019s probably better to [fork this repository](https://github.com/hannesharnisch/dotfiles/fork) instead, though.\n\n### Sensible macOS defaults\n\nWhen setting up a new Mac, you may want to set some sensible macOS defaults:\n\n```bash\n./.macos\n```\n\n### Install Homebrew formulae\n\nWhen setting up a new Mac, you may want to install some common [Homebrew](https://brew.sh/) formulae (after installing Homebrew, of course):\n\n```bash\n./brew.sh\n```\n\nSome of the functionality of these dotfiles depends on formulae installed by `brew.sh`. If you don\u2019t plan to run `brew.sh`, you should look carefully through the script and manually install any particularly important ones. A good example is Bash/Git completion: the dotfiles use a special version from Homebrew."}
{"url": "https://github.com/hannesharnisch/hannesharnisch", "owner": "hannesharnisch", "repository_name": "hannesharnisch", "date_all_variable_collection": "2023-09-11", "description": null, "size": 2, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "hannesharnisch", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "## Hey, I'm Hannes \ud83d\udc4b\n\nI'm currently studying at the University of Potsdam \ud83e\uddd1\u200d\ud83c\udf93 in Germany \ud83c\udde9\ud83c\uddea\nI love [Swift](https://swift.org) and [nodejs](https://nodejs.org).\nAlso doing smaller projects with [Ionic](https://ionicframework.com), [Python](https://www.python.org), [Kotlin](https://kotlinlang.org) and others.\n\nBeside coding \ud83d\udc68\u200d\ud83d\udcbb, I like sports - going to the gym \ud83c\udfcb\ud83c\udffb, Calisthenics and Sailing \u26f5 \n\n\u26a1 Fun fact: 2-time German champion in sailing\n\n\n\ud83d\udceb You can always reach me [here](mailto:haharnisch@uni-potsdam.de?subject=[GitHub]%20Questions)\n\n<!--\n**hannesharnisch/hannesharnisch** is a \u2728 _special_ \u2728 repository because its `README.md` (this file) appears on your GitHub profile.\n\nHere are some ideas to get you started:\n\n- \ud83d\udd2d I\u2019m currently working on ...\n- \ud83c\udf31 I\u2019m currently learning ...\n- \ud83d\udc6f I\u2019m looking to collaborate on ...\n- \ud83e\udd14 I\u2019m looking for help with ...\n- \ud83d\udcac Ask me about ...\n- \ud83d\udceb How to reach me: ...\n- \ud83d\ude04 Pronouns: ...\n- \u26a1 Fun fact: ...\n-->\n"}
{"url": "https://github.com/hannesharnisch/IOWarriorInfo", "owner": "hannesharnisch", "repository_name": "IOWarriorInfo", "date_all_variable_collection": "2023-09-11", "description": "Messen des Spannungsabfalls eines Kondensators im Informatikunterricht", "size": 359, "stargazers_count": 1, "watchers_count": 1, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 97186}, {"language": "Java", "num_chars": 3183}, {"language": "CSS", "num_chars": 1391}, {"language": "Gnuplot", "num_chars": 1339}], "readme": "\n# IOWarrior Projekt\n\n## How to run project\n\n1. download the i4k file and the Code\n2. export projekt as a jar file\n3. copy files of lib64 into \"Pers\u00f6nlicher Ordner\"\n4. Run Projekt on Console:\n\nTo set the library path and run the projekt execute the following commands on the Command line:\n\n```\nexport LD_LIBRARY_PATH=/home/student/:$LD_LIBRARY_PATH\n```\n\nrun projekt with:\n\n```\n/usr/lib/jvm/java-1.8.0-openjdk-amd64/bin/java -jar test.jar\n```\n\nor:\n\n```\n/usr/lib/jvm/java-1.8.0-openjdk-amd64/bin/java -jar test.jar > Kondensatorabfall.txt\n```\n\nThen create a plotting gnuplot script that plots the data from this txt file. \n\n\n## Beweis Tau (RC) hat Einheit Sekunden\n\nU(t) = U0 * e ^ -t/RC\n\nTau = R * C\nR = 1 Ohm = 1V/A = 1 kg*m\u00b2/A\u00b2*s\u00b3\nC = 1 F = 1 A\u00b2*s\u2074/kg*m\u00b2\n\n---\nTau = 1 kg*m\u00b2*A\u00b2*s\u2074/A\u00b2*s\u00b3*kg*m\u00b2 = 1 s\n\n\n## Liegt Graph innerhalb der Abweichungsgrenzen?\n\n- 20% abweichung am Kondensator\n- 5% am Wiederstand\n\n---\nFitting:\n\n- U0 1. Standardabweichung betr\u00e4gt +/- 6.748\n- R*C 1. Standardabweichung betr\u00e4gt +/- 80.96\n\n![Unser gemessener Kondensatorabfall](https://github.com/hannesharnisch/IOWarriorInfo/blob/master/Kondensator.png)\n![Unser gemessener Kondensatorabfall2](https://github.com/hannesharnisch/IOWarriorInfo/blob/master/KondensatorimAbweichungsbereich.png)\n### Maximum Rechnung:\n---\nUnser Kondensator hat eine Genauigkeit von **20%** und unser Wiederstand von **5%**\n\n#### Max Wiederstand:\n \n100000\u03a9 + 5% = 100000\u03a9 + 5000\u03a9 = **105000\u03a9**\n\n#### Max Kapazit\u00e4t Kondensator:\n\n100\u00b5F + 20% = 100\u00b5F + 20\u00b5F = 120\u00b5F = **0.12F**\n\n---\nTau = 105000\u03a9 * 0.12F = **12600s**\n\n### Min Rechnung:\n\n#### Min Wiederstand: \n\n100000\u03a9 - 5% = 100000\u03a9 - 5000\u03a9 = **95000\u03a9**\n\n#### Min Kapazit\u00e4t Kondensator:\n\n100\u00b5F - 20% = 100\u00b5F - 20\u00b5F = 80\u00b5F = **0.08F**\n\n---\nTau = 95000\u03a9 * 0.08F = **7600s**\n\nUnser gefittete wert ist 11127.8s und ist damit ein Guter Messwert da er zwischen dem Maximalen und Minimalen Wert liegt:\n\n```\n12600s > 11127.8s > 7600s\n```\n\n"}
{"url": "https://github.com/hannesharnisch/localizationExcelParser", "owner": "hannesharnisch", "repository_name": "localizationExcelParser", "date_all_variable_collection": "2023-09-11", "description": null, "size": 8, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "hannesharnisch", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# localizationExcelParser"}
{"url": "https://github.com/hannesharnisch/MPConnectivity", "owner": "hannesharnisch", "repository_name": "MPConnectivity", "date_all_variable_collection": "2023-09-11", "description": "Swift library on top of Apples MultipeerConnectivity Framework", "size": 11, "stargazers_count": 0, "watchers_count": 0, "language": "Swift", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hannesharnisch", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Swift", "num_chars": 22039}], "readme": "# MPConnectivity\nSwift library on top of Apples MultipeerConnectivity Framework\n"}
{"url": "https://github.com/hannesharnisch/MusicSwift", "owner": "hannesharnisch", "repository_name": "MusicSwift", "date_all_variable_collection": "2023-09-11", "description": "Library for finding and Playing Music", "size": 55, "stargazers_count": 0, "watchers_count": 0, "language": "Swift", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hannesharnisch", "contributions": 26}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Swift", "num_chars": 31634}], "readme": "# MusicSwift\nLibrary for finding and Playing Music\n"}
{"url": "https://github.com/hannesharnisch/PasswordStoreSwift", "owner": "hannesharnisch", "repository_name": "PasswordStoreSwift", "date_all_variable_collection": "2023-09-11", "description": "Package for storing Passwords", "size": 5, "stargazers_count": 0, "watchers_count": 0, "language": "Swift", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hannesharnisch", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Swift", "num_chars": 4935}], "readme": "# PasswordStoreSwift\nPackage for storing Passwords\n"}
{"url": "https://github.com/hannesharnisch/PublishedPropertyWrapper", "owner": "hannesharnisch", "repository_name": "PublishedPropertyWrapper", "date_all_variable_collection": "2023-09-11", "description": null, "size": 2, "stargazers_count": 0, "watchers_count": 0, "language": "Swift", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "hannesharnisch", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Swift", "num_chars": 4792}], "readme": "# Published PropertyWrapper\n\nThis Repository is supposed to show how you can create a custom PropertyWrapper that replicates the behaviour of the `@Published` PropertyWrapper provided in SwiftUI.\nThis example provides a publisher as a projected value which can be accessed via the `$` operator in front of the variable. Furthermore it can be used inside of an ObservableObject in MVVM Applications to have all the power of using the value as a `Binding`.\n\n## Usage\nThe following example shows how the propertywrapper can be used to monitor changes to a variable:\n\n```\nclass Weather {\n    @CustomPublished var temperature: Double\n    init(temperature: Double) {\n        self.temperature = temperature\n    }\n}\n\nlet weather = Weather(temperature: 20)\nlet cancellable = weather.$temperature.sink() {\n     print (\"Temperature now: \\($0)\")\n}\nweather.temperature = 25 \n```\n\nOutput: \n\n```\nTemperature now: 20.0\nTemperature now: 25.0\n```\n\n\n> **Warning**\n> Values get emitted on willSet\n\n\n### MVVM\nThis Example shows how the propertywrapper can be used to acchieve a binding between the variable and a textfield.\n\n```\nclass ViewModel: ObservalbleObject {\n    @CustomPublished var text = \"\"\n}\n```\n\n```\nstruct ContentView: View {\n    @ObservedObject var viewModel = ViewModel()\n    var body: some View {\n        VStack {\n            TextField(\"Input\", text: $viewModel.text)\n        }\n    }\n}\n```\n\n"}
{"url": "https://github.com/hannesharnisch/sch_felder", "owner": "hannesharnisch", "repository_name": "sch_felder", "date_all_variable_collection": "2023-09-11", "description": null, "size": 5, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 2228}]}
{"url": "https://github.com/hannesharnisch/sch_montecarlo", "owner": "hannesharnisch", "repository_name": "sch_montecarlo", "date_all_variable_collection": "2023-09-11", "description": "Monte Carlo simulation mit UI", "size": 12, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["java", "schule"], "languages": [{"language": "Java", "num_chars": 8659}, {"language": "CSS", "num_chars": 202}], "readme": "# Monte Carlo simulation"}
{"url": "https://github.com/hannesharnisch/swiftHTTP", "owner": "hannesharnisch", "repository_name": "swiftHTTP", "date_all_variable_collection": "2023-09-11", "description": null, "size": 120, "stargazers_count": 0, "watchers_count": 0, "language": "Swift", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hannesharnisch", "contributions": 24}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Swift", "num_chars": 9789}], "readme": "# swiftHTTP\n\nA description of this package.\n"}
{"url": "https://github.com/hannesharnisch/SwiftLiveData", "owner": "hannesharnisch", "repository_name": "SwiftLiveData", "date_all_variable_collection": "2023-09-11", "description": null, "size": 10, "stargazers_count": 0, "watchers_count": 0, "language": "Swift", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "hannesharnisch", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Swift", "num_chars": 13318}], "readme": "# SwiftLiveData\n\nThis is a package for syncing background data storages that can be monitored with a publisher directly to a ViewModel.\n"}
{"url": "https://github.com/hannesharnisch/swiftui-essentials", "owner": "hannesharnisch", "repository_name": "swiftui-essentials", "date_all_variable_collection": "2023-09-11", "description": "useful Swiftui components that can be reused", "size": 9, "stargazers_count": 0, "watchers_count": 0, "language": "Swift", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hannesharnisch", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Swift", "num_chars": 21326}], "readme": "# swiftui-essentials\nuseful Swiftui components that can be reused\n\n## NowPlayingView\nView that is expandable, shows and controlls Music content\n\n\n"}
{"url": "https://github.com/hannesharnisch/TiMaTo", "owner": "hannesharnisch", "repository_name": "TiMaTo", "date_all_variable_collection": "2023-09-11", "description": "TiMaTo zeiterfassungstool f\u00fcr die Arbeitszeit", "size": 84, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["javafx-application", "ppi"], "languages": [{"language": "HTML", "num_chars": 6271}, {"language": "CSS", "num_chars": 278}], "readme": "# TiMaTo"}
{"url": "https://github.com/hannesharnisch/WeParty", "owner": "hannesharnisch", "repository_name": "WeParty", "date_all_variable_collection": "2023-09-11", "description": "Create a Party and share Musik", "size": 1744, "stargazers_count": 0, "watchers_count": 0, "language": "Swift", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hannesharnisch", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Swift", "num_chars": 135547}, {"language": "Lua", "num_chars": 257}], "readme": "# WeChat\nCreate a Party and share Musik\n"}
{"url": "https://github.com/hatschito/bbb_logo_geowiss", "owner": "hatschito", "repository_name": "bbb_logo_geowiss", "date_all_variable_collection": "2023-09-11", "description": null, "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/hatschito/BuildingDetection", "owner": "hatschito", "repository_name": "BuildingDetection", "date_all_variable_collection": "2023-09-11", "description": "Detect buildings by a combination of different filters and clusterin (kmean, sobel, morphological filters)", "size": 2, "stargazers_count": 3, "watchers_count": 3, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "hatschito", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 2989}]}
{"url": "https://github.com/hatschito/download_bio_reactor_locations", "owner": "hatschito", "repository_name": "download_bio_reactor_locations", "date_all_variable_collection": "2023-09-11", "description": null, "size": 18, "stargazers_count": 0, "watchers_count": 0, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "hatschito", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 1559}], "readme": "# download_bio_reactor_locations\n\nA shell script that downloads bio generator locations within a defined bounding box from the OpenStreetMap and converts the .osm data to the ESRI .shp format using GDAL. \n"}
{"url": "https://github.com/hatschito/Download_Geocoded_Real_estate_data", "owner": "hatschito", "repository_name": "Download_Geocoded_Real_estate_data", "date_all_variable_collection": "2023-09-11", "description": "The following short R script uses the Json parser Jsonlite and fetches gecoded real estate offers via the Nestoria REST API. ", "size": 2, "stargazers_count": 2, "watchers_count": 2, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "hatschito", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 952}], "readme": "# Download_Geocoded_Real_estate_data\n\nThe following short R script uses the Json parser Jsonlite and fetches gecoded real estate offers via the Nestoria REST API. The Nestoria API does not require any kind of authentification (as OAuth or an API key) and delivers current real estate date from all big and also smaller German real estate portals. Downloads are limited to 20 or 50 data points per page and to 1000 offers per request. So if you need a larger area, just adapt the bounding box or by filtering using the request paramaters documented on the Nestoria developers website: http://www.nestoria.co.uk/help/api-search-listings\nThe script loops through the pages provided by the API and puts the result into a R dataframe. The R dataframe easily can be exported as CSV for further use in QGIS or any other GIS software (e.g. Arc GIS).\nIf you have any questions, feel free to ask. The comments in the script are partly German and partly English, sorry for that mess :-). I tested the script fetching Berlin and Potsdam real estate data.\n"}
{"url": "https://github.com/hatschito/maptimeBER", "owner": "hatschito", "repository_name": "maptimeBER", "date_all_variable_collection": "2023-09-11", "description": "A repo for organizers of maptimeBER sessions ", "size": 9, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": false, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "alsino", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# maptimeBER\nA repo for organizers of maptimeBER sessions \n"}
{"url": "https://github.com/hatschito/Random_Forest_Landsat", "owner": "hatschito", "repository_name": "Random_Forest_Landsat", "date_all_variable_collection": "2023-09-11", "description": "RandomForest classification of satellite imagery (Landsat 5 TM / Landat 8 OLI)  and validation ", "size": 13, "stargazers_count": 4, "watchers_count": 4, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 4, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 4, "open_issues": 0, "watchers": 4, "default_branch": "master", "contributors": [{"contributor": "hatschito", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 9080}], "readme": "# Random_Forest_Landsat\nRandomForest classification of satellite imagery (Landsat 5 TM / Landat 8 OLI)  and validation \n\n#Script: Harald Schernthanner, Aura Cardenas: RandomForest classifier /  \n                                                        \n#Content                                 \n#I: Perparing the R working enviroment   \n#II: Preprocess the imagery              \n#III: RandomForest Model                 \n#IV:Accuracy assessment                  \n#V: Credits                              \n\n"}
{"url": "https://github.com/hatschito/Remote_Sensing_Lab", "owner": "hatschito", "repository_name": "Remote_Sensing_Lab", "date_all_variable_collection": "2023-09-11", "description": "Informations about the Remote Sensing Lab", "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/hatschito/Rental_data_download_shell_script_WGET_JQ", "owner": "hatschito", "repository_name": "Rental_data_download_shell_script_WGET_JQ", "date_all_variable_collection": "2023-09-11", "description": "Rental_data_download_shell_script_WGET_JQ", "size": 6, "stargazers_count": 1, "watchers_count": 1, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hatschito", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 3891}, {"language": "R", "num_chars": 363}], "readme": "# Fetch_rental data from NESTORIA\nUntil recently I fetched rental data via a R script based on R\u00b4s Jsonlite library and by accessing Nestoria\u00b4s API  (a  vertical search engine, that bundles the data of several real estate engines). My first script had to be executed manually; in the next attempt, I started to automate the data downloading, unlikely the service blocked my IP.  I admit, I excessively downloaded data and did the download  using  a static IP and a  cronjob that has been executed always on daily basis always on the same daytime. This resulted in a 403 error (IP forbidden, I used a static IP). So together with Nico (@bellackn) an alternative was figured out. Instead of Jsonlite our shell script uses WGET and makes use of the great JQ tool (CSV to JSON Parser). Thank\u00b4s Nico, for the input and ideas.\n\nWe use the  w 60 and \u2013random-wait flag, this tells WGET to either wait 0, 60 or 120 secs to download. This behavior tricks the server. Within WGET also the area of interest is defined. The API allows LAT/LONG in decimal degrees or place names.\n\nNext the first page is downloaded and the first page has to be altered with the sed command (UNIX command to parse text). A while loop does the downloading of the remaining pages, the page number to be downloaded can be changed. We receive JSON files, that have to be parsed to a geodata format.\n\nNext the data is loaded to a short R script. R\u00b4s SP library converts the CSV to a Shapefile (actually we will skip this part and in the next version GDAL should manage the file conversion). \nAt the end of the script the shapefile is converted to a GEOJSON dataset, so it can be used as an input for a webmap. \nBack in the shell script, a timestamp is appended to the Shapefile. After some cleaning at the end of the shell script, finally a cronjob is created to schedule the daily data download. \n\n\nA GUI based job sheduler can be found here https://wiki.ubuntuusers.de/GNOME_Schedule/\n\nStill the resulting shapefiles are stored file based but in the next step I\u00b4ll hook the script to an PostgreSQL database that was already installed on a Linux VServer.\n\nFeel free to use our script if you are interested in downloading geocoded rental data for your area of interest. Any feedback or comment is appreciated.\n"}
{"url": "https://github.com/hatschito/scrape_geocode_rental_data", "owner": "hatschito", "repository_name": "scrape_geocode_rental_data", "date_all_variable_collection": "2023-09-11", "description": "Script to scrape rental data from the German portal Immobilienscout24 ", "size": 7, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hatschito", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 4346}], "readme": "## scrape_geocode_rental_data\nScript to scrape rental data from the German portal Immobilienscout24.\n\n### Scrape rental data (source statisquo.de; modified by hatschito)\nThe first part of the script scrapes rental data with the  \u201ebeautiful soup\u201c Python library. Based on code from statisquo.de, that had to be updated, as Immobilienscout24 changed the structure, how they put their data on the website. The code was partly re-written, and now serves as nice efficient way, to scrape through the rental portals webpages and download data as csv.\n### Geocode\nIn the second part of the script, is a geocoding part. Geopy is used to geocode the csv and export a geopackage. \n\nThe code daily scrapes and geocodes data and writes it to a PostgreSQL database with PostGIS extension.  \n\n\n"}
{"url": "https://github.com/hatschito/Sentinel_dataSearch", "owner": "hatschito", "repository_name": "Sentinel_dataSearch", "date_all_variable_collection": "2023-09-11", "description": null, "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/hatschito/webodm_intro", "owner": "hatschito", "repository_name": "webodm_intro", "date_all_variable_collection": "2023-09-11", "description": "An introduction to WebODM", "size": 24, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hatschito", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Introduction to WebODM and OpenDroneMap (ODM): A few notes\n\nThese notes are part of a short introduction to WebODM. The motivation behind this introducion is to show, that an alternative to Agissoft Metashape or Pix4D exists. \n\n## What is OpenDroneMap and what are it's capabilites?\n\n* OpenDroneMap: An open source toolkit for aerial drone imagery.\n* Alternative to propiertary photogrammetric software, able to generate Orthophotos, Point Clouds, digital elevation models (DSM and DTM) and other products\u2026.\n * Uses the  Scale invariant local features algorithm (SIFT) :https://www.youtube.com/watch?v=oKAnOzIu66c&t=31s\nNice explanation from udemy\n* WebODM: A web based interface for OpenDroneMap \n* ODM developers started to include MICMAC, *the holy grail?*:\nhttps://www.opendronemap.org/2019/05/nodemicmac-a-new-webodm-node/\n\n\n## Quality?\n\n*There are not that much studys out there*\n\n* Conference paper:\n\nVacca G. Overview of Open Source Software for Close Range Photogrammetry. ISPRS-International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences. 2019 Aug;4214:239-45. [Available online at:https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLII-4-W14/239/2019/]\n\n  * Performance comparison of different photogrammetric software packages. Test object: Basilica of the Beata Vergine Assunta.\n\n  * Found points on 111 images shot by Canon EOS M3 with a sensor CMOS 22.3x14.9 mm and a 24.2 Megapixel resolution\n\n  | Software          | Matched points          |\n  | ----------------- |:-----------------------:|\n  | Agisoft Metashape |  114.453.295 points     |\n  | WebODM            |    3.545.806 points     |\n\n\n* Further paper: Burdziakowski, P. (2017). Evaluation of open drone map toolkit for geodetic grade aerial drone mapping\u2013case study.\n\n## Installation\n\nWays to install ODM:\n* Docker (Windows, MacOS, Linux)\n* Natively using Ubuntu 16.04 or later (or with a Virtual Machine)\n* Windows WebODM installer is sold\n https://WebODM.org\n\n### Prerequisites to install WebODM on Ubuntu 18.04\n\n* Docker and GIT\n\n### Install Docker on Ubuntu 18.04\n\n```\n#Install Docker\nsudo apt-get update \nsudo apt-get upgrade\nsudo apt install docker.io\n#Start and Enable Docker\nsudo systemctl start docker\nsudo systemctl enable docker\n\n#In some cases docker has to be updated after installation to avoid backport errors\nsudo pip install --upgrade docker\n\n```\n\n### Enable non root users to use docker\n\n```\nsudo groupadd docker\nsudo gpasswd -a student docker\n#activate the changes\nsudo newgrp docker\n```\n\n\n### Install WebODM\n\n```\ngit clone https://github.com/OpenDroneMap/WebODM --config core.autocrlf=input --depth 1\ncd WebODM\n./webodm.sh start\n```\n\n\n### Installations for the introduction\n\n#### Virtual machine\n\nFurther a virtual machine in the Ova2.0 (Open virtualisation) was generated; WebODM was installed insed OSGEOLive an Lubuntu based Live Linux distribution packed with GIS software. It can by using VirtualBox. Be aware, that you need enough diskspace (~40 GB). \n*Docker inside a virtual machine, does this make sense?*\n\nOSGEOLive: https://live.osgeo.org/en/index.html\n\nThe virtual machine can be downloaded at: https://drive.google.com/file/d/1E40hDe8fznzUccU4wOVRunYf505ryJ9Q/view?usp=sharing\nIt\u00b4s an ova container, for VirtualBox. If you use it on you own machine, you have to be aware of the specs (the VM uses 16GB of RAM and 4 cores; this and the mounted folders have to be adapted to your needs). \n\n#### Server based installation\n\nFor your convencience WebODM was installed on a virtualisation server and can be used by you on request. The URL of the server is: http://141.89.192.147:8000/ The admin acount to enter the interface is:\nadmin, the password:xxxxxx A user account can be accesd via: user / xxxxxx \n\n* Server capacities:  \n    * Processor: 24 Xeon E7 v2/Xeon E5 v2/Core i7 Bridge\n    * RAM: 128 GB\n\n* Issues with the server installation:\n\nUploading to VM Server sometimes is \"incomplete\":https://community.opendronemap.org/t/upload-kind-of-complete-but-hangs-after-progress-bar/1352\n\n## Launch WebODM\n\n```\n1. Start container: ./webodm.sh start\n2. Launch in browser: http://localhost:8000/dashboard/\n3.Stop WebODM: ./webodm.sh stop\n\n```\n\n## Sample Data\n\nExamples to play around with WebODM\nhttps://github.com/OpenDroneMap/ODMdata\n\nIn the intro this dataset is used:\n\nGeopark Kielce-Centrum Geoedukacji: https://github.com/merkato/odm_wietrznia\n\n### Explore the sample data: QGIS Photo Plugin: \n\nThe QGIS Photo Plugin is a plugin to import geotagged photos to QGIS. It's a helpul plugin to explore drone imagery: The plugin creates a layer which will contain the name of the picture, its directory, the date and time taken, altitude, longitude, latitude, azimuth, north, camera maker. \n\nhttps://plugins.qgis.org/plugins/ImportPhotos/\n\n* Photo plugin\n     * Exif tools is a prerequisite and can be installed via\n\n```\nsudo apt-get install libimage-exiftool-perl perl-doc\n\n```\n\n## Generate products:\n\nOrthophotos, Point Clouds, digital elevation models (DSM and DTM) and other products can be derived after uploading imagery. It' s a very easy to use drop down menu. \nThe process simply can be started with: *Start processing: Review -> start process*\n\n\n## Go further I: Access the docker container and it's commandline\n\n* Get id of running docker container\n```\nsudo docker ps -aqf \"name=containername\"\n```\n\n* Access bash of the docker machine\n```\ndocker exec -ti 5d402bd522f3 bash\n \n```\n\n*But I did not manage to run ODM commands within the container*\n\n## Go further II: Install ODM docker\n\nhttps://docs.opendronemap.org/installation.html#install-on-ubuntu-debian\n\n* Example run to process imagery: \n\n```\nRun: docker run -ti --rm -v /my/project:/datasets/code opendronemap/odm --project-path /datasets\n```\n\n### Include Gcps\nGcps can be used as text file as followed: \n\n* coordinate system descriptionx1 y1 z1 pixelx1 pixely1 imagename1x2 y2 z2 pixelx2 pixely2 imagename2x3 y3 z3 pixelx3 pixely3 imagename3\n\n* WGS84 UTM 10N544256.7 5320919.9 5 3044 2622 IMG_0525.jpg544157.7 5320899.2 5 4193 1552 IMG_0585.jpg544033.4 5320876.0 5 1606 2763 IMG_0690\n\n\n\n## Further reading\n* OpenDroneMap Manual: https://docs.opendronemap.org\n\n\n"}
{"url": "https://github.com/hatschito/WFS_Leaflet", "owner": "hatschito", "repository_name": "WFS_Leaflet", "date_all_variable_collection": "2023-09-11", "description": "WFS in leaflet.js via Ajax", "size": 0, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/Hazem0803/Income-Project", "owner": "Hazem0803", "repository_name": "Income-Project", "date_all_variable_collection": "2023-09-11", "description": "This is a binary classification where classify if the income greater than 50k or less than 50k depends on many features.", "size": 389, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "AbouClaude", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": []}
{"url": "https://github.com/heiko-etzold/cubeling-app", "owner": "heiko-etzold", "repository_name": "cubeling-app", "date_all_variable_collection": "2023-09-11", "description": "Source Code of App Cubeling", "size": 44657, "stargazers_count": 1, "watchers_count": 1, "language": "Swift", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "heiko-etzold", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Swift", "num_chars": 324792}, {"language": "Shell", "num_chars": 1640}]}
{"url": "https://github.com/heiko-etzold/cubeling-material", "owner": "heiko-etzold", "repository_name": "cubeling-material", "date_all_variable_collection": "2023-09-11", "description": "This is an open guide for teachers about the Cubeling App by Heiko Etzold.", "size": 126784, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": false, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "heiko-etzold", "contributions": 26}, {"contributor": "JoaRad", "contributions": 19}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 7845}, {"language": "R", "num_chars": 2884}, {"language": "CSS", "num_chars": 333}], "readme": "Shield: [![CC BY-SA 4.0][cc-by-sa-shield]][cc-by-sa]\n\nThis work is licensed under a\n[Creative Commons Attribution-ShareAlike 4.0 International License][cc-by-sa].\n\n[![CC BY-SA 4.0][cc-by-sa-image]][cc-by-sa]\n\n[cc-by-sa]: http://creativecommons.org/licenses/by-sa/4.0/\n[cc-by-sa-image]: https://licensebuttons.net/l/by-sa/4.0/88x31.png\n[cc-by-sa-shield]: https://img.shields.io/badge/License-CC%20BY--SA%204.0-lightgrey.svg\n"}
{"url": "https://github.com/heiko-etzold/nim-app", "owner": "heiko-etzold", "repository_name": "nim-app", "date_all_variable_collection": "2023-09-11", "description": null, "size": 10155, "stargazers_count": 0, "watchers_count": 0, "language": "Swift", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "heiko-etzold", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Swift", "num_chars": 182014}, {"language": "Shell", "num_chars": 2452}], "readme": "# Nim-App\n\n*english version below*\n\n## Handreichung f\u00fcr Lehrkr\u00e4fte\n\nEine Handreichung f\u00fcr Lehrkr\u00e4fte zur Verwendung der App im Mathematikunterricht und zu Hintergr\u00fcnden des Nim-Spiels findet sich unter https://heiko-etzold.github.io/nim-material.\n\n## Sprachen-Unterst\u00fctzung\n\nDie App ist in mehreren Sprachen verf\u00fcgbar:\n\n* Arabisch (ar)\n* Deutsch (de)\n* Englisch (en)\n* Franz\u00f6sisch (fr)\n* Isl\u00e4ndisch (is)\n* K\u00f6lsch (ksh)\n* Plattdeutsch/Niederdeutsch (nds)\n* Russisch (ru)\n* Ukrainisch (uk)\n\n\nFall Sie f\u00fcr weitere \u00dcbersetzungen Unterst\u00fctzung bieten k\u00f6nnen, wenden Sie sich gern an mich (heiko.etzold@uni-potsdam.de). Sie k\u00f6nnen folgende Dateien als Grundlage f\u00fcr weitere Sprachen nutzen (zum \u00c4ndern der Basissprache einfach \"de\" durch den entsprechenden Sprach-Code ersetzen):\n\n* https://github.com/heiko-etzold/nim-app/blob/main/Nim/de.lproj/Localizable.strings\n* https://github.com/heiko-etzold/nim-app/blob/main/Nim/de.lproj/Localizable.stringsdict\n* https://github.com/heiko-etzold/nim-app/blob/main/Nim/de.lproj/Main.strings\n* https://github.com/heiko-etzold/nim-app/blob/main/Nim/Settings.bundle/de.lproj/Root.strings\n\n\n# Nim App\n\n## Language Support\n\nThe app is available in several languages:\n\n* Arabic (ar)\n* Colognian (ksh)\n* English (en)\n* French (fr)\n* German (de)\n* Icelandic (is)\n* Low German (nds)\n* Russian (ru)\n* Ukrainian (uk)\n\nIf you want to support more languages, please contact me (heiko.etzold@uni-potsdam.de). You can use the following files as base (change \"de\" to other language codes if necessary):\n\n* https://github.com/heiko-etzold/nim-app/blob/main/Nim/de.lproj/Localizable.strings\n* https://github.com/heiko-etzold/nim-app/blob/main/Nim/de.lproj/Localizable.stringsdict\n* https://github.com/heiko-etzold/nim-app/blob/main/Nim/de.lproj/Main.strings\n* https://github.com/heiko-etzold/nim-app/blob/main/Nim/Settings.bundle/de.lproj/Root.strings\n"}
{"url": "https://github.com/heiko-etzold/nim-material", "owner": "heiko-etzold", "repository_name": "nim-material", "date_all_variable_collection": "2023-09-11", "description": null, "size": 24080, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "heiko-etzold", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 4240}, {"language": "R", "num_chars": 2981}, {"language": "CSS", "num_chars": 406}], "readme": "Shield: [![CC BY-SA 4.0][cc-by-sa-shield]][cc-by-sa]\n\nThis work is licensed under a\n[Creative Commons Attribution-ShareAlike 4.0 International License][cc-by-sa].\n\n[![CC BY-SA 4.0][cc-by-sa-image]][cc-by-sa]\n\n[cc-by-sa]: http://creativecommons.org/licenses/by-sa/4.0/\n[cc-by-sa-image]: https://licensebuttons.net/l/by-sa/4.0/88x31.png\n[cc-by-sa-shield]: https://img.shields.io/badge/License-CC%20BY--SA%204.0-lightgrey.svg\n"}
{"url": "https://github.com/heiko-etzold/teaching-material", "owner": "heiko-etzold", "repository_name": "teaching-material", "date_all_variable_collection": "2023-09-11", "description": null, "size": 16047, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "heiko-etzold", "contributions": 13}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 1608132}], "readme": "Shield: [![CC BY-SA 4.0][cc-by-sa-shield]][cc-by-sa]\n\nThis work is licensed under a\n[Creative Commons Attribution-ShareAlike 4.0 International License][cc-by-sa].\n\n[![CC BY-SA 4.0][cc-by-sa-image]][cc-by-sa]\n\n[cc-by-sa]: http://creativecommons.org/licenses/by-sa/4.0/\n[cc-by-sa-image]: https://licensebuttons.net/l/by-sa/4.0/88x31.png\n[cc-by-sa-shield]: https://img.shields.io/badge/License-CC%20BY--SA%204.0-lightgrey.svg\n"}
{"url": "https://github.com/heiko-etzold/teaching-stoffdidaktik", "owner": "heiko-etzold", "repository_name": "teaching-stoffdidaktik", "date_all_variable_collection": "2023-09-11", "description": "Vorlesungsskript zur Stoffdidaktik Mathematik im Wintersemester 2022/23 an der Universit\u00e4t Potsdam bei Dr. Heiko Etzold", "size": 310727, "stargazers_count": 1, "watchers_count": 1, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "heiko-etzold", "contributions": 28}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["mathematik", "stoffdidaktik", "vorlesungsskript"], "languages": [{"language": "TeX", "num_chars": 60703}, {"language": "HTML", "num_chars": 10075}, {"language": "CSS", "num_chars": 426}], "readme": "# Stoffdidaktik Mathematik\nVorlesungsskript zur Stoffdidaktik Mathematik im Wintersemester 2021/22 an der Universit\u00e4t Potsdam bei Dr. Heiko Etzold\n\nDas Respository stellt die Rohdaten des o.g. Vorlesungsskriptes zur Verf\u00fcgung, das mit RStudio erstellt worden ist. \nAufgrund der CC-BY-SA-4.0-Lizenz ist es m\u00f6glich und gew\u00fcnscht , die Materialien weiterzuverwenden, abzu\u00e4ndern und \nerneut unter einer entsprechenden Lizenz offen zur Verf\u00fcgung zu stellen.\n\nDas Skript selbst ist unter https://stoffdidaktik.heiko-etzold.de einsehbar.\n\n"}
{"url": "https://github.com/heyhen/funNCion", "owner": "heyhen", "repository_name": "funNCion", "date_all_variable_collection": "2023-09-11", "description": "predicting LOF vs GOF variant effects in SCN and CACNA1 genes", "size": 13068, "stargazers_count": 3, "watchers_count": 3, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "heyhen", "contributions": 22}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 19536}], "readme": "# funNCion\n\nThe program funNCion predicts functional effects of pathogenic variants in voltage-gated sodium and calcium channels encoded by the SCN and CACNA1 gene families.\nThis repository includes the code and files to perform the machine learning based predictions.\n\nFind out more on the bioRxiv version of our manuscript: https://www.biorxiv.org/content/10.1101/671453v1. \nCheck out the online tool: http://funNCion.broadinstitute.org.\nFind the code/data tables used to perform ancestry conditional site-specific selection here: https://github.com/astheeggeggs/parsel.\n"}
{"url": "https://github.com/heyhen/starter-hugo-research-group", "owner": "heyhen", "repository_name": "starter-hugo-research-group", "date_all_variable_collection": "2023-09-11", "description": null, "size": 51972, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "heyhen", "contributions": 211}, {"contributor": "gcushen", "contributions": 17}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 399}, {"language": "SCSS", "num_chars": 201}], "readme": "# [Hugo Research Group Theme](https://github.com/wowchemy/starter-hugo-research-group)\n\n[![Screenshot](./preview.png)](https://wowchemy.com/hugo-themes/)\n\nThe **Research Group Template** empowers your research group to easily create a beautiful website with a stunning homepage, news, academic publications, events, team profiles, and a contact form.\n\n\ufe0f**Trusted by 250,000+ researchers, educators, and students.** Highly customizable via the integrated **no-code, widget-based Wowchemy page builder**, making every site truly personalized \u2b50\u2b50\u2b50\u2b50\u2b50\n\n[![Get Started](https://img.shields.io/badge/-Get%20started-ff4655?style=for-the-badge)](https://wowchemy.com/hugo-themes/)\n[![Discord](https://img.shields.io/discord/722225264733716590?style=for-the-badge)](https://discord.com/channels/722225264733716590/742892432458252370/742895548159492138)  \n[![Twitter Follow](https://img.shields.io/twitter/follow/wowchemy?label=Follow%20on%20Twitter)](https://twitter.com/wowchemy)\n\nEasily write technical content with plain text Markdown, LaTeX math, diagrams, RMarkdown, or Jupyter, and import publications from BibTeX.\n\n[Check out the latest demo](https://research-group.netlify.app/) of what you'll get in less than 60 seconds, or [view the showcase](https://wowchemy.com/creators/).\n\nThe integrated [**Wowchemy**](https://wowchemy.com) website builder and CMS makes it easy to create a beautiful website for free. Edit your site in the CMS (or your favorite editor), generate it with [Hugo](https://github.com/gohugoio/hugo), and deploy with GitHub or Netlify. Customize anything on your site with widgets, light/dark themes, and language packs.\n\n- \ud83d\udc49 [**Get Started**](https://wowchemy.com/hugo-themes/)\n- \ud83d\udcda [View the **documentation**](https://wowchemy.com/docs/)\n- \ud83d\udcac [Chat with the **Wowchemy research community**](https://discord.gg/z8wNYzb) or [**Hugo community**](https://discourse.gohugo.io)\n- \u2b07\ufe0f **Automatically import citations from BibTeX** with the [Hugo Academic CLI](https://github.com/wowchemy/hugo-academic-cli)\n- \ud83d\udc26 Share your new site with the community: [@wowchemy](https://twitter.com/wowchemy) [@GeorgeCushen](https://twitter.com/GeorgeCushen) [#MadeWithWowchemy](https://twitter.com/search?q=%23MadeWithWowchemy&src=typed_query)\n- \ud83d\uddf3 [Take the survey and help us improve #OpenSource](https://forms.gle/NioD9VhUg7PNmdCAA)\n- \ud83d\ude80 [Contribute improvements](https://github.com/wowchemy/wowchemy-hugo-themes/blob/main/CONTRIBUTING.md) or [suggest improvements](https://github.com/wowchemy/wowchemy-hugo-themes/issues)\n- \u2b06\ufe0f **Updating?** View the [Update Guide](https://wowchemy.com/docs/hugo-tutorials/update/) and [Release Notes](https://github.com/wowchemy/wowchemy-hugo-themes/releases)\n\n## We ask you, humbly, to support this open source movement\n\nToday we ask you to defend the open source independence of the Wowchemy website builder and themes \ud83d\udc27\n\nWe're an open source movement that depends on your support to stay online and thriving, but 99.9% of our creators don't give; they simply look the other way.\n\n### [\u2764\ufe0f Click here to become a GitHub Sponsor, unlocking awesome perks such as _exclusive academic templates and widgets_](https://github.com/sponsors/gcushen)\n\n## Demo credits\n\nPlease replace the demo images with your own.\n\n- [Female scientist](https://unsplash.com/photos/uVnRa6mOLOM)\n- [2 Coders](https://unsplash.com/photos/kwzWjTnDPLk)\n- [Cafe](https://unsplash.com/photos/RnDGGnMEOao)\n- Blog posts\n  - https://unsplash.com/photos/AndE50aaHn4\n  - https://unsplash.com/photos/OYzbqk2y26c\n- Avatars\n  - https://unsplash.com/photos/5yENNRbbat4\n  - https://unsplash.com/photos/WNoLnJo7tS8\n"}
{"url": "https://github.com/hGl0/BA_Code", "owner": "hGl0", "repository_name": "BA_Code", "date_all_variable_collection": "2023-09-11", "description": "Implementation for my bachelor thesis about fair correlation clustering", "size": 6629, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "hGl0", "contributions": 35}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 1411856}, {"language": "Python", "num_chars": 15545}]}
{"url": "https://github.com/hGl0/Covid-19", "owner": "hGl0", "repository_name": "Covid-19", "date_all_variable_collection": "2023-09-11", "description": "Implementation of COVID-19 feature analysis and machine learning techniques to predict outcome of infection", "size": 3764, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "hGl0", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 3525446}]}
{"url": "https://github.com/hGl0/Cryptology", "owner": "hGl0", "repository_name": "Cryptology", "date_all_variable_collection": "2023-09-11", "description": "Implementations for course cryptology at AU", "size": 10, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "hGl0", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 6497}]}
{"url": "https://github.com/hGl0/Dynamics-of-the-climate-System-1", "owner": "hGl0", "repository_name": "Dynamics-of-the-climate-System-1", "date_all_variable_collection": "2023-09-11", "description": "Implementation of Myles Model to display changes of temperature over time regarding CO2 changes", "size": 413, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hGl0", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 7432}]}
{"url": "https://github.com/hGl0/IDA", "owner": "hGl0", "repository_name": "IDA", "date_all_variable_collection": "2023-09-11", "description": "Implementation of project for course Intelligente Datenanalyse/Machine Learning at University Potsdam", "size": 1829, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hGl0", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 2105170}], "readme": "# IDA\nImplementation of project for course Intelligente Datenanalyse/Machine Learning at University Potsdam\nContains implementation with a decision tree, random forest and neural network as well as evaluation and comparism of these models\n"}
{"url": "https://github.com/hGl0/NearestPair", "owner": "hGl0", "repository_name": "NearestPair", "date_all_variable_collection": "2023-09-11", "description": "Implementation of algorithms to find the closest pair of points in a set in two dimensional space", "size": 7, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hGl0", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 9793}], "readme": "# NearestPair\nImplementation of algorithms to find the closest pair of points in a set in two dimensional space.\n\nDuring the Cartesian Seminar of University Potsdam we took a look into Probabilistic Algorithms (1976) by M. O. Rabin.\nThis repository aims to implement some approaches mentioned in the paper for the sake of better understanding and comparism.\n"}
{"url": "https://github.com/hGl0/Sarcopenia", "owner": "hGl0", "repository_name": "Sarcopenia", "date_all_variable_collection": "2023-09-11", "description": "Data and implementation of statistical analyiss of sarcopenia dataset", "size": 1873, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hGl0", "contributions": 14}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 325557}, {"language": "TeX", "num_chars": 17757}]}
{"url": "https://github.com/hkraemer/Border-effect-corrections-for-diagonal-line-based-recurrence-quantification-analysis-measures", "owner": "hkraemer", "repository_name": "Border-effect-corrections-for-diagonal-line-based-recurrence-quantification-analysis-measures", "date_all_variable_collection": "2023-09-11", "description": "This repository contains all correction schemes proposed and used in the article \"Border effect corrections for diagonal line based recurrence quantification analysis measures\" (submitted to Physics Letters A)", "size": 11803, "stargazers_count": 1, "watchers_count": 1, "language": "MATLAB", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hkraemer", "contributions": 21}, {"contributor": "pucicu", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "MATLAB", "num_chars": 132664}], "readme": "# Border-effect-corrections-for-diagonal-line-based-recurrence-quantification-analysis-measures\n\nThis repository contains all correction schemes proposed and used in the article \"Border \neffect corrections for diagonal line based recurrence quantification analysis measures\" \n(Kraemer & Marwan Physics Letters A, 2019). There are basically two kinds of corrections: \n\n1. correction schemes for counting the diagonal lines in a recurrence plot \n   (the `dl_`-functions) and \n   \n2. correction schemes for the recurrence plot itself in order to suppress the effect of \n   tangential motion (the `rp_`-functions)\n\nSee the respective docstrings for further information.\n\nTo get an idea of the functionality of the correction approaches you might just run the\nMATLAB-Live scripts `examples_correction_schemes_Logistic_map.mlx` and \n`examples_correction_schemes_Roessler_system.mlx`, respectively (or the plain code found in\nthe corresponding `.m`-files). In these scripts we exemplary show the application of the\nmentioned methods to map and flow data, similar to the data used in the paper. For a \nbetter understanding you should run the different sections in the script individually. \nPlay around with the parameters and noise level of the data! \n\nIn order to properly run the provided code you might need to install the CRP toolbox by\nNorbert Marwan (open source; [http://tocsy.pik-potsdam.de/CRPtoolbox/]\n(http://tocsy.pik-potsdam.de/CRPtoolbox/)) and the Signal Processing toolbox from MathWorks \n(just for the `rp_LM2P`-function; [https://de.mathworks.com/products/signal.html]\n(https://de.mathworks.com/products/signal.html)).\n"}
{"url": "https://github.com/hkraemer/InterSpikeSpectra-Matlab", "owner": "hkraemer", "repository_name": "InterSpikeSpectra-Matlab", "date_all_variable_collection": "2023-09-11", "description": "InterSpikeSpectra for Matlab", "size": 1354, "stargazers_count": 0, "watchers_count": 0, "language": "MATLAB", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "hkraemer", "contributions": 38}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "MATLAB", "num_chars": 27716}], "readme": "# InterSpikeSpectra for Matlab\n\nA MATLAB toolbox for obtaining inter-spike spectra from signals. It is recommended to analyze \"spiky\" signals with \nthis method. As the authors showed in the corresponding paper (Kraemer et al. 2022, Spike spectra for recurrences) \nthis method can yield reasonable results and insights into $\\tau$-recurrence rate signals obtained from \nrecurrence plots of the underlying signal.\n\n# Installation\nSimply double-click `InterSpikeSpectra-Matlab.mltbx` for installing the toolbox.\n\n# Functionality\nThe main function to call is `inter_spike_spectrum()`, simply type \n```matlab\nhelp inter_spike_spectrum\n```\ninto you MATLAB-IDE and read the documentation including an example how to use it."}
{"url": "https://github.com/hkraemer/InterSpikeSpectra.jl", "owner": "hkraemer", "repository_name": "InterSpikeSpectra.jl", "date_all_variable_collection": "2023-09-11", "description": "Obtaining spectra of spike-train-decomposed signals.", "size": 171, "stargazers_count": 0, "watchers_count": 0, "language": "Julia", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 5, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 5, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "hkraemer", "contributions": 41}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Julia", "num_chars": 24456}], "readme": "# InterSpikeSpectra\n\n[![Stable](https://img.shields.io/badge/docs-stable-blue.svg)](https://hkraemer.github.io/InterSpikeSpectra.jl/stable)\n[![Dev](https://img.shields.io/badge/docs-dev-blue.svg)](https://hkraemer.github.io/InterSpikeSpectra.jl/dev)\n[![Build Status](https://github.com/hkraemer/InterSpikeSpectra.jl/actions/workflows/CI.yml/badge.svg?branch=main)](https://github.com/hkraemer/InterSpikeSpectra.jl/actions/workflows/CI.yml?query=branch%3Amain)\n\n# InterSpikeSpectra.jl\n\nA Julia package for obtaining inter-spike spectra from signals. It is recommended to analyze \"spiky\" signals with \nthis method. As the authors showed in the corresponding paper (Kraemer et al. 2022, Spike spectra for recurrences) \nthis method can yield reasonable results and insights into $\\tau$-recurrence rate signals obtained from \nrecurrence plots of the underlying signal.\n\n# Installation\nIn Julia, activate your package manager via `]`+`ENTER`, then type\n```julia\nadd https://github.com/hkraemer/InterSpikeSpectra.jl.git\n```\nWhen you now type \n```julia\nstatus\n```\nyou should see `InterSpikeSpectra.jl` listed. Now it is ready to use in any of your script via \n```julia\nusing InterSpikeSpectra\n\n#...\n```\n\n# Functionality\nThe main function to call is `inter_spike_spectrum()`, simply type \n```julia\n? inter_spike_spectrum\n```\ninto you Julia-IDE and read the documentation.\n"}
{"url": "https://github.com/hkraemer/MCDTS.jl", "owner": "hkraemer", "repository_name": "MCDTS.jl", "date_all_variable_collection": "2023-09-11", "description": null, "size": 342496, "stargazers_count": 1, "watchers_count": 1, "language": "Julia", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hkraemer", "contributions": 154}, {"contributor": "maximilian-gelbrecht", "contributions": 20}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Julia", "num_chars": 101341}], "readme": "# Monte Carlo Decision Tree Search for optimal embedding\n\nThis project implements the MCDTS algorithm outlined in the paper \"Optimal state space reconstruction via Monte Carlo Decision Tree Search\", accepted for publication in Nonlinear Dynamics. It aims to provide an optimal time delay state space reconstruction from time series data with the help of decisions trees and suitable statistics that guide the decisions done during the rollout of these trees. For all details of the algorithm the reader is referred to the accompanying paper. Here we provide an implementation of all the variants described in the paper. All major functions have docstrings that describe their use. In what follows basic use examples are outlined.\n\n## Usage\n\n*This repository serves the purpose of reproducibility only*. The proposed method will soon be part of the [DynamicalSystems.jl framework](https://juliadynamics.github.io/DynamicalSystems.jl/latest/) which will also contain sufficient documentation of the functionality. In order to reproduce the data, which has been used in the paper you have to\nset back this repository to commit 842037 (MCDTS version 0.9.10). We are still further developing this repo in order to incorporate more functionality and preparing the\ncode for a migration to [DynamicalSystems.jl](https://juliadynamics.github.io/DynamicalSystems.jl/latest/).\n\nIf you do not want to wait that long, we give an example of the basic usage (for that old version we mentioned).\nWe embed a Lorenz63 system. This is meant as a toy example: we generate\ndata from a Lorenz63 system and then try to reconstruct the full state space from only one of the three observables.\n\nFor this we also make use of `DynamicalSystems.jl`.\n\nFirst we import the needed modules and generate a long trajectory of the Lorenz system (and discard any transient dynamics)\n\n```julia\nusing DynamicalSystems, MCDTS, Random, Test, DelayEmbeddings\n\n# Check Lorenz System\nRandom.seed!(1234)\nds = Systems.lorenz()\ndata = trajectory(ds,200)\ndata = data[10001:end,:]\n```\n\nThe easiest way to use MCDTS for embedding is to use it with its default options just as\n\n```julia\ntree = mcdts_embedding(data, 100)\n```\nhere with `N=100` trials. This will perform the MCDTS algorithm and return the full decision tree. The best embedding can then just be printed as\n\n```julia\nbest_node = MCDTS.best_embedding(tree)\nprintln(best_node)\n```\ne.g.\n```\nNode with \u03c4=12, i_t=1 ,L=-1.5795030971438209 - full embd. \u03c4=[0, 61, 48, 12] ,i_ts=[1, 1, 1, 1]\n```\nThis means we have a 4-dimensional embedding with delays [0, 61, 48, 12], which decreased\nthe chosen cost/Loss-function (in this case the L-statistic) by a total amount of\nL=-1.5795030971438209. Further, customized embedding options covering an ensemble\nof different cost-functions can be looked up in the documentation.\n"}
{"url": "https://github.com/hkraemer/PECUZAL_Julia", "owner": "hkraemer", "repository_name": "PECUZAL_Julia", "date_all_variable_collection": "2023-09-11", "description": "For Hauke and George's code on delay coordinate embedding", "size": 22928, "stargazers_count": 0, "watchers_count": 0, "language": "Julia", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hkraemer", "contributions": 70}, {"contributor": "Datseris", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": true, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Julia", "num_chars": 353745}, {"language": "MATLAB", "num_chars": 67935}, {"language": "Shell", "num_chars": 1450}], "readme": ".. image:: https://img.shields.io/badge/docs-dev-blue.svg\n    :target: https://juliadynamics.github.io/DynamicalSystems.jl/dev/embedding/unified/\n\n.. image:: https://zenodo.org/badge/DOI/10.5281/zenodo.4449785.svg\n   :target: https://doi.org/10.5281/zenodo.4449785\n\nPECUZAL Julia\n=============\nThis code base is using the Julia Language and `DrWatson <https://juliadynamics.github.io/DrWatson.jl/stable/>`_\nto make a reproducible scientific project, authored by K.Hauke Kraemer and\nGeorge Datseris. It contains all the source code for producing the article [kraemer2020]_.\n\n\nTo (locally) reproduce this project, do the following:\n\n0. Download this code base. Notice that raw data are typically not included in the\n   git repo and may need to be downloaded independently.\n1. Open a Julia console and do:\n\n   .. code-block:: julia\n\n       julia> cd(\"path/to/this/project\")\n       julia> using Pkg; Pkg.activate(\".\")\n       julia> Pkg.instantiate()\n\nThis will install all necessary packages for you to be able to run the scripts and\neverything should work out of the box.\n\nDocumentation\n=============\nThis repository is not intended to make a self-contained Julia package, but rather\ngive readers of [kraemer2020]_ the opportunity to get full access to any source\ncode.\nThe PECUZAL method is incorporated and maintained in the\n`DynamicalSystems.jl <https://juliadynamics.github.io/DynamicalSystems.jl/dev/>`_-Ecosystem,\nspecifically in the `DelayEmbeddings.jl <https://github.com/JuliaDynamics/DelayEmbeddings.jl>`_\npackage. `Here <https://juliadynamics.github.io/DynamicalSystems.jl/latest/embedding/unified/>`_\nthe reader can find a full documentation and some basic example illustrating the usage of the PECUZAL method.\n\nCiting and reference\n====================\nIf you enjoy this tool and find it valuable for your research please cite\n\n.. [kraemer2020] Kraemer et al., \"A unified and automated approach to attractor reconstruction\",  `arXiv:2011.07040 [physics.data-an] <https://arxiv.org/abs/2011.07040>`_, 2020.\n\nor as BiBTeX-entry:\n\n::\n\n    @misc{kraemer2020,\n    title={A unified and automated approach to attractor reconstruction},\n    author={K. H. Kraemer and G. Datseris and J. Kurths and I. Z. Kiss and J. L. Ocampo-Espindola and N. Marwan},\n    year={2020},\n    eprint={2011.07040},\n    archivePrefix={arXiv},\n    primaryClass={physics.data-an}\n    url={https://arxiv.org/abs/2011.07040}\n    }\n\n\nLicence\n=======\nThis is program is free software and runs under `MIT Licence <https://opensource.org/licenses/MIT>`_.\n"}
{"url": "https://github.com/hkraemer/PECUZAL_Matlab", "owner": "hkraemer", "repository_name": "PECUZAL_Matlab", "date_all_variable_collection": "2023-09-11", "description": "PECUZAL implementation in Matlab", "size": 47932, "stargazers_count": 1, "watchers_count": 1, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 3, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 3, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "hkraemer", "contributions": 91}, {"contributor": "pucicu", "contributions": 15}, {"contributor": "JayeshMD", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": true, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 1660661}, {"language": "MATLAB", "num_chars": 54785}], "readme": ".. image:: https://github.com/hkraemer/PECUZAL_Matlab/actions/workflows/matlab-actions.yml/badge.svg\n    :target: https://github.com/hkraemer/PECUZAL_Matlab/actions\n\n.. image:: https://img.shields.io/badge/docs-dev-blue.svg\n    :target: https://hkraemer.github.io/PECUZAL_Matlab/\n\n.. image:: https://zenodo.org/badge/DOI/10.5281/zenodo.4451879.svg\n   :target: https://doi.org/10.5281/zenodo.4451879\n\n.. image:: https://www.mathworks.com/matlabcentral/images/matlab-file-exchange.svg\n  :target: https://de.mathworks.com/matlabcentral/fileexchange/86004-pecuzal-embedding-algorithm-for-matlab\n\n\nPECUZAL Matlab\n==============\n\nWe introduce the PECUZAL automatic embedding of time series method for Matlab. It is solely based\non the paper [kraemer2021]_ `(Open Source) <http://iopscience.iop.org/article/10.1088/1367-2630/abe336>`_, where the functionality is explained in detail. Here we\ngive an introduction to its easy usage in three examples. Enjoy Embedding!\n\n.. image:: icon.png\n\n\nGetting started\n===============\n\nThere are two ways of using the proposed PECUZAL method:\n\n- Install as Toolbox. This is the easiest way and allows the usage of the the function `pecuzal_embedding.m` independently from your current working directory. It gets treated as a built-in Matlab-function and you do not have to copy any files etc. For this simply download the 'pecuzal-embedding.mltbx' from this repository or from `Matlab-Central <https://de.mathworks.com/matlabcentral/fileexchange/86004-pecuzal-embedding-algorithm-for-matlab>`_ and double-click `pecuzal-embedding.mltbx` for installation. That's it.\n- You can also download this repository and copy the folder into the MATLAB user's directory. This is usually the user's \"Documents\" folder appended with \"MATLAB\" (you can find out using the function `userpath`). Add the toolbox by the `addpath` command, e.g., `addpath ~/Documents/MATLAB/PECUZAL_Matlab` on a Linux system. For everyday use, copy this command to a `startup.m` file in the MATLAB user's directory.\n\n\nNOTE\n====\n\nFor performance reasons we recommend to use the implementation\nin the `Julia language <https://juliadynamics.github.io/DynamicalSystems.jl/latest/embedding/unified/>`_,\nin order to get fast results, especially in the multivariate case. Moreover,\nit is well documented and embedded in the\n`DynamicalSystems.jl <https://juliadynamics.github.io/DynamicalSystems.jl/dev/>`_ ecosystem.\nThe computation times can be magnitudes higher than in the Julia implementation.\n\n\nDocumentation and basic usage\n=============================\n\nThere is a `documentation <https://hkraemer.github.io/PECUZAL_Matlab/>`_ and a\n`Matlab Live-Script <https://github.com/hkraemer/PECUZAL_Matlab/blob/main/html/pecuzal_examples.mlx>`_ available including some basic usage examples.\n\n\nCiting and reference\n====================\nIf you enjoy this tool and find it valuable for your research please cite\n\n.. [kraemer2021] Kraemer et al., \"A unified and automated approach to attractor reconstruction\", New Journal of Physics 23(3), 033017. `doi:10.1088/1367-2630/abe336 <https://doi.org/10.1088/1367-2630/abe336>`_ (2021).\n\nor as BiBTeX-entry:\n\n::\n\n\ufeff   @article{Kraemer2021,\n        doi = {10.1088/1367-2630/abe336},\n        url = {https://doi.org/10.1088/1367-2630/abe336},\n        year = 2021,\n        month = {mar},\n        publisher = {{IOP} Publishing},\n        volume = {23},\n        number = {3},\n        pages = {033017},\n        author = {K H Kraemer and G Datseris and J Kurths and I Z Kiss and J L Ocampo-Espindola and N Marwan},\n        title = {A unified and automated approach to attractor reconstruction},\n        journal = {New Journal of Physics},\n        abstract = {We present a fully automated method for the optimal state space reconstruction from univariate and multivariate time series. The proposed methodology generalizes the time delay embedding procedure by unifying two promising ideas in a symbiotic fashion. Using non-uniform delays allows the successful reconstruction of systems inheriting different time scales. In contrast to the established methods, the minimization of an appropriate cost function determines the embedding dimension without using a threshold parameter. Moreover, the method is capable of detecting stochastic time series and, thus, can handle noise contaminated input without adjusting parameters. The superiority of the proposed method is shown on some paradigmatic models and experimental data from chaotic chemical oscillators.}\n    }\n\n\nLicence\n=======\nThis is program is free software and runs under `MIT Licence <https://opensource.org/licenses/MIT>`_.\n"}
{"url": "https://github.com/hkraemer/PECUZAL_python", "owner": "hkraemer", "repository_name": "PECUZAL_python", "date_all_variable_collection": "2023-09-11", "description": null, "size": 14975, "stargazers_count": 4, "watchers_count": 4, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 3, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 3, "open_issues": 0, "watchers": 4, "default_branch": "main", "contributors": [{"contributor": "hkraemer", "contributions": 118}, {"contributor": "pucicu", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": true, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 55078}], "readme": ".. image:: https://github.com/hkraemer/PECUZAL_python/actions/workflows/test_pecuzal.yml/badge.svg\n    :target: https://github.com/hkraemer/PECUZAL_python/actions/workflows/test_pecuzal.yml\n\n.. image:: https://img.shields.io/badge/docs-dev-blue.svg\n    :target: https://hkraemer.github.io/PECUZAL_python/\n\n.. image:: https://zenodo.org/badge/312547816.svg\n   :target: https://zenodo.org/badge/latestdoi/312547816\n\nPECUZAL Python\n==============\n\nWe introduce the PECUZAL automatic embedding of time series method for Python. It is solely based\non the paper [kraemer2021]_ `(Open Source) <https://iopscience.iop.org/article/10.1088/1367-2630/abe336>`_, where the functionality is explained in detail. Here we\ngive an introduction to its easy usage in three examples. Enjoy Embedding!\n\n.. image:: icon.png\n\n\nGetting started\n===============\n\nInstall from `PyPI <https://pypi.org/project/pecuzal-embedding/>`_ by simply typing\n\n::\n\n   pip install pecuzal-embedding\n\nin your console.\n\nNOTE\n====\n\nThis implementation is not profiled well. We recommend to use the implementation\nin the `Julia language <https://juliadynamics.github.io/DynamicalSystems.jl/latest/embedding/unified/>`_ or\nin `Matlab <https://github.com/hkraemer/PECUZAL_Matlab>`_,\nin order to get fast results, especially in the multivariate case. Moreover,\nit is well documented and embedded in the\n`DynamicalSystems.jl <https://juliadynamics.github.io/DynamicalSystems.jl/dev/>`_ ecosystem.\nFor instance, the compuations made in the `Univariate example <https://hkraemer.github.io/PECUZAL_python/univariate_example.html>`_\nand the `Multivariate example <https://hkraemer.github.io/PECUZAL_python/multivariate_example.html>`_\nin this documentation took approximately `800s` (approx. 13 mins) and `4700s` (approx. 1 hour and 10 mins!), respectively, even when\nusing the `econ` option in the function call, for an accelerated computation. In the Julia implementation\nthe exact same computation took `4s` and `25s`, respectively! (running on a 2.8GHz Quad-Core i7,  16GB 1600 MHz DDR3)\n\n\nDocumentation\n=============\n\nThere is a `documentation available <https://hkraemer.github.io/PECUZAL_python/>`_ including some basic usage examples.\n\n\nCiting and reference\n====================\nIf you enjoy this tool and find it valuable for your research please cite\n\n.. [kraemer2021] Kraemer et al., \"A unified and automated approach to attractor reconstruction\", New Journal of Physics 23(3), 033017,  `10.1088/1367-2630/abe336 <https://iopscience.iop.org/article/10.1088/1367-2630/abe336>`_, 2021.\n\nor as BiBTeX-entry:\n\n::\n\n    @article{Kraemer2021,\n        doi = {10.1088/1367-2630/abe336},\n        url = {https://doi.org/10.1088/1367-2630/abe336},\n        year = 2021,\n        month = {mar},\n        publisher = {{IOP} Publishing},\n        volume = {23},\n        number = {3},\n        pages = {033017},\n        author = {K H Kraemer and G Datseris and J Kurths and I Z Kiss and J L Ocampo-Espindola and N Marwan},\n        title = {A unified and automated approach to attractor reconstruction},\n        journal = {New Journal of Physics},\n        abstract = {We present a fully automated method for the optimal state space reconstruction from univariate and multivariate time series. The proposed methodology generalizes the time delay embedding procedure by unifying two promising ideas in a symbiotic fashion. Using non-uniform delays allows the successful reconstruction of systems inheriting different time scales. In contrast to the established methods, the minimization of an appropriate cost function determines the embedding dimension without using a threshold parameter. Moreover, the method is capable of detecting stochastic time series and, thus, can handle noise contaminated input without adjusting parameters. The superiority of the proposed method is shown on some paradigmatic models and experimental data from chaotic chemical oscillators.}\n    }\n\n\nLicence\n=======\nThis is program is free software and runs under `MIT Licence <https://opensource.org/licenses/MIT>`_.\n"}
{"url": "https://github.com/hkraemer/Recurrence_Spike_Spectra", "owner": "hkraemer", "repository_name": "Recurrence_Spike_Spectra", "date_all_variable_collection": "2023-09-11", "description": "Reproducible Code Base for the application of the InterSpike-Spektrum idea to tau-recurrence data from complex systems.", "size": 288708, "stargazers_count": 1, "watchers_count": 1, "language": "PostScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "hkraemer", "contributions": 76}, {"contributor": "pucicu", "contributions": 17}, {"contributor": "FHell", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PostScript", "num_chars": 1452724}, {"language": "TeX", "num_chars": 1170728}, {"language": "MATLAB", "num_chars": 365561}, {"language": "Julia", "num_chars": 74050}, {"language": "Shell", "num_chars": 2283}], "readme": "# Recurrence_Spike_Spectra\nReproducible Code Base for the application of the InterSpike-Spektrum idea to tau-recurrence data from complex systems.\n"}
{"url": "https://github.com/hpi-sam/Adversarial-Digital-Twins", "owner": "hpi-sam", "repository_name": "Adversarial-Digital-Twins", "date_all_variable_collection": "2023-09-11", "description": "Materials from the course Adversarial Self-Supervised Learning with Digital Twins", "size": 73361, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 1, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "Phimanu", "contributions": 34}, {"contributor": "max-3l", "contributions": 33}, {"contributor": "christianadriano", "contributions": 18}, {"contributor": "hpi-classroom", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 1479322}, {"language": "Jupyter Notebook", "num_chars": 801993}, {"language": "HTML", "num_chars": 338747}, {"language": "Python", "num_chars": 112516}, {"language": "CSS", "num_chars": 12808}, {"language": "JavaScript", "num_chars": 827}], "readme": "# Adversarial-Digital-Twins\nMaterials from the course Adversarial Self-Supervised Learning with Digital Twins\n"}
{"url": "https://github.com/hpi-sam/AI_Ethics_Engineering", "owner": "hpi-sam", "repository_name": "AI_Ethics_Engineering", "date_all_variable_collection": "2023-09-11", "description": "Prototypes, Tutorials, Speifications for Engineering Ethical AI Systems", "size": 17054, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 14, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 14, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "christianadriano", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# AI_Ethics_Engineering\nPrototypes, Tutorials, Speifications for Engineering Ethical AI Systems\n"}
{"url": "https://github.com/hpi-sam/ask-your-repository-api", "owner": "hpi-sam", "repository_name": "ask-your-repository-api", "date_all_variable_collection": "2023-09-11", "description": "This service provides an api to store artefacts with their related meta-data and tags and performs machine learning on them", "size": 1472, "stargazers_count": 4, "watchers_count": 4, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 16, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 16, "watchers": 4, "default_branch": "master", "contributors": [{"contributor": "Askir", "contributions": 136}, {"contributor": "Adrian-St", "contributions": 118}, {"contributor": "arne-z", "contributions": 34}, {"contributor": "erksch", "contributions": 32}, {"contributor": "henleo", "contributions": 17}, {"contributor": "luisebenkert", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 237724}, {"language": "HTML", "num_chars": 17512}, {"language": "Shell", "num_chars": 1500}, {"language": "Dockerfile", "num_chars": 412}], "readme": "# Elija &middot; Ask your Repository Backend API  \n[![Coverage Status](https://coveralls.io/repos/github/hpi-sam/ask-your-repository-api/badge.svg)](https://coveralls.io/github/hpi-sam/ask-your-repository-api)[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/ambv/black)\n\nThis repo is part of the \"Ask your Repository\" Bachelor project containing the following repos:  \n- [Elija - Ask your Repository Backend API](https://github.com/hpi-sam/ask-your-repository-api)  \n- [Jona - Ask your Repository Web Frontend](https://github.com/hpi-sam/ask-your-repository-web)  \n- [Tobito - Ask your Repository Dialogflow Adapter](https://github.com/hpi-sam/ask-your-repository-dialogflow-adapter)  \n- [Ask your Repository Docker Deployment](https://github.com/hpi-sam/ask-your-repository-docker)  \n- [Ask your Repository Project Documentation](https://github.com/hpi-sam/BP2018HG1)  \n\n\n# Setup service\n- If you have docker installed you can simply run `docker-compose up -d` and skip the rest of this readme.\n- **Install Python 3.7**:\n  - On Windows:\n    - Click: Add path\n    - At the end of installation allow usage of paths longer than 260 characters\n    - See: [Setup Python](https://docs.python.org/3/using/windows.html)\n  - On Unix systems its highly recommended to use [pyenv](https://github.com/pyenv/pyenv#installation) instead for this as it makes swapping python versions much easier.  \n  You can use the installer from [here](https://github.com/pyenv/pyenv-installer) for easy installation.\n\n- **Installing dependencies**:\n  -Setup Poetry:\n    - [Install Poetry](https://poetry.eustace.io/docs/#system-requirements)\n    - Install dependencies via: `poetry install`\n\n  - Copy .env.example into new .env file\n  - It's highly recommended you have docker installed it makes environment setup much easier: https://www.docker.com/get-started\n  - Install Neo4j\n    - Neo4J is our GraphDB you can find more info and an install guide on it here: https://neo4j.com/\n    - To run tests you need a neo4j installation on the ports specified in `.env.testing`\n    - To simply run the application locally I recommend seting up a docker container with neo4j with this command: \n      ```\n      docker run \\\n      --publish=7474:7474 --publish=7687:7687 \\\n      --volume=$HOME/neo4j/data:/data \\\n      --volume=$HOME/neo4j/logs:/logs \\\n      neo4j:3.0\n      ```\n\n  - Install Elasticsearch\n    - [Setup Elasticsearch](https://www.elastic.co/guide/en/elasticsearch/reference/current/install-elasticsearch.html)\n    - Don't forget to set JAVA_HOME path to the path of java jdk\n    - You can setup a local ES docker container with this command:\n      ```\n      docker run -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" docker.elastic.co/elasticsearch/elasticsearch:6.5.2\n      ```\n\n- Setup elasticsearch development and testing\n  - Rename config directory to config.development in your elasticsearch installation directory\n  - Copy the contents of elasticsearch.example.yml in this repository into elasticsearch.yml in config.development\n  - Make a new directory named config.test and copy the contents of config.development into it\n  - Edit the elasticsearch.yml by replacing every occurence of development with test and **change the port to 9400**\n  - Start both services by running\n    `ES_PATH_CONF=config.development ./bin/elasticsearch-service.bat install elasticsearch-development`\n    `./bin/elasticsearch-service.bat start elasticsearch-development`\n    and\n    `ES_PATH_CONF=config.test ./bin/elasticsearch-service.bat install elasticsearch-test`\n    `./bin/elasticsearch-service.bat start elasticsearch-test`\n  - Unfortunately sometimes a service crashes, then you neet to run both commands again\n\n# Install dependencies\n- Run: `poetry install`\n\n# Setup database\n- Install constraints for neo4j for development and testing database (adapt the urls if you have a different setup):\n  - Run: `poetry run neomodel_install_labels application application.models --db bolt://:@localhost:7687`\n  - Run: `poetry run neomodel_install_labels application application.models --db bolt://:@localhost:17687`\n \n# Download Wordkit for synonyms\n- Run: `poetry run shovel utils.download_wordkit`\n\n# Running tests\n- Run: `poetry run mamba specs`\n\n# Running linter\n- Run: `poetry run black --check .`\n- Run: `poetry run flake8 ./`\n\n# Running auto-formater\n- Run: `poetry run black .`\n\nAutoformating and linting can be automized if you have [Pre-Commit](https://pre-commit.com/) installed on user.\n\n# Start service\n- Run: `poetry run flask run`\n\n## Documentation\n\nFurther documentation can be found in the [wiki](https://github.com/hpi-sam/ask-your-repository-api/wiki).\n\n## License\nThis project is licensed under the terms of the MIT license.\n"}
{"url": "https://github.com/hpi-sam/ask-your-repository-dialogflow-adapter", "owner": "hpi-sam", "repository_name": "ask-your-repository-dialogflow-adapter", "date_all_variable_collection": "2023-09-11", "description": "NodeJS API for handling voice query fulfilment with Dialogflow.", "size": 1122, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 31, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 31, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "arne-z", "contributions": 82}, {"contributor": "henleo", "contributions": 26}, {"contributor": "Adrian-St", "contributions": 12}, {"contributor": "erksch", "contributions": 7}, {"contributor": "christianadriano", "contributions": 1}, {"contributor": "Askir", "contributions": 1}, {"contributor": "dependabot[bot]", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 59566}, {"language": "Dockerfile", "num_chars": 426}, {"language": "Shell", "num_chars": 121}], "readme": "# Tobito &middot; Ask your Repository Dialogflow Adapter\n[![Coverage Status](https://coveralls.io/repos/github/hpi-sam/ask-your-repository-dialogflow-adapter/badge.svg?branch=master)](https://coveralls.io/github/hpi-sam/ask-your-repository-dialogflow-adapter?branch=master)\n\nThis repo is part of the \"Ask your Repository\" Bachelor project containing the following repos:  \n- [Elija - Ask your Repository Backend API](https://github.com/hpi-sam/ask-your-repository-api)  \n- [Jona - Ask your Repository Web Frontend](https://github.com/hpi-sam/ask-your-repository-web)  \n- [Tobito - Ask your Repository Dialogflow Adapter](https://github.com/hpi-sam/ask-your-repository-dialogflow-adapter)  \n- [Ask your Repository Docker Deployment](https://github.com/hpi-sam/ask-your-repository-docker)  \n- [Ask your Repository Project Documentation](https://github.com/hpi-sam/BP2018HG1)  \n\n## Setup\n1. Install YARN: https://yarnpkg.com/lang/en/docs/install/\n2. Clone the repository: `git clone https://github.com/hpi-sam/ask-your-repository-dialogflow-adapter.git`\n3. Change directory into the repository folder: `cd ask-your-repository-dialogflow-adapter`\n4. Execute `yarn install` to install dependencies\n5. Execute `yarn flow-typed install` to install types for all dependencies\n5. Start developing and Have fun!\n6. ???\n7. Profit!\n\n## Preconfigured project commands\n\nIf you have a look at the `package.json` you can see quite a few preconfigured 'scripts'.  \nThe most important one is `yarn start`. This basically executes everything you could wish for:\n* Automatically starts builds on file change\n* Automatically restarts the server on file change\n* Automatically executes tests on file change\n* Automatically runs ESLint on file change\n* Automatically runs flow type check on file change\n\nIf you want to only do one of the above you can use: `yarn build`, `yarn serve`, `yarn test`, `yarn lint`, `yarn flow` respectively.  \nFor test and lint the commands `yarn tdd` and `yarn ldd` start a watcher to run them automatically on file change. `yarn build` and `yarn serve` are always running with a watcher.\n\n## Major Dependencies\n\nWe use the [actions on google library](https://www.npmjs.com/package/actions-on-google) to manage out interaction with Dialogflow.\nOur interaction with the backend Elija server is managed with simple axios requests found [here](https://github.com/hpi-sam/ask-your-repository-dialogflow-adapter/blob/master/src/controller/RequestController.js). \n\n## Documentation\n\nFurther documentation can be found in the [Wiki](https://github.com/hpi-sam/ask-your-repository-dialogflow-adapter/wiki).\n\n## License\nThis project is licensed under the terms of the MIT license.\n"}
{"url": "https://github.com/hpi-sam/ask-your-repository-docker", "owner": "hpi-sam", "repository_name": "ask-your-repository-docker", "date_all_variable_collection": "2023-09-11", "description": "Docker Deployment of Ask-Your-Repository", "size": 24, "stargazers_count": 0, "watchers_count": 0, "language": "Shell", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "erksch", "contributions": 42}, {"contributor": "henleo", "contributions": 4}, {"contributor": "arne-z", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Shell", "num_chars": 840}], "readme": "# Ask your Repository Docker Deployment\n\nA docker-compose deployment for ask-your-repository.\n\nThis repo is part of the \"Ask your Repository\" Bachelor project containing the following repos:  \n- [Elija - Ask your Repository Backend API](https://github.com/hpi-sam/ask-your-repository-api)  \n- [Jona - Ask your Repository Web Frontend](https://github.com/hpi-sam/ask-your-repository-web)  \n- [Tobito - Ask your Repository Dialogflow Adapter](https://github.com/hpi-sam/ask-your-repository-dialogflow-adapter)  \n- [Ask your Repository Docker Deployment](https://github.com/hpi-sam/ask-your-repository-docker)  \n- [Ask your Repository Project Documentation](https://github.com/hpi-sam/BP2018HG1)  \n\n## Setup on Server\n\nMake sure [docker](https://docs.docker.com/install/linux/docker-ce/ubuntu/) and [docker-compose](https://docs.docker.com/compose/install/) are installed.\n\n----\n\nClone this repository on your server:\n\n`git clone https://github.com/hpi-sam/ask-your-repository-docker.git`\n\nChange directory:\n\n`cd ask-your-repository-docker`\n\nSetup .env files:\n\n`cp .env.example .env`  \n`cp nginx.env.example nginx.env`\n\n`touch elija.env` (see [here](https://github.com/hpi-sam/ask-your-repository-api/blob/master/.env.example) for env example)  \n`touch tobito.env` (see [here](https://github.com/hpi-sam/ask-your-repository-dialogflow-adapter/blob/master/.env.example) for env example)\n\nFill the environment files with appropriate data.\n\n------\n\nInitialize docker swarm:\n\n`docker swarm init`\n\nExplicitly export your envars:\n\n`export $(cat .env | xargs)`\n\nDeploy application:\n\n`docker stack deploy -c docker-compose.yaml <name>`\n\nMake sure all services are up and running:\n\n`docker service ls`\n\nOnce these steps are executed the following services should be running:\n\n- Main NGINX (Reverse proxy for all services)\n- Jona (Web/Frontend)\n- Elija (API/Backend)\n- Tobito (Dialogflow Adapter)\n- Files NGINX (Serving uploaded files)\n- Elasticsearch (Search database)\n- Neo4J (Graph database)\n\nYou can take a look at the [`docker-compose.yaml`](https://github.com/hpi-sam/ask-your-repository-docker/blob/master/docker-compose.yaml) for more information.\n\n## Changes to the configuration\n\n**Always commit your changes to this repo to keep it in sync with the files on the server!**\n\nDo not make adjustments to the `docker-compose.yaml` directly.  \nInstead, use the env files to change configurations.  \n\nIf you do need to change the compose file try to keep things customizable.  \nMake sure the compose file still works for different environments (development, staging, production).\n\nAfter making adjustments redeploy the stack:\n\n`docker stack deploy -c docker-compose.yaml <name>`\n\n## Redeploy services\n\nYou can deploy another version of a service by using the `deploy` script:\n\n`./deploy <service> <image>`\n\nFor example to deploy the latest Jona image:\n\n`./deploy jona bp2018hg1/jona:latest`\n\nMind that you don't need to specify the real service name with the stack name as a prefix.\nThe stack name is added automatically.\n\nFor more informations view the [deploy script file](https://github.com/hpi-sam/ask-your-repository-docker/blob/master/deploy).\n"}
{"url": "https://github.com/hpi-sam/ask-your-repository-old-api", "owner": "hpi-sam", "repository_name": "ask-your-repository-old-api", "date_all_variable_collection": "2023-09-11", "description": null, "size": 895, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 7, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 7, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Askir", "contributions": 20}, {"contributor": "erksch", "contributions": 9}, {"contributor": "henleo", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 16041}, {"language": "Dockerfile", "num_chars": 156}], "readme": "# esra\nCoverage: [![Coverage Status](https://coveralls.io/repos/github/hpi-sam/ask-your-repository-api/badge.svg)](https://coveralls.io/github/hpi-sam/ask-your-repository-api)  Branch-Master:\n[![CircleCI](https://circleci.com/gh/hpi-sam/ask-your-repository-api/tree/master.svg?style=svg)](https://circleci.com/gh/hpi-sam/ask-your-repository-api/tree/master)\n## Setup\n1. Install YARN: https://yarnpkg.com/lang/en/docs/install/\n2. Clone the repository: `git clone https://github.com/hpi-sam/ask-your-repository-api.git`\n3. Change directory into the repository folder: `cd ask-your-repository-api`\n4. Execute `yarn install` to install dependencies\n5. Execute `yarn flow-typed install` to install types for all dependencies\n5. Start developing and Have fun!\n6. ???\n7. Profit!\n\n## Preconfigured project commands\n\nIf you have a look at the `package.json` you can see quite a few preconfigured 'scripts'.  \nThe most important one is `yarn start`. This basically executes everything you could wish for:\n* Automatically starts builds on file change\n* Automatically restarts the server on file change\n* Automatically executes tests on file change\n* Automatically runs ESLint on file change\n* Automatically runs flow type check on file change\n\nIf you want to only do one of the above you can use: `yarn build`, `yarn serve`, `yarn test`, `yarn lint`, `yarn flow` respectively.  \nFor test and lint the commands `yarn tdd` and `yarn ldd` start a watcher to run them automatically on file change. `yarn build` and `yarn serve` are always running with a watcher.\n\n## [Git Workflow](https://github.com/hpi-sam/BP2018HG1/wiki/Git-Workflow)\n"}
{"url": "https://github.com/hpi-sam/ask-your-repository-web", "owner": "hpi-sam", "repository_name": "ask-your-repository-web", "date_all_variable_collection": "2023-09-11", "description": "React Web Application for visualising and managing image data. Main user interface of the Ask You Repository project.", "size": 11920, "stargazers_count": 2, "watchers_count": 2, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 23, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 23, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "erksch", "contributions": 153}, {"contributor": "Adrian-St", "contributions": 43}, {"contributor": "arne-z", "contributions": 20}, {"contributor": "Askir", "contributions": 18}, {"contributor": "henleo", "contributions": 18}, {"contributor": "luisebenkert", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 236517}, {"language": "CSS", "num_chars": 55197}, {"language": "HTML", "num_chars": 6635}, {"language": "Dockerfile", "num_chars": 466}], "readme": "# Jona &middot; Ask your Repository Web Frontend  \n[![Coverage Status](https://coveralls.io/repos/github/hpi-sam/ask-your-repository-web/badge.svg?branch=master)](https://coveralls.io/github/hpi-sam/ask-your-repository-web?branch=master) [![CircleCI](https://circleci.com/gh/hpi-sam/ask-your-repository-web.svg?style=svg)](https://circleci.com/gh/hpi-sam/ask-your-repository-web)\n\nReact App and frontend of Ask Your Cloud!\n\nThis repo is part of the \"Ask your Repository\" Bachelor project containing the following repos:  \n- [Elija - Ask your Repository Backend API](https://github.com/hpi-sam/ask-your-repository-api)  \n- [Jona - Ask your Repository Web Frontend](https://github.com/hpi-sam/ask-your-repository-web)  \n- [Tobito - Ask your Repository Dialogflow Adapter](https://github.com/hpi-sam/ask-your-repository-dialogflow-adapter)  \n- [Ask your Repository Docker Deployment](https://github.com/hpi-sam/ask-your-repository-docker)  \n- [Ask your Repository Project Documentation](https://github.com/hpi-sam/BP2018HG1)  \n\n## Setup\n1. Install YARN: https://yarnpkg.com/lang/en/docs/install/\n2. Clone the repository: `git clone https://github.com/hpi-sam/ask-your-repository-web.git`\n3. Change directory into the repository folder: `cd ask-your-repository-web`\n4. Execute `yarn install` to install dependencies\n5. Execute `yarn flow-typed install` to install types for all dependencies\n5. Start developing and Have fun!\n6. ???\n7. Profit!\n\n## Available Scripts\n\n`yarn install` &middot; Install dependencies\n\n`yarn start` &middot; Run the app in development mode on `localhost:3000`\n\n`yarn test` &middot; Execute tests\n\n`yarn build` &middot; Build app for production to the `/build` folder\n\n`yarn flow-typed install` &middot; Install flow dependencies\n\n`yarn flow` &middot; Type check the code\n\n`yarn lint` &middot; Run ESLint\n\n## Documentation\n\nFurther documentation can be found in the [Wiki](https://github.com/hpi-sam/ask-your-repository-web/wiki).\n\n## License\nThis project is licensed under the terms of the MIT license.\n"}
{"url": "https://github.com/hpi-sam/bandits-4-self-repair", "owner": "hpi-sam", "repository_name": "bandits-4-self-repair", "date_all_variable_collection": "2023-09-11", "description": "Multi-Armed bandits models for online learning of self-repair actions", "size": 55409, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 4, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 4, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "henleo", "contributions": 4}, {"contributor": "christianadriano", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 10953572}, {"language": "Python", "num_chars": 68971}], "readme": "# bandits-4-self-repair\nMulti-Armed bandits models for online learning of self-repair actions\n"}
{"url": "https://github.com/hpi-sam/BP2018HG1", "owner": "hpi-sam", "repository_name": "BP2018HG1", "date_all_variable_collection": "2023-09-11", "description": "Bachelor Project Documentation", "size": 29639, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 25, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 25, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "henleo", "contributions": 313}, {"contributor": "luisebenkert", "contributions": 24}, {"contributor": "Askir", "contributions": 21}, {"contributor": "christianzoellner", "contributions": 8}, {"contributor": "Adrian-St", "contributions": 8}, {"contributor": "erksch", "contributions": 3}, {"contributor": "arne-z", "contributions": 2}, {"contributor": "christianadriano", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# BP2018HG1\n\nWelcome to the BP2018HG1 wiki!\n\nThis repo is part of the \"Ask your Repository\" Bachelor project containing the following repos:  \n- [Elija - Ask your Repository Backend API](https://github.com/hpi-sam/ask-your-repository-api)  \n- [Jona - Ask your Repository Web Frontend](https://github.com/hpi-sam/ask-your-repository-web)  \n- [Tobito - Ask your Repository Dialogflow Adapter](https://github.com/hpi-sam/ask-your-repository-dialogflow-adapter)  \n- [Ask your Repository Docker Deployment](https://github.com/hpi-sam/ask-your-repository-docker)  \n- [Ask your Repository Project Documentation](https://github.com/hpi-sam/BP2018HG1)  \n\n### Development\n  - [Authentication](contribution/Authentication.md)\n  - [Kubernetes Setup](contribution/Kubernetes-Setup.md)\n  - [Developer (git) Workflow](contribution/Git-Workflow.md)\n  - [Review Guide](contribution/reviews.md)\n  - [Codestyle](contribution/linting.md)  \n  - [ZenHub Board](https://app.zenhub.com/workspaces/christian-ity-5c6c00094c2d6a432f785fcf/)\n  - [Definition of Done](dod.md)  \n  \n### Bachelor Thesis\n  - [Ideas](thesis/ideas.md)\n  - [Codebases](thesis/codebases.md)\n\n### User Testing\n  - [User Testing](contribution/UserTestingEval.md)\n\n\n## License\nThis project is licensed under the terms of the MIT license.\n"}
{"url": "https://github.com/hpi-sam/digital-fuesim-manv", "owner": "hpi-sam", "repository_name": "digital-fuesim-manv", "date_all_variable_collection": "2023-09-11", "description": "A German simulation system for training emergency medical services leadership personnel on how to manage Mass Casualty Incidents.", "size": 13845, "stargazers_count": 14, "watchers_count": 14, "language": "TypeScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": true, "forks_count": 7, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 76, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 7, "open_issues": 76, "watchers": 14, "default_branch": "dev", "contributors": [{"contributor": "ClFeSc", "contributions": 632}, {"contributor": "Dassderdie", "contributions": 621}, {"contributor": "Greenscreen23", "contributions": 98}, {"contributor": "hpistudent72", "contributions": 86}, {"contributor": "Nils1729", "contributions": 82}, {"contributor": "lukasrad02", "contributions": 65}, {"contributor": "benn02", "contributions": 53}, {"contributor": "anonym-HPI", "contributions": 19}, {"contributor": "web-flow", "contributions": 9}, {"contributor": "dependabot[bot]", "contributions": 4}, {"contributor": "github-actions[bot]", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["angular", "emergency-medical-services", "germany", "immerjs", "mci", "nodejs", "openlayers", "simulation", "training", "typescript"], "languages": [{"language": "TypeScript", "num_chars": 1925441}, {"language": "HTML", "num_chars": 260277}, {"language": "JavaScript", "num_chars": 21410}, {"language": "Shell", "num_chars": 4493}, {"language": "Dockerfile", "num_chars": 3671}, {"language": "SCSS", "num_chars": 1995}, {"language": "Batchfile", "num_chars": 78}], "readme": "# Digitale F\u00fcSim MANV\n\n## If you're interested in the most recent stable release, please check out the [main](https://github.com/hpi-sam/digital-fuesim-manv/tree/main) branch.\n\nThis is the codebase for a digital implementation of the \"F\u00fcSim MANV\" (F\u00fchrungssimulation Massenanfall von Verletzen), a German simulation system for training emergency medical services leadership personnel on how to manage [Mass Casualty Incidents](https://en.wikipedia.org/wiki/Mass-casualty_incident).\n\n**You can try it out at [https://fuesim-manv.de/](https://fuesim-manv.de/)**.\n\n![image](https://user-images.githubusercontent.com/18506183/172071147-24b9aabe-51ee-4105-a5a4-6cbf8063eece.png)\n_A screenshot of a part of an MCI exercise with initially ca. 50 patients at the Brandenburg Gate._\n\nThe concept is as follows:\n\n-   A _trainer_ creates an exercise, which consists of _patients_, _vehicles_, _viewports_, _transferPoints_ and other objects placed on a map.\n-   _Participants_ can then join the exercise.\n-   The _trainer_ can restrict the participants to a specific _viewport_. The _participant_ cannot move out of this area.\n-   _Vehicles_ (containing _material_, _personnel_ and (sometimes) _patients_) can be transferred to other areas via _transferPoints_.\n-   After the exercise is started, _patients_ that are not adequately treated by _personnel_ and _material_ can deteriorate and die. The goal of the _participants_ is to prevent the _patients_ from dying and transport them to the _hospitals_. To do this effectively they have to communicate with each other (via real radio devices, or remote via third-party services) and make the right decisions.\n-   Afterward, the exercise can be evaluated via statistics and a \"time-travel\" feature.\n\nThis simulation has been designed in cooperation with and with support from the [Federal Academy for Civil Protection and Civil Defence](https://www.bbk.bund.de/DE/Themen/Akademie-BABZ/akademie-babz_node.html) of the [Federal Office of Civil Protection and Disaster Assistance Germany](https://www.bbk.bund.de/DE/Home/home_node.html), who are the original copyright holders of the analog \"F\u00fcSim MANV\" simulation system, and the [Malteser Hilfsdienst e.V. Berlin](https://www.malteser-berlin.de/) as well as the [Johanniter Akademie NRW, Campus M\u00fcnster der Johanniter-Unfall-Hilfe e.V.](https://www.johanniter.de/bildungseinrichtungen/johanniter-akademie/johanniter-akademie-nordrhein-westfalen/standorte-der-akademie-in-nordrhein-westfalen/campus-muenster/)\n\nThe simulation is implemented as a web application with an Angular frontend and NodeJS backend.\n\nThis project is currently developed as a [bachelor project](https://hpi.de/en/studies/before-your-studies/degree-programs/bachelor.html) at the [HPI](https://hpi.de/). You can find the official project website [here](https://hpi.de/giese/teaching/bachelor-projects/digitales-fuehrungssimulationstraining.html).\n\n## Links for collaborators\n\n-   [Internal test scenarios](https://github.com/hpi-sam/digital-fuesim-manv_test-scenarios)\n    -   Used only for private testing\n-   [Public test scenarios](https://github.com/hpi-sam/digital-fuesim-manv-public-test-scenarios)\n    -   Used for test scenarios in pipelines, Can also be used for private testing\n    -   For usage see the README.md in that repo\n    -   This repo is also a submodule of this repo. Use `--recurse-submodules` when cloning the repo or `run git submodule update --init --recursive` if you have cloned the repo already to get its contents.\n\n## Installation\n\n1. Install [NodeJs](https://nodejs.org/) (at least version 18.x) (if you need different node versions on your machine we recommend [nvm](https://github.com/nvm-sh/nvm) or [nvm for windows](https://github.com/coreybutler/nvm-windows))\n2. [npm](https://www.npmjs.com/) should already come with NodeJs - if not install it\n3. Clone the repo by running `git clone https://github.com/hpi-sam/digital-fuesim-manv`. To be able to run migration tests, you also have to clone the submodules: use `git clone --recurse-submodules https://github.com/hpi-sam/digital-fuesim-manv` or run `git submodule update --init --recursive` if you have cloned the repo already.\n4. Run `npm run setup` from the root folder\n5. Copy the [`.env.example`](./.env.example) file to `./.env` and adjust the settings as you need them. Note that some of the variables are explained under the next point.\n6. Choose whether you want to use a database:\n   You can (optionally) use a database for the persistence of exercise data. Look at the [relevant section](./backend/README.md#database) in the backend README for further information.\n   Note that to not use the database you have to edit an environment variable, see the [relevant section](./backend/README.md#without-a-database).\n7. (Optional) We have a list of recommended [vscode](https://code.visualstudio.com/) extensions. We strongly recommend you to use them if you are developing. You can see them via [the `@recommended` filter in the extensions panel](https://code.visualstudio.com/docs/editor/extension-marketplace#_recommended-extensions).\n8. (Optional) We have prepared default settings, tasks and debug configurations for VS Code. You can find them in `.vscode/*.example`. Crete a copy of those files removing the `.example` and adjust them to your needs. The files without `.example`-Extensions are untracked so your adjustments won't be committed automatically.\n\n## Starting for development\n\n### Option 1\n\nIf you are using [vscode](https://code.visualstudio.com/), you can run the [task](https://code.visualstudio.com/docs/editor/tasks) `Start all` to start everything in one go.\nNote that this _tries_ to start the database using `docker compose`. In case this fails please start the database in another way (see [this section in the backend README](./backend/README.md#database)).\nIf you're not using a database anyway, you could use the task `Start all but database` instead.\n\n### Option 2\n\n1. Open a terminal in `/shared` and run `npm run watch`\n2. Open another terminal in `/frontend` and run `npm run start`\n3. Open another terminal in `/backend` and run `npm run start`\n4. Consider the database -- see point 7 of the [installation](#installation).\n\n## Starting for deployment (using docker)\n\nYou need to have [`docker`](https://www.docker.com/) installed.\n\n### With docker compose (recommended)\n\n1. [`docker compose`](https://docs.docker.com/compose/) needs to be installed. Note that, depending on your setup, you may use `docker-compose` instead of `docker compose`. In this case, just replace the space in the commands with a dash (`-`). For more information, see the [relevant section of the documentation](https://docs.docker.com/compose/#compose-v2-and-the-new-docker-compose-command).\n2. Run `docker compose up -d` in the root directory. This also starts the database. If you don't want to start the database run `docker compose up -d digital-fuesim-manv` instead.\n\n### Without docker compose\n\n1. Execute `docker run -p -d 80:80 digitalfuesimmanv/dfm`.\n\nThe server will start listening using nginx on port `80` for all services (frontend, API, WebSockets).\n\nNote the database requirements depicted in [the installation section](#installation).\n\n### Building the container from scratch\n\n#### Option 1\n\n1. Uncomment the build section of [the docker compose file](./docker-compose.yml).\n2. Run `docker compose build`\n\n#### Option 2\n\n1. Run `docker build -f docker/Dockerfile -t digital-fuesim-manv .`\n\n### Docker volumes / persistent data\n\n-   All important volumes are listed in [the docker-compose file](./docker-compose.yml).\n\n### Docker ENVs\n\n-   All available Docker ENVs are listed with their default values in [.env.example](./.env.example) file. Copy this file and name it `.env` (under Linux, this would be e.g. `cp .env.example .env`)\n\n## Before you commit\n\n-   We are using [prettier](https://prettier.io/) as our code formatter. Run it via `npm run prettier` or `npm run prettier:windows` in the root to format all files and make the CI happy. Please use the [vscode extension](https://marketplace.visualstudio.com/items?itemName=esbenp.prettier-vscode).\n-   We are using [eslint](https://eslint.org/) as our linter. Run it via `npm run lint:fix` in the root to lint (and auto fix if possible) all files. Please use the [vscode extension](https://marketplace.visualstudio.com/items?itemName=dbaeumer.vscode-eslint).\n\n## Debugging\n\nThere are already the following [debug configurations](https://code.visualstudio.com/docs/editor/debugging) for vscode saved:\n\n-   `Launch Frontend [Chrome]`\n-   `Launch Frontend [Firefox]` (You have to install an extra extension)\n-   `Debug Jest Tests`\n\nIn addition, you can make use of the following browser extensions:\n\n-   [Angular DevTools](https://chrome.google.com/webstore/detail/angular-devtools/ienfalfjdbdpebioblfackkekamfmbnh)\n\n## Testing\n\n### Migration tests\n\nWhenever adding a new action or new state altering ui components (things that a user can use to alter the state in new ways) one should add exports of exercises in which the new features where tested to the [Public test scenarios](https://github.com/hpi-sam/digital-fuesim-manv-public-test-scenarios)\n\nThe test scenarios are stored in a submodule. Use `--recurse-submodules` when cloning the repo or run `git submodule update --init --recursive` if you have cloned the repo already.\n\nIf you wish to run the migration tests use `npm run test:migration`\n\n### Unit tests\n\nWe are using [Jest](https://jestjs.io/) for our unit tests.\n\nYou can run it during the development\n\n-   from the terminal via `npm run test:watch` in the root, `/shared`, `/backend` or `/frontend` folder\n-   or via the [recommended vscode extension](https://marketplace.visualstudio.com/items?itemName=Orta.vscode-jest). **(Note: this option is currently broken)**\n\n### End to end tests\n\nWe are using [cypress](https://www.npmjs.com/package/cypress) to run the end-to-end tests. You can find the code under `/frontend/cypress` in the repository.\n\n#### Running the tests\n\nTo run the tests locally, it is recommended to use the vscode [task](https://code.visualstudio.com/docs/editor/tasks) `Start all & cypress`. Alternatively, you can start the frontend and backend manually and then run `npm run cy:open` in `/frontend`.\n\nIf you only want to check whether the tests pass, you can run `npm run cy:run` in `/frontend` instead.\n\n## Benchmarking\n\nYou can run the benchmarks via `npm run benchmark` in the root folder.\nLook at the [benchmark readme](./benchmark/README.md) for more information.\n\n## Styleguide\n\n-   names are never unique, ids are\n-   Use [StrictObject](shared\\src\\utils\\strict-object.ts) instead of `Object` wherever possible\n-   A leading underscore should only be used\n    -   for private properties that may be used with getters/setters\n    -   to resolve certain naming conflicts (e.g. `.some(_item => ...)`)\n-   `dependencies` should be used for packages that must be installed when running the app (e.g. `express`), whereas `devDependencies` should be used for packages only required for developing, debugging, building, or testing (e.g. `jest`), which includes all `@types` packages. We try to follow this route even for the frontend and the backend, although it is not important there. See also [this](https://stackoverflow.com/a/22004559) answer on StackOverflow for more information about the differences.\n-   Use JSDoc features for further documentation because editors like VSCode can display them better.\n    -   Be aware that JSDoc comments must always go above the Decorator of the class/component/function/variable etc.\n    ```ts\n    /**\n     * Here is a description of the class/function/variable/etc.\n     *\n     * @param myParam a description of the parameter\n     * @returns a nice variable that is bigger than {@link myVariable}\n     * @throws myError when something goes wrong\n     */\n    ```\n-   You should use the keyword `TODO` to mark things that need to be done later. Whether an issue should be created is an individual decision.\n    -   You are encouraged to add expiration conditions to your TODOs. Eslint will complain as soon as the condition is met. See [here](https://github.com/sindresorhus/eslint-plugin-unicorn/blob/main/docs/rules/expiring-todo-comments.md) for more information.\n    ```ts\n    // TODO [engine:node@>=8]: We can use async/await now.\n    // TODO [typescript@>=4.9]: Use satisfies https://www.typescriptlang.org/docs/handbook/release-notes/typescript-4-9.html#the-satisfies-operator\n    ```\n\n## Releases\n\n### Versions\n\nVersion numbers follow the pattern `${major}.${minor}.${patch}`. `major`, `minor` and `patch` are decimal numbers without leading zeroes, similar to [SemVer](https://semver.org/). But since we do not have a public API, we do not adhere to SemVer.  \nThe major version is updated for breaking changes, i.e. old state exports of configured exercises that have never been started, cannot be imported.  \nThe minor version is updated with every release on `main`. State exports of configured exercises from older minor versions that have never been started must successfully import and started exercises should be importable and behave consistently with older versions, although this is not strictly required.  \nThe patch versions is incremented if and only if critical issues on `main` are being fixed during a milestone.\n\nEvery time a part of the version number is updated, all numbers to the right are reset to zero.\nFor each new release, pull requests both to `main` and `dev` are created from the same `release/` branch. For scheduled releases, such PRs are created by the `Create Release PR` workflow.\n\n### Workflows\n\nWith every significant PR into `dev`, the change must be briefly described in [CHANGELOG.md](./CHANGELOG.md). Pay attention to [Keep a Changelog](https://keepachangelog.com/en/1.0.0/).\n\nThe `Create Release PR` workflow accepts a new version number, updates the version in all relevant source files and moves the `Unreleased` section in [CHANGELOG.md](./CHANGELOG.md) to a release heading, creating a new `Unreleased` section. It then prepares two draft PRs, one into `dev` and one into `main` with these changes. They have to be marked as ready to run the pipeline and need approval. Merge them without rebase (use merge commit option).\n\nUpon pushing to `main` or `dev`, GitHub Actions will build and push docker containers to Docker Hub tagged `latest` and `dev`. `latest` is additionally tagged with the current version number on `main` and a GitHub release is created.\n\n## Architecture\n\nThis repository is a monorepo that consists of the following packages:\n\n-   [frontend](./frontend) the browser-based client application ([Angular](https://angular.io/))\n-   [backend](./backend) the server-side application ([NodeJs](https://nodejs.org/))\n-   [benchmark](./benchmark/) benchmarks and tests some parts of the application\n-   [shared](./shared) the shared code that is used by the frontend, backend and the benchmark package\n\nEach package has its own `README.md` file with additional documentation. Please check them out before you start working on the project.\n\nOne server can host multiple _exercises_. Multiple clients can join an exercise. A client can only join one exercise at a time.\n\n### State management and synchronization\n\nThis is a real-time application.\n\nEach client is connected to the server via a [WebSocket connection](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API). This means you can send and listen for events over a two-way communication channel.\nVia [socket.io](https://socket.io/docs) it is also possible to make use of a more classic request-response API via [acknowledgments](https://socket.io/docs/v4/emitting-events/#acknowledgements).\n\n#### State, actions and reducers\n\nWe borrow these core concepts from [Redux](https://redux.js.org/).\n\n##### What is an immutable JSON object?\n\nA JSON object is an object whose properties are only the primitives `string`, `number`, `boolean` or `null` or another JSON object or an array of any of these (only state - no `functions`).\nAny object reference can't occur more than once anywhere in a JSON object (including nested objects). This means especially that no circular references are possible.\n\n[An immutable object is an object whose state cannot be modified after it is created](https://en.wikipedia.org/wiki/Immutable_object). In the code immutability is conveyed via typescripts [readonly](https://www.typescriptlang.org/docs/handbook/2/objects.html#readonly-properties) and the helper type `Immutable<T>`.\n\n##### State\n\nA state is an immutable JSON object. Each client as well as the server has a global state for an exercise. The single point of truth for all states of an exercise is the server. All these states should be synchronized.\n\nYou can find the exercise state [here](./shared/src/state.ts).\n\n##### Action\n\nAn action is an immutable JSON object that describes what should change in a state. The changes described by each action are [atomic](<https://en.wikipedia.org/wiki/Atomicity_(database_systems)>) - this means either all or none of the changes described by an action are applied.\n\nActions cannot be applied in parallel. The order of actions is important.\n\nIt is a bad practice to encode part of the state in the action (or values derived/calculated from it). Instead, you should only read the state in the accompanying reducer.\n\n##### Reducer\n\nA reducer is a [pure function](https://en.wikipedia.org/wiki/Pure_function) (no side effects!) that takes a state and an action of a specific type and returns a new state where the changes described in the action are applied. A state can only be modified by a reducer.\n\nTo be able to apply certain optimizations, it is advisable (but not necessary or guaranteed) that the reducer only changes the references of properties that have been changed.\n\nYou can find all exercise actions and reducers [here](./shared/src/store/action-reducers). Please orient yourself on the already implemented actions, and don't forget to register them in [shared/src/store/action-reducers/action-reducers.ts](shared/src/store/action-reducers/action-reducers.ts)\n\n#### Immutability\n\nIt isn't necessary to copy the whole immutable object by value if it should be updated. Instead, only the objects that were modified should be shallow copied recursively. [Immer](https://immerjs.github.io/immer/) provides a simple way to do this.\n\nBecause the state is immutable and reducers (should) only update the properties that have changed, you can short circuit in comparisons between immutable objects, if the references of objects in a property are equal. Therefore it is very performant to compare two states in the same context.\n\nTo save a state it is enough to save its reference. Therefore it is very performant as well.\nIf the state would have to be changed, a new reference is created as the state is immutable.\n\n#### Large values (WIP)\n\nLarge values (images, large text, binary, etc.) are not directly stored in the state. Instead, the store only contains UUIDs that identify the blob. The blob can be retrieved via a separate (yet to be implemented) REST API.\n\nThe blob that belongs to a UUID cannot be changed or deleted while the state is still saved on the server. To change a blob, a new one should be uploaded and the old UUID in the state replaced with the new one.\n\nIf an action would add a new blobId to the state, the blob should have previously been uploaded to the server.\n\nA blob should only be downloaded on demand (lazy) and cached.\n\n#### Synchronisation\n\n1. A client gets a snapshot of the state from the server via `getState`.\n2. Any time an action is applied on the server, it is sent to all clients via `performAction` and applied to them too. Due to the maintained packet ordering via a WebSocket and the fact that the synchronization of the state in the backend works synchronously, it is impossible for a client to receive actions out of order or receive actions already included in the state received by `getState`.\n3. A client can propose an action to the server via `proposeAction`.\n4. If the proposal was accepted, the action is applied on the server and sent to all clients via `performAction`.\n5. The server responds to a proposal with a response that indicates a success or rejection via an [acknowledgment](https://socket.io/docs/v4/emitting-events/#acknowledgements). A successful response is always sent after the `performAction` was broadcasted.\n\n#### Optimistic updates\n\nA consequence of the synchronization strategy described before is that it takes one roundtrip from the client to the server and back to get the correct state on the client that initiated the action. This can lead to a bad user experience because of high latency.\n\nThis is where optimistic updates come into play. We just assume optimistically that the proposed action will be applied on the server. Therefore we can apply the action on the client directly without waiting for a `performAction` from the server.\n\nIf the server rejects the proposal or a race condition occurs, the client corrects its state again. In our case, the [optimisticActionHandler](./frontend/src/app/core/optimistic-action-handler.ts) encapsulates this functionality.\n\nThe state in the frontend is not guaranteed to be correct. It is only guaranteed to automatically correct itself.\n\nIf you need to read from the state to change it, you should do this inside the action reducer because the `currentState` passed into a reducer is always guaranteed to be correct.\n\n#### Performance considerations\n\n-   Currently, every client maintains the whole state, and every action is sent to all clients. There is no way to only subscribe to a part of the state and only receive updates for that part.\n\n## Licenses and Attributions\n\n-   License information about used images can be found [here](frontend/src/assets/image-sources.md). All images are licensed under their original license.\n\n## Contributors\n\n<!-- Inspired by https://github.com/all-contributors/all-contributors -->\n\n<!-- markdownlint-disable -->\n<table>\n    <tr>\n    <td style=\"text-align: center\">\n            <a href=\"https://github.com/Greenscreen23\">\n                <img\n                    src=\"https://avatars.githubusercontent.com/u/43916057?v=4\"\n                    width=\"100px;\"\n                />\n                <br />\n                <sub><b>Lukas Hagen</b></sub>\n            </a>\n            <br />\n            <a\n                href=\"https://github.com/hpi-sam/digital-fuesim-manv/commits?author=Greenscreen23\"\n                title=\"Code\"\n                >\ud83d\udcbb</a\n            >\n            <span title=\"Review\">\ud83d\udc40</span>\n            <br />\n            <small>Student 2022/23<small>\n        </td>\n        <td style=\"text-align: center\">\n            <a href=\"https://github.com/Nils1729\">\n                <img\n                    src=\"https://avatars.githubusercontent.com/u/45318774?v=4\"\n                    width=\"100px;\"\n                />\n                <br />\n                <sub><b>Nils Hanff</b></sub>\n            </a>\n            <br />\n            <a\n                href=\"https://github.com/hpi-sam/digital-fuesim-manv/commits?author=Nils1729\"\n                title=\"Code\"\n                >\ud83d\udcbb</a\n            >\n            <span title=\"Review\">\ud83d\udc40</span>\n            <br />\n            <small>Student 2022/23<small>\n        </td>\n        <td style=\"text-align: center\">\n            <a href=\"https://github.com/benn02\">\n                <img\n                    src=\"https://avatars.githubusercontent.com/u/82985280?v=4\"\n                    width=\"100px;\"\n                />\n                <br />\n                <sub><b>Benildur Nickel</b></sub>\n            </a>\n            <br />\n            <a\n                href=\"https://github.com/hpi-sam/digital-fuesim-manv/commits?author=benn02\"\n                title=\"Code\"\n                >\ud83d\udcbb</a\n            >\n            <span title=\"Review\">\ud83d\udc40</span>\n            <br />\n            <small>Student 2022/23<small>\n        </td>\n        <td style=\"text-align: center\">\n            <a href=\"https://github.com/lukasrad02\">\n                <img\n                    src=\"https://avatars.githubusercontent.com/u/49586507?v=4\"\n                    width=\"100px;\"\n                />\n                <br />\n                <sub><b>Lukas Radermacher</b></sub>\n            </a>\n            <br />\n            <a\n                href=\"https://github.com/hpi-sam/digital-fuesim-manv/commits?author=lukasrad02\"\n                title=\"Code\"\n                >\ud83d\udcbb</a\n            >\n            <span title=\"Review\">\ud83d\udc40</span>\n            <br />\n            <small>Student 2022/23<small>\n        </td>\n        </tr><tr>\n        <td style=\"text-align: center\">\n            <a href=\"https://github.com/Dassderdie\">\n                <img\n                    src=\"https://avatars.githubusercontent.com/u/18506183?v=4\"\n                    width=\"100px;\"\n                />\n                <br />\n                <sub><b>Julian Schmidt</b></sub>\n            </a>\n            <br />\n            <a\n                href=\"https://github.com/hpi-sam/digital-fuesim-manv/commits?author=Dassderdie\"\n                title=\"Code\"\n                >\ud83d\udcbb</a\n            >\n            <span title=\"Review\">\ud83d\udc40</span>\n            <br />\n            <small>Student 2021/22<small>\n        </td>\n        <td style=\"text-align: center\">\n            <a href=\"https://github.com/ClFeSc\">\n                <img\n                    src=\"https://avatars.githubusercontent.com/u/68013019?v=4\"\n                    width=\"100px;\"\n                />\n                <br />\n                <sub><b>Clemens Schielicke</b></sub>\n            </a>\n            <br />\n            <a\n                href=\"https://github.com/hpi-sam/digital-fuesim-manv/commits?author=ClFeSc\"\n                title=\"Code\"\n                >\ud83d\udcbb</a\n            >\n            <span title=\"Review\">\ud83d\udc40</span>\n            <br />\n            <small>Student 2021/22<small>\n        </td>\n        <td style=\"text-align: center\">\n            <a href=\"https://github.com/hpistudent72\">\n                <img\n                    src=\"https://avatars.githubusercontent.com/u/64257074?v=4\"\n                    width=\"100px;\"\n                />\n                <br />\n                <sub><b>Florian Krummrey</b></sub>\n            </a>\n            <br />\n            <a\n                href=\"https://github.com/hpi-sam/digital-fuesim-manv/commits?author=hpistudent72\"\n                title=\"Code\"\n                >\ud83d\udcbb</a\n            >\n            <br />\n            <small>Student 2021/22<small>\n        </td>\n        <td style=\"text-align: center\">\n            <a href=\"https://github.com/anonym-HPI\">\n                <img\n                    src=\"https://avatars.githubusercontent.com/u/68286419?v=4\"\n                    width=\"100px;\"\n                />\n                <br />\n                <sub><b>Marvin M\u00fcller-Mettnau</b></sub>\n            </a>\n            <br />\n            <a\n                href=\"https://github.com/hpi-sam/digital-fuesim-manv/commits?author=anonym-HPI\"\n                title=\"Code\"\n                >\ud83d\udcbb</a\n            >\n            <span title=\"Deployment\">\ud83d\udce6</span>\n            <br />\n            <small>Student 2021/22<small>\n        </td>\n        </tr><tr>\n        <td style=\"text-align: center\">\n            <a href=\"https://github.com/mbarkowsky\">\n                <img\n                    src=\"https://avatars.githubusercontent.com/u/7481705?v=4\"\n                    width=\"100px;\"\n                />\n                <br />\n                <sub><b>Matthias Barkowsky</b></sub>\n            </a>\n            <br />\n            \ud83d\udcc6\n            <br />\n            <small>Supervisor 2021-23<small>\n        </td>\n        <td style=\"text-align: center\">\n            <a href=\"https://github.com/christianzoellner\">\n                <img\n                    src=\"https://avatars.githubusercontent.com/u/4678160?v=4\"\n                    width=\"100px;\"\n                />\n                <br />\n                <sub><b>Christian Z\u00f6llner</b></sub>\n            </a>\n            <br />\n            \ud83d\udcc6\n            <br />\n            <small>Supervisor 2021-23<small>\n        </td>\n    </tr>\n</table>\n<!-- markdownlint-restore -->\n"}
{"url": "https://github.com/hpi-sam/digital-fuesim-manv-public-test-scenarios", "owner": "hpi-sam", "repository_name": "digital-fuesim-manv-public-test-scenarios", "date_all_variable_collection": "2023-09-11", "description": "Public test scenarios for the Digital Fuesim MANV project.", "size": 3526, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "benn02", "contributions": 26}, {"contributor": "lukasrad02", "contributions": 18}, {"contributor": "Greenscreen23", "contributions": 13}, {"contributor": "Nils1729", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# digital-fuesim-manv-public-test-scenarios\n\nPublic test scenarios for the Digital Fuesim MANV project.\n\nThe subfolder migration-test-scenarios contains test scenarios that should be migratable.\n\nIt contains only folders following the naming scheme `from-state-[stateVersion]` where [stateVersion] has to be replaced with the version of the state in the exports that are contained in that folder.\n\nThese folders contain up to three different folders named `combined-scenarios`, `one-action` or `state-altering-ui` depending on their contents. `combined-scenarios` are tests that test a range of different things. `one-action` are tests that test one action with very little overhead. `state-altering-ui` are tests that test one state altering ui-component with very little overhead.\n\nThose folders contain the actual exports. Things in these folders named starting with EXCLUDE-FROM-TEST will not be tested.\n\nPlease use a name that describes what happened in the scenario and add a -complete or -current at the end depending on whether the\nexport was a full export or an export of the current state.\n\nThe resulting naming scheme is: `./migration-test-scenarios/from-state-[stateVersion]/[combined-scenarios | one-action | state-altering-ui]/test-name-[complete | current]`\n\nPlease do not create folders without exercises in them.\n\nThe files do not need to be formatted in a particular but it is also fine if they are.\n"}
{"url": "https://github.com/hpi-sam/dps.training_shared_files", "owner": "hpi-sam", "repository_name": "dps.training_shared_files", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1599, "stargazers_count": 3, "watchers_count": 3, "language": "Dart", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 5, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 5, "watchers": 3, "default_branch": "dev", "contributors": [{"contributor": "smofe", "contributions": 55}, {"contributor": "C-8", "contributions": 49}, {"contributor": "UliPrantz", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Dart", "num_chars": 142344}], "readme": "![CI](https://github.com/hpi-sam/BPMANV-App-SharedFiles/workflows/Continuous%20Integration/badge.svg)\n\n# dps.training_shared_files\n\nThis repository contains Widgets, data models, API-Routes and utility functions for both the [trainer](https://github.com/hpi-sam/dps.training_trainer) and the [helper](https://github.com/hpi-sam/dps.training_player) app of our digital MCI simulation.\n\n## Project repositories\nThis digital MCI simulation is distributed over several repositories. They are:\n- [dps.training_server](https://github.com/hpi-sam/dps.training-server): The backend of the MCI simulation, written in Python with the Django Framework.\n- [dps.training_player](https://github.com/hpi-sam/dps.training_player): The Frontend of the MCI simulation for helpers, written in Dart with the Flutter Framework.\n- [dps.training_trainer](https://github.com/hpi-sam/dps.training_trainer): The Frontend of the MCI simulation for trainers, written in Dart with the Flutter Framework.\n- [dps.training_shared_files](https://github.com/hpi-sam/dps.training_shared_files): Shared Widgets, data models and functions that both the trainer and the helper app use.\n\n## Usage\n\nYou can use this package by referencing it in the pubspec.yaml of your App, e.g.:\n```\n  dps.training_shared_files_widgets: \n    git:  \n      url: git@github.com:hpi-sam/dps.training_shared_files.git\n```\n\nCurrently all contributers have to be set as collaborators for this repository. Furthermore, to access the private repository, you'll need to add a ssh key to your github and provide the keys locally in your root directory in a .ssh folder. Now, Android Studio will be able to fetch this package. When making changes to this repository, make sure to run flutter pub upgrade in your app to fetch newest package version. \n\n\n## Developing this package\n\nThis package is developed in flutter. For setup, we recommend following these instructions: https://flutter.dev/docs/get-started/install.\nWe recommend using Android Studio as your IDE.\n\nThis package is developed on the flutter stable channel (default channel). To switch channels please refer to: https://flutter.dev/docs/development/tools/sdk/upgrading\n\n\n---\n\n## Design and architectural decisions\n\nIf you want to start contributing to this project, we strongly recommend getting familiar with [Cubit](https://pub.dev/documentation/flutter_cubit/latest/) for state management. \n\n### Pre-Commit Hook\n\nWe use a pre-commit git hook to automatically format our code with dartfmt on every commit. You need to configure this hook locally to make it work. [See this wiki page for how to do so (and more information)](https://github.com/hpi-sam/dps.training_player/wiki/Git-Hooks).\n\n### Use of Github Actions\n\nWe currently use Github Actions to analyze & build the project on every commit. Please make sure to run `Flutter analyze` locally before commiting to make sure that our CI stays happy :-)\n\n"}
{"url": "https://github.com/hpi-sam/ethical-recsys-engineering", "owner": "hpi-sam", "repository_name": "ethical-recsys-engineering", "date_all_variable_collection": "2023-09-11", "description": "Ethical concerns and solutions for engineering recommender systems", "size": 106, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "benbuc", "contributions": 1}, {"contributor": "christianadriano", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# ethical-recsys-engineering\nEthical concerns and solutions for engineering recommender systems\n"}
{"url": "https://github.com/hpi-sam/Extended-GDNs", "owner": "hpi-sam", "repository_name": "Extended-GDNs", "date_all_variable_collection": "2023-09-11", "description": "Evaluation artifacts for extended Generalized Discrimination Networks", "size": 421, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Eclipse Public License 1.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "mbarkowsky", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 1710774}]}
{"url": "https://github.com/hpi-sam/GNN-Commenters", "owner": "hpi-sam", "repository_name": "GNN-Commenters", "date_all_variable_collection": "2023-09-11", "description": "Exploration of Graph Neural Network techniques for representation, prediction, and intervention on networks of comments on news sites.", "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "christianadriano", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# GNN-Commenters\nExploration of Graph Neural Network techniques for representation, prediction, and intervention on networks of comments on news sites.\n"}
{"url": "https://github.com/hpi-sam/GNN-CommunityInteraction", "owner": "hpi-sam", "repository_name": "GNN-CommunityInteraction", "date_all_variable_collection": "2023-09-11", "description": "Repo fro Bastian, Leo and Berkay project", "size": 34773, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "BastianThiede", "contributions": 12}, {"contributor": "buzem", "contributions": 6}, {"contributor": "christianadriano", "contributions": 2}, {"contributor": "henleo", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 3559771}, {"language": "Python", "num_chars": 55471}, {"language": "Shell", "num_chars": 78}], "readme": "\n\n# Community Interaction GNN\nExploring Graphical Neural Networks for representing, predicting, and intervening in community interaction phenomena\nMembers: Bastian, Leo and Berkay\n"}
{"url": "https://github.com/hpi-sam/GNN-Connectomics", "owner": "hpi-sam", "repository_name": "GNN-Connectomics", "date_all_variable_collection": "2023-09-11", "description": "Exploration of Graph Neural Networks techniques for Connectomics ", "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "christianadriano", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# GNN-Connectomics\nExploration of Graph Neural Networks techniques for Connectomics \n"}
{"url": "https://github.com/hpi-sam/GNN-Course-2020", "owner": "hpi-sam", "repository_name": "GNN-Course-2020", "date_all_variable_collection": "2023-09-11", "description": "Lecture Materials", "size": 109835, "stargazers_count": 2, "watchers_count": 2, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 2, "default_branch": "main", "contributors": [{"contributor": "christianadriano", "contributions": 99}, {"contributor": "EricSchuMa", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 428349}], "readme": "# Topics\n- Lecture Materials\n- Reference lists\n- Group lists\n\n# Projects:\n- Tibor, Max, Tiago (topic: Traffic network sensors) - https://github.com/hpi-sam/GNN-SpaceTimeGraphs\n- Henrik & Simon (topic: Drug network interactions) - https://github.com/hpi-sam/GNN-Effectants\n- Bastian, Leo, Berkay (topic: Reddit Comments)- https://github.com/hpi-sam/GNN-CommunityInteraction\n- Mai & Validmar (topic: Entity Linking prediction) - https://github.com/hpi-sam/GNN-EntityLinking\n- Sassan (topic: News comments recommendations) - https://github.com/hpi-sam/GNN-Commenters\n- Maria Lomeva (topic: keyphrase detection) - https://github.com/hpi-sam/GNN-NLP\n\n\n"}
{"url": "https://github.com/hpi-sam/GNN-Course-2021", "owner": "hpi-sam", "repository_name": "GNN-Course-2021", "date_all_variable_collection": "2023-09-11", "description": "Materials of the Graph Neural Networks course taught in Winter Semester 2021 at the Hasso-Plattner Institute University of Potsdam", "size": 29543, "stargazers_count": 2, "watchers_count": 2, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 2, "default_branch": "main", "contributors": [{"contributor": "christianadriano", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# GNN-Course-2021\nMaterials of the Graph Neural Networks course taught in Winter Semester 2021 at the Hasso-Plattner Institute University of Potsdam\n\n##Projects developed\n\n- GNN_Graph_Query-Matching/ThinkMatch/\n\n- GNN_Graph_Query-Matching/neural-subgraph-matching/\n\n**Repository**:\nhttps://github.com/hpi-sam/GNN_Graph_Query-Matching\n\n"}
{"url": "https://github.com/hpi-sam/GNN-Effectants", "owner": "hpi-sam", "repository_name": "GNN-Effectants", "date_all_variable_collection": "2023-09-11", "description": "Investigate different methods for link prediction and their effectiveness for the polypharmacy problem. ", "size": 88853, "stargazers_count": 2, "watchers_count": 2, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "main", "contributors": [{"contributor": "witsyke", "contributions": 24}, {"contributor": "christianadriano", "contributions": 3}, {"contributor": "WeHenrik", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 22367730}, {"language": "Python", "num_chars": 345406}, {"language": "Scala", "num_chars": 17304}, {"language": "R", "num_chars": 12036}, {"language": "Shell", "num_chars": 3926}], "readme": "# GNN-Effectants\nExploratory study of graph neural networks methods to represent, predict, and intervene in the effects of drug combinations. \n\n\nDetailed instructions on how to execute the benchmarking scripts for each approach can be found in the readme file of the respective approach in /benchmarking"}
{"url": "https://github.com/hpi-sam/GNN-EntityLinking", "owner": "hpi-sam", "repository_name": "GNN-EntityLinking", "date_all_variable_collection": "2023-09-11", "description": "Exploration of Graph Neural Network techniques to represent, predict, and intervene on Entity Linking tasks.", "size": 3367, "stargazers_count": 3, "watchers_count": 3, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 1, "watchers": 3, "default_branch": "main", "contributors": [{"contributor": "christianadriano", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 5229329}, {"language": "Python", "num_chars": 15313}], "readme": "# GNN-EntityLinking\nExploration of Graph Neural Network techniques to represent, predict, and intervene on Entity Linking tasks.\n\n\nhttps://www.overleaf.com/project/5fc978e4e59e0f2e05d3968b\n"}
{"url": "https://github.com/hpi-sam/GNN-for-Knowledge-Graphs", "owner": "hpi-sam", "repository_name": "GNN-for-Knowledge-Graphs", "date_all_variable_collection": "2023-09-11", "description": "Graph Neural Networks for Knowledge-Graph Systesm ", "size": 46918, "stargazers_count": 1, "watchers_count": 1, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "christianadriano", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# GNN-for-Knowledge-Graphs\nGraph Neural Networks for Knowledge-Graph Systesm \n"}
{"url": "https://github.com/hpi-sam/GNN-NLP", "owner": "hpi-sam", "repository_name": "GNN-NLP", "date_all_variable_collection": "2023-09-11", "description": "Exploration of Graph Neural Networks for representation, prediction, and intervention in NLP tasks", "size": 6194, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "christianadriano", "contributions": 1}, {"contributor": "veerlosar", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# GNN-NLP\nExploration of Graph Neural Networks for representation, prediction, and intervention in NLP tasks\n"}
{"url": "https://github.com/hpi-sam/GNN-SpaceTimeGraphs", "owner": "hpi-sam", "repository_name": "GNN-SpaceTimeGraphs", "date_all_variable_collection": "2023-09-11", "description": "Graph Neural Networks utilization for Spatiotemporal graphs. These methods will be applied into the problem of forecasting traffic flow on PEMS-Bay, METR-LA and Seattle Loop Datasets", "size": 19006, "stargazers_count": 13, "watchers_count": 13, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 3, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 3, "open_issues": 1, "watchers": 13, "default_branch": "main", "contributors": [{"contributor": "EricSchuMa", "contributions": 92}, {"contributor": "tiborboglar", "contributions": 27}, {"contributor": "christianadriano", "contributions": 1}, {"contributor": "tsanona", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["forecasting-algorithm", "graph-convolutional-networks", "graph-neural-networks", "spatio-temporal-data", "traffic-forecasting", "traffic-graphs"], "languages": [{"language": "Jupyter Notebook", "num_chars": 2595865}, {"language": "Python", "num_chars": 67198}, {"language": "Makefile", "num_chars": 643}, {"language": "Shell", "num_chars": 130}], "readme": "# GNN-SpaceTimeGraphs\n\n## Setup\n\nFrom your terminal, run the following commands sequentially\n\n```bash\n\n# Clone git repo && create a new env with required libraries\ngit clone https://github.com/hpi-sam/GNN-SpaceTimeGraphs.git\ncd GNN-SpaceTimeGraphs\nmake env\nconda activate gnn-env\n\n# Download the metr-la and pems-bay data from \n# https://drive.google.com/file/d/1wD-mHlqAb2mtHOe_68fZvDh1LpDegMMq/view?usp=sharing\nexport fileid=1pAGRfzMx6K9WWsfDcD1NMbIif0T0saFC\nexport filename=data/metr_la/metr-la.h5\nwget -O $filename 'https://drive.google.com/uc?export=download&id='$fileid\n\nexport fileid=1wD-mHlqAb2mtHOe_68fZvDh1LpDegMMq\nexport filename=data/pems_bay/pems-bay.h5\nwget -O $filename 'https://drive.google.com/uc?export=download&id='$fileid\n\n# Run utils script to process the data that is going to be used\npython utils.py --output_dir=data/metr_la \\\n                    --traffic_df_filename=data/metr_la/metr-la.h5 --sts=True\npython utils.py --output_dir=data/metr_la \\\n                    --traffic_df_filename=data/metr_la/metr-la.h5\npython utils.py --output_dir=data/metr_la \\\n                    --traffic_df_filename=data/pems_bay/pems-bay.h5 --sts=True\npython utils.py --output_dir=data/metr_la \\\n                    --traffic_df_filename=data/pems_bay/pems-bay.h5\n```\n\nIf you find any problems with `wget [...]`, you can manually download the datasets from [this Google Drive link](https://drive.google.com/file/d/1wD-mHlqAb2mtHOe_68fZvDh1LpDegMMq/view?usp=sharing)\n\nTo train a model, run the following command from the `GNN-SpaceTimeGraphs` folder \n```bash\npython run.py -c configs/p3d.yml --toy_data\n```\n\n## Abstract\nIn Intelligent Transport Systems (ITS), traffic forecasting is a crucial tool to improve road security, planning and operation. Before using neural architectures, autoregressive models were employed for time-series forecasting which faced difficulties to model highly non-linear and spatially dependent traffic data.\nSpeed sensors in road networks are arranged in graph like structures, therefore, spatial and temporal dependencies are often modeled based on traffic graphs. Because relationships of sensors are modeled in space and time concurrently, the effectiveness of each mechanisms needs to be isolated when comparing neural network architectures. Contrary to a formulation where edges in a traffic graph are predefined through physical road connections or closeness in space, there is a trend towards refining the structure of traffic graphs during the learning process.\nWe propose a series of experiments based on spectral graph convolution using a concept introduced by Zhang et. al (AAAI 2020), which regards the graph laplacian as a learnable parameter. We compare this setup to one that uses a static laplacian.\nAdditionally we use a latent correlation layer as proposed by Chao et. al (NeurIPS 2020) as another way of learning the laplacian.\nTo keep the variants of the spectral convolution comparable the temporal modeling component stays fixed.\nThe contributions of this work can be summarized answering the following two research questions (RQ):\n- RQ1: How does learning the graph structure affect the precision of predictions in graph neural networks for traffic forecasting?\n- RQ2: Do graph convolution operators benefit from having the graph structure as a learnable parameter?\n\nWe employ two widely used benchmark datasets and compare different setups to answer RQ1 and RQ2. We were able to reproduce results shown by Zhang et. al and extend the comparison to models that utilize a latent correlation layer.\n\n"}
{"url": "https://github.com/hpi-sam/GNN_Graph_Query-Matching", "owner": "hpi-sam", "repository_name": "GNN_Graph_Query-Matching", "date_all_variable_collection": "2023-09-11", "description": "Graph Neural Networks for Graph Query Matching Tasks", "size": 17426, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "schTi", "contributions": 13}, {"contributor": "christianadriano", "contributions": 8}, {"contributor": "nicolas-alder", "contributions": 4}, {"contributor": "arberaga", "contributions": 2}, {"contributor": "Lando-L", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 465835}, {"language": "C++", "num_chars": 17463}, {"language": "Cuda", "num_chars": 6544}, {"language": "Dockerfile", "num_chars": 2573}, {"language": "Batchfile", "num_chars": 778}, {"language": "Makefile", "num_chars": 607}, {"language": "Shell", "num_chars": 62}], "readme": "# GNN for Graph Query Matching Tasks\n\nGoal: Study and compare Graph Neural Networks and Combinatorial methods for Graph Query Matching Tasks\nProjects developed during the GNN Course of 2021 - https://github.com/hpi-sam/GNN-Course-2021\n\n\n"}
{"url": "https://github.com/hpi-sam/host-graph-sensitive-rete-nets", "owner": "hpi-sam", "repository_name": "host-graph-sensitive-rete-nets", "date_all_variable_collection": "2023-09-11", "description": "Repository containing evaluation artifacts for host-graph-sensitive RETE nets.", "size": 546129, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Eclipse Public License 1.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "mbarkowsky", "contributions": 21}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 1269646}, {"language": "Shell", "num_chars": 12940}], "readme": "Installation:\n- download and install Eclipse Modeling Tools (e.g. via the Eclipse installer from https://www.eclipse.org/downloads/)\n- add the Eclipse Neon update-site (http://download.eclipse.org/releases/neon/) to the list of registered update-sites\n- install SDM-related Eclipse-Plugins (required for reading query specifications , i.e., .mlsp-files) from our update-site: https://www.hpi.uni-potsdam.de/giese/update-site/ (\"SDM Metamodels, Editors, and Interpreters\" category)\n- install the VIATRA Eclipse-Plugins from the VIATRA update-site: http://download.eclipse.org/viatra/updates/release/2.4.0\n\nLDBC SNB\n- the mdelab.mlsdm.ldbc.snb.incremental project contains classes with main methods for query execution using our RETE implementation and different construction techniques\n- .mlsp (required for ExecuteDynamicIncremental, ExecutePeriodicIncremental, and ExecuteStaticIncremental) and .gdn (required for ExecuteGDNIncremental) specifications of the adapted benchmark queries used in our evaluation can be found in ldbc_snb/replication/rules\n- the mdelab.ldbc.snb.viatra.patterns.plain project contains a class with a main method for query execution using VIATRA\n- experiments can also be run from the ldbc_snb/replication folder using the scripts and prebuilt .jar files\n\nTrain Benchmark\n- the project trainbenchmark-tool-sdm contains an implementation of the Train Benchmark with our RETE net construction technique and simple graph queries\n- the project trainbenchmark-tool-viatra-patterns replaces the Train Benchmark project with the same name and contains simple graph query versions of the benchmark queries in VIATRA's query language\n- experiments have to be run using the Train Benchmark framework available under https://github.com/ftsrg/trainbenchmark\n\nTests\n- the ldbc_snb/de.mdelab.ldbc.snb.incremental.rete.tests project contains test cases for validating the host-graph-sensitive rete net construction techniques for a number of simple queries (SimpleQueryTest) and more complex queries from the adapted LDBC SNB (LDBCQueryTest)\n- as host graph for these tests, a small dataset generated with the LDBC SNB data generator (https://github.com/ldbc/ldbc_snb_datagen_hadoop) is used\n- the trainbenchmark/de.mdelab.trainbenchmark.rete.tests project contains test cases for validating the host-graph-sensitive rete net construction techniques for the adapted Train Benchmark queries\n- as host graph for these tests, a small dataset generated with the Train Benchmark framework (https://github.com/ftsrg/trainbenchmark) is used\n- note that the execution of the test cases related to the Train Benchmark requires a project from the Train Benchmark framework\n\nWiki\n- additional measurement results, visualizations of the test queries, and a description of the test cases can be found in the wiki\n"}
{"url": "https://github.com/hpi-sam/HT_WithinBetweenGroups", "owner": "hpi-sam", "repository_name": "HT_WithinBetweenGroups", "date_all_variable_collection": "2023-09-11", "description": "Hypotheses tests for within and between group experiments ", "size": 54, "stargazers_count": 0, "watchers_count": 0, "language": "R", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "christianadriano", "contributions": 33}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "R", "num_chars": 28573}], "readme": "# HT_WithinBetweenGroups\nHypotheses tests for within and between group experiments \n"}
{"url": "https://github.com/hpi-sam/Incremental-TGGs-for-Multi-version-Models", "owner": "hpi-sam", "repository_name": "Incremental-TGGs-for-Multi-version-Models", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1847, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Eclipse Public License 1.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "mbarkowsky", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 7925335}], "readme": "Installation:\n- download and install Eclipse Modeling Tools (e.g. via the Eclipse installer from https://www.eclipse.org/downloads/)\n- add the Eclipse Neon update-site (http://download.eclipse.org/releases/neon/) to the list of registered update-sites\n- install ClassDiagram, SDM- and MoTE2-related Eclipse-Plugins from our update-site: https://www.hpi.uni-potsdam.de/giese/update-site/ (\"SAM Modeling Languages\", \"SDM Metamodels, Editors, and Interpreters\" and \"MoTE2\" category)\n- install MoDisco from the MoDisco update-site: http://download.eclipse.org/modeling/mdt/modisco/updates/release/\n\nRunning\n- the \"de.mdelab.migmm.sample.java2class.execute\" project contains classes with main methods for experiment execution\n- these classes usually need to be parametrized with at least an input model (e.g. from https://zenodo.org/record/8109856; use \"*.history\" files for multi-version (\"History\") experiments and the related directories for single-version (\"Vanilla\") experiments) and a TGG (\"de.mdelab.mltgg.java2class/model-gen/config.xmi\" for single-version models or \"de.mdelab.mltgg.java2class.adapted/model-gen/config.xmi\" for multi-version models)\n- the \"de.mdelab.migmm.sample.java2class.tests\" project contains tests that validate the transformation and synchronization results of the multi-version implementation against the standard MoTE2 implementation for a sample model\n"}
{"url": "https://github.com/hpi-sam/MachineLearningControl", "owner": "hpi-sam", "repository_name": "MachineLearningControl", "date_all_variable_collection": "2023-09-11", "description": "Machine Learning-Based Control of Dynamical Systems ", "size": 54671, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "paul-ww", "contributions": 79}, {"contributor": "GoesOnTangents", "contributions": 30}, {"contributor": "christianadriano", "contributions": 21}, {"contributor": "Sghahremani", "contributions": 11}, {"contributor": "jkhlr", "contributions": 10}, {"contributor": "matthias-barkowsky", "contributions": 1}, {"contributor": "mbarkowsky", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 1478515}, {"language": "Jupyter Notebook", "num_chars": 741887}, {"language": "HTML", "num_chars": 338747}, {"language": "Python", "num_chars": 23898}, {"language": "CSS", "num_chars": 12808}, {"language": "JavaScript", "num_chars": 827}], "readme": "# MachineLearningControl\nMachine Learning-Based Control of Dynamical Systems \nRequirements and Design\nImplementation (training) of controllers to steer and stabilize a dynamical system\nThe dynamica system is a software platform of multi-tenant e-commerce shops\n\n## Implementation of the following packages:\n- 1 Non-Linear and Non-Stationary Environment (Identifiability, Stability)\n- 2 Environment with Latent States (Observability)\n- 3 Transfer Learning within Environemnt Instances (Generalizability under Sparsity)\n- 4 Reinforcement Learning Control (Automated Control Synthesis)\n\n## Install procedure for MRUBIS dependencies:\n\n- Eclipse IDE: Update it\n- External libraries:\n  - Install from http://download.eclipse.org/releases/neon/\n    -The GMF libraries, which are model-driven tools to generate graphical editors in the Eclipse IDE.\n  - Install from https://www.hpi.uni-potsdam.de/giese/update-site/\n     - In the following order:\n       - MDELab Workflow/MDELab Workflow\n       - MDELab Workflow/MLSDM Interpreter Component\n       - SDM Metamodels, Editors, and Interpreters/MLSDM Metamodel Editor Validation\n       - SDM Metamodels, Editors, and Interpreters/MLSDM Interpreter Debugger\n  - mRubis source code:\n     - Clean update your local repository MachineLearningControl\n     - Import the following projects in Eclipse:\n       - mRUBiS\\ML_based_Control\n       - mRUBiS\\mRUBiS_CompArch_Simulator\n       - mRUBiS\\CompArch_Metamodel\n\n## Supplying paths to the python side\nDue to the nature of Eclipse's dependency handling, we have to supply all dependencies via a terminal command. We also need to know the path to the java version which should run MRUBIS. These paths should be supplied in the `path.json` file in the `py` directory. You can get the required paths from Eclipse by going to `Run -> Run Configurations... -> Show Command Line`.\n\n## Smoke Test!\nTwo steps\n1- Run the Main System (mRubis)   \nExecute the following class as a Java Application\n- Project: Predict_SelfHealing_Utility\n- Package: mRubis_Tasks\n- Class: Task_1\n\n2- Run the the controller\nExecute following Python Application in a second command line session:\n- Project: Predict_SelfHealing_Utility\n- Folder: mrubis_controller/ \n- File: controller.py \n\nExpected output: A set of messages showing Failures being Fixed by Actions chosen by the Controller.\n"}
{"url": "https://github.com/hpi-sam/MarkovModels_Lecture", "owner": "hpi-sam", "repository_name": "MarkovModels_Lecture", "date_all_variable_collection": "2023-09-11", "description": "Hidden Markov Models Learning for Self-Adaptive Systems. Defintion of hidden states, observations, and application of the Baum-Welch algorithm", "size": 13548, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "christianadriano", "contributions": 26}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 12401}], "readme": "# About\nExploring various Markov models for Self-Adaptive Systems\n- Discrete Markov Chains\n- Continuous Time Markov Chains\n- Hidden Markov Models \n- Semi-Markov Models \n\n# Content\nLecture slides and project specifications\n"}
{"url": "https://github.com/hpi-sam/MARL-TransferLearning", "owner": "hpi-sam", "repository_name": "MARL-TransferLearning", "date_all_variable_collection": "2023-09-11", "description": "Projects on Transfer Learning for Multi-Agent Reinforcement Learning (MARL) in Self-Adaptive Systems", "size": 254230, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 1, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "christianadriano", "contributions": 9}, {"contributor": "max-3l", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# MARL-TransferLearning\nProjects on Transfer Learning for Multi-Agent Reinforcement Learning (MARL) in Self-Adaptive Systems\n"}
{"url": "https://github.com/hpi-sam/Meta-Reinforcement-Learning-for-SAS", "owner": "hpi-sam", "repository_name": "Meta-Reinforcement-Learning-for-SAS", "date_all_variable_collection": "2023-09-11", "description": "Exploration of meta-learning methods and techniques in reinforcement learning with appication to self-adaptives systems", "size": 16624, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "christianadriano", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Meta-Reinforcement-Learning-for-SAS\nExploration of meta-learning methods and techniques in reinforcement learning with appication to self-adaptives systems\n"}
{"url": "https://github.com/hpi-sam/minimum-wage-rl", "owner": "hpi-sam", "repository_name": "minimum-wage-rl", "date_all_variable_collection": "2023-09-11", "description": "Project to share documentation, source code and analyzes on the topic of simulating effects of minimum wage interventions on employment and other economic metrics.", "size": 19684, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "AkshayGudi", "contributions": 12}, {"contributor": "christianadriano", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 58772}], "readme": "# Project description\n+Research Problem+: Multi-player game framework to minimize unemployment and poverty while intervening on minimum wage and interest rates.\n+Methods+: Model-Based Reinforcement Learning and Adversarial Training\n+Data+: Synthetic Data from a built-in parameterized economics simulation data generative model\n+Master Thesis: Akshay Gudi\n+Advisors HPI+: Prof. Holger Giese, Christian Adriano \n+Advisors SAP: Frank Feinbube\n\n# Endpoints - Web based simulator\n**base_url = http://ccloud@minwage-app.sp.only.sap:8080**\n\n1. Create User\n    * Method: POST\n    * Endpoint: base_url/reg-user\n    * Input:\n      ```javascript\n      {\"username\":\"My-User-Name\",\n      \"password\":\"My-Password\",\n      \"email\":\"myemail@email.com\"}\n      ```\n    \n2. Getting API Token\n    * Method : POST\n    * Endpoint : base_url/api-token-auth\n    * Input:\n      ```javascript\n      {\"username\":\"My-User-Name\", \"password\":\"My-Password\"}\n      ```\n    * Response:\n      ```javascript\n      {\"token\": \"<token here>\",\n      \"user_id\": \"<id here>\",\n      \"email\": \"<email here>\"}\n      ```\n\n3. Start Game \n    * Method : GET\n    * Endpoint: base_url/start-game?level=<level_number>\n    * Authorization: API Key  Token <>\n    * Response:\n      ```javascript\n      {\"status\": 200,\n      \"message\": {\n         \"User Data\": {\n            \"Year\": 1,\n            \"Unemployment Rate\": 100,\n            \"Poverty Rate\": 100,\n            \"Minimum wage\": 7,\n            \"Inflation Rate\": 0,\n            \"population\": 1500\n                },\n          \"AI Data\": {\n            \"Year\": 1,\n            \"Unemployment Rate\": 100,\n            \"Poverty Rate\": 100,\n            \"Minimum wage\": 7,\n            \"Inflation Rate\": 0,\n            \"population\": 1500\n                },\n          \"end flag\": false,\n          \"message\": \"\"\n            }\n         }\n      ```\n\n4. Perform Action\n    * Method : POST\n    * Endpoint: base_url/perform-action/<action-value>\n    * Authorization: API Key  Token <>\n    * Input: ```javascript {\"minimum_wage\": <value>}```\n    * Response (For last step of game):\n      ```javascript\n      {\n        \"status\": 200,\n        \"message\": {\n          \"User Data\": {\n               \"Year\": 30,\n               \"Minimum wage\": 7.1,\n               \"Unemployment Rate\": 0,\n               \"Poverty Rate\": 46.86,\n               \"Quantity\": 1395,\n               \"Inflation\": -0.01,\n               \"Product Price\": 7.32,\n               \"Population\": 1848,\n               \"Small Companies\": 0,\n               \"Medium Companies\": 0,\n               \"Large Companies\": 6,\n               \"Bank Balance\": 656117.4013145872,\n               \"Retired Current Year\": 0,\n               \"Start Up Founders Current Year\": 0\n          },\n         \"AI Data\": {\n               \"Year\": 30,\n               \"Minimum wage\": 10.74,\n               \"Unemployment Rate\": 0,\n               \"Poverty Rate\": 2.98,\n               \"Quantity\": 29925,\n               \"Inflation\": 0.98,\n               \"Product Price\": 11.96,\n               \"Population\": 1848,\n               \"Small Companies\": 0,\n               \"Medium Companies\": 0,\n               \"Large Companies\": 6,\n               \"Bank Balance\": 323638.6078008192,\n               \"Retired Current Year\": 0,\n               \"Start Up Founders Current Year\": 0\n                },\n          \"game_stats\": {\n               \"player_game_stats\": {\n                     \"year\": 30,\n                     \"average_poverty\": 69.76,\n                     \"average_unemployment\": 16.13,\n                     \"average_inflation\": 0.22,\n                     \"average_product_price\": 11.41,\n                     \"average_minimum_wage\": 7.1\n                     },\n               \"ai_game_stats\": {\n                    \"year\": 30,\n                    \"average_poverty\": 32.84,\n                    \"average_unemployment\": 18.71,\n                    \"average_inflation\": 0.4,\n                    \"average_product_price\": 11.87,\n                    \"average_minimum_wage\": 9.39\n                     }\n                },\n          \"interact\": {\n               \"emotion\": \"\",\n               \"comments\": [\n                  { \"role\": 1, \"Message\": \"\" },\n                  {\"role\": 3, \"Message\": \"\"}],\n               \"has_comments\": false\n                   },\n          \"end flag\": true,\n          \"message\": {\"message\": \"End of Episode\"}\n        }\n      }\n      ```\n  \n5. Stop Game: To stop the game before last step of episode\n    * Method : GET\n    * Endpoint: base_url/stop-game\n    * Authorization: API Key  Token <>\n    * Response\n      ```javascript\n      {\n       \"status\": 200,\n       \"message\": {\n           \"player_game_stats\": {\n               \"year\": 11,\n               \"average_poverty\": 93.74,\n               \"average_unemployment\": 50.32,\n               \"average_inflation\": 0.69,\n               \"average_product_price\": 19.17,\n               \"average_minimum_wage\": 7.56\n                 },\n           \"ai_game_stats\": {\n               \"year\": 11,\n               \"average_poverty\": 70.92,\n               \"average_unemployment\": 50.4,\n               \"average_inflation\": 0.7,\n               \"average_product_price\": 16.53,\n               \"average_minimum_wage\": 8.32\n                 }\n             }\n      }\n      ```\n\n6. Save and End Game: Option to save the game\n    * Method : GET\n    * Endpoint: base_url/save-game?save_game=false\n    * Authorization: API Key  Token <>\n\n# Launch the Application using Docker\n   \n   1. Switch to the branch 'new-web-branch'.\n         `git checkout new-web-branch`\n   2. Launch Docker container\n         `docker compose build`\n         `docker compose up`\n   4. Access the application using above end-points at address `localhost:8080/` using Postman.\n   5. Stop the containers after using the application\n         `docker compose down`\n\n# Hints to play\n   \n   1. **If you see Bank balance is moderate but, product price is high.**\n      * Increase minimum wage by little bit or decrease it a bit.\n      * This causes low inflation or negative inflation and makes country to import products rather than increasing the price.\n  \n   2. **If bank balance is low and product price moderate, but people poor because of low minimum wage.**\n      * Then increase minimum wage more than hint 1.\n      * This causes minimum wage to increase however product prices will also increase.\n   \n   3. **If bank balance is high, product price is high, people are poor.**\n      * Then you can increase minimum wage even more (more than hint-2), this causes country to import lot of products instead of increasing product price. \n      * However bank balance will decrease considerably while importing, that is why lot of bank-balance is needed.\n"}
{"url": "https://github.com/hpi-sam/multi-version-models", "owner": "hpi-sam", "repository_name": "multi-version-models", "date_all_variable_collection": "2023-09-11", "description": "Repository containing evaluation artifacts for multi-version models.", "size": 28754, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Eclipse Public License 1.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "mbarkowsky", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 7305883}], "readme": "Installation:\n- download and install Eclipse Modeling Tools (e.g. via the Eclipse installer from https://www.eclipse.org/downloads/)\n- add the Eclipse Neon update-site (http://download.eclipse.org/releases/neon/) to the list of registered update-sites\n- from the eclipse release update site, install the \"MoDisco SDK\" feature under the \"Modeling\" category\n- install SDM-related Eclipse-Plugins (required for reading query specifications , i.e., .mlsp-files) from our update-site: https://www.hpi.uni-potsdam.de/giese/update-site/ (\"SDM Metamodels, Editors, and Interpreters\" category)\n\nExperiments:\n- experiments can be run via the main methods of the classes in the package de.mdelab.migmm.history.modisco.java.experiments (in the project with the same name)\n- data used for our experiments is available under de.mdelab.migmm.history.modisco.java.experiments/instances\n\t- note that, due to GitHub's file size limit, the larger dataset is split into three parts and has to be unified before it can be read"}
{"url": "https://github.com/hpi-sam/ProbabilisticModels_WiSe22_23", "owner": "hpi-sam", "repository_name": "ProbabilisticModels_WiSe22_23", "date_all_variable_collection": "2023-09-11", "description": "Projects on Discrete Time Markov Chains, Continuous Time Markov Chains, Hidden Markov Models, Markov Decision Processes", "size": 39242, "stargazers_count": 2, "watchers_count": 2, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 2, "default_branch": "main", "contributors": [{"contributor": "LinqLover", "contributions": 44}, {"contributor": "christianadriano", "contributions": 23}, {"contributor": "Finnk11", "contributions": 8}, {"contributor": "max-3l", "contributions": 4}, {"contributor": "Phimanu", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 8088132}, {"language": "Python", "num_chars": 60890}], "readme": "# ProbabilisticModels_WiSe22_23\nProjects on Discrete Time Markov Chains, Continuous Time Markov Chains, Hidden Markov Models, Markov Decision Processes\n"}
{"url": "https://github.com/hpi-sam/QuantumProgramming", "owner": "hpi-sam", "repository_name": "QuantumProgramming", "date_all_variable_collection": "2023-09-11", "description": "Exercises, Tasks, and Projects for the Course on Quantum Programming", "size": 21468, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 3, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 3, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "christianadriano", "contributions": 12}, {"contributor": "hpi-classroom", "contributions": 9}, {"contributor": "henleo", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 135700}, {"language": "TeX", "num_chars": 75111}, {"language": "Python", "num_chars": 58387}], "readme": "# QuantumProgramming\nExercises, Tasks, and Projects for the Course on Quantum Programming\n"}
{"url": "https://github.com/hpi-sam/Responsible-AI", "owner": "hpi-sam", "repository_name": "Responsible-AI", "date_all_variable_collection": "2023-09-11", "description": "Course work of Responsible Artificial Intelligence Project Seminar", "size": 34575, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "christianadriano", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Responsible AI\nCourse work of Responsible Artificial Intelligence Project Seminar\n"}
{"url": "https://github.com/hpi-sam/rl-4-self-repair", "owner": "hpi-sam", "repository_name": "rl-4-self-repair", "date_all_variable_collection": "2023-09-11", "description": "Reinforcement Learning Models for Online Learning of Self-Repair and Self-Optimization", "size": 53837, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 25, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 25, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "2start", "contributions": 31}, {"contributor": "christianadriano", "contributions": 4}, {"contributor": "MrBanhBao", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 6405058}, {"language": "Python", "num_chars": 72774}], "readme": "# rl-4-self-repair\nReinforcement Learning Models for Online Learning of Self-Repair and Self-Optimization\n"}
{"url": "https://github.com/hpi-sam/RL.4.Autonomous.Vehicles", "owner": "hpi-sam", "repository_name": "RL.4.Autonomous.Vehicles", "date_all_variable_collection": "2023-09-11", "description": "Training reinforcement learning agents to coordinate autonomous vehicles ", "size": 4716, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "christianadriano", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Reinforcement Learning for Autonomous Vehicles Coordination\nTraining reinforcement learning agents to coordinate autonomous vehicles \n"}
{"url": "https://github.com/hpi-sam/RL_4_Feedback_Control", "owner": "hpi-sam", "repository_name": "RL_4_Feedback_Control", "date_all_variable_collection": "2023-09-11", "description": "Train a reinforcement learning agent online to control a self-healing mechanism", "size": 55039, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "2start", "contributions": 31}, {"contributor": "christianadriano", "contributions": 7}, {"contributor": "MrBanhBao", "contributions": 2}, {"contributor": "GoesOnTangents", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 6402664}, {"language": "Python", "num_chars": 72785}], "readme": "\n# RL_4_Feedback_Control\nTrain a reinforcement learning agent online to control a self-healing mechanism\n"}
{"url": "https://github.com/hpi-sam/RL_SelfSupervised_GameEngine", "owner": "hpi-sam", "repository_name": "RL_SelfSupervised_GameEngine", "date_all_variable_collection": "2023-09-11", "description": "Exploring Self-supervised Self-Adaption Mechanisms Based on Continuous Reinforcement Learning with Application to Game Systems\"", "size": 5, "stargazers_count": 2, "watchers_count": 2, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 2, "default_branch": "main", "contributors": [{"contributor": "christianadriano", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# RL_SelfSupervised_GameEngine\n### Motivation\nSelf-adaption is a desired feature of real-time systems like flight control and driverless vehicles. Self-adaption in these systems is particularly challenging in the real world because these systems are subject to unpredictable changes that can be endogenous (e.g., partial failures or performance degradation) and exogenous (e.g., environmental or other concurrent systems). The current solution has been to trained these self-adaptation mechanism on supervised way, which implies the strong assumption that all change situations are known at training time. For this reason, the solution is to rely on simulators to produce change situations that could be used to train the adaptation mechanism in real time (continuous learning).\n\n### Problem \nHowever, designing simulators is a domain-dependent task, which is difficult to generalize across domains. Recent research on game showed that it is possible to train without human input while playing the game. While this is step to continuous learning, it does not deal with two major problems: (1) how to learn when the environment is changing (e.g., changes in the game rules) and (2) when to trigger learning (how to know which events and magnitude of effects to monitor?).\n\n### Approach \nWe are interested in exploring reinforcement learning techniques to continuously train an adaptation mechanims in a self-supervised way. The adaptation mechanism is part of an agent that interacts (makes decisions) by means of actions on an environment (system) that is subject to endogenous and exogenous changes. Our insight is to model the problem as simulation architecture that is executed in run time with the deployed system. As a proof of concept, we would execute experiments both with game engine and an e-commerce engine. \n\n### Preliminary References\n- Ameneyro, V., et al., \"Playing Carcassonne with Monte Carlo Tree Search.\" arXiv e-prints (2020): arXiv-2009. (https://arxiv.org/pdf/2009.12974.pdf)\n- Heyden, C. (2009). Implementing a computer player for Carcassonne. Master's thesis, Department of Knowledge Engineering, Maastricht University. (https://project.dke.maastrichtuniversity.nl/games/files/msc/MasterThesisCarcassonne.pdf)\n- Silver, D., et al. \"Mastering the game of go without human knowledge.\" nature 550.7676 (2017): 354-359. (https://www.nature.com/articles/nature24270.%20)\n- Schrittwieser, J., Silver, D., et al, (2020). Mastering atari, go, chess and shogi by planning with a learned model. Nature, 588(7839), 604-609. (https://www.nature.com/articles/s41586-020-03051-4)\n\n### Sequential Decision Making Techniques\n- Model-Based Reinforcement Learning (DQN)\n- Multi-Armed Bandits (Bayesian Bandits)\n- Monte Carlo Tree Search (MCTS)\n- Machine Learning on Graphs (Graph Neural Nets, Causal Inference)\n\n### Our Sister Projects\n- Reinforcement Learning for Self-Repair Mechanisms (https://github.com/hpi-sam/rl-4-self-repair)\n- Multi-Armed Bandits for Self-Repair Mechanisms (https://github.com/hpi-sam/bandits-4-self-repair)\n\n### Our Lectures\n- Markov Models (https://github.com/hpi-sam/MarkovModels_Lecture)\n- Graph Neural Networks (https://github.com/hpi-sam/GNN-Lecture)\n- Reinforcement Learning (https://github.com/christianadriano/RL_4_SelfHealingSystems)\n\n### get in touch with us:\n- Tibor (https://github.com/tiborboglar)\n- Christian (https://github.com/christianadriano)\n"}
{"url": "https://github.com/hpi-sam/robust-marl4sas", "owner": "hpi-sam", "repository_name": "robust-marl4sas", "date_all_variable_collection": "2023-09-11", "description": "Research project on robust multi-agent reinforcement learning (marl) for self-adaptive systems (sas)", "size": 76929, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 38, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 38, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "jokrah", "contributions": 86}, {"contributor": "florenceboettger", "contributions": 57}, {"contributor": "ulibath", "contributions": 35}, {"contributor": "caustt", "contributions": 15}, {"contributor": "christianadriano", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 7044814}, {"language": "Java", "num_chars": 1504398}, {"language": "HTML", "num_chars": 338747}, {"language": "Python", "num_chars": 174199}, {"language": "CSS", "num_chars": 12808}, {"language": "JavaScript", "num_chars": 827}], "readme": "# robust-marl4sas\nResearch project on robust multi-agent reinforcement learning (marl) for self-adaptive systems (sas)\n"}
{"url": "https://github.com/hpi-sam/Safe-RL-4-SAS", "owner": "hpi-sam", "repository_name": "Safe-RL-4-SAS", "date_all_variable_collection": "2023-09-11", "description": null, "size": 13240, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "Finnk11", "contributions": 10}, {"contributor": "christianadriano", "contributions": 6}, {"contributor": "LucaMariottoHPI", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 12967}], "readme": "# Safe Reinforcement Learning for Self-Adaptive Systems\nProject Seminar on Safe Reinforcement Learning for Self-Adaptive Systems\n"}
{"url": "https://github.com/hpi-sam/sct-teaching-materials", "owner": "hpi-sam", "repository_name": "sct-teaching-materials", "date_all_variable_collection": "2023-09-11", "description": null, "size": 3690, "stargazers_count": 1, "watchers_count": 1, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "christianzoellner", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "TeX", "num_chars": 111781}], "readme": "# Teaching Materials for Tool-Supported Statechart Modeling\n\nCollection of teaching materials related to the example environments that are published with our validation framework: https://github.com/hpi-sam/sct-validation-framework\n\n\n\n## Contents of this Repo\n\n* Teaching Materials for the **[Warehouse with Autonomous Robots Environment](infinitewarehouse)**. Contains a separate assignment document and detailed specification document.\n* Teaching Materials for the **[Vehicles and Traffic Lights Environment](infinitewarehouse)**. Contains an assignment document that contains two main statechart modeling tasks and a few minor tasks.\n* A **[Tutorial for our Tool Support](tool_tutorial)**. Includes hints on the statechart syntax, a guide for installing and using the [YAKINDU Statechart Tools](https://www.itemis.com/en/yakindu/state-machine/) and complete setup instructions and feature documentation for our [Validation Framework](https://github.com/hpi-sam/sct-validation-framework) \n* A **[LaTeX Template](template)** for all aforementioned documents that can be modified.\n\n\n\n## Language Note\n\n**Note that as of now, all materials are available in German language only.**\n\nHowever, anything that is actually captured in models or in the statecharts to be modeled, such as class or method names, is named in English, so that a translation is feasible without having to create alternative versions of the model and code artifacts.\n\n\n## Contribution\n\nIf you are interested in translating our materials, want to create alternative versions of the tasks or share our own materials, please feel free to open a pull request."}
{"url": "https://github.com/hpi-sam/sct-validation-framework", "owner": "hpi-sam", "repository_name": "sct-validation-framework", "date_all_variable_collection": "2023-09-11", "description": "Tool Support for the Teaching of State-Based Behavior Modeling: A validation framework that simulates and animated environments interacting with the code generated from statecharts to be used for teaching modeling.", "size": 2954, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": false, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "christianzoellner", "contributions": 291}, {"contributor": "Oluwoye", "contributions": 224}, {"contributor": "SimonWiet", "contributions": 97}, {"contributor": "jonaskordt", "contributions": 89}, {"contributor": "Paulpanther", "contributions": 31}, {"contributor": "Schirmchens", "contributions": 20}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 874487}], "readme": "# Validation Framework\r\n\r\nThis project is a validation framework which allows to run simulations of different environments that may include code generated from statechart models specified with YAKINDU Statechart Tools.\r\n\r\nRelated teaching materials are published at https://github.com/hpi-sam/sct-teaching-materials.\r\n\r\n\r\n\r\n## Project Structure\r\n\r\nThe project is devided into the following directories:\r\n- **`model`** contains the statechart models\r\n    + The models are contained in the `.sct` - files. They can be edited by YAKINDU.\r\n    + The belonging `.sgen`-file contains a predefined configuration for generating executable code from the statechart.\r\n- **`src-gen`** contains the code generated from the statecharts. It is automatically updated after choosing \"Generate Code Artifacts\" on the `.sgen`-file.\r\n- **`res`** contains resources for the GUI, as for example images\r\n- **`test`** contains tests for the project\r\n- **`src`** contains the source code of the simulation environment.\r\n\r\n## Simulator Code Structure (in directory `src`)\r\n- To start the simulator, execute the class `de.hpi.mod.sim.App`\r\n- The simulator code is devided in two packages, `de.hpi.mod.sim.core` and `de.hpi.mod.sim.worlds`.\r\n  + The `core` package covers everything that is needed for *every* simulation, e.g. the setting up the frame and a framework for executing scenarios and test cases. When adding new applications of the simulator, the core package should not have to be touched. See details in **Core**.\r\n  + In the `world` package, code is placed to specify the environment and entities for ones application. That is, what the environment, in which the statechart is simulated, looks like. See details in **Worlds**.\r\n- The file `architecture.pdf` shows a diagram visualizing the most important classes of our architecture. In the following, we describe their functionality. \r\n\r\n### Core\r\nThe core contains 2 classes and 4 packages.\r\n- `core.World` is the abstract class which is the base of every specific environment. It allows to hold entities and gives a list of abstract methods to be implemented in extending classes. See `Worlds`.\r\n- `core.Configuration` holds execution parameters (*magic numbers*) used for the simulation. If you need to adapt these or add more parameters, best do it by creating a subclass of this class in your world package, as done in `worlds.abstract_grid.GridConfiguration` or `worlds.infinitewarehouse.InfiniteWarehouseConfiguration`.\r\n- The package `core.scenario` holds classes to manage the execution of *scenarios* that is certain set ups of the environment. By default (`core.scenario.Scenario`), scenarios offer an open-end simulation. However, test cases (`core.scenario.TestScenario`) allow to simulate small situations and fail or pass depending on individually defined conditions, e.g. to verify the correct behavior of the statecharts. `core.scenario.ScenarioManager` manages the list of defined scenarios and test cases and their execution.\r\n- The package `core.simulation` handles running the simulation (starting and refreshing) and provides the interfaces `Entity` (active objects in the simulation) and `IHighlightable` (objects that can be clicked to view information). The concept of detectors (`core.simulation.Detector`) can be used to react to certain conditions in the simulation, e.g. fail the simulation if an entity goes to a place where it should not be able to go (e.g., a wall) and thereby testing the statechart implenentation.\r\n- The package `statechart` provides utilities to include the statechart behavior into the environment. The abstract class `StateChartWrapper` starts and stops the execution of statecharts and is able to provide the name of the current (hierarchical) state. For each entity defined by a statechart, a non-abstract class should be defined that inherits from `StatechartWrapper`. Such entities should implement the interface `StatechartEntity` in order to display the (hierarchical) state when highlighted.\r\nFurther, the class `SimulationTimerService` manages the translation of time events between the code from the statechart and the simulation as allows customizing the speed.\r\n\r\n- The package `view` holds all used UI elements. Most importantly, it holds a collection of `Panel`-classes for the different graphical user interfaces. The class `view.panels.AnimationPanel` displays the animated environment and is responsible for showing additional information on the state of up to two highlighted entities.\r\n\r\n\r\n### Worlds\r\nA `world` is the definition of the environment for a specific application. To set up an environment, one thus has to overwrite the abstract class `de.hpi.mod.sim.core.World`.\r\n+ One can use inheritance to build a structure of abstract and more and more specific environments\r\n+ Currently there are 6 worlds\r\n  - `abstract_grid.GridWorld` introduces an **abstract** environment with a grid-based 2D surface and provides useful utilities like the concept of positions and orientations in that grid\r\n  - `abstract_robots.RobotWorld` is a still abstract extension of the `GridWorld` and introduces robots to be moved around on the grid\r\n  - `infinitewarehouse.InfiniteWarehouseWord` is a ready-to-use implementation of a `RobotWorld` where robots transport packages from stations to unloading stations, have to avoid collisions and be recharged. The exact behavior of the robots drivesystem is specified by a YAKINDU statechart.\r\n  - `simpletrafficlights.SimpleTrafficLightsWord` is a ready-to-use implementation of a `RobotWorld` where robots drive in a grid-like street network with longer street stections and intersections that are governed by traffic ligths. Robots drive from one entry point to an exit point. The exact behavior of both the the robots and the traffic ligths is specified by YAKINDU statecharts.\r\n  - `trafficlights.TrafficLightWorld` is an **unfinished** implementation of a RobotWorld where robots transport packages from stations to unloading stations, have to avoid collisions. There are trraffic lights to help avoiding collisions. The exact behavior of the robots and traffic lights is specified by YAKINDU statecharts.\r\n  - `pong.PongWold` is leand on the traditionally Pong- Game. There is a one player and two player- mode. You have to catch the ball with your paddle. The exact behavior of the paddles are specified by a YAKINDU statechart.\r\n  - `flasher.FlashWorld` contains a world with a flashlight. In the beginning you get a number. This number represents the amount the bulb has to blink. The exact behavior of the bulb is specified by a YAKINDU statechart.\r\n \r\n#### Setting up your world\r\n   - Start by creating a new subpackage in the `worlds` package. Everything you develop and customize is to be placed in this subpackage.\r\n   - To set up a world, you have to implement a subclass of `core.World` which implements all its abstract methods. Inheritance hierarchies can be used. To get a feeling for this, have a look at the hierarchy of `worlds.infinitewarhouse.InfiniteWarehouse`. The required methods are\r\n     - `getDetectors()` should return a list of implementations of `core.simulation.Detector` to trigger events on certain conditions. Can be empty.\r\n     - `resetScenario()` is called when a scenario is ended and should thus contain code to reset the environment such that a new scenario can be started.\r\n     - `getEntities()` should return the list of active elements in the environment (which should be implementations of `core.Simulation.Entity`).\r\n     - `updateEntities(float delta)` should define the behaviour of entities when the simulation is updated (e.g., by passing the update call to the entities). `delta` is the number of miliseconds since the last frame. Entities should *do the next step*.\r\n     - `refreshEntities()` called when data changes such that entities might to be redrawn or react.\r\n     - `getScenarios()` the list of executable (open-end) scenarios\r\n     - `getTestGroups()` the map of named groups of executable test cases.\r\n     - `getAnimationPanel()` should return an implementation of `core.view.panels.AnimationPanel` in which the environment is drawn.\r\n     - `render(java.awt.Graphics graphics)` should perform all necessary rendering of the simulated environment. Takes place inside of the `AnimationPanel`.\r\n     - `refreshSimulationProperties(int currentHeight, int currentWidth)` called when the size of the frame changes. React to change or leave blank.\r\n     - `getHighlightAtPosition(int x, int y)` is called after a click on the coordinates in the parameters. If something implementing `IHighlightable` is clicked, this should be returned to display its information. If `null` is returned, the current selection is kept.\r\n     - `close()` is called when the simulator is closed. Clean up everything that needs to be cleaned up.\r\n  -  Your custom World class must bee added to the list of `POSSIBLE_WORLDS` in `de.hpi.mod.sim.App`.\r\n\r\n   - When you need to overwrite and/or add static parameters (magic numbers), do so by adding a class that extends `core.Configuration` in your `world` subpackage.\r\n\r\n   - To build an entity type that is controlled by the code generated from a statechart, write a subclass of `StateChartWrapper<T>`, where `T` is the generic type of a state in the generated code and will always be `[name of the statechart].State`. Subclasses of `StateChartWrapper` have access to the protected attribute `chart` representing the statechart. You have to implement the following methods\r\n     - `isActive([name of the statechart].State state)` is used for displaying the current state of the statechart. Return `(([name of the statechart]) chart).isStateActive(state)`\r\n     - `getStates()` should return the list of states of the statechart. They are stored in in the class file generated by Yakindu, so simply return `de.hpi.mod.sim.statemachines.[name of the world].[name of the statechart].State.values();`.\r\n     - `createStateMachine()` should simply return the generated class, so return `de.hpi.mod.sim.statemachines.[name of the world].[name of the statechart].State.values();`\r\n     - `update()` is used to relay outputs from the statechart to the simulation code. Hence, for each possible output `X` it should test if `(([name of the statechart])chart).isRaisedX()` returns true and if so react accordingly.\r\n\r\n  To raise input events from the simulation to the state machine, use `getStateMachine().raise[name of the event]`.  \r\n  See for example the method `update()` in `worlds.pong.LeftPaddle`.\r\n\r\n  Furthermore, if the statechart employs variables, you have to implement the required methods and returning the desired value. Such an example is the `long myPos()` method in the `LeftPaddle` class. \r\n\r\n## Setup\r\n\r\nYAKUNDU Statechart Tools ist ein Eclipse-Plugin. Da es Gelegentlich zu Problemen mit einem Nachinstallierten Plugin kommt, empfehlen wir Eclipse und YAKINDU als separates Standalone-Bundle zu installieren.\r\n\r\nEs wird mindestens Java Version 10 ben\u00f6tigt.\r\n\r\n\r\n\r\n## Benutzung\r\n\r\n#### Modellierung\r\n\r\n- In dem Ordner model k\u00f6nnen Eclipse/YAKINDU Steuerungen modelliert werden\r\n\t- F\u00fcr die InfinityWarehouse world wird die Roboter-Steuerung in der Datei `model/drivesystem.sct` modelliert.\r\n\t- F\u00fcr die FlashWorld wird die Gl\u00fchbirnen-Steuerung in der Datei `model/flasher.sct` modelliert.\r\n\t- Die Pong World kann mit einem paddle ge\u00f6ffnet werden. Die Steuerung des 1. paddles(dieses wird in der Welt links angezeigt) wird in der Datei `model/paddle1.sct` modelliert. Die des 2. paddles(das paddle wird in der Welt rechts angezeigt) wird in der Datei `model/paddle2.sct` modelliert.\r\n\t- Die flash-light world ben\u00f6tigt ein Modell f\u00fcr die Ampel- und eines f\u00fcr die Roboter Steuerung. Die Steuerung der Ampeln wird in der Datei `model/trafficlight.sct`modelliert, die Roboter in der Datei `tlRobot.sct`.\r\n- Die Schnittellen des Statecharts sind bereits vorgegeben (\"Definition section\" links). Diese d\u00fcrfen **nicht ver\u00e4ndert** werden, es k\u00f6nnen interne Variablen (\"internal\") erg\u00e4nzt werden.\r\n- Auf den Webseiten von YAKINDU findet sich [eine Anleitung zum Modellieren](https://www.itemis.com/en/yakindu/state-machine/documentation/user-guide/edit_editing_statecharts) und eine [Statechart-Referenz](https://www.itemis.com/en/yakindu/state-machine/documentation/user-guide/sclang_statechart_language_reference).\r\n\r\n#### Namenskonventionen f\u00fcr Zust\u00e4nde\r\n\r\n* Damit der aktuelle Zustand im Simulator angezeigt werden kann, m\u00fcssen bei der Benennung der Zust\u00e4nde einige Bedingungen eingehalten werden.\r\n* Die **\u00e4u\u00dferste Region** muss in den einzelnen Welten spezielle Namen haben:\r\n\t* InfiniteWarehouseWorld: Die  Region muss ``Drive System`` hei\u00dfen bzw zumindest genau 13 Zeichen lang sein (inkl. Leerzeichen).\r\n\t* FlashWorld: Die Region muss ``flasher``\r\n\t* PongWorld: Die Region muss ``pong``\r\n\r\n* Wenn **Unterregionen** verwendet werden m\u00fcssen sie entweder unbenannt sein oder mit einem Unterstich (\"_\") beginnen. \r\nSie d\u00fcrfen keine Lehrzeichen und keine weiteren Unterstiche enthalten.\r\n\r\n* In **Zustandsnamen** d\u00fcrfen *keine* Unterstiche (\"_\") benutzt werden.\r\n\r\n\r\n#### Codegenerierung\r\n\r\n- Die beigelegten `.sgen`-Dateien enthalten die Konfigurationen f\u00fcr die Codegenerierung. So ist z.B. drivesystem.sgen die Konfiguration f\u00fcr das Modell in drivesystem.sct. \r\n- Um den Code aus den Modellen zu generieren, muss in Eclipse/YAKINDU ein Rechtsklick auf die .sgen Datei gemacht werden um dann \"Generate Code Artifacts\" auszuw\u00e4hlen. Daraufhin wird der zum Statechart passende Quelltext automatisch neu generiert.\r\n\r\n#### Simulation\r\n\r\n- Zum Starten der Simulation wird die Klasse `de.hpi.mod.sim.App` im Ordner `src` rechts geklickt und \"Run as\" > \"Java Application\" ausgew\u00e4hlt.\r\n- Als Shortcut steht danach der \"Run\" Button oben im Eclipse-Men\u00fc zur Verf\u00fcgung.\r\n- Zu Beginn kann die Welt ausgew\u00e4hlt werden, die simuliert werden soll. Dabei sind zur Auswahl: \r\n\t* InfinityWarehouse world\r\n\t* FlashWorld\r\n\t* PongWorld\r\n- Ist der Simulator gestartet k\u00f6nnen entweder \"Szenarien\" (= dynamisch generierte Abl\u00e4ufe mit einem oder mehreren Robotern) oder \"Tests\" (= vordefinierte Situationen) ausgew\u00e4hlt werden. Innerhalb dieser Szenarien und Tests wird jeweils f\u00fcr alle Entit\u00e4ten der generierte Quelltext des zuvor modellierten Statecharts ausgef\u00fchrt.\r\n- Sobald ein Szenario oder Test gestartet wird l\u00e4uft ein Timer und die Geschwindigkeit kann ver\u00e4ndert werden.\r\n- Mit den Pfeiltasten kann navigiert werden, mit `Strg +` und `Strg -` gezoomt. `R` setzt die Kamera zur\u00fcck. `Space` pausiert den aktuelle laufenden Test / das aktuelle Szenario.\r\n- Mit der linken und rechten Maustaste kann jeweils ein Entit\u00e4t ausgew\u00e4hlt werden, deren Eigenschaften dann in einer info-box ablesbar sind."}
{"url": "https://github.com/hpi-sam/Spatio-Temporal-Graphs", "owner": "hpi-sam", "repository_name": "Spatio-Temporal-Graphs", "date_all_variable_collection": "2023-09-11", "description": "Projects on Spatio-Temporal Graphs", "size": 71625, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "iqrazaf", "contributions": 23}, {"contributor": "max-3l", "contributions": 21}, {"contributor": "christianadriano", "contributions": 19}, {"contributor": "lisakoeritz", "contributions": 18}, {"contributor": "schTi", "contributions": 4}, {"contributor": "AndreaNathansen", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 1635804}, {"language": "Python", "num_chars": 210537}], "readme": "# Exploring Spatio-Temporal Graphs as Means to Identify Failure Propagation\n\nThis repository includes our data and code for exploring failure propagation in spatio-temporal graphs.\n\nOur approach is separated in three subtasks:\n- Generating Anomaly Propagation Subgraphs from a system structure and given time series as source subgraphs\n- Exploring Synthetic Subgraph Generation loosely based on a given system structure as target subgraphs\n- Graph Matching of source and target subgraphs using Graph Auto Encoder \n\nThe code for those subtasks is available in the `/src` folder.\n\nThe underlying system graph structure and timeseries data is available in the `/data` folder. This folder also contains the output of the source and target subgraph generation. The output is provided as numpy arrays and stored in .npy files. To decode and encode those graphs for use in networkx graph structures, see `src/correlation.py`.\n\nFor calculating the Temporal Centrality Metrics the overtime package was used. The overtime directory was cloned directly from the [overtime3 package]{https://github.com/overtime3/overtime}.\n\nThe project seminar slides are available in the `/slides` folder and information on the project scope definition is given in the `/project scope` folder.\n\nFor code provided by the instructors, see `/SourceCode` folder."}
{"url": "https://github.com/hpi-sam/TGGs-for-Multi-Version-Models", "owner": "hpi-sam", "repository_name": "TGGs-for-Multi-Version-Models", "date_all_variable_collection": "2023-09-11", "description": "Evaluation artifacts for TGGs for multi-version models", "size": 1274, "stargazers_count": 0, "watchers_count": 0, "language": "Java", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Eclipse Public License 1.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "mbarkowsky", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Java", "num_chars": 7816015}]}
{"url": "https://github.com/HPIMakerKlub/Cyberblaster", "owner": "HPIMakerKlub", "repository_name": "Cyberblaster", "date_all_variable_collection": "2023-09-11", "description": "Cyber! Cyber! Yeah!", "size": 778, "stargazers_count": 2, "watchers_count": 2, "language": "Arduino", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "Fluepke", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Arduino", "num_chars": 1859}], "readme": "# Cyberblaster\nBecause light isn't just light\n\n![Image of a cyberblaster](https://raw.githubusercontent.com/HPIMakerKlub/Cyberblaster/master/photo357857809430327000.jpg)\n### Materialien\n- 4mm Sperrholz f\u00fcr die Spanten\n- 6mm Sperrholz f\u00fcr die beiden Ringe\n- CPU K\u00fchler (> 100 Watt TDP, ansonsten muss der L\u00fcfter st\u00e4ndig w\u00fchlen)\n- LED Treiber, z.B. http://de.aliexpress.com/item/Brand-new-100W-LED-Power-Supply-Driver-For-100-Watt-High-Power-LED-Light-Lamp-Bulb/32412210627.html\n- 100 Watt LED, die gibt es auch in warmwei\u00df\n- MOSFET, IRF7413 funktioniert gut\n- WeMos, siehe wemos.cc (Zur Not habe ich auch welche vorr\u00e4tig)\n- H\u00fchnerfutter zum MOSFET treiben\n\n### Anleitung\n- Bauteile lasercutten und zusammenkleben\n- LED mit W\u00e4rmeleitpaste auf dem K\u00fchler anbringen und den K\u00fchler am Lampenschirm anbringen\n- MOSFET zwischen Treiber(-) und LED(-) h\u00e4ngen. WeMos \u00fcber Transistoren mit dem MOSFET verdrahten (D0). Schaltplan folgt.\n"}
{"url": "https://github.com/HPIMakerKlub/dice", "owner": "HPIMakerKlub", "repository_name": "dice", "date_all_variable_collection": "2023-09-11", "description": "A simple dice pcb to be used a student events", "size": 91, "stargazers_count": 0, "watchers_count": 0, "language": "Eagle", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Fluepke", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Eagle", "num_chars": 902050}], "readme": "# dice\nA simple dice pcb to be used a student events.\n"}
{"url": "https://github.com/HPIMakerKlub/doorbell", "owner": "HPIMakerKlub", "repository_name": "doorbell", "date_all_variable_collection": "2023-09-11", "description": null, "size": 3437, "stargazers_count": 2, "watchers_count": 2, "language": "Arduino", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "janetzki", "contributions": 17}, {"contributor": "Fluepke", "contributions": 2}, {"contributor": "niccokunzmann", "contributions": 2}, {"contributor": "jakobbraun", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Arduino", "num_chars": 1961}, {"language": "C++", "num_chars": 1424}, {"language": "JavaScript", "num_chars": 749}, {"language": "QMake", "num_chars": 215}, {"language": "Shell", "num_chars": 32}], "readme": "# doorbell\n\n![](other/photo.jpg)\n\n## Benutzung\n![](other/qrcode.png)\n\nDie Klingel wird durch das Scannen des QR-Codes bet\u00e4tigt. Der hinterlegte Link\n\n    http://j.braun.mooo.com:8080/bell\n\nmuss im Browser ge\u00f6ffnet werden.\n\n## SERVER\n\nUm den fertigen Container zu starten folgendes Kommando verwenden:\n\n    docker run -d --name bell -p 8080:8080 -p 8081:8081 jakobbraun/hpi-makerklub-bell \n\nUm den Container selbst zu erstellen:\n\n    sudo docker build -t jakobbraun/hpi-makerklub-bell .\n\n## Hardware\nNeben der ESP Umgebung wird folgende Bibliothek ben\u00f6tigt: https://github.com/morrissinger/ESP8266-Websocket.git\n"}
{"url": "https://github.com/HPIMakerKlub/ESP8266_Time", "owner": "HPIMakerKlub", "repository_name": "ESP8266_Time", "date_all_variable_collection": "2023-09-11", "description": "A time library, that keeps the current time automatically updated via NTP", "size": 1, "stargazers_count": 2, "watchers_count": 2, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "Fluepke", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 3776}]}
{"url": "https://github.com/HPIMakerKlub/Fluepdot", "owner": "HPIMakerKlub", "repository_name": "Fluepdot", "date_all_variable_collection": "2023-09-11", "description": null, "size": 194, "stargazers_count": 0, "watchers_count": 0, "language": "Eagle", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Fluepke", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Eagle", "num_chars": 1527009}, {"language": "C++", "num_chars": 4962}, {"language": "Arduino", "num_chars": 599}], "readme": "# Fluepdot\nThis is going to be all about controlling Annax 37623 flipdot displays.\nMore will follow soon.\n\nIn case of questions contact us via github.\n\nMaintainer: @fluepke, @kryptokommunist\n"}
{"url": "https://github.com/HPIMakerKlub/Fotobox", "owner": "HPIMakerKlub", "repository_name": "Fotobox", "date_all_variable_collection": "2023-09-11", "description": "Visit the website:", "size": 1136, "stargazers_count": 2, "watchers_count": 2, "language": "CSS", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Apache License 2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "Fluepke", "contributions": 6}, {"contributor": "MasterCarl", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "CSS", "num_chars": 22488}, {"language": "HTML", "num_chars": 13577}, {"language": "JavaScript", "num_chars": 9044}], "readme": "# [Start Bootstrap](http://startbootstrap.com/) - [Grayscale](http://startbootstrap.com/template-overviews/grayscale/)\n\n[Grayscale](http://startbootstrap.com/template-overviews/grayscale/) is a multipurpose, one page HTML theme for [Bootstrap](http://getbootstrap.com/) created by [Start Bootstrap](http://startbootstrap.com/). This template features various content sections and a Google Maps section with a custom map marker.\n\n## Getting Started\n\nTo use this template, choose one of the following options to get started:\n* Download the latest release on Start Bootstrap\n* Fork this repository on GitHub\n\n## Bugs and Issues\n\nHave a bug or an issue with this template? [Open a new issue](https://github.com/IronSummitMedia/startbootstrap-grayscale/issues) here on GitHub or leave a comment on the [template overview page at Start Bootstrap](http://startbootstrap.com/template-overviews/grayscale/).\n\n## Creator\n\nStart Bootstrap was created by and is maintained by **David Miller**, Managing Parter at [Iron Summit Media Strategies](http://www.ironsummitmedia.com/).\n\n* https://twitter.com/davidmillerskt\n* https://github.com/davidtmiller\n\nStart Bootstrap is based on the [Bootstrap](http://getbootstrap.com/) framework created by [Mark Otto](https://twitter.com/mdo) and [Jacob Thorton](https://twitter.com/fat).\n\n## Copyright and License\n\nCopyright 2013-2015 Iron Summit Media Strategies, LLC. Code released under the [Apache 2.0](https://github.com/IronSummitMedia/startbootstrap-grayscale/blob/gh-pages/LICENSE) license."}
{"url": "https://github.com/HPIMakerKlub/game_controller", "owner": "HPIMakerKlub", "repository_name": "game_controller", "date_all_variable_collection": "2023-09-11", "description": "A game controller built from Arduino sensors.", "size": 925, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "janetzki", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 964}], "readme": "# game_controller\nA game controller built from Arduino sensors.\n![](game_controller.jpg)\n"}
{"url": "https://github.com/HPIMakerKlub/knitting", "owner": "HPIMakerKlub", "repository_name": "knitting", "date_all_variable_collection": "2023-09-11", "description": "Strickmaschinen", "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "niccokunzmann", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# knitting\nStrickmaschinen\n\nDie Strickmaschinen sind vom Typ KH-910, gehackt mit dem [Ayab kit](http://ayab-knitting.com/).\n"}
{"url": "https://github.com/HPIMakerKlub/LED_Panel", "owner": "HPIMakerKlub", "repository_name": "LED_Panel", "date_all_variable_collection": "2023-09-11", "description": "A Reverse-Engineering project for controlling Annax LED panels (from trains).", "size": 4171, "stargazers_count": 1, "watchers_count": 1, "language": "Objective-C", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "Fluepke", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Objective-C", "num_chars": 37628}, {"language": "Arduino", "num_chars": 5071}], "readme": "# LED_Panel\nA finished Reverse-Engineering project for controlling Annax LED panels (from trains).\n\n![halbes Panel](https://github.com/HPIMakerKlub/LED_Panel/raw/master/DSC_3423.JPG \"Eine Displayeinheit besteht aus zwei dieser Panels\")\n"}
{"url": "https://github.com/HPIMakerKlub/loetworkshop", "owner": "HPIMakerKlub", "repository_name": "loetworkshop", "date_all_variable_collection": "2023-09-11", "description": null, "size": 18212, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "niccokunzmann", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# L\u00f6tworkshop\n\nHier ist ein [Comic](http://mightyohm.com/files/soldercomic/translations/DE_SolderComic.pdf), wie man richtig l\u00f6tet.\n\n[Bilder](bilder) vom Workshop\n\n"}
{"url": "https://github.com/HPIMakerKlub/notenBox", "owner": "HPIMakerKlub", "repository_name": "notenBox", "date_all_variable_collection": "2023-09-11", "description": "Eine Box f\u00fcrs Regal - Lasercut", "size": 80, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "jakobbraun", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Notenbox \u2013 Lasercutter Vorlage f\u00fcr eine Notenbox f\u00fcrs Regal\n\nf\u00fcr 4mm Sperrholz\n\n![](notenBox.jpg)\n\nEntstehung:\n* Box erstellt mit http://www.makercase.com/\n* mit Inkscape die Pfade angepasst (Note als .svg von wikimedia: https://commons.wikimedia.org/wiki/File:Parts_of_a_musical_note.svg)\n* ausgedruckt (power = 100%; speed = 6%; ppi = 1000; z-axis: 4mm)\n* geklebt mit Holzleim\n\n<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons Lizenzvertrag\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" href=\"http://purl.org/dc/dcmitype/StillImage\" property=\"dct:title\" rel=\"dct:type\">notenBox</span> von <span xmlns:cc=\"http://creativecommons.org/ns#\" property=\"cc:attributionName\">Jakob Braun</span> ist lizenziert unter einer <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Namensnennung 4.0 International Lizenz</a>.\n"}
{"url": "https://github.com/HPIMakerKlub/sensebox", "owner": "HPIMakerKlub", "repository_name": "sensebox", "date_all_variable_collection": "2023-09-11", "description": "Die Sensebox vom Makerklub", "size": 1196, "stargazers_count": 1, "watchers_count": 1, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "niccokunzmann", "contributions": 39}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 204670}, {"language": "HTML", "num_chars": 10251}, {"language": "C", "num_chars": 2090}], "readme": "# sensebox\nDie Sensebox vom Makerklub.\n\n![](bilder/auf_dem_bett.jpg)\n\n- Hier findest du die [Statistiken](http://rawgit.com/HPIMakerKlub/sensebox/master/statistics/sensor.html?senseBoxID=5719c4037514d05c121e317c) aus dem Ordner [`statistics`](statistics).\n- Die Sensebox ist auf der Karte eingezeichnet: [OpenSenseMap](http://www.opensensemap.org/#/explore/5719c4037514d05c121e317c)\n\n[![](bilder/statistics.png)](http://rawgit.com/HPIMakerKlub/sensebox/master/statistics/sensor.html?senseBoxID=5719c4037514d05c121e317c)"}
{"url": "https://github.com/HPIMakerKlub/vrsandbox", "owner": "HPIMakerKlub", "repository_name": "vrsandbox", "date_all_variable_collection": "2023-09-11", "description": null, "size": 9709, "stargazers_count": 0, "watchers_count": 0, "language": "CSS", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Other", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "gh-pages", "contributors": [{"contributor": "niccokunzmann", "contributions": 16}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "CSS", "num_chars": 27538}, {"language": "JavaScript", "num_chars": 16065}, {"language": "HTML", "num_chars": 3191}], "readme": "# vrsandbox\n\n- [View the website.](http://hpimakerklub.github.io/vrsandbox/)\n- [Edit the website.](https://github.com/HPIMakerKlub/vrsandbox/generated_pages/new)\n\n## Installation\n\n- You can install the software from the [master branch](https://github.com/HPIMakerKlub/vrsandbox/tree/master#readme).\n\n"}
{"url": "https://github.com/HPIMakerKlub/Wordclock", "owner": "HPIMakerKlub", "repository_name": "Wordclock", "date_all_variable_collection": "2023-09-11", "description": "Eine einfach nachzubauende Wordclock.", "size": 2708, "stargazers_count": 5, "watchers_count": 5, "language": "C++", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 5, "default_branch": "master", "contributors": [{"contributor": "Fluepke", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "C++", "num_chars": 26832}, {"language": "HTML", "num_chars": 14746}, {"language": "JavaScript", "num_chars": 3662}, {"language": "CSS", "num_chars": 3268}, {"language": "Arduino", "num_chars": 3015}, {"language": "C", "num_chars": 1386}, {"language": "Shell", "num_chars": 257}], "readme": "# Wordclock\nEine einfach nachzubauende Wordclock.\n\nWer Teile daf\u00fcr gecuttet braucht, kann mich, fluepke, via github kontaktieren.\nNachbauten erw\u00fcnscht, berichtet gerne :)\n\n# Materialien\n- 30 x 40cm Bilderrahmen (z.B. https://www.amazon.de/Walther-KV040B-Lifestyle-Kunststoffrahmen-schwarz/dp/B003TBKKNE/ref=sr_1_1?ie=UTF8&qid=1478877933&sr=8-1&keywords=30+x+40+rahmen)\n- WeMos (siehe wemos.cc)\n- 5V WS2811 / WS2812 LED Stripe mit 60 LEDs/m\n- Tonpapier (logischerweise mind. 30x40 cm, idealerweise >= 300g/m^2)\n- MDF Platte 6mm\n- Brotpapier\n\n# Bauanleitung\n1. Front aus Tonpapier lasern. (HPI Cutter: 100% Speed bei 100% eignet sich ganz gut und hinterl\u00e4sst nur minimale Ru\u00dfspuren)\n2. Tonpapier mit Brotpapier bekleben.\n3. R\u00fcckseite aus 6mm MDF cutten, f\u00fcr eigene Gravuren ggf. Lichtkammer anpassen\n4. St\u00f6rende Gegenst\u00e4nde von der beim Bilderrahmen mitgelierferten Platte entfernen.\n5. Lichtkammern auf die mitgelieferte Platte nachzeichnen, LED-Streifen aufkleben und verl\u00f6ten (sodass oben von der Kammer f\u00fcr den WeMos eingespeist werden kann).\n6. WeMos programmieren.\n7. WeMos anl\u00f6ten.\n8. MDF-Platte mit Platte des Bilderrahmens verkleben.\n9. USB Kabel durch das Geh\u00e4use herausf\u00fchren.\n\n![Bild der Wordclock](https://raw.githubusercontent.com/HPIMakerKlub/Wordclock/master/bilder/wordclock_hinten.jpg \"Tadaaa\")\n"}
{"url": "https://github.com/hsleonis/achitecture", "owner": "hsleonis", "repository_name": "achitecture", "date_all_variable_collection": "2023-09-11", "description": "Achitect website", "size": 357276, "stargazers_count": 1, "watchers_count": 1, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 48}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 7524114}, {"language": "JavaScript", "num_chars": 5101495}, {"language": "CSS", "num_chars": 1654259}, {"language": "HTML", "num_chars": 311271}, {"language": "Shell", "num_chars": 12698}, {"language": "CoffeeScript", "num_chars": 9072}, {"language": "Ruby", "num_chars": 8330}, {"language": "Batchfile", "num_chars": 7659}, {"language": "ApacheConf", "num_chars": 4166}], "readme": "# achitecture\n"}
{"url": "https://github.com/hsleonis/alquran-dashboard", "owner": "hsleonis", "repository_name": "alquran-dashboard", "date_all_variable_collection": "2023-09-11", "description": "Angular Js dashboard with PHP EL framework", "size": 440, "stargazers_count": 2, "watchers_count": 2, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 48984}, {"language": "CSS", "num_chars": 33766}, {"language": "JavaScript", "num_chars": 9617}, {"language": "ApacheConf", "num_chars": 212}], "readme": "# alquran-dashboard\n"}
{"url": "https://github.com/hsleonis/bamboo_hr", "owner": "hsleonis", "repository_name": "bamboo_hr", "date_all_variable_collection": "2023-09-11", "description": "Python API tool for Bamboo HR management", "size": 125, "stargazers_count": 1, "watchers_count": 1, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 3, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 3, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["api-client", "bamboohr", "python3"], "languages": [{"language": "Python", "num_chars": 51530}, {"language": "HTML", "num_chars": 16409}, {"language": "CSS", "num_chars": 2967}, {"language": "JavaScript", "num_chars": 2013}, {"language": "Shell", "num_chars": 1141}], "readme": "# Bamboo HR API Tool\nSimple web-based (Python / Django) API tool for the Bamboo HR with user authentication & session login.\n\n## This perticular tool contains 4 modules:\n* Single profile upload : Upload file with additional information to employee profiles\n* Document download: Download document from all employees of a perticular category/folder\n* Backup: Download employee (Active / All) files as a zip\n* Report: Download CSV report of employee (Active / All) files\n\n# Why should you use Bamboo HR?\nHR is for the people, not the paperwork. That's why we created BambooHR: the online Human Resources Information System (HRIS) that makes time for the work you were meant to do. But change can be hard. So here's our promise: BambooHR guarantees your success when changing from spreadsheets to our intuitive online HR software.\n"}
{"url": "https://github.com/hsleonis/basetech", "owner": "hsleonis", "repository_name": "basetech", "date_all_variable_collection": "2023-09-11", "description": "Base Technologies", "size": 259253, "stargazers_count": 1, "watchers_count": 1, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 30}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 7701012}, {"language": "JavaScript", "num_chars": 5785037}, {"language": "CSS", "num_chars": 1798962}, {"language": "HTML", "num_chars": 383602}, {"language": "Shell", "num_chars": 14512}, {"language": "CoffeeScript", "num_chars": 10368}, {"language": "Batchfile", "num_chars": 9559}, {"language": "Ruby", "num_chars": 9520}, {"language": "ApacheConf", "num_chars": 4729}], "readme": "# basetech\n"}
{"url": "https://github.com/hsleonis/bladewp", "owner": "hsleonis", "repository_name": "bladewp", "date_all_variable_collection": "2023-09-11", "description": "Parse plain HTML data and converts to WP snippets", "size": 1187, "stargazers_count": 2, "watchers_count": 2, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 445638}, {"language": "CSS", "num_chars": 12926}, {"language": "PHP", "num_chars": 5127}], "readme": "# Enqueuer is a helpful tool for WordPress theme developers. It parses CSS & JS links from plain HTML and generates simple WordPress enqueue function.\n\n    Parses full page HTML code and separate css & js links.\n    It understands <head> & <body> scripts.\n    Adds get_template_directory_uri() in front of relative paths.\n    Auto generate script Handles.\n    It can also convert HTML snippets to single enqueue.\n\n"}
{"url": "https://github.com/hsleonis/brandmakers", "owner": "hsleonis", "repository_name": "brandmakers", "date_all_variable_collection": "2023-09-11", "description": "Builders site with angular js", "size": 157068, "stargazers_count": 1, "watchers_count": 1, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 19}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 7497512}, {"language": "JavaScript", "num_chars": 5027724}, {"language": "CSS", "num_chars": 1721828}, {"language": "HTML", "num_chars": 327040}, {"language": "Shell", "num_chars": 12698}, {"language": "CoffeeScript", "num_chars": 9072}, {"language": "Ruby", "num_chars": 8330}, {"language": "Batchfile", "num_chars": 7659}, {"language": "ApacheConf", "num_chars": 4391}], "readme": "# Brand Makers\nBuilders site with angular js\nWebsite: http://162.144.89.76/projects/web/brand \n"}
{"url": "https://github.com/hsleonis/cancer-analysis", "owner": "hsleonis", "repository_name": "cancer-analysis", "date_all_variable_collection": "2023-09-11", "description": "Machine Learning Model for Cancer Analysis (Random Forest and Linear Regression)", "size": 89, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 148675}], "readme": "Machine Learning for Cancer Analysis\n"}
{"url": "https://github.com/hsleonis/development-company", "owner": "hsleonis", "repository_name": "development-company", "date_all_variable_collection": "2023-09-11", "description": "Developer website in WordPress", "size": 80017, "stargazers_count": 1, "watchers_count": 1, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 1, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 16}, {"contributor": "bravotanmoy", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 10992173}, {"language": "JavaScript", "num_chars": 2211983}, {"language": "CSS", "num_chars": 1948705}, {"language": "Shell", "num_chars": 2727}, {"language": "ApacheConf", "num_chars": 271}], "readme": "# Developer Website\n(c) 2016\n\n# Installation\n* Create a directory named 'doreendev'\n* Initialize git in that directory:\n``\ngit init\n``\n* Now clone this repo:\n``\ngit clone https://github.com/hsleonis/development-company.git\n``\n* You will find the MySQL database in wp-content/database folder, import it. Your database name should be 'doreendev'\n* You can change database settings in 'wp-config.php' if needed.\n"}
{"url": "https://github.com/hsleonis/dgroup", "owner": "hsleonis", "repository_name": "dgroup", "date_all_variable_collection": "2023-09-11", "description": "Corporate company theme", "size": 16428, "stargazers_count": 1, "watchers_count": 1, "language": "CSS", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 25}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "CSS", "num_chars": 428136}, {"language": "PHP", "num_chars": 316334}, {"language": "JavaScript", "num_chars": 229593}, {"language": "Shell", "num_chars": 2727}], "readme": "# dgroup\n"}
{"url": "https://github.com/hsleonis/earthquakemap", "owner": "hsleonis", "repository_name": "earthquakemap", "date_all_variable_collection": "2023-09-11", "description": "Voluntery earthquake support and public support wp theme", "size": 7974, "stargazers_count": 1, "watchers_count": 1, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 617351}, {"language": "CSS", "num_chars": 204207}, {"language": "JavaScript", "num_chars": 95892}], "readme": "# earthquakemap\n"}
{"url": "https://github.com/hsleonis/expenser", "owner": "hsleonis", "repository_name": "expenser", "date_all_variable_collection": "2023-09-11", "description": "Desktop app Expense calculator with chromium", "size": 315, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Creative Commons Zero v1.0 Universal", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 220013}, {"language": "HTML", "num_chars": 4768}, {"language": "CSS", "num_chars": 596}], "readme": "Expense Calculator\n================================\n\nAuthor: Md. Hasan Shahriar\nTechnology: NodeJs, Electron, Chromium, Loki\nDescription: Calculates daily expenses and shows monthly expense statistics.\nDate: 18 October 2016"}
{"url": "https://github.com/hsleonis/expressworks", "owner": "hsleonis", "repository_name": "expressworks", "date_all_variable_collection": "2023-09-11", "description": "Nodeschool.io Expressworks tutorial solutions", "size": 1655, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 3387}, {"language": "HTML", "num_chars": 406}, {"language": "CSS", "num_chars": 15}], "readme": "# EXPRESS WORKS\n\n> This workshop that will teach you basics of Express.js \n\n> _Looking for more interactive tutorials like this? Go to [nodeschool.io](http://nodeschool.io)._\n\n## Get help\nHaving issues with expressworks? Get help troubleshooting in the [nodeschool discussions repo](http://github.com/nodeschool/discussions), or on gitter:\n\n[![Gitter](https://badges.gitter.im/Join Chat.svg)](https://gitter.im/nodeschool/discussions?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\n## Install Node.js\n\nMake sure Node.js is installed on your computer.\n\nInstall it from [nodejs.org/download](http://nodejs.org/download)\n\n### Install `expressworks` with `npm`\n\nOpen your terminal and run this command:\n\n```\nnpm install --global expressworks\n```\n\nThe `--global` option installs this module globally so that you can run it as a command in your terminal.\n\n#### Having issues with installation?\n\nIf you get an `EACCESS` error, the simplest way to fix this is to rerun the command, prefixed with sudo:\n\n```\nsudo npm install --global expressworks\n```\n\nYou can also fix the permissions so that you don't have to use `sudo`. Take a look at this npm documentation:\nhttps://docs.npmjs.com/getting-started/fixing-npm-permissions\n\n## Run the workshop\n\nOpen your terminal and run the following command:\n\n```\nexpressworks\n```\n\n## Solutions\n\nIn the Javascript files, you will find solutions to the lessons.\nTo know details about the module: https://github.com/azat-co/expressworks\n\n## Need help with an exercise?\n\nOpen an issue in the nodeschool/discussions repo: https://github.com/nodeschool/discussions\n\nInclude the name `expressworks` and the name of the challenge you're working on in the title of the issue.\n\n## License\n\nMIT\n"}
{"url": "https://github.com/hsleonis/filmmaker-wp-theme", "owner": "hsleonis", "repository_name": "filmmaker-wp-theme", "date_all_variable_collection": "2023-09-11", "description": "WP minimal theme for company promotion", "size": 3420, "stargazers_count": 0, "watchers_count": 0, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 537793}, {"language": "JavaScript", "num_chars": 48481}, {"language": "CSS", "num_chars": 28210}, {"language": "Shell", "num_chars": 3357}], "readme": "# filmmaker-wp-theme\n"}
{"url": "https://github.com/hsleonis/grading_app", "owner": "hsleonis", "repository_name": "grading_app", "date_all_variable_collection": "2023-09-11", "description": "Small app in flask displaying student grades", "size": 63, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "hsleonis", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 1410}], "readme": "# Grading app\nSmall app in flask displaying student grades.\n\n### Add CSV in this format (grades.csv):\n| First name | Surname | Student ID | Grade 1a | Grade 1b | ... | Grade | Total | Percentage |\n|------------|---------|------------|----------|----------|-----|-------|-------|------------|\n|            |         |            |          |          |     |       |       |            |\n|            |         |            |          |          |     |       |       |            |\n\n### Initial screen:\n![Initial screen](1.jpg)\n\n### Output screen with grades:\n![Output screen with grades](2.jpg)\n"}
{"url": "https://github.com/hsleonis/gulp-frontend-developer", "owner": "hsleonis", "repository_name": "gulp-frontend-developer", "date_all_variable_collection": "2023-09-11", "description": "Development environment for frontend developer", "size": 1, "stargazers_count": 0, "watchers_count": 0, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 889}], "readme": "# gulp-frontend-developer\n"}
{"url": "https://github.com/hsleonis/healthy-entrepreneurs", "owner": "hsleonis", "repository_name": "healthy-entrepreneurs", "date_all_variable_collection": "2023-09-11", "description": "Angular js admin panel", "size": 25548, "stargazers_count": 2, "watchers_count": 2, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 29}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 484933}, {"language": "PHP", "num_chars": 88974}, {"language": "JavaScript", "num_chars": 77445}, {"language": "CSS", "num_chars": 22373}, {"language": "ApacheConf", "num_chars": 1246}], "readme": "# healthy-entrepreneurs\n"}
{"url": "https://github.com/hsleonis/image-resizer", "owner": "hsleonis", "repository_name": "image-resizer", "date_all_variable_collection": "2023-09-11", "description": "Bulk Image resizer with PHP & GD library", "size": 13, "stargazers_count": 22, "watchers_count": 22, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 10, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 10, "open_issues": 0, "watchers": 22, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 26}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 8789}], "readme": "# PHP Image Resizer\n\nCreate bulk image thumbnails or scale to eaxct size instantly with PHP and the awesome GD library.\nGD library is builtin with most PHP build. To make sure, use `phpinfo()`.\n\nThis library will create thumbnails of all images from the given directory path and store them wherever you want.\nYou can just resize proportionally, crop to exact dimension after resizing proportionally and compress to reduce image size keeping good quality.\n\nThis library comes with default HTML resized image list.\n\n# How to use\nRequire the `class.imageresizer.php` from your file.\n````php\nrequire_once ('class.imageresizer.php');\n````\n\n### With options\nNow pass an argument associative array with options\n````php\n// Create thumbnails\n$args = array(\n    'height'    => 975,\n    'width'     => 650,\n    'is_crop_hard' => 1\n);\n$img = new ImageResizer($args);\n$img->create();\n````\n\n### Without options\nYou can just use default properties by just:\n\n````php\n$img = new ImageResizer();\n$img->create();\n````\n\n### Single image\n`create()` function will resize all image files from the folder. To resize only one image, use `createThumbnail()`. You have to pass the image filename with extension, width in pixel and height in pixel as arguments:\n\n````php\n$args = array(\n    'compress'     => 0.8,\n    'is_crop_hard' => 1\n);\n$img = new ImageResizer($args);\n$img->createThumbnail('Desires_LB_MF16_7290.jpg',300,450);\n````\n\n### Prevent HTML resize list\nTo prevent the class from printing image resize list as HTML, use `resize_list` property:\n````php\n$args = array(\n    'height'    => 400,\n    'width'     => 270,\n    'is_crop_hard' => 1,\n    'resize_list'  => false\n);\n$img = new ImageResizer($args);\n$msg = $img->create();\n\n// Now we can do whatever we want, maybe JSON\nprint_r(json_encode($msg));\n````\n\n# Agruments\n\nKey | Type | Value | Default\n--- | --- | --- | ---\nheight | int/float | Thumbnail height in px | 200\nwidth | int/float | Thumbnail width in px | 200\nimg_dir | string | Full size image directory path | '/img'\nthumb_dir | string | Thumbnail image directory path (Remember to add extra backslash after. You can use file name prefix :) ) | '/thumb/'\ncompress | int/float | Image compression (0~1, 0.15 is 15% ) | 0.8\nis_crop_hard | boolean | Crops the image with exact height & width proportionally from the center of the image | false\nresize_list | boolean | Prevents default HTML resized image list | true\n\n# Example\nThis is how it works:\n````php\n\nrequire_once ('class.imageresizer.php');\n\n// Create thumbnails\n$args = array(\n    'height'    => 975,\n    'width'     => 650,\n    'is_crop_hard' => 1\n);\n$img = new ImageResizer($args);\n$img->create();\n\n````\n\n# Author\nMd. Hasan Shahriar\n\nGithub: https://github.com/hsleonis\n\nEmail: hsleonis2@gmail.com\n\n2016\n\n# License\nCopyright (c) 2016 Md. Hasan Shahriar Licensed under the The [MIT License (MIT)](http://opensource.org/licenses/MIT).\n"}
{"url": "https://github.com/hsleonis/ios-icon-splash-screen", "owner": "hsleonis", "repository_name": "ios-icon-splash-screen", "date_all_variable_collection": "2023-09-11", "description": "Generate iOS app icon and splash screen from one image", "size": 389, "stargazers_count": 0, "watchers_count": 0, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 11554}], "readme": "# iOS App Icon & Launch Screen Generator\n\nCreate bulk image thumbnails or scale to eaxct size instantly with PHP and the awesome GD library.\nGD library is builtin with most PHP build. To make sure, use `phpinfo()`.\n\nThis library will create thumbnails of all images from the given directory path and store them wherever you want.\nYou can just resize proportionally, crop to exact dimension after resizing proportionally and compress to reduce image size keeping good quality.\n\nThis library comes with default HTML resized image list.\n\n# How to use\nRequire the `class.imageresizer.php` from your file.\n````php\nrequire_once ('class.imageresizer.php');\n````\n\n### With options\nNow pass an argument associative array with options\n````php\n// Create thumbnails\n$args = array(\n    'height'    => 975,\n    'width'     => 650,\n    'is_crop_hard' => 1\n);\n$img = new ImageResizer($args);\n$img->create();\n````\n\n### Without options\nYou can just use default properties by just:\n\n````php\n$img = new ImageResizer();\n$img->create();\n````\n\n### Single image\n`create()` function will resize all image files from the folder. To resize only one image, use `createThumbnail()`. You have to pass the image filename with extension, width in pixel and height in pixel as arguments:\n\n````php\n$args = array(\n    'compress'     => 0.8,\n    'is_crop_hard' => 1\n);\n$img = new ImageResizer($args);\n$img->createThumbnail('Desires_LB_MF16_7290.jpg',300,450);\n````\n\n### Prevent HTML resize list\nTo prevent the class from printing image resize list as HTML, use `resize_list` property:\n````php\n$args = array(\n    'height'    => 400,\n    'width'     => 270,\n    'is_crop_hard' => 1,\n    'resize_list'  => false\n);\n$img = new ImageResizer($args);\n$msg = $img->create();\n\n// Now we can do whatever we want, maybe JSON\nprint_r(json_encode($msg));\n````\n\n# Agruments\n\nKey | Type | Value | Default\n--- | --- | --- | ---\nheight | int/float | Thumbnail height in px | 200\nwidth | int/float | Thumbnail width in px | 200\nimg_dir | string | Full size image directory path | '/img'\nthumb_dir | string | Thumbnail image directory path (Remember to add extra backslash after. You can use file name prefix :) ) | '/thumb/'\ncompress | int/float | Image compression (0~1, 0.15 is 15% ) | 0.8\nis_crop_hard | boolean | Crops the image with exact height & width proportionally from the center of the image | false\nresize_list | boolean | Prevents default HTML resized image list | true\n\n# Example\nThis is how it works:\n````php\n\nrequire_once ('class.imageresizer.php');\n\n// Create thumbnails\n$args = array(\n    'height'    => 975,\n    'width'     => 650,\n    'is_crop_hard' => 1\n);\n$img = new ImageResizer($args);\n$img->create();\n\n````\n\n# Author\nMd. Hasan Shahriar\n\nGithub: https://github.com/hsleonis\n\nEmail: hsleonis2@gmail.com\n\n2016\n\n# License\nCopyright (c) 2016 Md. Hasan Shahriar Licensed under the The [MIT License (MIT)](http://opensource.org/licenses/MIT)."}
{"url": "https://github.com/hsleonis/javascripting", "owner": "hsleonis", "repository_name": "javascripting", "date_all_variable_collection": "2023-09-11", "description": "Nodeschool.io Javascripting tutorial solutions", "size": 0, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1911}], "readme": "# JAVASCRIPTING\n\n> Learn JavaScript by adventuring around in the terminal.  \n\n> _Looking for more interactive tutorials like this? Go to [nodeschool.io](http://nodeschool.io)._\n\n## Get help\nHaving issues with javascripting? Get help troubleshooting in the [nodeschool discussions repo](http://github.com/nodeschool/discussions), or on gitter:\n\n[![Gitter](https://badges.gitter.im/Join Chat.svg)](https://gitter.im/nodeschool/discussions?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\n## Install Node.js\n\nMake sure Node.js is installed on your computer.\n\nInstall it from [nodejs.org/download](http://nodejs.org/download)\n\n### Install `javascripting` with `npm`\n\nOpen your terminal and run this command:\n\n```\nnpm install --global javascripting\n```\n\nThe `--global` option installs this module globally so that you can run it as a command in your terminal.\n\n#### Having issues with installation?\n\nIf you get an `EACCESS` error, the simplest way to fix this is to rerun the command, prefixed with sudo:\n\n```\nsudo npm install --global javascripting\n```\n\nYou can also fix the permissions so that you don't have to use `sudo`. Take a look at this npm documentation:\nhttps://docs.npmjs.com/getting-started/fixing-npm-permissions\n\n## Run the workshop\n\nOpen your terminal and run the following command:\n\n```\njavascripting\n```\n\n## Solutions\n\nIn the Javascript files, you will find solutions to the lessons.\nTo know details about the module: https://github.com/sethvincent/javascripting\n\n## Need help with an exercise?\n\nOpen an issue in the nodeschool/discussions repo: https://github.com/nodeschool/discussions\n\nInclude the name `javascripting` and the name of the challenge you're working on in the title of the issue.\n\n## License\n\nMIT\n"}
{"url": "https://github.com/hsleonis/jquery-flipbook", "owner": "hsleonis", "repository_name": "jquery-flipbook", "date_all_variable_collection": "2023-09-11", "description": "Builders project with jQuery flipbook", "size": 7456, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 130871}, {"language": "CSS", "num_chars": 15879}, {"language": "HTML", "num_chars": 6842}], "readme": "# jquery-flipbook\n"}
{"url": "https://github.com/hsleonis/learnyounode", "owner": "hsleonis", "repository_name": "learnyounode", "date_all_variable_collection": "2023-09-11", "description": "Learn you node official node tutorial solutions", "size": 244, "stargazers_count": 3, "watchers_count": 3, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 8158}, {"language": "HTML", "num_chars": 913}], "readme": "# LEARN YOU NODE\n\n> Learn You The Node.js For Much Win!\n\n> An intro to Node.js via a set of self-guided workshops.\n\n> _Looking for more interactive tutorials like this? Go to [nodeschool.io](http://nodeschool.io)._\n\n<b><code>learnyounode</code></b> will run through a series of Node.js workshops. Starting at a basic *\"HELLO WORLD\"* and moving on to more advanced exercises about dealing with synchronous & asynchronous I/O, filesystem operations, TCP and HTTP networking, events and streams.\n\nOnce you have finished <b><code>learnyounode</code></b>, graduate to <b><code>[stream-adventure](https://github.com/substack/stream-adventure)</code></b> for a set of exercises that dig in to Node's streams.\n\n## Get help\nHaving issues with javascripting? Get help troubleshooting in the [nodeschool discussions repo](http://github.com/nodeschool/discussions), or on gitter:\n\n[![Gitter](https://badges.gitter.im/Join Chat.svg)](https://gitter.im/nodeschool/discussions?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\n## Install Node.js\n\nMake sure Node.js is installed on your computer.\n\nInstall it from [nodejs.org/download](http://nodejs.org/download)\n\n### Install `learnyounode` with `npm`\n\nOpen your terminal and run this command:\n\n```\nnpm install --global learnyounode\n```\n\nThe `--global` option installs this module globally so that you can run it as a command in your terminal.\n\n#### Having issues with installation?\n\nIf you get an `EACCESS` error, the simplest way to fix this is to rerun the command, prefixed with sudo:\n\n```\nsudo npm install --global learnyounode\n```\n\nYou can also fix the permissions so that you don't have to use `sudo`. Take a look at this npm documentation:\nhttps://docs.npmjs.com/getting-started/fixing-npm-permissions\n\n## Run the workshop\n\nOpen your terminal and run the following command:\n\n```\nlearnyounode\n```\n\n## Solutions\n\nIn the Javascript files, you will find solutions to the lessons.\nTo know details about the module: https://github.com/workshopper/learnyounode\n\n## Need help with an exercise?\n\nOpen an issue in the nodeschool/discussions repo: https://github.com/nodeschool/discussions\n\nInclude the name `learnyounode` and the name of the challenge you're working on in the title of the issue.\n\n## License\n\nMIT\n\n"}
{"url": "https://github.com/hsleonis/leoSlider", "owner": "hsleonis", "repository_name": "leoSlider", "date_all_variable_collection": "2023-09-11", "description": "Cool jquery slider plugin with moving lines.", "size": 2645, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 56650}, {"language": "CSS", "num_chars": 5318}, {"language": "HTML", "num_chars": 966}, {"language": "PHP", "num_chars": 249}], "readme": "# leoSlider\n"}
{"url": "https://github.com/hsleonis/machine-learning", "owner": "hsleonis", "repository_name": "machine-learning", "date_all_variable_collection": "2023-09-11", "description": "Some Machine Learning and Data Science Notebooks.", "size": 27641, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 20}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 2453709}], "readme": "# Machine learning and Data Science Notebooks\nSome Beginner Machine Learning and Data Science Notebooks.\n\n### NumPy, Pandas, Matplotlib\n* Data Science Tutorial for Beginners [\u276f](https://github.com/hsleonis/machine-learning/blob/master/Data%20Science%20Tutorial%20for%20Beginners/Data%20Science%20Tutorial%20for%20Beginners.ipynb)\n* Introduction to DataCamp Projects [\u276f](https://github.com/hsleonis/machine-learning/blob/master/Introduction%20to%20DataCamp%20Projects/notebook.ipynb)\n* Exploring 67 years of LEGO [\u276f](https://github.com/hsleonis/machine-learning/blob/master/Exploring%2067%20years%20of%20LEGO/notebook.ipynb)\n* TV, Halftime Shows, and the Big Game [\u276f](https://github.com/hsleonis/machine-learning/blob/master/TV%2C%20Halftime%20Shows%2C%20and%20the%20Big%20Game/notebook.ipynb)\n\n### Machine Learning\n* Titanic Machine Learning from Disaster [\u276f](https://github.com/hsleonis/machine-learning/blob/master/Titanic%20Machine%20Learning%20from%20Disaster/titanic-machine-learning-from-disaster.ipynb)\n* Cancer Cell Analysis with Machine Learning [\u276f](https://github.com/hsleonis/machine-learning/blob/master/Cancer%20Cell%20Analysis%20with%20Machine%20Learning/cancer_analysis.ipynb)\n* Digit Recognizer with CNN [\u276f](https://github.com/hsleonis/machine-learning/blob/master/Digit%20Recognizer%20with%20CNN/Digit%20Recognizer%20with%20CNN.ipynb)\n* Natural Language Processing (NLP) [\u276f](https://github.com/hsleonis/machine-learning/blob/master/Natural%20Language%20Processing%20(NLP)/NLP_Basics.ipynb)\n"}
{"url": "https://github.com/hsleonis/meditation-theme", "owner": "hsleonis", "repository_name": "meditation-theme", "date_all_variable_collection": "2023-09-11", "description": null, "size": 3326, "stargazers_count": 0, "watchers_count": 0, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 1604856}, {"language": "JavaScript", "num_chars": 320314}, {"language": "CSS", "num_chars": 144292}, {"language": "HTML", "num_chars": 52644}, {"language": "Shell", "num_chars": 5884}], "readme": "# meditation-theme\n"}
{"url": "https://github.com/hsleonis/minimac-laravel", "owner": "hsleonis", "repository_name": "minimac-laravel", "date_all_variable_collection": "2023-09-11", "description": "Laravel Minimal Blog", "size": 2099, "stargazers_count": 1, "watchers_count": 1, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 117843}, {"language": "JavaScript", "num_chars": 42021}, {"language": "HTML", "num_chars": 36472}, {"language": "Vue", "num_chars": 561}, {"language": "ApacheConf", "num_chars": 553}], "readme": "# minimac-laravel\n"}
{"url": "https://github.com/hsleonis/ngMaker", "owner": "hsleonis", "repository_name": "ngMaker", "date_all_variable_collection": "2023-09-11", "description": "Angular project directory structure maker", "size": 21978, "stargazers_count": 2, "watchers_count": 2, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 2344}], "readme": "ngMaker\n=========\n\nAuthor: MD. Hasan Shahriar\nVersion: 1.0.1\n\nA small script providing utility methods to create Angular JS project directory structure\n> It will make necessary folders for different files in MVC pattern\n> Create example main files like: index.js, style.css etc\n> Download the LATEST version of angular js for your project\n\n## Directory structure\n```````\n\tProject folder -->\n\t\t\tangular -->\n\t\t\t\t- directives\n\t\t\t\t- controllers\n\t\t\t\t- services\n\t\t\t\t- library\n\t\t\t\t- core\n\t\t\t\t- router\n\t\t\t\tapp.js\n\t\t\tresources -->\n\t\t\t\t- css\n\t\t\t\t- js\n\t\t\t\t- img\n\t\t\t\t- fonts\n\t\t\ttemplates\n\t\t\tindex.html \n````````\n\n## Installation\n  \n  You will require 'node' to use ngmaker.\n\n  npm install ngmaker --save\n\n## Usage\n\n  var ngmaker = require('ngmaker');\n  ngmaker.init();\n\n## License\n   MIT License\n\n## Release History\n\n* 1.0.1 Initial release\n"}
{"url": "https://github.com/hsleonis/seagul-wp-theme", "owner": "hsleonis", "repository_name": "seagul-wp-theme", "date_all_variable_collection": "2023-09-11", "description": "WordPress Theme", "size": 8884, "stargazers_count": 0, "watchers_count": 0, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 784956}, {"language": "JavaScript", "num_chars": 468576}, {"language": "CSS", "num_chars": 64271}, {"language": "Shell", "num_chars": 3357}], "readme": "# seagul-wp-theme\n"}
{"url": "https://github.com/hsleonis/shahriar-plugin-framework", "owner": "hsleonis", "repository_name": "shahriar-plugin-framework", "date_all_variable_collection": "2023-09-11", "description": "WP Plugin Framework", "size": 123, "stargazers_count": 0, "watchers_count": 0, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 15}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 62953}], "readme": "# shahriar-plugin-framework\n"}
{"url": "https://github.com/hsleonis/slack-slash", "owner": "hsleonis", "repository_name": "slack-slash", "date_all_variable_collection": "2023-09-11", "description": null, "size": 1550, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 12}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 257878}, {"language": "JavaScript", "num_chars": 1618}]}
{"url": "https://github.com/hsleonis/spa", "owner": "hsleonis", "repository_name": "spa", "date_all_variable_collection": "2023-09-11", "description": "Single page application - Mini blog with facebook integretion", "size": 700, "stargazers_count": 2, "watchers_count": 2, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 17442}, {"language": "CSS", "num_chars": 8195}, {"language": "JavaScript", "num_chars": 4475}], "readme": "# spa\nSingle page application - Mini blog with facebook integretion\n"}
{"url": "https://github.com/hsleonis/titan-file-upload", "owner": "hsleonis", "repository_name": "titan-file-upload", "date_all_variable_collection": "2023-09-11", "description": "This plugin is an extension of Titan Framework. It adds any file upload functionality on Titan Framework which is currently unavailable.", "size": 49, "stargazers_count": 2, "watchers_count": 2, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 1, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 1, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 141600}, {"language": "CSS", "num_chars": 1904}], "readme": "# Titan File Uploader\nCreate any file upload functionality with this extension on Titan Framework which is currently unavailable.\n\nEasy to use:\n````php\n$mySection->createOption( array(\n\t\t'name' => 'PDF',\n\t\t'id' => 'sec_pdf_upload',\n\t\t'type' => 'file',\n\t\t'desc' => 'Upload your pdf'\n\t) );\n````\n[Titan Framework Documentation](http://www.titanframework.net/docs)\n\n* Requires at least: WordPress 4.1\n* Tested up to: WordPress 4.6\n* Stable tag: 1.10\n* License: GPLv2 or later\n* License URI: http://www.gnu.org/licenses/gpl-2.0.html\n* Tags: file, upload, framework, options, admin, admin panel, meta box, theme customizer, option framework, library, sdk, edd, settings, api, theme creator, theme framework\n\n# Description\n\nTitan Framework allows theme and plugin developers to create admin pages, options, meta boxes, and theme customizer options with just a few simple lines of code. This plugin is an essential tool to make any upload possible on Titan Framework.\n\nThis means faster theme & plugin creation for everyone.\n\n[How it works?](https://github.com/hsleonis/titan-file-upload)\n\n# Features\n\n* Easy Digital Download\n* Unlimited File upload option (Image, Music, Video, PDF, DOCX, XLS, CSV etc.)\n* Makes development unbelievably easy\n* Built with optimization in mind\n* Does NOT clutter the database\n* Integrates with your project seamlessly\n* Theme customizer live preview integration\n* Supports child themes\n* Automatic CSS generation with SCSS support\n* Full font style fields\n\n# Easy creation of:\n\n* Admin menus and submenus\n* Admin pages\n* Admin options and tabs\n* Meta boxes and options\n* Theme customizer sections and options\n\n**File upload option available in admin pages, meta boxes and theme customizer.**\n\n# Donate to the Development\n\nIf this helped you in any way, we would appreciate any amount of donations that you give us. Donations would mean more development time for the framework as I am continuously developing it during my free time.\n\n[![Contact me](https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif)](mailto:hsleonis2@gmail.com)\n\n# Special Thanks to all the Contributors\n\nThanks to everyone involved in development of Titan Framework and this extension.\n\n# Installation\n\n1. Upload `plugin-name.php` to the `/wp-content/plugins/` directory\n2. Activate the plugin through the 'Plugins' menu in WordPress\n3. Use the provided classes and functions in your theme or plugin. This extension requires Titan Framework available either in your theme or plugin.\n\n# Frequently Asked Questions\n\n* [Titan File Uploader GitHub Repository](https://github.com/hsleonis/titan-file-upload)\n* [Issue Tracker](https://github.com/hsleonis/titan-file-upload/issues)\n\n# Screenshots\n\nWill be added soon.\n\n# Changelog\n\n= 1.0 =\n\nFirst release\n"}
{"url": "https://github.com/hsleonis/tmx-any-post-plugin", "owner": "hsleonis", "repository_name": "tmx-any-post-plugin", "date_all_variable_collection": "2023-09-11", "description": "This plugin will help you to use any custom post or pages as widget.", "size": 392, "stargazers_count": 1, "watchers_count": 1, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 8}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 20617}, {"language": "CSS", "num_chars": 1727}], "readme": "# tmx-any-post-plugin\n# tmx-any-post-plugin\n"}
{"url": "https://github.com/hsleonis/user-forum", "owner": "hsleonis", "repository_name": "user-forum", "date_all_variable_collection": "2023-09-11", "description": "Forum with PHP EL framework for creating REST APIS", "size": 13, "stargazers_count": 1, "watchers_count": 1, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 14752}, {"language": "ApacheConf", "num_chars": 212}], "readme": "User Forum with EL Framework (PHP)\n==================================\n###### Author: MD. HASAN SHAHRIAR ######\n\n#### Forum with PHP EL framework for creating REST APIS ####\n\nThe aim of the project is to create a lightweight APIs with a very low level of complexity \u2014 in other words, for dummies. The EL framework provides simple file inclusion and routing, different paths for APIS.\n\n\n#### Core functions from EL framework ####\n\nPrint data without error and null checked\n@param value\n\n````\nollo(value)\n````\n\nGet table data as JSON\n@param table name,condition,parameters (comma separated)\n\n````\ntable_data(table, conditions, parameters)\n````\n\nGet table data as associative array\n@param table,condition,limit\n@return object if true, false otherwise\n\n````\nsql_data($tbl, condition, limit)\n````\n\nUpdate data into table\n@param table,data array,condition\n@return MySQL object\n\n````\nupdate_data(table, args, condition)\n````\n\nInsert data into table\n@param table,data associative array\n\n````\ninsert_data(table, args)\n````\n\nCheck if any data is parsed from table\n@param MySQL object\n@return boolean\n\n````\nmysql_valid(result)\n````\n\nDelete data\n@param table,condition\n@return boolean\n\n````\ndelete_data(table, condition)\n````\n\n#### Methods ####\n\nList posts\n@return JSON object \n\n````\npost_list()\n````\n\t\nSingle post view\n@param post id (int)\n@return JSON object\n\n````\nsingle_post(postId)\n````\n\nSingle post comments\n@param post id (int)\n@return JSON object\n\n````\npost_comment(postId)\n````\n\t \nSingle post sub-comments\n@param post id (int)\n@return JSON object \n\n````\nsub_comments(postId, post_parent)\n````\n\n#### License ####\nMIT\nDo whatever awesomeness you want!\n"}
{"url": "https://github.com/hsleonis/viewerjs", "owner": "hsleonis", "repository_name": "viewerjs", "date_all_variable_collection": "2023-09-11", "description": "Viewer JS and PDF demo", "size": 4417, "stargazers_count": 1, "watchers_count": 1, "language": "JavaScript", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "JavaScript", "num_chars": 1250641}, {"language": "Java", "num_chars": 305368}, {"language": "HTML", "num_chars": 41396}, {"language": "PHP", "num_chars": 7205}, {"language": "CSS", "num_chars": 1112}], "readme": "# viewerjs\n"}
{"url": "https://github.com/hsleonis/vola-wp-theme", "owner": "hsleonis", "repository_name": "vola-wp-theme", "date_all_variable_collection": "2023-09-11", "description": "Fully object oriented wp theme", "size": 5507, "stargazers_count": 0, "watchers_count": 0, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 552727}, {"language": "CSS", "num_chars": 294124}, {"language": "JavaScript", "num_chars": 143089}, {"language": "HTML", "num_chars": 7813}, {"language": "Shell", "num_chars": 3357}], "readme": "# vola-wp-theme\n"}
{"url": "https://github.com/hsleonis/woocommerce-massive-customization-theme", "owner": "hsleonis", "repository_name": "woocommerce-massive-customization-theme", "date_all_variable_collection": "2023-09-11", "description": "Woocommerce practice theme", "size": 1348, "stargazers_count": 0, "watchers_count": 0, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 3}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 887001}, {"language": "CSS", "num_chars": 147102}, {"language": "JavaScript", "num_chars": 71750}, {"language": "Shell", "num_chars": 3357}], "readme": "# Woocommerce practice theme\n\n\nInteresting:\n* Custom product loop in table.\n* Product image and on sale.\n* Add to cart and view cart.\n* Product price.\n* Product short description.\n* Mini cart on header.\n* Add product on header cart with AJAX.\n* Remove product from all (header, sidebar) mini carts with AJAX.\n* Update all (header, siderbar) mini cart total price with AJAX."}
{"url": "https://github.com/hsleonis/wp-lock-screen", "owner": "hsleonis", "repository_name": "wp-lock-screen", "date_all_variable_collection": "2023-09-11", "description": null, "size": 980, "stargazers_count": 1, "watchers_count": 1, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 432558}, {"language": "CSS", "num_chars": 19409}, {"language": "JavaScript", "num_chars": 8865}, {"language": "Shell", "num_chars": 2359}], "readme": "# wp-lock-screen\nWp-lock-screen is a simple wordpress plugin to add lock screen.\n"}
{"url": "https://github.com/hsleonis/wp-revision-master", "owner": "hsleonis", "repository_name": "wp-revision-master", "date_all_variable_collection": "2023-09-11", "description": "Powerful and best post revision control, compare, restore!", "size": 218, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "=== WP Revision Master ===\nContributors: @leonis\nTags: revision, revise, version, compare, control, post, manage, woocommerce, product\nDonate link: mailto:themeaxe@gmail.com\nRequires at least: 3.6\nTested up to: 4.7.2\nStable tag: trunk\nLicense: GPLv2 or later\nLicense URI: http://www.gnu.org/licenses/license-list.html#GPLCompatibleLicenses\n\nPowerful and best post revision control, compare, restore!\n\n== Description ==\n**WP Revision Master** is a powerful plugin to control over the default Revision functionality in WordPress.\n\nThe plugin allows the user to set a site-global setting **(Settings -> Revision Settings)** for pages,posts or any public custom posts to enable/disable/limit the number of revisions which are saved for the page,post or custom post type. The user may change this setting on a per-page/post basis from the Revisions Meta box with cool AJAX messages.\n\nThis plugin can add \\'Revision\\' support to any custom post type and show limited/unlimited revisions. It has builtin **woocommerce** support. So keep track of your product description changes.\n\nThe plugin also allows the user to delete specific or all revisions from the Revisions Meta box.\n\n**And the best thing is, this plugin is actively supported! If you need support, mail at [info@themeaxe.com](mailto:info@themeaxe.com)**\n\n== Installation ==\n1. Upload wp-revision-master to /wp-content/plugins/.\n2. Activate plugin through the WordPress Plugins menu.\n3. Go to Settings > Revision Settings and set the options.\n\n== Frequently Asked Questions ==\n= 1. What are the basic features? =\nA: Enable/disable site-wide revision control, with enable revision per-post type and individual post, page or product!\n\n= 2. Does it support Woocommerce or Jigoshop? =\nA: Yes, it can add revisions to any public post types, even if the post type doesn\\'t support revisions when registered.\n\n= 3. Can I set unlimited revisions? =\nA: Yes, of course.\n\n= 4. Is the plugin translatable? =\nA: Yes, sure.\n\n= 5. How can I change settings? =\nA: Navigate to **Settings > Revision Settings** in your WordPress Dashboard.\n\n= 6. Can I control revision of a specific post? =\nA: Yes, look for the metabox called 'Revisions' below the post editor.\n\n= 7. How to override global settings from a single post or page? =\nA: Use the following values in metabox:\nGet unlimited revisions : -1\nUse global setting : 0\nMinimum number of revision : 1 \n\n== Screenshots ==\n1. WP Revision Master global settings\n2. Revisions Metabox\n3. Update metabox with AJAX\n4. No revisions yet!\n\n== Changelog ==\n= 1.0.1 =\n* Initial public release\n\n== Upgrade Notice ==\n= 1.0.1 =\n* Initial public release\n"}
{"url": "https://github.com/hsleonis/WP-waterboat", "owner": "hsleonis", "repository_name": "WP-waterboat", "date_all_variable_collection": "2023-09-11", "description": "WodrPress theme with LEO's WP framework", "size": 3038, "stargazers_count": 0, "watchers_count": 0, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 594994}, {"language": "JavaScript", "num_chars": 49205}, {"language": "CSS", "num_chars": 45151}, {"language": "Shell", "num_chars": 3357}], "readme": "# WP-waterboat\n"}
{"url": "https://github.com/hsleonis/xportfolio-wp-plugin", "owner": "hsleonis", "repository_name": "xportfolio-wp-plugin", "date_all_variable_collection": "2023-09-11", "description": "xPortFolio is a simple wordpress plugin for easily adding various portfolio on your wordpress site.", "size": 444, "stargazers_count": 2, "watchers_count": 2, "language": "PHP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "hsleonis", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "PHP", "num_chars": 66975}, {"language": "JavaScript", "num_chars": 36144}, {"language": "CSS", "num_chars": 29275}], "readme": "# wp-lock-screen\nWp-lock-screen is a simple wordpress plugin to add lock screen.\n"}
{"url": "https://github.com/Hugo-Robalino/IM_Graph_Neural_Network", "owner": "Hugo-Robalino", "repository_name": "IM_Graph_Neural_Network", "date_all_variable_collection": "2023-09-11", "description": "Center Loss implementation in a Graph Neural Network", "size": 295, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "Hugo-Robalino", "contributions": 6}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 21765}], "readme": "# Implementation of the Center Loss in a Graph Neural Network for Fake News Detection\n\nTools used:\n- GNN model from UPFD framework: https://github.com/safe-graph/GNN-FakeNews\n- Center Loss: https://github.com/KaiyangZhou/pytorch-center-loss\n- PyTorch Geometric: https://pytorch-geometric.readthedocs.io/en/latest/\n\nThis projects investigates if an improvement in performance in the GNN model can be achieved by implementing the center loss, which provides the model with not only separability but also discriminative power.\n\nIt was found that, although the center loss does give the model discriminative power, there is no improvement in performance.\n\n## Setting up data and virtual environment\nThe dataset is integrated in [PyTorch-geometric](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.UPFD). Instructions for how to acces it can be found in the original UPFD framework [GitHub page](https://github.com/safe-graph/GNN-FakeNews).\n\nThe [utils](https://github.com/safe-graph/GNN-FakeNews/tree/main/utils) directoy as well as the [center_loss](https://github.com/KaiyangZhou/pytorch-center-loss/blob/master/center_loss.py) file were uploaded again to ensure that the main.py file works properly.\n\nAll the environment requirements can be found in the .yml file.\n"}
{"url": "https://github.com/Hugo-Robalino/PM_Asprilo", "owner": "Hugo-Robalino", "repository_name": "PM_Asprilo", "date_all_variable_collection": "2023-09-11", "description": "Warehouse automation with mobile robots, focus: step parallelization", "size": 24, "stargazers_count": 0, "watchers_count": 0, "language": "Classic ASP", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "main", "contributors": [{"contributor": "Hugo-Robalino", "contributions": 19}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Classic ASP", "num_chars": 9192}, {"language": "Python", "num_chars": 1242}, {"language": "Shell", "num_chars": 921}], "readme": "# PM_Asprilo\nThis is an ongoing project about intra-logistics and warehouse automation. All information can be found in their GitHub pages [asprilo](https://github.com/potassco/asprilo) and [asprilo-encodings](https://github.com/potassco/asprilo-encodings) as well as in the official [website](https://potassco.org/asprilo/).\n\nThe main goal of this project is to achieve parallelization of actions taken by robots in a warehouse. In other words, robots can make now two actions per time-step instead of one.\n\nParallelization of actions is based on this [paper](https://www.sciencedirect.com/science/article/pii/S0004370206000774).\n"}
{"url": "https://github.com/Hugo-Robalino/PM_Coreference", "owner": "Hugo-Robalino", "repository_name": "PM_Coreference", "date_all_variable_collection": "2023-09-11", "description": "Performance evaluation of neuralcoref using the GUM Corpus", "size": 380, "stargazers_count": 0, "watchers_count": 0, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Hugo-Robalino", "contributions": 7}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 20118}], "readme": "# Performance of neuralcoref / data exploration\n\nTools used:\n- GUM Corpus: https://github.com/amir-zeldes/gum\n- neuralcoref: https://github.com/huggingface/neuralcoref\n- Reference Coreference Scorer: https://github.com/conll/reference-coreference-scorers\n- Spacy: https://spacy.io/models/en\n\nThis projects investigates how well neuralcoref (a coreference system using neural networks) fed by spacy language models for English (en_core_web_sm and en_core_web_lg) performs on the GUM corpus among different POS categories(Speech pronouns, third person pronouns, demonstratives, definite expressions, proper names and others).The performance is assessed via Reference Coreference Scorer. This project was inspired by Pascal Denis & Jason Baldridge [paper](https://www.aclweb.org/anthology/D08-1069.pdf).\n\nIt was found that neuralcoref fed with en_core_web_sm had the best performance on third person pronouns having a F1 score of 96.09 for the bio section of the GUM corpus (compare this to the F1 score of 2.63 of speech pronouns for the whow section of the GUM corpus)\n"}
{"url": "https://github.com/Hugo-Robalino/PM_Text_Mining", "owner": "Hugo-Robalino", "repository_name": "PM_Text_Mining", "date_all_variable_collection": "2023-09-11", "description": "Text classification of self reports from teaching students", "size": 1524, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "Hugo-Robalino", "contributions": 4}, {"contributor": "lisabecker", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 385227}, {"language": "Python", "num_chars": 17247}], "readme": "# Classification of pre-service science teacher's self reflections\nText mining project for the classification of \"self reports\" from teaching students. \nProject Module for the Cognitive Systems Master's program of the University of Potsdam (12 ECTS).\nThis project was in cooperation with the Physics Education Research, Institute of Astronomy and Physics of the University of\nPotsdam. Supervised by Professor Manfred Stede at the University of Potsdam.\n\nThe data is collected from pre-service science teachers and is under non-disclosure.\n\nThis project investigated whether natural language processing can be used to automate the process of analyzing self-reflection \nreports and giving automated feedback to the pre-service teachers on their enactment. Several Machine Learning algorithms were\nexploited, amongst others Naive Bayes, Linear Support Vector Machines, Logistic Regression and Random Forest Classifiers.\nDifferent features were compared to find the optimal combination for classification. The Random Forest Classifier with the \npositioning of of sentences in a given document proved to be the best approach with a classification accuracy of 76,6%\n(compared to 72% of inner-annotator accuracy).\n"}
{"url": "https://github.com/hydrogo/2018_VinoRead_wrkshp", "owner": "hydrogo", "repository_name": "2018_VinoRead_wrkshp", "date_all_variable_collection": "2023-09-11", "description": "Runoff modeling: as simple as possible, but not simpler. Hydrological modeling workshop.", "size": 1515, "stargazers_count": 4, "watchers_count": 4, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 4, "default_branch": "master", "contributors": [{"contributor": "hydrogo", "contributions": 10}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["google-colab", "gr4j", "hydrology", "modeling", "runoff"], "languages": [{"language": "Jupyter Notebook", "num_chars": 473635}, {"language": "Python", "num_chars": 10348}], "readme": "# Runoff modeling: as simple as possible, but not simpler. Hydrological modeling workshop.\n\n## Lecture and programming workshop\n\nEvent: [3rd Vinogradov's conference \"Facets of Hydrology\"](http://vinogradovconference.ru). Hydrological Modeling School.\n\nDates: 24-27 March, 2018. \n\nAuthor: Georgy Ayzel, PhD-student, the University of Potsdam, ayzel@uni-potsdam.de.\n\nThe main idea of the presented lecture and programming workshop titled \"*Runoff modeling: as simple as possible, but not simpler*\" is to establish a baseline solution for runoff predictions for any basin around the globe using only an open data and models.\n\n[The lecture is available via Google Slides](https://docs.google.com/presentation/d/e/2PACX-1vTG-w2cF_QUZfVxVQMSDtofnP8oob48IpYcEDqgQyMZI9AWl45rMJcKIkjDBWj7mM_Y2wzjayOpi7Fe/pub?start=false&loop=false&delayms=3000).\n\n[The programming workshop is available via Google Colab\u00b9\u00b2](https://drive.google.com/file/d/1ypyQMzKf-_7ucAMsrQiL2ijL7vgoD3R2/view?usp=sharing).\n\nTo be in touch please:\n\n* [Follow me in twitter](https://twitter.com/hydrogo89)\n* [Subscribe to my Telegram channel](https://t.me/showmethebest)\n* [Use my code](https://github.com/hydrogo/)\n* [Cite my papers](https://scholar.google.de/citations?user=wXSZ4ogAAAAJ&hl=en)\n\n\u00b9 you can find an overview of the Google Colab project, useful examples, and using scenarious [here](https://colab.research.google.com/notebooks/welcome.ipynb).\n\n\u00b2 for a quick start with the Google Colab without reading any documentation, please watch [an introductory video](https://youtu.be/xdbkayi0PA4).\n"}
{"url": "https://github.com/hydrogo/4Y11M2D", "owner": "hydrogo", "repository_name": "4Y11M2D", "date_all_variable_collection": "2023-09-11", "description": null, "size": 21244, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hydrogo", "contributions": 9}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 842464}, {"language": "Python", "num_chars": 11215}], "readme": "# Macondo in a trouble \n\n![4Y11M2D logo](https://raw.githubusercontent.com/hydrogo/4Y11M2D/master/docs/4Y11M2D_logo.png)\n\nHere is the repository that holds an app [Macondo in a trouble (aka 4Y11M2D)](https://hydrogo.github.io/4Y11M2D/).\n\nThis project has been done for the \"Hack-Data\" challenge on the [#OpenDataHack2018](https://events.ecmwf.int/event/79/) organized by [ECMWF](https://www.ecmwf.int/).\n\nThe main idea of the presented project is to estimate a runoff response to an extreme rainfall scenario mentioned in  Gabriel Garcia Marquez novel [One Hundred Years of Solitude](https://en.wikipedia.org/wiki/One_Hundred_Years_of_Solitude): \"The rains last for four years, eleven months, and two days.\"\n\nProject presentation and a short description are also available [here](https://docs.google.com/presentation/d/e/2PACX-1vT3ad_RYrzlsRuMgwlX3Bd1kBU2DtOR-HSPrS-oyW-odTRzxdyU3Ml5MdGAlX7EfxDJN_aw4XzvuHlJ/pub?start=false&loop=false&delayms=3000).\n\nFeel free to contact us for any details using [GitHub Issues](https://github.com/hydrogo/4Y11M2D/issues).\n\n___\n\nThe Georgy Ayzel's trip to the [#OpenDataHack2018](https://events.ecmwf.int/event/79/) project was funded by [Geo.X](https://www.geo-x.net/en/)."}
{"url": "https://github.com/hydrogo/beats-of-the-era", "owner": "hydrogo", "repository_name": "beats-of-the-era", "date_all_variable_collection": "2023-09-11", "description": null, "size": 637, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hydrogo", "contributions": 13}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Beats of the ERA\n\n![Beats of the ERA logo](https://raw.githubusercontent.com/hydrogo/beats-of-the-era/master/docs/era_beats_logo.png)\n\nHere is the repository that holds an app [\"Beats of the ERA\"](https://hydrogo.github.io/beats-of-the-era/).\n\nThis project has been done for the \"Hack-Out\" challenge on the [#OpenDataHack2018](https://events.ecmwf.int/event/79/) organized by [ECMWF](https://www.ecmwf.int/).\n\nThe main idea of the presented project is to enrich an [AI-inspired music generation](https://magenta.tensorflow.org/) with the latest [ERA5](https://www.ecmwf.int/en/forecasts/datasets/archive-datasets/reanalysis-datasets/era5) climate reanalysis data.\n\nYou can find the [Google Collab](https://colab.research.google.com) notebook for beats generation for your own location [here](https://drive.google.com/file/d/1tdjEx9Fwm_yYx_2sQ5vf5i-IYMkiwMFT/view?usp=sharing).\n\nProject presentation and a short description are also available [here](https://docs.google.com/presentation/d/e/2PACX-1vRwnDfz2AkmdUD-ggfg-_a30jGPAE4FrpyisKPAW6fUOWkVevG2sLDU9A-u0UrgbaAGu2zti2hD1X0u/pub?start=false&loop=false&delayms=3000).\n\nWe have also created the [SoundCloud playlist](https://soundcloud.com/georgy-ayzel/sets/beats-of-the-era) with the presented beats.\n\nFeel free to contact us for any details using [GitHub Issues](https://github.com/hydrogo/beats-of-the-era/issues).\n\n___\n\nThe Georgy Ayzel's trip to the [#OpenDataHack2018](https://events.ecmwf.int/event/79/) project was funded by [Geo.X](https://www.geo-x.net/en/)."}
{"url": "https://github.com/hydrogo/blog", "owner": "hydrogo", "repository_name": "blog", "date_all_variable_collection": "2023-09-11", "description": null, "size": 2479, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 5, "license": "Apache License 2.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 5, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hydrogo", "contributions": 4}, {"contributor": "dependabot[bot]", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 16506}, {"language": "JavaScript", "num_chars": 10532}, {"language": "CSS", "num_chars": 8922}, {"language": "Ruby", "num_chars": 5114}, {"language": "Shell", "num_chars": 3965}, {"language": "Python", "num_chars": 2766}, {"language": "Smarty", "num_chars": 1750}, {"language": "Makefile", "num_chars": 1374}, {"language": "Dockerfile", "num_chars": 747}], "readme": "[//]: # (This template replaces README.md when someone creates a new repo with the fastpages template.)\n\n![](https://github.com/hydrogo/blog/workflows/CI/badge.svg) \n![](https://github.com/hydrogo/blog/workflows/GH-Pages%20Status/badge.svg) \n[![](https://img.shields.io/static/v1?label=fastai&message=fastpages&color=57aeac&labelColor=black&style=flat&logo=data:image/png;base64,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)](https://github.com/fastai/fastpages)\n\nhttps://hydrogo.github.io/blog/\n\n# My Blog\n\n\n_powered by [fastpages](https://github.com/fastai/fastpages)_\n\n\n## What To Do Next?\n\nGreat!  You have setup your repo.  Now its time to start writing content.  Some helpful links:\n\n- [Writing Blogs With Jupyter](https://github.com/fastai/fastpages#writing-blog-posts-with-jupyter)\n\n- [Writing Blogs With Markdown](https://github.com/fastai/fastpages#writing-blog-posts-with-markdown)\n\n- [Writing Blog Posts With Word](https://github.com/fastai/fastpages#writing-blog-posts-with-microsoft-word)\n\n- [(Optional) Preview Your Blog Locally](_fastpages_docs/DEVELOPMENT.md)\n\nNote: you may want to remove example blog posts from the `_posts`,  `_notebooks` or `_word` folders (but leave them empty, don't delete these folders) if you don't want these blog posts to appear on your site.\n\nPlease use the [nbdev & blogging channel](https://forums.fast.ai/c/fastai-users/nbdev/48) in the fastai forums for any questions or feature requests.\n"}
{"url": "https://github.com/hydrogo/DA_and_ML_in_hydrology", "owner": "hydrogo", "repository_name": "DA_and_ML_in_hydrology", "date_all_variable_collection": "2023-09-11", "description": "\"Data analysis and Machine learning in hydrology\" course materials", "size": 21364, "stargazers_count": 11, "watchers_count": 11, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 7, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 7, "open_issues": 0, "watchers": 11, "default_branch": "master", "contributors": [{"contributor": "hydrogo", "contributions": 30}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["hydrology", "machine-learning", "modeling", "tutorial"], "languages": [{"language": "Jupyter Notebook", "num_chars": 4467673}, {"language": "HTML", "num_chars": 3768589}], "readme": "# \u0410\u043d\u0430\u043b\u0438\u0437 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0432 \u0433\u0438\u0434\u0440\u043e\u043b\u043e\u0433\u0438\u0438\n\n\u041d\u0430 \u044d\u0442\u043e\u0439 \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u0435 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u044b \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u044b \u043a\u0443\u0440\u0441\u0430 \"\u0410\u043d\u0430\u043b\u0438\u0437 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0432 \u0433\u0438\u0434\u0440\u043e\u043b\u043e\u0433\u0438\u0438\", \u0447\u0438\u0442\u0430\u0435\u043c\u043e\u0433\u043e \u0434\u043b\u044f \u0430\u0441\u043f\u0438\u0440\u0430\u043d\u0442\u043e\u0432 \u0442\u0440\u0435\u0442\u044c\u0435\u0433\u043e \u0433\u043e\u0434\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0432 [\u0418\u043d\u0441\u0442\u0438\u0442\u0443\u0442\u0435 \u0432\u043e\u0434\u043d\u044b\u0445 \u043f\u0440\u043e\u0431\u043b\u0435\u043c \u0420\u0410\u041d](iwp.ru) \u043d\u0430\u0443\u0447\u043d\u044b\u043c \u0441\u043e\u0442\u0440\u0443\u0434\u043d\u0438\u043a\u043e\u043c \u041b\u0430\u0431\u043e\u0440\u0430\u0442\u043e\u0440\u0438\u0438 \u0444\u0438\u0437\u0438\u043a\u0438 \u043f\u043e\u0447\u0432\u0435\u043d\u043d\u044b\u0445 \u0432\u043e\u0434 [\u0413\u0435\u043e\u0440\u0433\u0438\u0435\u043c \u0410\u0439\u0437\u0435\u043b\u0435\u043c](ayzelgv.wordpress.com).\n\n\n\n![](course_logo.jpg?raw=true)\n\n"}
{"url": "https://github.com/hydrogo/FIT_ML", "owner": "hydrogo", "repository_name": "FIT_ML", "date_all_variable_collection": "2023-09-11", "description": "Machine learning models determine factors affecting transit line dynamics", "size": 597, "stargazers_count": 0, "watchers_count": 0, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hydrogo", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 3495935}, {"language": "Python", "num_chars": 61409}], "readme": "# FIT_ML\nMachine learning models determine factors affecting transit line dynamics\n"}
{"url": "https://github.com/hydrogo/HMM", "owner": "hydrogo", "repository_name": "HMM", "date_all_variable_collection": "2023-09-11", "description": "hydrological modeling metrics of fit ", "size": 144, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 3, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 3, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hydrogo", "contributions": 4}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 116998}, {"language": "Python", "num_chars": 9646}], "readme": "# HMM\nhydrological modeling metrics of fit \n"}
{"url": "https://github.com/hydrogo/KALI", "owner": "hydrogo", "repository_name": "KALI", "date_all_variable_collection": "2023-09-11", "description": "KALI", "size": 13638, "stargazers_count": 3, "watchers_count": 3, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "hydrogo", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": true, "howfairis_checklist": false}, "topics": ["artificial-neural-networks", "calibration", "deep-learning", "gru-network", "hydrologic-model", "hydrologic-modeling", "hydrology", "lstm-network", "mlp-network", "rnn-network", "validation"], "languages": [{"language": "Jupyter Notebook", "num_chars": 387425}, {"language": "Python", "num_chars": 24711}], "readme": "# KALI\n\n## Investigating the effect of the calibration data length on the performance of hydrological models\n\nIn the present repository, you can find the materials for the paper \n\n> **Ayzel G., Heistermann M. The effect of calibration data length on the performance of conceptual versus data-driven hydrological models.** \n\nwhich was submitted to [*Computers & Geosciences*](https://www.sciencedirect.com/journal/computers-and-geosciences).\n\n\n### Idea and workflow\n\nIn this study, we want to investigate the effect of calibration data length on the validation performance of different rainfall-runoff models. To this aim, we consequently increase the calibration data length from one to twenty calendar years and investigate how that affects the model skill on a hold-out (validation) period. \n\n-----\n\n![](workflow.png)\n\n-----\n\nWe use five models for runoff prediction at hourly temporal resolution:\n\n> one **conceptual**\n\n1. GR4H -- a conceptual hydrological model. It is a derivative from [the GR4J model](https://webgr.inrae.fr/en/models/daily-hydrological-model-gr4j/) -- the version for runoff prediction at daily temporal resolution.\n\n> and four **data-driven** models which differ by the type of the computational layer used\n\n1. Multi-Layer Perceptron (MLP)\n2. Recurrent Neural Network (RNN) \n3. Long Short-Term Memory Network (LSTM)\n4. Gated Recurrent Units Network (GRU)\n\n### Code\n\nThe code is written in [*Python*](https://docs.python.org/) programming language (v3.6) using open-source software libraries, such as [*numpy*](https://numpy.org/), [*pandas*](https://pandas.pydata.org/), [*scipy*](https://www.scipy.org/), [*numba*](http://numba.pydata.org/), [*tensorflow*](https://www.tensorflow.org/), and [*keras*](https://keras.io/). The analysis of obtained results was done also using [*jupyter notebooks*](https://jupyter.org/) and [*matplotlib*](https://matplotlib.org/) plotting library.\n\nYou can install all the required dependencies using [*conda*](https://docs.conda.io/projects/conda/en/latest/index.html) -- an open-source package management system. First, [install conda itself](https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html), then use the provided `environment.yml` file to create the isolated environment:\n\n```bash\nconda env create -f environment.yml\n```\n\nThere are three files in the `code` directory:\n1. [`experiment.py`](https://github.com/hydrogo/KALI/blob/master/code/experiment.py)\n\n\\- describes the workflow for the main calibration/validation experiment. \n\n2. [`metrics.py`](https://github.com/hydrogo/KALI/blob/master/code/metrics.py)\n\n\\- calculates and aggregates the evaluation metrics based on obtained results of streamflow simulation [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3696832.svg)](https://doi.org/10.5281/zenodo.3696832).\n\n3. [`analysis.ipynb`](https://github.com/hydrogo/KALI/blob/master/code/analysis.ipynb)\n\n\\- represents the analysis of the effect of calibration data length on the performance of hydrological models.\n\n\n### Models\n\nThere are two files in the `models` directory:\n1. `gr4h.py`\n\n\\- holds the code for the GR4H hydrological model. \n\n2. `anns.py`\n\n\\- holds the code for generating data-driven hydrological models based on different architectures of artificial neural networks: MLP, RNN, LSTM, and GRU.\n\nThese files are used as modules in [`experiment.py`](https://github.com/hydrogo/KALI/blob/master/code/experiment.py).\n\n\n### Results\n\nTwo files aggregate evaluation metrics for the calibration and validation periods: `summary_calibration.npy` and `summary_validation.npy`, respectively. The `figures` subfolder consists of figures that were generated using the [`analysis.ipynb`](https://github.com/hydrogo/KALI/blob/master/code/analysis.ipynb) jupyter notebook.\n\n\n### Note on data availability\n\n> Unfortunately, we cannot directly provide the compiled dataset we use for the presented study due to license restrictions from data suppliers.\n> Thus, the discharge data for Rimbaud River as well as rain gauge records for the area Real Collobrier should request it from the RECOVER research laboratory at INRAE (https://www6.paca.inrae.fr/recover). The data for the SAFRAN reanalysis is also available upon request from Meteo France.\n> \n> Please, [contact us](https://github.com/hydrogo/KALI/issues) in case you need additional details or support for retrieving the data."}
{"url": "https://github.com/hydrogo/KALIv2", "owner": "hydrogo", "repository_name": "KALIv2", "date_all_variable_collection": "2023-09-11", "description": "KALIv2", "size": 89332, "stargazers_count": 3, "watchers_count": 3, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 3, "default_branch": "master", "contributors": [{"contributor": "hydrogo", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": true, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 860830}, {"language": "Python", "num_chars": 34442}, {"language": "Shell", "num_chars": 594}], "readme": "# KALIv2\n\n## Investigating the effect of the calibration data length on the performance of hydrological models\n\nIn the present repository, you can find the materials for the paper \n\n> **Ayzel G., Heistermann M. The effect of calibration data length on the performance of conceptual versus data-driven hydrological models.** \n\nwhich was revised and re-submitted to [*Computers & Geosciences*](https://www.sciencedirect.com/journal/computers-and-geosciences). The initially submitted version of the paper and the corresponding repository are located [here](https://github.com/hydrogo/KALI).\n\n\n### Idea and workflow\n\nIn this study, we want to investigate the effect of calibration data length on the validation performance of different rainfall-runoff models. To this aim, we consequently increase the calibration data length from one to twenty calendar years and investigate how that affects the model skill on a hold-out (validation) period. \n\n-----\n\n![](figures/workflow.png)\n\n-----\n\nWe use three models for runoff prediction at hourly temporal resolution:\n\n> one **conceptual**\n\n1. GR4H -- a conceptual hydrological model. It is a derivative from [the GR4J model](https://webgr.inrae.fr/en/models/daily-hydrological-model-gr4j/) -- the version for runoff prediction at daily temporal resolution.\n\n> and two **data-driven** models which differ by the type of the computational layer used\n\n1. Long Short-Term Memory Network (LSTM)\n2. Gated Recurrent Units Network (GRU)\n\n### Code\n\nThe code is written in [*Python*](https://docs.python.org/) programming language (v3.6) using open-source software libraries, such as [*numpy*](https://numpy.org/), [*pandas*](https://pandas.pydata.org/), [*scipy*](https://www.scipy.org/), [*numba*](http://numba.pydata.org/), [*tensorflow*](https://www.tensorflow.org/), and [*keras*](https://keras.io/). The analysis of obtained results was done also using [*jupyter notebooks*](https://jupyter.org/) and [*matplotlib*](https://matplotlib.org/) plotting library.\n\nYou can install all the required dependencies using [*conda*](https://docs.conda.io/projects/conda/en/latest/index.html) -- an open-source package management system. First, [install conda itself](https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html), then use the provided `environment.yml` file to create the isolated environment:\n\n```bash\nconda env create -f environment.yml\n```\n\nThe `code` directory consists the following files:\n1. `gr4h.py`\n\n\\- holds the code for the GR4H hydrological model. \n\n2. `gr4h_script.py`\n\n\\- describes the workflow for the main calibration/validation experiment for the GR4H model.\n\n3. `ann_script.py`\n\n\\- describes the workflow for the main calibration/validation experiment for LSTM and GRU models.\n\n4. `run_$model_name$_experiment.sh`\n\n\\- bash scripts that run the main calibration/validation experiment for the selected river basins.\n\n\nThere are three files (Jupyter notebooks) in the `analysis` directory:\n1. `00_results_summary_calculation.ipynb`\n\n\\- calculates and aggregates the evaluation metrics based on obtained results of streamflow simulation [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.4013737.svg)](https://doi.org/10.5281/zenodo.4013737).\n\n2. `01_results_visualization.ipynb`\n\n\\- represents the visual analysis of the effect of calibration data length on the performance of hydrological models.\n\n3. `02_hydrograph_plotting.ipynb`\n\n\\- consists the code for plotting hydrographs (observed and simulated runoff time series).\n\n\n### Results\n\nThe full results of the conducted experiment can be found in the respective [data repository](https://doi.org/10.5281/zenodo.4013737]) [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.4013737.svg)](https://doi.org/10.5281/zenodo.4013737). \n\nTwo files aggregate evaluation metrics for the calibration and validation periods: `summary_calibration.npy` and `summary_validation.npy`, respectively. \n\nThe `figures` subfolder consists of figures that were generated using the `01_results_visualization.ipynb` Jupyter notebook.\n\n\n### Data availability\n\nInput data (discharge and meteorological forcing time series) for the selected set of basins is located in the `forcing` directory. \n\nWe used the following sources for the input data compilation:\n1. [National Water Information System (NWIS)](https://nwis.waterdata.usgs.gov/nwis) -- to retrieve discharge time series.\n2. [NLDAS reanalysis](https://disc.gsfc.nasa.gov/datasets/NLDAS_FORA0125_H_002/summary) -- to retrieve precipitation and air temperature data.\n"}
{"url": "https://github.com/hydrogo/LHMP", "owner": "hydrogo", "repository_name": "LHMP", "date_all_variable_collection": "2023-09-11", "description": "Lumped Hydrological Models Playgroud", "size": 28314, "stargazers_count": 19, "watchers_count": 19, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 11, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 11, "open_issues": 0, "watchers": 19, "default_branch": "master", "contributors": [{"contributor": "hydrogo", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 29760}, {"language": "Jupyter Notebook", "num_chars": 24298}], "readme": "# LHMP\nLumped Hydrological Models Playgroud\n\n## General aim\nTo provide opportunity for hydrologists and local communities to become closer to water-related problems, its assessment and solving for the large domain\nof Russian Arctic.\n\n## Spatial coverage\nNadym, Pur, and Taz river basins.\n\n## Installation\nYou can use LHMP easily on your local machine. Please, follow instructions:\n\n1. Install Docker on your machine - please, refer to the official Docker documentation ([https://docs.docker.com/engine/installation/](https://docs.docker.com/engine/installation/));\n2. There is a Docker image available to try out LHMP without concerns about the further installation process. To run interactive shell of LHMP (just the jupyter notebook), please copy-paste following code to your command prompt:\n```docker run -d -p 8888:8888 hydrogo/lhmp```\n3. Once started, point a web browser to \n\t* [http://localhost:8888](http://localhost:8888) (on Linux);\n\t* If using docker-machine (Win or Mac users), this will not be [http://localhost:8888](http://localhost:8888). The IP address will be given by tapping in your command prompt: ```docker-machine ip [name-of-your-docker-machine-vm]```. If you unsure about the name of your docker-machine VM, check the output of the command ```docker-machine ls```. Do not forget to add link to the port ```:8888``` in the end of your ip address (e.g. ```001.002.003.04:8888```). And do not forget about the great power of classical system reboot in solving installation problems on Win (smile).\n\n## Using as your own playground\nAfter the installation you should go to the folder called \"interfaces\", select the model you like to test and run appropriate jupyter notebook (.ipynb). There are few model playgrounds for:\n\n* HBV (```hbv.ipynb```);\n* GR4J-Cema-Neige (```gr4j_cema-neige.ipynb```);\n* SIMHYD-Cema-Neige (```simhyd_cema-neige.ipynb```).\n\nInside every jupiter notebook you can find additional information about model playgroung.\n\n## Using as framework for your own tasks\nInside LHMP repository you can find:\n\n* models source code (folder ```models```);\n* WFDEI forcing data for the Nadym, Pur, and Taz basins (folder ```data```);\n* auxiliary tools for data preparation and evaluation of commonly used efficiency metrics (folder ```tools```)\n\n## How to cite\nYou can use presented code and data without any restrictions, but do not forget to properly cite separate items. We recommend to follow citations below:\n\n* For HBV model:\n\t* Bergstr\u00f6m, S. (1992). The HBV model: Its structure and applications. Swedish Meteorological and Hydrological Institute.\n\t* Lindstr\u00f6m, G., Johansson, B., Persson, M., Gardelin, M., & Bergstr\u00f6m, S. (1997). Development and test of the distributed HBV-96 hydrological model. Journal of hydrology, 201(1), 272-288.\n\t* Beck, H. E., van Dijk, A. I., de Roo, A., Miralles, D. G., McVicar, T. R., Schellekens, J., & Bruijnzeel, L. A. (2016). Global\u2010scale regionalization of hydrologic model parameters. Water Resources Research.\n* For GR4J-Cema-Neige model:\n\t* Perrin, C., Michel, C., & Andr\u00e9assian, V. (2003). Improvement of a parsimonious model for streamflow simulation. Journal of Hydrology, 279(1), 275-289.\n\t* Val\u00e9ry, A. (2010). Mod\u00e9lisation pr\u00e9cipitations\u2013d\u00e9bit sous influence nivale. \u00c9laboration d\u2019un module neige et \u00e9valuation sur 380 bassins versants. Agro Paris Tech., Paris, France.\n* For SIMHYD-Cema-Neige model:\n\t* Chiew, F. H. S., Peel, M. C., Western, A. W., Singh, V. P., & Frevert, D. (2002). Application and testing of the simple rainfall-runoff model SIMHYD. Mathematical models of small watershed hydrology and applications, 335-367.\n\t* Val\u00e9ry, A. (2010). Mod\u00e9lisation pr\u00e9cipitations\u2013d\u00e9bit sous influence nivale. \u00c9laboration d\u2019un module neige et \u00e9valuation sur 380 bassins versants. Agro Paris Tech., Paris, France.\n* For LHMP framework and playgroound:\n\t* Ayzel, G. (2016). Lumped Hydrological Models Playground. [github.com/hydrogo/LHMP](github.com/hydrogo/LHMP), [hub.docker.com/r/hydrogo/lhmp/](hub.docker.com/r/hydrogo/lhmp/), doi: [10.5281/zenodo.59680](http://dx.doi.org/10.5281/zenodo.59680).\n\t* Ayzel Georgy. (2016). LHMP: lumped hydrological modelling playground. Zenodo. doi: [10.5281/zenodo.59501](http://dx.doi.org/10.5281/zenodo.59501).\n\n"}
{"url": "https://github.com/hydrogo/mel", "owner": "hydrogo", "repository_name": "mel", "date_all_variable_collection": "2023-09-11", "description": "Mass extinction (machine) learning", "size": 14426, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 1, "default_branch": "master", "contributors": [{"contributor": "hydrogo", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 2559363}], "readme": "# MEL\n## Mass extinction (machine) learning\n\nRun interactively using Binder: [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/hydrogo/mel/master)\n"}
{"url": "https://github.com/hydrogo/ML_in_hydrology_gs", "owner": "hydrogo", "repository_name": "ML_in_hydrology_gs", "date_all_variable_collection": "2023-09-11", "description": "Getting started with machine learning in hydrology", "size": 2047, "stargazers_count": 2, "watchers_count": 2, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 2, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 2, "open_issues": 0, "watchers": 2, "default_branch": "master", "contributors": [{"contributor": "hydrogo", "contributions": 11}], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# Getting started with machine learning in hydrology\n\nSome basic info about getting started with python and maching learning for hydrology-related issues.\n\nFollow me on twitter (@hydrogo) and Facebook (/ayzelgv).\n"}
{"url": "https://github.com/hydrogo/MORS", "owner": "hydrogo", "repository_name": "MORS", "date_all_variable_collection": "2023-09-11", "description": "modern hydrological modeling and forecasting system", "size": 29522, "stargazers_count": 5, "watchers_count": 5, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 7, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "GNU General Public License v3.0", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 7, "open_issues": 0, "watchers": 5, "default_branch": "master", "contributors": [{"contributor": "hydrogo", "contributions": 21}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 1999415}, {"language": "Python", "num_chars": 49538}], "readme": "![](mors_ico_small.png?raw=true)\n# MORS\nmodern hydrological modeling and forecasting system\n\n## General aim\nprovide simple interface to river runoff modeling and forecasting\n"}
{"url": "https://github.com/hydrogo/openforecast", "owner": "hydrogo", "repository_name": "openforecast", "date_all_variable_collection": "2023-09-11", "description": "OpenForecast: runoff forecasts for free", "size": 125143, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hydrogo", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# openforecast\nOpenForecast: runoff forecasts for free\n"}
{"url": "https://github.com/hydrogo/opennowcast", "owner": "hydrogo", "repository_name": "opennowcast", "date_all_variable_collection": "2023-09-11", "description": "OpenNowcast: the first end-to-end operational platform for precipitation nowcasting based on deep learning", "size": 114104, "stargazers_count": 4, "watchers_count": 4, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 1, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 1, "open_issues": 0, "watchers": 4, "default_branch": "master", "contributors": [{"contributor": "hydrogo", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# opennowcast\nOpenNowcast: the first end-to-end operational platform for precipitation nowcasting based on deep learning\n"}
{"url": "https://github.com/hydrogo/rainnet", "owner": "hydrogo", "repository_name": "rainnet", "date_all_variable_collection": "2023-09-11", "description": "RainNet: a convolutional neural network for radar-based precipitation nowcasting", "size": 874, "stargazers_count": 94, "watchers_count": 94, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 58, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 6, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 58, "open_issues": 6, "watchers": 94, "default_branch": "master", "contributors": [{"contributor": "PradyumnaGupta", "contributions": 5}, {"contributor": "hydrogo", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": true, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 4110}], "readme": "# RainNet: a convolutional neural network for radar-based precipitation nowcasting\n\n<img src=\"misc/RainNet_logo.png\" alt=\"RainNet logo\" width=\"10%\"/>\n\n## Brief description\n\nHere we introduce RainNet -- a convolutional neural network for radar-based precipitation nowcasting. RainNet was trained to predict continuous precipitation intensities at a lead time of five minutes, using several years of quality-controlled weather radar composites provided by the German Weather Service (DWD). \n\nThe source code of the RainNet model written using [_Keras_](https://keras.io) functional API is in the file `rainnet.py`.\n\nThe pretrained instance of `keras` `Model` for RainNet, as well as RainNet's pretrained weights are available on Zenodo: \n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3630429.svg)](https://doi.org/10.5281/zenodo.3630429)\n\n## Architecture\n\nThe RainNet's design was inspired by the [U-Net](https://arxiv.org/abs/1505.04597) and [SegNet](https://arxiv.org/abs/1511.00561) families of deep learning models which were originally designed for binary segmentation tasks. RainNet follows an encoder-decoder architecture in which the encoder progressively downscales the spatial resolution using pooling, followed by convolutional layers; and the decoder progressively upscales the learned patterns to a higher spatial resolution using upsampling, followed by convolutional layers. There are skip connections from the encoder to the decoder branches in order to ensure semantic connectivity between features on different layers.\n\nIn total, RainNet has 20 convolutional, four max pooling, four upsampling, two dropout layers, and four skip connections.\n\n<img src=\"misc/RainNet_architecture.png\" alt=\"RainNet architecture\" width=\"100%\"/>\n\nOne of the prerequisites for U-Net based architectures is that the spatial extent of input data has to be a multiple of 2<sup>n+1</sup>, where _n_ is the number of max pooling layers. As a consequence, the spatial extent on different resolutional levels becomes identical for the decoder and encoder branches. Correspondingly, the radar composite grids were transformed from the native spatial extent of 900x900 cells to the extent of 928x928 cells using mirror padding.\n\n[source: RainNet architecture](misc/RainNet_architecture.png)\n\n[source: RainNet architecture by PyDot](misc/RainNet_architecture_pydot.png)\n\n## Optimization procedure\n\nIn total, RainNet has almost 31.4 million parameters. We optimized these parameters using a procedure of which we show one iteration in [figure below](misc/RainNet_training_procedure.png).\n\n<img src=\"misc/RainNet_training_procedure.png\" alt=\"RainNet architecture\" width=\"100%\"/>\n\nFirst, we read a sample of input data that consists of radar scans at time _t-15_, _t-10_, _t-5_ minutes,  and _t_ (where _t_ is nowcast time), and a sample of the observed precipitation at time _t+5_. For both, input and observation, we increase the spatial extent to 928x928 using mirror padding, and transform precipitation depth _x_ (in mm) as follows :\n\n<img src=\"https://latex.codecogs.com/svg.latex?x_{transformed}&space;=&space;\\ln(x_{raw}&space;&plus;&space;0.01)\" title=\"x_{transformed} = \\ln(x_{raw} + 0.01)\" />\n\nSecond, RainNet makes a prediction based on the input data. Third, we calculate a loss function that represents the deviation between prediction and observation. We use the _logcosh_ loss function as follows:\n\n<img src=\"https://latex.codecogs.com/svg.latex?Loss&space;=&space;\\frac{\\sum_{i=1}^{n}\\ln(\\cosh(now_{i}&space;-&space;obs_{i}))}{n};&space;\\cosh(x)&space;=&space;\\frac{1}{2}(e^{x}&space;&plus;&space;e^{-x})\" title=\"Loss = \\frac{\\sum_{i=1}^{n}\\ln(\\cosh(now_{i} - obs_{i}))}{n}; \\cosh(x) = \\frac{1}{2}(e^{x} + e^{-x})\" />\n\nwhere _now_<sub>i</sub> and _obs_<sub>i</sub> are nowcast and observation at the _i_-th location, respectively; _cosh_ is the hyperbolic cosine function; _n_ is the number of cells in radar scans.\n\nFinally, we update RainNet's model parameters to minimize the loss function using backpropagation algorithm where the [Adam](https://arxiv.org/abs/1412.6980v8) optimizer is utilized to compute the gradients.\n\nWe optimized RainNet's parameters using 10 epochs with a mini batch of size 2. The optimization procedure has converged on the 8<sup>th</sup> epoch showing saturation of RainNet's performance on the validation data.\n\nThe pretrained weights of the RainNet model are available on Zenodo: [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3630429.svg)](https://doi.org/10.5281/zenodo.3630429).\n\nTo train RainNet from scratch, a [Colab](examples/RainNet_Training.ipynb) notebook has been provided by [Pradyumna Gupta](https://github.com/PradyumnaGupta) in the `examples/` folder.The notebook contains the essential description of the code and the links to the dataset.\n\n## Radar data\n\nWe use the sample of the [RY product]() of the German Weather Service (DWD) as input data for training and validating the RainNet model. The RY product represents a quality-controlled rainfall-depth composite of 17 operational DWD Doppler radars. It has a spatial extent of 900x900 km, covers the whole area of Germany, and is available since 2006. The spatial and temporal resolution of the RY product is 1x1 km and 5 minutes, respectively.\n\nThe sample data is available on Zenodo:\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3629951.svg)](https://doi.org/10.5281/zenodo.3629951)\n\n## Basic usage\n\n**Prerequisites**: \n* Python 3.6+, \n* Keras 2.2+, \n* h5py 2.8\n* pretrained RainNet model (file `rainnet.h5`) and its weights (file `rainnet_weights.h5`) has to be downloaded from the corresponding [Zenodo repository](https://doi.org/10.5281/zenodo.3630429): [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3630429.svg)](https://doi.org/10.5281/zenodo.3630429)\n\nThere are two scenarios of how to use the pretrained RainNet model.\n\nThe first scenario allows you to load the RainNet's model architecture alongside pretrained weights using built-in `keras` `load_model` function:\n\n```python3\nfrom keras.models import load_model\n\nmodel = load_model(\"rainnet.h5\")\n```\n\nThe second scenario allows you to build the RainNet model from scratch using `rainnet` function from the module `rainnet.py` and then load pretrained weights stored in the file `rainnet_weights.h5`:\n\n```python3\nfrom rainnet import rainnet\n\nmodel = rainnet()\n\nmodel.load_weights(\"rainnet_weights.h5\")\n```\n\nHaving the RainNet model in place, you can then use built-in `keras` [`Model class API`](https://keras.io/models/model/), e.g., for running the RainNet model or evaluating its skill.\n\nSome available options are:\n* `model.predict(X)` -- runs the model with specified input data _X_ to obtain the corresponding nowcast.\n* `model.evaluate(X, y)` -- returns the loss value for the model in test mode. Here X stands for input data, and y specifies ground truth data. \n* `model.summary()` -- creates a brief summary about model's layers and the number of parameters.\n* `model.get_layer(name, index)` -- retrieves a layer based on either its name or index.\n\n\nIn case you only want to train  RainNet from scratch (on RY or some different radar data archive), you can avoid loading the provided pretrained weights. \nThere is also an option to specify the input data shape using `input_shape` argument (just have in mind that the spatial extent of input data has to be a multiple of 2<sup>n+1</sup>, where _n_ is the number of max pooling layers (4 for the vanilla RainNet)). Then, use the code as follows:\n\n```python3\nfrom rainnet import rainnet\n\n# you can pass the specific input shape of (x,y,z),\n# where x and y provide the spatial extent, \n# and z specifies how many previous radar scans\n# you want to account for.  \nmodel = rainnet(input_shape=(x,y,z))\n```\n\nYou can find more examples of RainNet usage in the corresponding `examples` subfolder, which is provided as a part of this repository.\n\n## Reference\nYou can cite the RainNet model repository as follows: \n\n`Ayzel, G.: RainNet: a convolutional neural network for radar-based precipitation nowcasting. GitHub repository, https://github.com/hydrogo/rainnet, 2020.`\n\nBibTeX:\n```\n@misc{Ayzel2020RainNet,\n  author = {Ayzel, Georgy},\n  title = {RainNet: a convolutional neural network for radar-based precipitation nowcasting},\n  year = {2020},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/hydrogo/rainnet}}\n}\n```\n\n## Contacts\nFeel free to ask any questions about RainNet by [creating an issue](https://github.com/hydrogo/rainnet/issues).\n"}
{"url": "https://github.com/hydrogo/rainymotion", "owner": "hydrogo", "repository_name": "rainymotion", "date_all_variable_collection": "2023-09-11", "description": "Python library for radar-based precipitation nowcasting based on optical flow techniques", "size": 30831, "stargazers_count": 163, "watchers_count": 163, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 53, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 5, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 53, "open_issues": 5, "watchers": 163, "default_branch": "master", "contributors": [{"contributor": "hydrogo", "contributions": 28}, {"contributor": "ElmerJeanpierreLopez", "contributions": 5}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Python", "num_chars": 50088}], "readme": "# rainymotion\n\n<img src=\"https://raw.githubusercontent.com/hydrogo/rainymotion/master/docs/notebooks/images/rainymotion_logo.png\" alt=\"rainymotion logo\" width=\"100px\"/>\n\n\n`rainymotion`:\nPython library for radar-based precipitation nowcasting based on optical flow techniques\n\n## Idea\nThe main idea of the `rainymotion` library is to provide an open baseline solution for radar-based precipitation nowcasting.\n\n## Development\n`rainymotion` is based only on free and open source software -- we tried to make a clue between the best scientific libraries to make them work together for providing reliable precipitation nowcasts.\n\n<img src=\"https://raw.githubusercontent.com/hydrogo/rainymotion/master/docs/notebooks/images/rainymotionisbasedonfoss.png\" alt=\"rainymotion logo\" width=\"400px\">\n\n## Documentation\n\n`rainymotion` [documentation](http://rainymotion.readthedocs.io) is hosted by [Read the Docs](https://readthedocs.org/).\n\n## Example\n\nTo obtain precipitation nowcasts using the `rainymotion` models you need to follow the only three steps:\n\n1. initialize the model (you have 4 variants)\n2. load data to the model's placeholder\n3. run the model\n\n```python\n# import rainymotion model\nfrom rainymotion.models import Dense\n\n# initialize model instance\nmodel = Dense()\n\n# load the data using your custom DataLoader function\nmodel.input_data = DataLoader(\"/path/to/data\")\n\n# run the model\nnowcasts = model.run()\n```\n\n## Reference\n\nPlease cite `rainymotion` as _Ayzel, G., Heistermann, M., and Winterrath, T.: Optical flow models as an open benchmark for radar-based precipitation nowcasting (rainymotion v0.1), Geosci. Model Dev., 12, 1387-1402, https://doi.org/10.5194/gmd-12-1387-2019, 2019._\n"}
{"url": "https://github.com/hydrogo/RFR", "owner": "hydrogo", "repository_name": "RFR", "date_all_variable_collection": "2023-09-11", "description": null, "size": 11666, "stargazers_count": 0, "watchers_count": 0, "language": "HTML", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [], "howfairis": {"howfairis_repository": true, "howfairis_license": false, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "HTML", "num_chars": 60399973}]}
{"url": "https://github.com/hydrogo/RFR-codes", "owner": "hydrogo", "repository_name": "RFR-codes", "date_all_variable_collection": "2023-09-11", "description": "The collection of python scripts and Jupyter Notebooks for the compilation of the Runoff for Russia (RFR v1.0) dataset.", "size": 15, "stargazers_count": 1, "watchers_count": 1, "language": "Jupyter Notebook", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "Creative Commons Zero v1.0 Universal", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 1, "default_branch": "main", "contributors": [{"contributor": "hydrogo", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [{"language": "Jupyter Notebook", "num_chars": 33217}, {"language": "Python", "num_chars": 12991}]}
{"url": "https://github.com/hydrogo/WAT", "owner": "hydrogo", "repository_name": "WAT", "date_all_variable_collection": "2023-09-11", "description": "What about water", "size": 1077, "stargazers_count": 0, "watchers_count": 0, "language": null, "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": true, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "hydrogo", "contributions": 2}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": [], "languages": [], "readme": "# WAT\nWhat about water\n"}
{"url": "https://github.com/iliakur/c-u-later-elevator", "owner": "iliakur", "repository_name": "c-u-later-elevator", "date_all_variable_collection": "2023-09-11", "description": null, "size": 414, "stargazers_count": 0, "watchers_count": 0, "language": "TeX", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 0, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 0, "license": "MIT License", "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "visibility": "public", "forks": 0, "open_issues": 0, "watchers": 0, "default_branch": "master", "contributors": [{"contributor": "iliakur", "contributions": 46}, {"contributor": "copper-head", "contributions": 1}], "howfairis": {"howfairis_repository": true, "howfairis_license": true, "howfairis_registry": false, "howfairis_citation": false, "howfairis_checklist": false}, "topics": ["answer-set-programming"], "languages": [{"language": "TeX", "num_chars": 908327}, {"language": "Python", "num_chars": 12642}, {"language": "Prolog", "num_chars": 11941}, {"language": "Shell", "num_chars": 766}], "readme": "\n# About\nThis is our submission for the final project of the course \"Answerset Solving in Practice\".\nIn the `INSTRUCTIONS` file you can find the task description.\n\nThe system is intended to be run with the following command:\n\n```sh\nclingo <instance.lp> elevator.lp\n```\n\n# Tests\nTo run them:\n```\n./run_tests.sh test-instance.lp\n```\n"}
